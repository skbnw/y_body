headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
地震発生後に大量の生成AI動画、「ディープフェイク」は一般化　透かしや細部の確認など見分け方のコツも解説【ファクトチェック】（日本ファクトチェックセンター）,https://news.yahoo.co.jp/articles/1b2d119e3b91c0ea631800619287c6e4a8758415,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20251212-00010000-jfactc-000-1-view.jpg?exp=10800,2025-12-12T10:58:59+09:00,2025-12-12T10:58:59+09:00,日本ファクトチェックセンター,jfactc,日本ファクトチェックセンター,2046,"地震発生後に大量の生成AI動画、「ディープフェイク」は一般化
2025年12月8日に青森県八戸市で震度6強を観測した地震で、生成AIで作った「ディープフェイク」動画がTikTokなどで多数拡散しました。災害など注目を集める話題には、ディープフェイクが拡散することが一般的になっています。AI生成特有の透かしや関連情報の確認が必要です。
地震直後から拡散した大量の「ディープフェイク」
拡散した投稿
生成AIで作られた画像や動画を「ディープフェイク」と言う。12月8日に青森県東方沖で地震が発生すると、その直後からTikTokなどSNSで被害を訴える動画や、ニュース速報のように見せた動画が多数投稿された(例1、例2、例3)。

動画では、津波の高さが最大3mだと伝えるものや、建物が崩落したり、地面がひび割れたりする映像が映っている。投稿したアカウントには、国内からのものだけでなく、海外からのものもある。

これらの投稿に関して「ああ、なんてことだ」「深刻だ」など事実と受け取っているコメントも付いている。

例1　https://archive.md/Iz8SH
例2　https://archive.md/tWqab
例3　https://archive.md/JXFIw
#selection
-1142.0-1146.0
AIで作ったことを示す「透かし」
TikTokで拡散した動画の例1、例2には透かし文字(下図の赤丸)がある
これらの動画の一部には「Sora」という透かし文字が画面上に表示されている。

Soraは、OpenAIが開発した動画生成AIだ。テキストで生成したい動画を打ち込んだり、画像をアップロードしたりすることで、簡単に動画を生成できるAIで生成した動画には、Soraという透かし文字が表示される(OpenAI.”Sora”)。

TikTokで拡散した動画の例1、例2には透かし文字(下図の赤丸)がある
生成AIであることを示すラベルも
TikTokでは、AIで生成したり、編集したりした動画に関して、動画作成者自身がラベルをつけることができる。その場合、画面の左下に「クリエイターがAI生成のラベルを付けました」という文言が示される。

また、作成者がラベルを付けていない場合でも、TikTokがAI生成によるコンテンツと判断すれば、「AI生成メディアを含む」というラベルが自動的に付加される(TikTok.”AI生成コンテンツにラベルを付けることをTikTokがクリエイターに求めているのはなぜですか？”)。

拡散した動画の例2、例3には、「AI生成メディアを含む」(上図、黄色下線)というラベルが付けられている。
生成AIコンテンツの見分け方
2025年は全国でクマによる被害が過去最多になっており、大きな話題となるとともに、AI生成による熊被害のディープフェイクも拡散した（JFC”TikTokで拡散するAI生成によるクマ被害の偽動画に注意【ファクトチェック】”）。

OpenAIやGoogleが精度の高い画像や動画を簡単に生成するAIを次々と発表したことで、日本でもディープフェイクが急激に広がっている。

見分け方として、透かしやラベル以外にも、細部を確認する手法がある。例えば、以下のような点だ。

・人間の手や指や髪や歯などの描写が破綻している。
・背景の看板に書かれている文字が崩れている。
・連続した動画なのに、一部で画像がカクカクする。
・突然、ものが現れたり消えたりする。
・顔などの輪郭の境界線がぼやけている。
・背景の構造物と影が一致していない。
・直線であるべき構造物が歪んでいる。

ただし、これらの細部をスマートフォンの小さな画面で見抜くことは難しい。そのため、まずは画像や動画や音声があったとしても、それが本物とは限らず、AIで作られた可能性があることを頭に入れる必要がある。

そのうえで、発信源・根拠・関連情報を確認することが重要だ。
出典・参考
NHK.”【地震】青森 岩手 北海道 50人けが 各地の被害状況は”.https://news.web.nhk/newsweb/na/na-k10014998551000 ,(閲覧日2025年12月11日)

OpenAI.”Sora”.https://openai.com/ja-JP/sora/ ,(閲覧日2025年12月11日)

TikTok.”AI生成コンテンツにラベルを付けることをTikTokがクリエイターに求めているのはなぜですか？”.https://www.tiktok.com/tns-inapp/pages/ai-generated-content?enter_from=web_fyp&hide_nav_bar=1⟨=ja-JP ,(閲覧日2025年12月11日)

検証：木山竣策
編集：古田大輔
木山竣策(Shunsaku Kiyama)",[],[]
