headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
職場でAI活用が広がらない背景にある、見えない不公平（DIAMOND ハーバード・ビジネス・レビュー）,https://news.yahoo.co.jp/articles/890ca23a8d3ef26873eda1600f7b67c684f8657b,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20251212-00012587-dhbrn-000-1-view.jpg?exp=10800,2025-12-12T12:00:40+09:00,2025-12-12T12:00:40+09:00,DIAMOND ハーバード・ビジネス・レビュー,dhbrn,DIAMOND ハーバード・ビジネス・レビュー,6416,"Illustration by Sandra Navarro
なぜ従業員のAI利用率が上がらないのか　ある大手テクノロジー企業のエンジニアリング担当バイスプレジデントは、四半期の導入率の指標を見つめながら不満を募らせていた。

　最新鋭のAIコーディングアシスタント──開発者の生産性の大幅な向上を約束するツール──の導入から12カ月後、それを試したエンジニアは41％に留まっていた。さらに憂慮すべきことに、女性エンジニアによる導入率はわずか31％、40歳以上のエンジニアでは39％だった。これは、同社のソフトウェアエンジニア2万8698人を対象とした筆者らの調査で判明した結果である。

　経営陣は驚いた。彼らは大金を費やし、熟考を重ね、最先端のツールに投資した。アクセス、インフラ、スキル開発に手厚く対応し、配備と普及を担う専任チームも編成した。準備を整えた彼らは、生産性が跳ね上がることを期待していたのである。

　この会社だけが例外ではない。米国のビジネス界全体でこのパターンは繰り返されている。ピュー・リサーチセンターの調査によれば、チャットGPTの登場から2年後の時点で、米国労働者の91％が仕事でAIを利用することを許可されているにもかかわらず、利用率はわずか16％に留まっている。一般的な説明では、スキル不足や研修への抵抗が指摘されている。AIがどこで役立つのかを認識していない、あるいは自分の技能に自信がないという従業員もいるかもしれない。

　実際、ソフトウェアエンジニアやデータサイエンティストといった最前線の技術者は、AIを活用する傾向が他業界の労働者よりも高い。しかし、これらのアーリーアダプターの間でさえ、AIの利用率は依然として驚くほど低く、ばらつきがあるのだ。なぜだろうか。

■能力評価ペナルティ

　筆者らはその理由を理解するために、同じ会社のエンジニア1026人を対象に事前登録済みの実験を実施した。実験の設計はシンプルだ。参加者は、別のエンジニアによって書かれたとされる短いPythonコードを評価するのだが、そこには、AIの支援を受けて書かれたか否かを示す説明が添えられていた。コード自体はすべての条件で同一であり、異なっているのは作成方法に関する説明だけであった。

　結果は衝撃的であった。レビュアーはまったく同じコードをレビューしているにもかかわらず、エンジニアがAIを使ったと信じた場合、そのエンジニアの能力を平均で9％低く評価した。これはコードの品質の問題ではない。コード自体への評価はAI利用の有無にかかわらず同程度であった。このペナルティコードは、コード作成者の能力に対する認識として生じたのである。

　能力に対するペナルティは女性エンジニアに対してのほうが2倍以上厳しく、男性エンジニアでは6％の評価減にとどまったのに対し、女性では13％減であった。レビュアーは、女性がAIを使ってコードを書いたと見なした場合、AIの支援を受けた男性の同じコードを評価する時に比べ、その女性の基本的能力をはるかに強く疑問視した。

　最も示唆に富むのは、誰がこのペナルティを科したかである。みずからはAIを導入していないエンジニアが、最も厳しい批判者であったのだ。特に男性の非導入者は、AIを使った女性エンジニアに対して、同じ条件でAIを利用した男性エンジニアを評価する場合よりも26％も厳しくペナルティを科した。

　919人のエンジニアを対象とした追跡調査によって、全体像がより明確に見えてきた。多くのエンジニアはこの能力へのペナルティを能動的に予期し、仕事上の評判を守るためにAIの利用を戦略的に避けていたのだ。テック業界で能力へのペナルティを最も恐れていたのは、特に女性と年長のエンジニアであり、まさにその人々がAIの導入率も最も低かった。生産性を高めるツールの恩恵を最も受けられるはずのグループが、それを使う余裕がないと感じていたのである。

■能力評価ペナルティの代償

　これらの調査結果は、AIの導入に伴う隠れた代償を浮き彫りにしている。新しいツールを使うことへの単なる躊躇のように見える姿勢は、実は理性的な自己防衛の表れなのだ。真の代償は、生産性の損失を──それ自体も大きなマイナスではあるが──はるかに超えて広がる。

　本調査に登場したテクノロジー企業を考えてみよう。同社はAIコーディングアシスタントの開発と配備に巨額の投資を行った。しかし導入率はわずか41％で──肝心の従業員層（女性および年長者）ではさらに低く──期待した効果の半分も得られなかった。その結果、年間利益の少なくとも2.5％、算出方法によっては最大14％の純損失となった（給与価値の損失と導入による予測利益の比較に基づく）。この規模の企業にとっては、控えめな推計であっても数億ドル規模の価値損失を意味する。

　能力評価ペナルティがもたらすもう一つの結果は、「シャドウAI」が使われる可能性である。従業員は正規のAIツールの利用を恐れても、AIを完全に避けるとは限らない。代わりに、一部の従業員は許可されていない他のAIツールを、雇用主の想定以上に利用するかもしれない。これらの行為は、追跡が不可能ではないにしても難しく、データセキュリティからコンプライアンスに至るまで多くのリスクに組織をさらすことになる。一貫性を欠く慣行によって、責任あるAIの使用が損なわれかねない。

　また、能力評価ペナルティは職場における既存の不平等を悪化させる。AIツールが全員の能力を強化し、公平な機会をもたらすはずだ、という想定は理にかなっており、魅力的に思えるかもしれない。しかし筆者らの調査結果によれば、それが保証されているわけではなく、むしろ反対のことが起きる可能性がある。若い男性が多数派を占める本調査の環境では、AIを平等に利用可能にしたことで、女性エンジニアに対する偏見が強まっていた。

　この現象は、「社会的アイデンティティへの脅威」と呼ばれるプロセスを通じて生じることが多い。偏見を持たれるグループ──たとえばテック業界の女性や、若年層が多数派を占める分野の年長労働者など──がAIを利用すると、彼ら彼女らの能力に対する既存の疑念が助長される。AIの支援を受けることは、ツールを戦略的に活用している証しではなく、「能力不足の証拠」として受け取られてしまうのである。どの業界であれ、一つの層が他の層より多数派を占めている場合、少数派の従業員に対する能力評価ペナルティがより厳しくなる可能性が高い。

　AI利用者に対するペナルティは、職場の情報開示方針についても厄介な問題を提起する。透明性は責任あるAIの使用における中核的要素だが、職場内の力学に関して言えば、メリットよりも弊害のほうが大きいかもしれない。筆者らの調査結果によれば、AIの利用を同僚に開示するよう従業員に義務づけることは、仕事上の不公平なリスクを生みかねない。

　したがって、適切なバランスを取ることが重要だ。能力へのペナルティが生じやすい環境では、開示を義務づけないほうがより責任ある方針かもしれない。

■ペナルティを解消する

　本調査に登場したテック企業は、大半の企業よりも多くの取り組みをすでに実行していた。専任のAIチームを編成し、インセンティブを設け、研修を提供した。だが、根底にある能力評価ペナルティの脅威に対処しなかったため、これらの投資は実を結ばなかった。筆者らの調査結果は、より洗練されたアプローチの必要性を示唆している。

■1. 組織内でペナルティが生じやすい場所を特定する

　能力評価ペナルティは厄介な力学を生じさせる。生産性を高めるツールの恩恵を最も受けるはずの人々が、まさにそれらを使うリスクを冒せないと感じてしまうのだ。筆者らの調査では、テック業界の若い女性は最も多くの生産的時間を得られる立場にありながら、導入率は最も低かった。この乖離への対処は、AI投資の最大化を図る組織がすぐにでも取り組める課題である。

　能力へのペナルティが最も深刻なチームを特定するには、人口統計学的に弱い立場と、権力の不均衡に目を向ければよい。下級職に女性や年長のエンジニアが少なく、上級職にAI非導入の男性レビュアーが多いチームは、能力評価ペナルティが生じる完璧な条件を備えている。

「昇進までの期間」の指標を人口統計学的属性とAIの利用状況に照らして検証し、ペナルティの影響がすでにキャリアに響いていないかを明らかにして、問題の緊急度を測定しよう。また、弱い立場のグループが強制的または任意でのAI開示方針に直面していないかを確認し、開示がキャリア成果に及ぼす影響を判断しよう。

■2. 影響力のある懐疑派を転向させる

　非導入者は最も厳しく能力へのペナルティを科す。そして大半の組織において、彼らはいまだに多数派を占める。本調査ではAIを導入していないエンジニアは、AIを使う同僚を特に厳しく評価し、男性の非導入者は女性エンジニアを最も厳しく減点した。

　この悪循環を断ち切るには、社会的影響力を戦略的に利用する必要がある。従業員は、尊敬されている同僚が仕事への影響を被らずにうまくAIを活用している姿を見れば、リスクはより低いと認識するようになる。最も効果的なアプローチは、AIの活用とプロフェッショナルとしての卓越性は両立できることを実証する、目に見えるロールモデルを活用することだ。

　最も強力な推進者は、最も厳しいペナルティに直面している層と同じ属性を持つ人である。筆者らの調査では、上級職の女性は下級職の女性に比べ、能力評価ペナルティに対する恐れが少ないことが判明している。これらのリーダーが公然とAIを活用すれば、同じ弱い立場にいる同僚たちへの大きな援護となる。

　BCGの調査もこの力学を如実に示している。女性の上級マネジャーによるAIの導入率が同等職の男性を上回ると、下級職における女性と男性の導入格差は大幅に縮小する。

　個人が模範を示すことは動機付けとなるが、体系的なプログラムは勢いを生む。ウェアラブル機器メーカーのフープで製品責任者を務めるヒラリー・グリッドリーが立ち上げた、「30日間GPT」チャレンジを考えてみよう。このプログラムは会議の議題作成のような単純なタスクから、カスタムGPTによる複雑なワークフローへと発展していった。毎日実際に動作させて成果を公開して称賛する取り組みにより、心理的安全性が生まれた。チームメンバーは、あらゆるスキルレベルの同僚たちがAIで成果を上げる様子を目にした。懐疑派も、上級リーダーだけでなく尊敬する同僚が実際の仕事でAIをうまく活用している姿を見れば、抵抗感を弱めるのだ。

　ピンタレストが行う毎年恒例の「メイカソン」も、このアプローチを組織全体に広げる方法を示している。この全社的なハッカソンは、技術職か否かを問わず全従業員に開かれている。参加チームはAIを活用したアイデアをプレゼンし、プロトタイプをつくり、プロジェクトを披露した。社内のリーダーたちは「ハックドクター」やチームリーダーを務め、自身の信頼性をAIの実験に役立てた。その結果を見れば成果は明らかだ。参加者の96％が毎月AIの利用を継続し、エンジニアの78％はAIのおかげで時間が節約されたと評価した。

■3. AI利用の表示を取り除くために、評価方法を再設計する

　エンジニアは自分の作成したコードに「AIを利用」とタグを付ける義務がある場合、偏った評価を受けやすくなる。組織文化が変わらない限り、このタグは先入観を伴う。解決法は単純だ。組織文化が整うまで、業績評価におけるAI利用の表示をやめればよい。

　筆者らの実験では、能力にペナルティが科されても、AIの支援を受けた成果物に品質の差はなかった。この乖離は、今後進むべき道を浮き彫りにしている。仕事がどのように遂行されたのかではなく、何が達成されたのかを評価するのだ。主観的な能力評価を、サイクルタイム、正確さ、欠陥率といった客観的な指標に置き換えよう。

　コンプライアンスのためのログが整備され次第、組織は「AIを利用」のタグの表示を段階的に廃止し、内部監査用にのみ保持すべきだ。個人情報を隠したブラインド評価によって、すでに厳しい視線にさらされている少数派の人々への偏見を減らすことができる。評価者は誰がコードを書いたのか、あるいはAIが関与したかどうかを見ることができなければ、成果のみに基づいて判断する可能性が高い。

　一部の先進的企業は中立に留まらず、AIの活用に対して積極的に見返りを提供し、能力評価ペナルティを「能力評価ボーナス」に変えている。マイクロソフトで開発者向けツール部門のプレジデントを務めるジュリア・リウソンは最近、「個人の業績とインパクトの総合的評価における一要素」として、AIの活用を含めるようマネジャーたちに指示した。一部のチームは来年の業績評価で、AI活用度を正式な指標として取り入れることを検討している。

　ショッピファイのトビアス・リュトケCEOは「AIの反射的な活用」を基本要件として定め、AIの活用状況に関する質問を業績評価と同僚の評価に加える計画を発表した。彼はAIへの習熟を、フィードバックと能力開発が必要な「当たり前ではないスキル」と捉え、AIを使いこなす従業員を非習熟者よりも価値が高いと位置づけている。

■進むべき道

　能力へのペナルティは、AI導入への組織の取り組み方に根本的なずれがあることを示唆している。企業はアクセス、研修、技術インフラに焦点を当てるものの、従業員が実際にそれらのツールを使うかどうかを左右する、社会的力学を見落しているのだ。

　この洞察は、AIトランスフォーメーションを蝕むいくつかの不可解な傾向を解明する役に立つ。なぜ従業員は許可されているツールを無視しながら、隠れてチャットGPTを使うのか。AIによる強化の恩恵を最も得られるグループの導入率が、最も低いのはなぜか。企業はAIに巨額の投資をしているにもかかわらず、その投資利益率はなぜ限られているのか。

　ペナルティによる被害を最も強く被るのは、すでに能力に疑問を持たれている人々だ。AIを使う女性が直面する評判の低下は、男性の約2倍であることを本調査は示している。若年層が多数派を占める分野における年長の労働者も、同様の偏見に遭う。皮肉にも、AIによる平等化の効果を最も必要とする人々が、AIを使う余裕が最もないのだ。

　しかしペナルティは不可避ではなく、組織は3つの的を絞った介入を通じて解消することができる。ペナルティが集中する場所を特定し、尊敬されているリーダーを目に見えるAI推進者として動員し、手段よりも結果に報いるよう評価方法を再設計することだ。

　結局のところ、AIトランスフォーメーションで先頭を行く組織は、必ずしも最良のツールや最大の予算を持っているわけではない。すべての従業員がAIを安全に活用できる環境をつくる組織こそが、変革の先駆者となる。それが実現しない限り、企業はライセンスを無駄にしている。そして何より、AIを活用する準備ができている人材の潜在能力を無駄にしているのだ。


""Research: The Hidden Penalty of Using AI at Work,"" HBR.org, August 01, 2025.
オウズ A. アジャル,フィリス・ジア・ガイ,ヤンピン・トゥ,ジアイー・ホウ",[],[]
