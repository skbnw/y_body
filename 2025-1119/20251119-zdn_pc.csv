headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
Core Ultraプロセッサ（シリーズ3）の「Xe3 GPU」の改良点をさらに深掘り　今後の取り組みもチェック！（ITmedia PC USER）,https://news.yahoo.co.jp/articles/2b2f13de7b116400eac598fcee337323d9dbca01,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20251119-00000066-zdn_pc-000-1-view.jpg?exp=10800,2025-11-19T17:05:09+09:00,2025-11-19T17:05:09+09:00,ITmedia PC USER,zdn_pc,ITmedia PC USER,13012,"GPUコアに関するセッションの説明を担当した、Intelのトーマス・ピーターセン氏（アーキテクチャ／グラフィックス／ソフトウェア担当フェロー）。NVIDIAでGPUのテクニカルマーケティングを担当していた経歴を持つ（写真提供：Intel）
Intelが2025年末に一部をリリースする予定の「Core Ultraプロセッサ（シリーズ3）」（開発コード名：Panther Lake）には「Xe3 GPU」と呼ばれる新型GPUコア（GPUタイル）が搭載される。前回はこのGPUの概要と、大まかなパフォーマンスを紹介した。
【画像】GPU全体のパフォーマンスの比較
後編となる本記事では、Xe3 GPUの演算器について“深掘り”すると共に、同GPUの付帯機能について紹介していく。
Xe3 GPUのXVEを深掘り
続いて、Xe3 GPUのシェーダープロセッサたる「Xe Vector Engine（XVE）」について深掘りしてみよう。

　Xe3 GPUのXeコアは「第3世代」を称しているが、前編でも触れた通り基本設計はIntel Arc BシリーズやCore Ultra 200Vプロセッサ用内蔵GPUとして採用された「Xe2 GPU（開発コード名：Battlemage）」を色濃く受け継いでいる。というか、ほぼBattlemageのままだ。

　下図で示した通り、Xeコア1基当たりの演算器は128基構成のままとなっている。

L1キャッシュ／SLMの容量は33％増し

　Xe3 GPUのSIMD16演算ユニットにおける単位演算器は、初代「Xeアーキテクチャ」から変わらず32bit浮動小数点演算器のままとなっている。1基のXVEは、512bitのベクトル演算器（32bit×16レーンSIMD）ということになる。

　ここで気になるのは、上図の「+33% L1$/SLM」という記述。これはどういう意味なのだろうか。

　「L1$」はL1キャッシュを意味する（Intelはキャッシュを「$」と表記することが多い）。「SLM」は「Shared Local Memory（共有ローカルメモリ）」だ。SLMは、同一のXeコア内にあるXVEがリニアなアドレス空間を通してアクセスできる汎用（はんよう）的なSRAM領域だ。

　L1キャッシュ／SLMの容量は「Xe2アーキテクチャ」では192KBだったものが、今回は「+33％」増量されて256KBとなった。ということで、図中の「+33％」は容量の増加を意味する。

　実際の動作では、Xeコア単位で稼働する「カーネル実行」の際に、カーネルが指定した割合でL1キャッシュとSLMの容量が定義される。Intelによると、SLMにより多くの容量を割り当てることが多いとのことだ。

　L1キャッシュの増量は、プログラム実行速度の向上に直結する。一方でSLMの増量については、「Compute Shader（コンピュートシェーダー）」などで“明示的に”活用しない限りパフォーマンス向上には結び付かない。「Mesh Shader（メッシュシェーダー）」の動作の仕組みはCompute Shaderに近いので、SLMの増量がパフォーマンス向上に結びつくかもしれない（ゲーム側のシェーダーコードがSLMサイズの可変に対応している場合に限られるが）。

　なお、L1キャッシュ／SLMの256KBという容量には「L1命令キャッシュ（L1I$）」は含まれていない。今回、L1I$の増量については言及がなかったので、Xe2アーキテクチャと同じ96KBだと思われる。

基本設計は変わらずも、処理できるスレッド数は増加

　Xe3 GPUにおけるXVEのブロックダイアグラムを見てみると、図中に「SIMD16 Native ALUs」「3way Co-issue」「Extended math＆FP64」「Xe Matrix Extensions」という記載が見られるが、これらは全てXe2アーキテクチャの仕様を受け継いでおり、大枠として変化はない。

　ダイアグラムを見れば分かる通り、3way Co-issue（3ウェイ同時発行）は「浮動小数点演算（FP64含む）」「整数演算および超越関数演算（INT／Extended Math）」「XMX」の3種類の命令を同時発行することを意味する。

　そして上図左側の「Up to 25％ more Threads」「Variable Register Allocation」「FP8 Dequantization Support」の3点は、Xe3 GPUにおける拡張ポイントになる。

　Up to 25％ more Threadsは、XVEにおいて実行できるスレッド数が25％増えたことを意味する。具体的には、従来は1基当たり最大8スレッドだったものが10スレッドとなった。このことは、Variable Register Allocation（可変レジスター配置）と深く関係しているので詳細は後述する。

　Xe／Xe2アーキテクチャ、そしてXe3 GPUでも、1基のXVEが持つ「汎用レジスタファイル（GRF）」は「512bit（64バイト）×1024本」あるので合計64KBとなっている。この点は各世代で変わりない。一方でXe／Xe2アーキテクチャでは、GRFを128本を割り当てて実行する「小規模スレッド」と、同じく256本を割り当てて実行する「大規模スレッド」の2種類しかない。となると、実行できる最大数は以下の通りとなる。

・小規模スレッド：1024本÷128本＝8スレッド
・大規模スレッド：1024本÷256本＝4スレッド

　小規模スレッドと大規模スレッドを混在実行する場合、XVE1基当たりの実行スレッド数は4～8ということになる。

　一方で、IntelによるとXe3 GPUではGRFの数を32本の粒度で可変割り当てできるように改善したという。これが「Variable Register Allocation」だ。ハードウェア上、Xe3 GPUではXVE1基当たり最大10スレッドまで実行できるとのことなので、GRFを「32本／32スレッド（1024本÷32本=32スレッド）」あるいは「64本／16スレッド（1024本÷64本=16スレッド）」で割り当てるモードはないと思われる。

　ただし、IntelはGRFを「96本／10スレッド（1024本÷96本≒10スレッド）」で割り当てるモードが存在することは明言しており、これが「Up to 25％ more Threads」の言わんとするところだ。一応、計算式は以下の通りとなる。

1024本÷96本＝10スレッド（従来の小規模スレッドの25％増し）

　Intelは明言していないものの、計算上は「160本モード（6スレッド）」「192本モード（5スレッド）」「224本モード（4スレッド）」も存在する可能性がある。

FP8演算の変換機能をサポート

　最後の「FP8 Dequantization Support」は、メモリに格納されている8bit浮動小数点（FP8）形式の数値を上位の高精度演算形式に変換（Dequantization）するというものだ。具体的には、FP8を「BF16」「FP16」「FP32」といった16bitや32bitの浮動小数点形式に変換可能だ。

　また、Xe3 GPUではFP8演算において符号1bit／指数部4bit／仮数部3bitからなる「E4M3」形式（別名「HF8（Hybrid Float8）」形式）に初対応した。表現範囲は約±448なので、推論演算により向いているとされる。

　なお、FP8のもう1つの演算形式で、符号1bit／指数部5bit／仮数部2bitからなる「E5M2」形式（別名「BF8（Brain-Float8）」形式）については、Xe2アーキテクチャの段階で対応済みとなっている。こちらの表現範囲は±57344程度で、学習用途に適している。
Xe3のXMXはどう変わった？
推論アクセラレータである「Xe Matrix Extensions（XMX）」については、ピーク性能が向上したという情報はない。下図を見ても分かる通り、性能値自体はXe2アーキテクチャにおけるXMXのスペックと変わらない。

　ただし、XVEの節で解説したように、GRFの割り当て粒度の向上に伴って、同時実行スレッド数が25％向上しているので、性能自体は改善している。

　XVEの段でも言及したが、BF8／HF8への対応はXMXでも行われている。しかし、FP8の演算速度（クロック当たりの演算実行回数）については、XMXだけでなくXVEでも意図的に隠している雰囲気がある。筆者としては「FP8の演算速度はFP16／BF16と変わらない」と確信している。

　Xe3 GPUではFP8 Dequantization Supportを通してFP8形式も取り扱えるようになっただけで、演算自体はFP16／BF16用の演算器で行われる――こういうことだろう。
レイトレーシングユニットの改良ポイントは？
Xe3 GPUのレイトレーシングユニットは「Xeコアあたり1基」という搭載バランスに変わりはない。

　しかし、前回取り上げた通り、12コア版のXe3 GPUはレンダースライス1基当たりのXeコアが4基から6基に変わったため（GPU全体では最大6基→12基）、理屈の上ではレイトレーシングの処理パフォーマンスはXeアーキテクチャ比で1.5倍向上している。

　上にXe3 GPUの説明図を掲載したが、ここで注目すべきは「Dynamic Ray Management for async ray tracing」という説明だ。日本語にすれば「非同期レイトレーシング向けの動的レイ管理」ということになるのだが、「非同期レイトレーシング」とは一体何なのだろうか？

　簡単に説明すると、非同期レイトレーシングはGPU内の各処理ステージ間で同期を取らず、独立性を持ってレイトレーシング（レイトレ）を実践していく処理系のことだ。

　レイトレのパイプライン（処理フロー）をざっくり書くと、「レイの発行→BVH（Bounding Volume Hierarchy）の探索→ポリゴンとの衝突判定→プログラマブルピクセルシェーダーの実行」という手順で進む。Dynamic Ray Management（動的レイ管理）は、このフローの下流のどこかで“詰まり”が出た場合にレイの新規発行を抑える仕組みだ。

　レイの新規発行のペースを落とすと、BVHキャッシュやL2キャッシュの利用ペースも落ちる。そのため、レイ発行より先のプロセスのパフォーマンス向上（もっというと処理の“くそ詰まり”の改善）を期待できる。
GPUの「固定機能」にもメスを入れて性能向上
近代的なGPUは、かなりの部分がプログラマブルになっている。しかし、30年前からほとんど形を変えていない「固定機能（Fixed Function）」も存在する。

　Xe3 GPUでは、この固定機能ブロックにも改良が加えられている。Intelは改良点を「New URB Manager」「Up to 2X Anisotropic Filtering」「Up to 2x Stencil Test rate」の3つに大別しているので、それぞれ解説してみよう。

New URB Manager

　New URB Managerは、その名の通り「新しいURBマネージャー」を意味する……のだが、これが何なのかを知るには「URB」とは何なのかを知る必要がある。

　URBはIntel固有の用語で「Unified Return Buffer」の略となる。これは一種の中継バッファーで、GPU内にある各プログラマブルシェーダー（頂点シェーダー／ハルシェーダー／ドメインシェーダー／ジオメトリシェーダー／ピクセルシェーダー）と、各種固定機能の入出力の受け渡しに使われる。

　過去のIntelの内蔵GPUでは、L3キャッシュの一部をURBに流用していたが、Xeアーキテクチャ以降のGPUではURBに専用バッファを確保している。専用バッファの位置はダイアグラムに記載されていない。しかし、URBはXeコア同士で共有できなければ意味がないので、常識的に考えるとレンダースライスごとに存在すると考えるのが自然だ。

　いずれにせよ、URBは無尽蔵“ではない”SRAM領域だ。そのため、シェーダーステージが進行するタイミングで「URB Manager」がリクエストに応じて必要な分を割り当てる。Xe3 GPUでは、URB ManagerによるURBの割り当てや更新の粒度を最適化したのだという。

　先述したGRFの粒度変更と近い改善が行われたと見て良いだろう。

Up to 2X Anisotropic Filtering

　Up to 2X Anisotropic Filteringは、「異方性テクスチャーフィルタリング（Anisotropic Filtering）」の処理パフォーマンスを最大2倍に改善したことを意味する。

　異方性テクスチャーフィルタリングは、視線から見たポリゴンの傾き具合にも配慮したテクスチャーフィルター処理を指す。その特性上、テクスチャーへのサンプル数は増え、テクスチャーアドレス計算の負荷がどうしても高くなる。

　「最大2倍に改善した」方法について、Intelは特に言及していない。しかし、明確に機能単位のパフォーマンス向上をアピールしているので、単純に「レンダースライスの2本化」あるいは「Xeコアの増加による副次的恩恵」ではなさそうだ。常識的に考えると、「キャッシュの増量」だけで最大2倍の改善効果を得るのも難しい。

　総合的に考えると、「テクスチャーサンプラーの拡充」や「テクスチャーアドレス計算の並列化」などが行われたと見るのが自然だ。

Up to 2x Stencil Test rate

　Up to 2x Stencil Test rateも、「ステンシルテスト（Stencil Test）」のパフォーマンスが最大2倍という意味だ。

　ステンシルテストは、「ステンシルバッファ（型抜きバッファ）」に描かれた内容（マスクパターン）で描画内容をマスク抜きなどする処理系となる。例えば「描画結果を円形マスクで抜いて、潜望鏡的な演出を付与する」「ゲーム画面で定番のゲージ表現を行う」といった方法で活用される。

　一般に、GPUではステンシルテストと「深度テスト（デプステスト）」をピクセルバックエンド（いわゆるROPユニット）の同一ユニット内で処理する。そのため、ステンシルテストのパフォーマンスが最大2倍なら、深度テストのパフォーマンスも最大2倍となっていると考えるのが自然だ。

　いずれにせよ、こちらも異方性テクスチャフィルタリングと同じく、処理パイプライン（≒サンプル数）を倍化したのだと思われる。
Xe3 GPUのパフォーマンスはどこまで上がった？
下の図は、Xe3 GPUの機能強化部分がXe2アーキテクチャと比べてどのくらいパフォーマンスを向上したのかを示したものだ（Xe2を「1」とした場合の相対スコア）。

　レイトレのパフォーマンスはXe2比で「2.0倍」となっている……のだが、Xe3 GPUのレイトレーシングユニットの数はXe2 GPU比で1.5倍でしかない。「0.5倍」の上乗せは、恐らくDynamic Ray Managementの恩恵だろう。

　メッシュレンダリング（Mesh Rendering）のパフォーマンスは「2.4倍」、高レジスタープレッシャーシェーダー（High Register Pressure Shader）のパフォーマンスに至っては「3.1倍」にまで向上している。これはVariable Register Allocationから導出された実行スレッド数の25％増加と、URBの改善による効果だ。

　16x Anisotropic Filtering sRGBのパフォーマンスが「2.0倍」となったことと、Depth Writesが「最大7.4倍」となっているのは、「Up to 2X Anisotropic Filtering」「Upto 2x Stencil Test rate」のチューニングの恩恵だろう。

　ちなみに「Xe3 GPUの“総合”パフォーマンスはどうなんだ？」という点について、Intelは非常にざっくりとしたグラフしか示していない。一応、Core Ultra 200Hプロセッサに搭載された「Xe GPU」やCore Ultra 200Vプロセッサに搭載された「Xe2 GPU」から順当な性能向上を果たしているよということは分かる。

　実際の人気ゲームにおけるパフォーマンスは、市販製品が出てきてから各メディアが実測して示してくれるはず。その時が来るまで、最終評価はお預けだ。

　下図は、とあるゲーム実行時のXe2 GPUとXe3 GPUのパフォーマンスの違いを見せたグラフになる。少し分かりにくいのだが、このグラフの横軸は時間ではなく、APIコールの通算数を表す。縦軸も難解で、こちらはAPIの実施に掛かった累積時間になる。

　つまり、このグラフは必ず右肩上がりとなり、高さが低い方が優秀ということになる。グラフの右端に書かれた時間（ミリ秒単位）は、1フレームの描画に掛かった総時間を表している。

　グラフの各所に囲まれたポイントが数カ所あるが、これらにはここまで筆者が解説してきた、Xe3 GPUのさまざまな機能改善点が大きく表れている。

　左端は、Variable Register Allocationによって実行スレッド数が最大10になったことによる処理時間の短縮分を表している。ここから右に順番に見ていくと、次はL2キャッシュが16MBに増量された効果だ。

　ここに記載されている「Render Pre Pass」とは、具体的にはDeferred Rendering（遅延レンダリング）における「G-Bufferレンダリング」を指している。G-Buffer（Geometry Buffer：ジオメトリバッファー）は、後段に行うライティングに必要なパラメーター群（法線／深度／鏡面反射／ベースカラーなど）を収めたものだ。平常は「Multi-Render Target（MRT）」で最大8枚を同時出力するため、それなりに負荷は高い。

　後段3つのポイントも、Variable Register Allocationの恩恵を表している。Compute ShaderやPixel Shaderの処理がXe2 GPUよりもだいぶ速くなっているということが分かる。

　Xeコアの最大数が1.5倍になったXe3 GPUだが、フレーム処理の時間は2倍近くも違うので、ここは素直にXe3 GPUの改良点が着実な効果を見せていると見て良いだろう。
XeSSは第3世代に　マルチフレーム生成を実装
今回、Panther LakeをCore Ultraプロセッサ（シリーズ3）として投入することを発表した際に、Intelは超解像ソリューション「Xe Super Sampling（XeSS）」に新機能として「XeSS MFG」を搭載することを予告した。

　察しのよい人は気付いたかもしれないが、MFGは「マルチフレーム生成」を意味する。NVIDIAの「DLSS（Deep Learning Super Sampling） 4」に実装されたものと同種の技術に“対抗”するものとなる。

　XeSSシリーズといえば、第2世代の「XeSS 2」において、前フレームと現在フレームから中間フレームを生成し補間する「XeSS-FG」を実装している。こちらは2024年末のXe2アーキテクチャベースの独立GPU「Intel Arc B Graphics」シリーズと同タイミングに発表されている。

　新たに発表されたXeSS-MFGは、新世代の「XeSS 3」に含まれる技術という位置付けで、その動作メカニズムは下図のようになる。見れば分かるが、アルゴリズム的にはXeSS-FGと変わりがなく、生成される補間用フレームが最大3枚になったものという理解でOKだ。

XeSS-FG／MFGの動作フローをチェック

　ここからは、XeSS-FG／MFGの動作フローを簡単に確認しよう。

　フレーム生成にあたって、必要な情報は「前フレーム」と「現在フレーム」の2枚のみだ。これはXeSS-FGもXeSS-MFGも変わらない。念のため、筆者もIntelの担当者に尋ねてみたが、「複数フレームのバッファリングは行っていない」と明言していた。

　この2枚のフレームから求めるのは、画素単位の「オプティカルフロー」と「モーションベクター」の2つだ。どちらも「画面内におけるピクセル単位の動き情報」のことなのだが、その性質がちょっと違う。

【オプティカルフロー】

　まずオプティカルフローだが、名前に「オプティカル（光学）」が付いていることから想像しやすいと思う。これはピクセル単位の色の動き情報だ。イメージ的には、過去フレームと現在フレームを参照し、MPEG動画圧縮で用いられる「動き補償」相当の情報を求める感じだ。

　MPEG圧縮では，着目しているピクセル（ブロック）がどっちに動いたのかを調べるために、過去フレームから現在フレームに対して空間的な周辺探索を行う。それに対して、リアルタイム性が重要視されるXeSS-FG／MFGでは、AIを活用してオプティカルフローを算出する。そのAI自体は「過去フレームと現在フレームの色差分の画像」と「オフライン演算で求めた超正確なオプティカルフロー」の相関を学習させたものだ。ランタイムでは、「過去フレームと現在フレームの色差分画像」をAIに入力して、オプティカルフローを推論してもらうという流れとなる。

【モーションベクター】

　次にモーションベクターだが、AIを使わずとも算術的に求められる。

　当たり前のことだが、GPUは描画しているポリゴンの画面上における座標を把握している。そのため、前フレームと現在フレームで描画された全ポリゴンの“移動幅”をピクセル単位で求められる。座標の差分値は、1ピクセル単位の速度に相当する。

　この差分値を求める際、動いているポリゴンが手前の遮蔽（しゃへい）物に隠れてしまったり、逆に手前にある遮蔽物からポリゴンが飛び出してきたりするような、遮蔽物が絡んだイレギュラーも起こりうる。このイレギュラーを判断するために、「Depth」で表される「深度バッファー（Zバッファー）」も精査する。

　モーションベクターは、最近のゲームだとゲームエンジン側がモーションブラーを表現するために利用する「ベロシティーバッファー」として生成していることが多い。ベロシティーバッファーがある場合は、そのままモーションベクターとして流用できる。

　これで、ピクセル単位の色の動き情報と、描画されたポリゴンのピクセル単位の動き情報を求められる。両者は補完関係にあり、互いの弱点をカバーできる情報となっている。

　3人称視点のレーシングゲームで、自分の車で前方に爆走している時を考えてみてほしい。路面のポリゴンは奥から手前に通り過ぎていくが、自分の車の“影”は、時速何百kmを出していようと、路面上に“静止したまま”となる。

　ある意味で当たり前なのだが、この時に路面上の影に注目してみてほしい。この影は、あくまでも路面上のピクセルなので、モーションベクターだけで移動量を判断すると、「手前から後ろに通り過ぎている」と見なされてしまう。しかし、オプティカルフローで判断すると、影はずっと同じ位置で描画されているため「静止したまま」として見なされる。この例の場合は、オプティカルフローの判断が正解だ。

　オプティカルフローとモーションベクターのどちらを採用するのか――細かく吟味して「何が動いているのか」「何が動いていないか」を正確に判断するのが、上のダイアグラムで「Blend」として表されるAIだ。

　あとは、求められた最終的な1ピクセル単位の速度情報を元に、過去フレームと現在フレームそれぞれからピクセル色をサンプルして、生成する補間フレーム上のピクセル色を確定していく。各ピクセルの色は、動きの速さに応じて、過去フレームと現在フレームのどちらのフレームのピクセル色の割合が強くなるのかを考慮して決定される。この補間フレーム生成も、AIではなく算術的に求められる。

　生成する補間フレームが最大3枚となるMFGの場合は、各ピクセルの速度情報を3等分した値で合成フレームを生成する。

XeSS-MFGはGPUに依存しない

　XeSS-MFGを含むXeSS 3だが、「DirectX 12世代で、シェーダーモデル6.4以上に対応」という要件を満たせば他社製のGPUでも動作する。

　「Vulkan」や「GLSL（OpenGL Shading Language）」といった他の描画系APIではシェーダーモデルという概念がないので，あえて細かく明記すると「DP4a系の8bit／4要素ベクトルの32bit積和算命令に対応しているGPU」が条件となる。

　この要件はXeSS 2以前から変わっていない。XeSS 2／3で実装されているAI処理部分（フレーム生成部分のAIなど)は、推論アクセラレーターを搭載していないGPUでもDP4a系の命令さえ使えれば、推論を走らせることができる。

　とはいえ、マルチフレーム生成は負荷が高い。ゲームで実用レベルとなるのは、最低でも「GeForce RTX 30」シリーズや「Radeon RX 6000」シリーズの中堅モデル以上になると言われている。

　ここで「（XeSS-FG／MFGを）Xe系GPUで動作させたときのメリットはあるのか？」とIntelのトーマス・ピーターセン氏（アーキテクチャ／グラフィックス／ソフトウェア担当フェロー）に尋ねてみたところ、ピーターセン氏は「ある」と即答した。どのような利点があるのだろうか？

　XMXを搭載しているXe系GPUでは、XeSSシリーズのAI処理は推論アクセラレータのXMXで動作するため、プログラマブルシェーダーユニットへの負荷が軽減される。DP4a命令で推論を走らせた場合は、がっつりプログラマブルシェーダーに負荷が掛かるのとは対照的だ。

　また、XMX版とDP4a版では、XMX版の方が複雑性の高いAIカーネルを回しているため、処理結果の画質はXMX版の方が良いとされる。そして一概には言えないが、DP4aは8bit整数精度（INT8）主体の演算主体で推論を回すのに対して、XMX版はGPU（XMX）の世代に応じて、演算精度をINT8／FP16／BF16／TF32から必要に応じて使い分けられる点も、画質に多少は影響している可能性がある。
Intel GPUの“将来の話”
今回のイベントでは次世代GPU「Celestial」（開発コード名）の話は一切なかったが、それでも将来提供予定の機能やサービスについての言及はあった。最後に、このあたりの話題について触れておきたい。

ニューラルレンダリングのサポート

　1つ目の話は、「ニューラルレンダリング（Neural Rendering）」への対応を表明したことだ。

　ニューラルレンダリングとは、グラフィックスレンダリングにおいて、高負荷なライティングやシェーディングの演算をまじめにせずに、AIの推論パワーに助けてもらって実践する新しい概念だ。

　この概念を真っ先に打ち出したのはNVIDIAで、1月に登場した「GeForce RTX 50」シリーズ（Blackwellアーキテクチャ）は「ニューラルレンダリングへの最適化」をうたっている。

　これを受けてAMDも6月、ニューラルレンダリングへの対応を進める旨を表明し、その一環として超解像技術「AMD FSR（FidelityFX Super Resolution）」においてテクノロジースイート「Redstone」（開発コード名）プロジェクトを公表した。さらにAMDは10月、ソニー・インタラクティブエンタテインメント（SIE）と次世代PlayStation向けにニューラルレンダリングに特化したプロセッサの開発を進めていることを明らかにした。

　この点、今回のIntelによる表明は「うちもニューラルレンダリングをやります」程度のものだった。ただし、複数の静止画からAI推論を使って3Dモデル構築する「Neural Radiance Field（NeRF）」のデモをCore Ultraプロセッサ（シリーズ3）を搭載する実機で披露していた。

　ちなみに、ニューラルレンダリングの業界標準化については、Microsoftが強いリーダーシップを取って急ピッチで進めている。具体的には、DirectX 12に「シェーダーモデル6.9」を規定して、その中に「Cooperative Vectors（協調ベクトル）」というシェーダー言語の命令セットを追加する方針だ。

　協調ベクトルという名前だが、ニューラルレンダリングでは「行列×ベクトル」の演算が頻発するので、これをシェーダープログラムの各スレッドで“協調”して大きな演算に束ねて実行する――という所から来ているとされる。

あらかじめコンパイルされたシェーダーの配信

　もう1つの話は「Precompiled Shader Distribution」、日本語に直訳すると「コンパイル済みのシェーダーの配信」だ。

　最近のゲームは、初回起動時にシェーダープログラムのコンパイル作業を行うものが多い。ゲームパッケージに含まれているシェーダープログラム群は中間言語で書かれており、ゲームの実行時に一度、搭載しているGPUのネイティブコードにコンパイル（変換）する必要があるのだ。

　この点でいうと、最近なら「モンスターハンターワイルズ」や「モンスターハンターワイルズ ベンチマーク」の初回起動した際に、コンパイル時間がとても長いことが話題となった。

　「Steam」など、一部のゲームストアではGPUごとにコンパイル済みのシェーダーコードを自動配布する仕組みが整っているが、他はまだまだという状況だ。Microsoftについては、同趣旨の「Advanced Shader Delivery」というサービスをASUSのポータブルゲーミングPC「ROG Xbox Ally」シリーズ限定で始めたばかりだ。

　「この手のことはGPUメーカーがやるべきでは？」という声を受けて、Intelは他社に先駆けて、Intel Arc Softwareをインストールしたデバイス限定で、インストール済みのゲームを自動認識した上で、コンパイル済みのシェーダーコードを自動ダウンロードしてインストールしてくれるサービスとしてPrecompiled Shader Distributionを開始することを決めた。11月中の開始を予定しているという。

　ゲームの初回起動でのイライラを大幅に緩和する観点で、これはいいサービスだ。
ITmedia PC USER",[],[]
ソノヴァ、利便性を高めた高機能補聴器「インフィニオ ウルトラ」（ITmedia PC USER）,https://news.yahoo.co.jp/articles/e1ca3d51b9e8f4155f62518d6074968bb38541ff,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20251119-00000070-zdn_pc-000-1-view.jpg?exp=10800,2025-11-19T17:00:54+09:00,2025-11-19T17:00:54+09:00,ITmedia PC USER,zdn_pc,ITmedia PC USER,288,"「インフィニオ ウルトラ」
ソノヴァ・ジャパンは11月19日、高機能設計の補聴器「インフィニオ ウルトラ」を発表、本日出荷を開始する。
【画像】インフィニオ ウルトラは、音環境の検出精度を従来より24％改善した高機能設計の補聴器だ
同社製補聴器の最新モデルで、音環境の検出精度を従来より24％改善したことで聴こえやすさを向上。スマートフォンとのペアリング機能も改善しより簡単に接続が可能となった他、最大8台までのマルチペアリングもサポートした。また、頻繁にフィルターを交換せず簡単に清掃が可能な「イージーガード耳せん」を採用しているのも特徴だ。
ITmedia PC USER",[],[]
エイサーがエントリーDLPプロジェクター4製品を発売（ITmedia PC USER）,https://news.yahoo.co.jp/articles/3a0198632f75cb96ee3ff6c6dd254411fa22cb31,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20251119-00000069-zdn_pc-000-1-view.jpg?exp=10800,2025-11-19T16:59:42+09:00,2025-11-19T16:59:42+09:00,ITmedia PC USER,zdn_pc,ITmedia PC USER,437,"SXGA表示対応モデルの「X1128H」
日本エイサーは11月19日、エントリークラスモデルとなるDLPプロジェクターを発表、11月19日に販売を開始する。ラインアップはSXGA表示対応モデルの「X1128H」、XGA表示対応モデルの「X1228」、WXGA表示対応モデルの「X1328」「X139Wi」の4製品を用意。予想実売価格はそれぞれ5万9800円、6万3800円、6万5800円、7万2800円だ（税込み）。
【画像】こちらはXGA表示対応モデルの「X1228」。「X1328」と「X139Wi」の画像もこちらから
いずれもスタンダード設計のDLPプロジェクターで、最大300インチまでの投写に対応。輝度はX1128H/X1228が4800ANSIルーメン、X1328/X139Wiが5000ANSIルーメンを実現している。

　映像入力はHDMI、アナログD-Subおよびコンポジットビデオに対応、出力3Wのスピーカーを内蔵した。
ITmedia PC USER",[],[]
Razerのマスコット「Sneki Snek」をデザインにした収納型トートバッグ（ITmedia PC USER）,https://news.yahoo.co.jp/articles/17ed78e8cb9dff8f7ae280a6de65fab3c781335a,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20251119-00000068-zdn_pc-000-1-view.jpg?exp=10800,2025-11-19T16:57:53+09:00,2025-11-19T16:57:53+09:00,ITmedia PC USER,zdn_pc,ITmedia PC USER,326,"「Razer Sneki Snek Reusable Bag」
Razerはこのほど、同社マスコットキャラクター「Sneki Snek」をモチーフにした収納型トートバッグ「Razer Sneki Snek Reusable Bag」を発表、販売を開始した。同社公式ストア販売価格は5980円だ。
【画像】Razer Sneki Snek Reusable Bagを収納した状態。普段はバッグパックなどに装着しておける
Sneki Snekの頭部をデザインした収納型トートバッグで、バッグ部分を内部に収納することでアクセサリーとしても利用可能。展開時のサイズは約400×400mmで同社製18型ノートPCなども収納できる。
ITmedia PC USER",[],[]
エレコム、PCバッグ“ZEROSHOCK”にバックパック／メッセンジャーバッグを追加（ITmedia PC USER）,https://news.yahoo.co.jp/articles/771be0321f4443f5fadae2df29d99bdea3691f7f,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20251119-00000059-zdn_pc-000-1-view.jpg?exp=10800,2025-11-19T16:28:43+09:00,2025-11-19T16:28:43+09:00,ITmedia PC USER,zdn_pc,ITmedia PC USER,471,"「ZSB-BP02P15BK」
エレコムはこのほど、同社製PCバッグ「ZEROSHOCK」シリーズにバックパック2サイズ「ZSB-BP01P14BK」「ZSB-BP02P15BK」とメッセンジャーバッグ「ZSB-BP02P15BK」の計3製品を追加、11月下旬に販売を開始する。予想実売価格はそれぞれ8980円、9980円、5980円だ（税込み）。
【画像】こちらは「ZSB-BP02P15BK」
いずれも内部に低反発ウェーブカットウレタンフォームを用いたノートPC収納スペースを備えるバッグで、ZSB-BP01P14BK/ZSB-BP02P15BKは14型までのノートPC、ZSB-BP02P15BKは15.6型までのノートPCの収納に対応した。

　撥水加工を施した表面生地を採用、背面側には通気性に優れるエアーメッシュ素材が用いられている。バックパックモデルのZSB-BP01P14BK/ZSB-BP02P15BKは小物収納に向くオープンポケットを装備、キャリーケースに固定できるキャリーベルトも備えた。
ITmedia PC USER",[],[]
ダイヤテック、「カレンダーキーキャップ」2026年度版の販売を開始（ITmedia PC USER）,https://news.yahoo.co.jp/articles/716ad93408475e6059daa3bb585cf216d171a3e2,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20251119-00000058-zdn_pc-000-1-view.jpg?exp=10800,2025-11-19T16:27:32+09:00,2025-11-19T16:27:32+09:00,ITmedia PC USER,zdn_pc,ITmedia PC USER,448,"2026年度のカレンダーを刻印したキーキャップセット「FILCO Calendar Keycap Set 2026」
ダイヤテックは11月19日、2026年度のカレンダーを刻印したキーキャップセット「FILCO Calendar Keycap Set 2026」を発表、12月3日に販売を開始する。同社Web直販価格は1480円（税込み、以下同様）。
【画像】シルバーモデルの「FK418BTS-JP/3」
CHERRY MXキースイッチ互換のキーキャップセットで、2026年1月～2027年1月までの13カ月分をプリントした計13キーがセットになっている。

　またダイヤテックは、同社が取り扱うMatias製の薄型Bluetoothキーボード「Matias Wireless Aluminum keyboard 日本語配列」の再販を発表、12月3日に販売が再開される。カラーバリエーションはシルバーとスペースグレーの2タイプを容易、直販価格は1万5480円だ。
ITmedia PC USER",[],[]
1ドライブで大容量の30TB！　個人でも買えるNAS向けHDD「IronWolf Pro」を試す（ITmedia PC USER）,https://news.yahoo.co.jp/articles/a055ee744360a0c9644701359e97a3758ae1f8d5,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20251119-00000039-zdn_pc-000-1-view.jpg?exp=10800,2025-11-19T12:00:13+09:00,2025-11-19T12:00:13+09:00,ITmedia PC USER,zdn_pc,ITmedia PC USER,2420,"日本シーゲートのIron Wolf Proシリーズで最大容量となる30TBモデル「ST30000NT011」
日本シーゲートのNAS向けHDD「IronWolf Pro」シリーズで、現時点で最大容量となるのは30TBモデルの「ST30000NT011」だ。同社では、AIモデルトレーニングを含む大規模データ処理に強い「Exos M」シリーズにも30TBの「ST30000NM004K」が発売済みだ。
【写真】利用時のサーモグラフィー画面
ついに1台で30TBという大容量が実現したわけで、みなさんは自宅にあるPCのストレージ容量はどの程度だろうか。我が家ではNASを使用しているが、1台の容量は16TBが最大で、その前に使っていたHDDは4TBだった。その4TBと30TBを比べると同じ大きさで容量が7.5倍となるモデルをチェックした。
NAS向けのHDDで最大容量となる30TBモデル
今回借用したST30000NT011は、インタフェースがSATA（6Gbps）で回転数は7200rpm、キャッシュは512MB、CMR記録方式を採用している。MTBFは250万時間、5年の保証と3年間のデータ復旧サービスが付いてくる。

　本製品はマルチベイ／マルチユーザーの商用NASおよびエンタープライズ用NAS向けに設計されており、常時稼働／常時アクセスに対応できるタフな設計や、内蔵RVセンサーがマルチベイ環境での振動検知と制御に対応し、安定した性能を発揮する。ちなみに、IronWolf Proシリーズは2TBから30TBまで、ほぼ2TB刻みで多数のモデルが用意されている。

　30TBになったからといって、パッと見は従来モデルと変わらない。とはいえ、裏側の基板も最小限のサイズとなり、昔のHDDなどでは見られたデコボコが少ないのが分かる。コネクターはもちろんSATAだ。そして実測の重量は691g（公称値は約695g）だった。
まずは自作PCに接続してテスト
本来はNAS向けのモデルだが、内蔵HDDとしても使えるので自作デスクトップPCに接続して使ってみた。

　フォーマット直後の空き容量は27.2TBで、CrystalDiskInfo（ひよひよ氏作）ではSATA 6Gbps転送モードで動作しているのが分かる。

　続いて、CrystalDiskMark（ひよひよ氏作）を使ってベンチマークテストを行った。16GiBと46GiBの結果だが、シーケンシャルのリードが毎秒283MB、シーケンシャルライトが毎秒284MB、ランダムだと4KQ32T1ではリードが毎秒2.93MB、ライトが毎秒3.02MBとなった。

　ランダムは言うまでもなくSSDが有利だが、HDDとしては十分高速なシーケンシャル速度が出ている。

　次にHD Tune Proを使用して全領域のリード速度をテストした。最大が毎秒286.5MB、最小で毎秒128.3MB だった。
USB接続でもテスト
USB接続では、外付けケースとしてセンチュリーの「裸族のお立ち台 M.2ダブルスタンディングプラス」を使った。USB 10Gbps接続にて、内蔵接続と同様にCrystalDiskMarkでテストした。

　シーケンシャルリードで毎秒290MB、シーケンシャルライトで毎秒291MBと、誤差範囲だが少しだけUSB接続の方が速い結果となった。
消費電力と温度チェック
消費電力は、USB接続時にACアダプターをワットチェッカーで目視にて確認した。HDDを付けない状態では1W、アイドル時は9W、スピンアップ時は21W、読み書き時は11Wと、おおむねスペック通りとなった。

　発熱のチェックは、内蔵接続時に無風状態にてサーモグラフィーカメラを使った。表面は約50度、裏面の一番高い温度でも58.4度だった、ここはコントローラーチップの部分と思われる。

　本来はNASに入れて使用するため、冷却ファンなどがあり実際にここまで温度が上がることはないだろう。
NASに入れてチェック！
本製品のメイン用途であるNASでは、手持ちのASUSTOR製「NIMBUSTOR 4 Gen2（AS5404T）」を使用し、PCとの接続には2.5Gbps接続でテストを行った。

　まずNASに取り付けディスク情報を見ると、「IronWolf Health Managementをダウンロードして実行してください」と表示された。

　NAS向けのアプリで、App Centralからインストールを行った。

　IronWolf Health Managementのインストール後、ディスクマネージャーにある「IronWolf 健全性状態」の詳細から、作業量と温度をチェックできるようになった。

　動画ファイルコピーして2TBほどファイルを作り、NASからデスクトップのSSDに1.6TBまでコピーしてその時間を計測した。

　2172ファイルを転送した際の平均速度は毎秒約260MB、時間にして約1時間48分だった。同じ容量のHDDがないため同じテストはできないが、フルにデータがある状態からデータを転送するには1日以上かかりそうだ。
まとめ
大容量HDDのメリットは、多彩なデータを貯めておける安心さにある。30TBは現時点で買える単体のストレージとしては最大容量ゆえ、価格も12万前後と安くはない。

　しかし、転送速度についてはHDDとしては速く、NAS向けにカスタムされた技術と高度なHDD診断機能、さらにデータ復旧サービスの「Rescue Data Recovery Services」（3年間）が無料で付帯するのは魅力だ。

　写真データや動画データなど、どんどん増える大容量データを気にせずNASに保管する際に使うには最適なモデルだろう。
ITmedia PC USER",[],[]
Microsoftが「Windows 11」に実装予定のAI新機能を披露　タスクバーからエージェントを呼び出せるように（ITmedia PC USER）,https://news.yahoo.co.jp/articles/09b0a263575a605ffe3eb1915c3b8c15617da1b7,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20251119-00000020-zdn_pc-000-1-view.jpg?exp=10800,2025-11-19T06:00:15+09:00,2025-11-19T06:00:15+09:00,ITmedia PC USER,zdn_pc,ITmedia PC USER,1621,"「Windows 365 for Agent」としてAIエージェントを組み込んだクラウドPCを利用できるようになる
Microsoftは11月18日から23日まで（米国太平洋時間）、ビジネスユーザー向けの年次イベント「Microsoft Ignite 2025」を開催する。
【画像】タスクバーやスタートメニューで使える「Ask Copilot」
この記事では、11月18日（同）に行われた各種発表のうち、「Windows 11」に実装される予定の新機能（プレビューを含む）を紹介する。
タスクバーへのAIエージェントの統合
Ignite 2025において、MicrosoftはWindows 11へのAIエージェント機能の統合を推進する方針を示した。その可用性やセキュリティを担保しつつ、管理やカスタマイズをしやすくするため、OSレベルの改良を順次進めていく。

　その一環として、タスクバーからエージェントを直接利用できる仕組みを導入する。また、エージェントに関するガバナンス（統制）機能やエージェントが質問したり新情報を提供したりする安全な仕組みも組み込むという。
Agent connectors／Agent workspace
Windows 11にAIエージェントを組み込むための仕組みも整備される。

　「Agent connectors」は、MicrosoftまたはサードパーティーのAIエージェントがWindowsのアプリ／ツールに接続するためのフレームワークで、MCP（Model Context Protocol）を活用して実装されている。

　「Agent workspace」は、エージェントがユーザーが普段使っているIDやアプリを使って、各種タスクを代理実行する仕組みだ。その動作はポリシーによる制御が可能で、動作に関する監査も行えるようになっている。

　クラウドPCサービス「Windows 365」でも、AIエージェントを組み込んだクラウドPC（Windows 365 for Agent）を展開できるようになる。

　上記は全て、現時点ではプレビュー提供という扱いとなる。
Ask Copilot
「Ask Copilot」は、Windows 11の「検索ボックス」「スタートメニュー」などから「Copilot」「Microsoft 365 Copilot」を含むAIエージェントを呼び出せる機能だ。「ツール」をクリック（タップ）するか、キーボードで「@」をして呼び出すことも可能だという。

　本機能は、現時点ではプレビュー提供という扱いとなる。
他のAI／Copilot機能
その他、今後Windows 11に実装される予定の主なAI／Copilot機能は以下の通りだ（★印が付いているものは「Copilot+ PC」限定）。

・Click to Doに「Microsoft 365 Copilotに質問」を追加★
・Click to Doで認識した文章やイメージをCopilotに直接伝送可能

エクスプローラー（File Explorer）に「Microsoft 365 Copilotに質問」を追加

・エクスプローラーで選んだファイルについて、サポートや分析情報を取得可能

Windows 検索の機能強化★

・ローカル／クラウド双方のファイルに対するセマンティック検索が可能に

「ライティング アシスタンス」の実装

・文章の書き直しや校正を利用可能
・オフラインでも利用可能★

「Hey Copilot」と話かけることでMicrosoft 365 Copilotを呼び出せる機能を実装

・CopilotキーまたはWindows＋Cキーでも同様の操作が可能

Fluid Dictation（プレビュー版）の品質改善★

ナレーター／拡大鏡の品質改善
ITmedia PC USER",[],[]
