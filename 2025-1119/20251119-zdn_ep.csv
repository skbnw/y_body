headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
Gemini 3、ついに登場　「驚異的」な性能と既存ユーザーへの影響（ITmedia エンタープライズ）,https://news.yahoo.co.jp/articles/d2f14dd5da44218dc02c60629248182cbe3bdec8,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20251119-00000077-zdn_ep-000-1-view.jpg?exp=10800,2025-11-19T20:30:13+09:00,2025-11-19T20:30:13+09:00,ITmedia エンタープライズ,zdn_ep,ITmedia エンタープライズ,1563,"（写真：ITmedia エンタープライズ）
Googleは最新のAIモデル「Gemini 3」の提供開始を発表した。発表時点から「Gemini」アプリや「Google AI Studio」「Vertex AI」などで利用可能になっている。
「Gemini 3」ついに登場　“驚異的”とうたうその性能
Gemini 3は「推論能力において最先端のモデル」とされ、ユーザーのプロンプトの細かなニュアンスを読み取ることが可能だという。Googleはその性能を「驚異的」とうたう。

　Gemini 3ファミリーの第1弾として「Gemini 3 Pro」がプレビュー公開されている。

　Gemini 3 Proの応答は「簡潔かつ直接的」とされ、「決まり文句やお世辞ではなく、真の洞察を提供する」という。

　併せて推論能力とマルチモーダル性能を向上させた「Gemini 3 Deep Think」モードも発表された。これは個人向けの最上位プラン「Google AI Ultra」加入者への展開が予定されており、まずセーフティーテスターへの提供から開始する。

　Gemini 3 Proは長期的なタスクの実行能力も向上した。長期の計画に沿ってタスクを実行する能力を自動販売機ビジネスのシミュレーションを通して測るベンチマークテスト「Vending-Bench 2」では「Claude Sonnet 4.5」や「GPT-5.1」を抑えて1位となった。
GeminiアプリにもGemini 3搭載の新機能
Gemini 3の発表に併せて、Geminiアプリの新機能も発表された。

　Geminiアプリは新たに「生成インターフェース」機能を搭載する。この内「ビジュアルレイアウト」機能を使うと、Geminiの応答に画像やユーザーの操作を促すボタンが配置される。「動的ビュー」機能を利用すれば、プロンプトでインタフェースをカスタマイズできる。

　Geminiが「Gmail」や「Google カレンダー」を直接操作する「Gemini Agent」機能も発表された（現時点では米国のみの提供。日本での提供は未定）。エージェントがユーザーの指示に基づいて受信トレイの整理やフライトの予約をこなす機能だという。
ユーザーへの影響は？
今回のGemini 3の発表はユーザーにどのような影響をもたらすのか。

　まず、日常の業務における利便性の向上が期待できる。Gemini 3 Proはユーザーのプロンプトから「ニュアンス」を読み取る性能が強化され、画面の内容の認識などマルチモーダルの性能も向上している。実際の使用感は今後検証する必要があるが、現時点の公開情報で分かる限りでは、資料作成や計画立案、開発などの多くの業務がこれまで以上に効率化されることが期待できそうだ。既に日本でもGeminiアプリなどで利用でき、ユーザーはすぐに性能向上の恩恵を受けられる。

　今後普及が期待されるAIエージェントの性能向上にもつながりそうだ。AIが人間と同じように働けるようになるためには、長期のタスクの実行能力が不可欠だ。Gemini 3は長期にわたるタスクの計画や、ツールの使用における能力が向上している。「Gemini Enterprise」やVertex AIで開発したAIエージェントの頭脳として利用すれば、より高度なタスクを効率化できるかもしれない。

　「GPT-5」発表当初、応答がドライだったため「GPT-4o」ロスが広がったのは記憶に新しい。Gemini 3は「簡潔かつ直接的」をアピールしており、あえて業務利用に特化した印象だ。このモデルが“AI従業員”として企業で受け入れられるか、注目したい。
ITmedia エンタープライズ",[],[]
ついに始まった「AIが自律的に攻撃する日」　調査で判明した衝撃のClaude Code悪用事例（ITmedia エンタープライズ）,https://news.yahoo.co.jp/articles/73094e8bc7a9a7c6a4e92ac15670cdb91e6269c3,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20251119-00000023-zdn_ep-000-1-view.jpg?exp=10800,2025-11-19T08:30:16+09:00,2025-11-19T08:30:16+09:00,ITmedia エンタープライズ,zdn_ep,ITmedia エンタープライズ,1691,"（写真：ITmedia エンタープライズ）
AnthropicはAI主体の大規模サイバー諜報（ちょうほう）活動に関する報告を公表した。AIが主要な作業工程を担ったサイバー攻撃として初めて確認されており、AI活用の進展が攻撃者側にも広がっている現状が浮き彫りとなった。
「Claude Code」悪用の大規模サイバー諜報活動をAnthropicが初確認
Anthropicは2025年9月中旬に不審な挙動を検出したことを契機に調査を開始した。解析の結果、極めて高度な手法での諜報活動が展開されていたことが判明した。攻撃者は同社のコーディングアシスタント「Claude Code」を悪用し、約30の世界的組織への侵入を試みたことが確認されており、攻撃者は中国政府系グループだと高い確度で判断されている。標的には大手テクノロジー企業や金融機関、化学産業関連企業、政府機関が含まれ、一部では侵入が成功していたとされている。

　今回のケースは、攻撃者がAIを助言役ではなく、攻撃の実行主体として使っていたことが特筆すべき点として挙げられている。

　AnthropicはAIモデルの能力が半年で倍増する状況を把握しており、実世界の攻撃活動でもAIの利用が進んでいることを追跡してきた。今回の事案は、そうした流れが急速かつ広範に拡大している実例だと位置付けている。

　攻撃は複数段階で構成されていたことが調査によって判明している。まず、人間のオペレーターが侵入対象を選定し、自律的に攻撃を実行する枠組みを準備。ここでClaude Codeに対し不正な目的を隠す形で指示が分割され、正当な業務を装う設定が与えられたとされる。この操作によってClaude Codeがガードレールを迂回（うかい）する状態を作り出していた。

　次の段階において、Claude Codeが標的システムの構成を調査し、価値の高いデータベースを特定。この工程は短時間で実施され、人間の攻撃者が同等の作業をする場合と比較して圧倒的に効率的であったとされる。その後、AIは脆弱（ぜいじゃく）性の分析および攻撃コードの生成を行い、そこから取得した認証情報を使って追加のアクセス権を獲得した。その後、大量の内部データが収集され、情報の性質ごとに分類されている。高い権限を持つアカウントには不正なバックドアが設置され、最終的には今回の作戦で得られた情報を整理した文書類もAI自身が作成している。

　Anthropicの分析では全工程の8～9割をAIが担当し、人間による決定が必要となった場面は1件の攻撃につき数回程度だったという。AIの作業量は膨大であり、ピーク時には毎秒複数の要求を発行する水準で動作していたとされる。この速度は人間のみでは実現困難とされている。ただし、Claude Codeは完全に正確というわけではなく、存在しない認証情報を生成した事例や、公開情報を秘密情報と誤認した事例も確認されている。ここに完全自律化への課題があるとみられている。

　Anthropicは、こうした攻撃手法の登場によって「高度な攻撃の実行条件が大きく変化した」と指摘している。より少ない経験や資源しか持たない攻撃者でも適切な環境を整えるだけで、熟練したサイバー犯罪グループでなければ実施が困難であった規模の攻撃であっても遂行できる現状にあるとしている。同時に、こうしたAIの能力は防御側にとっても不可欠と説明している。

　Anthropicは、防御側がAIを活用した監視自動化や脅威検知、脆弱性分析、インシデント対応の分野で技術を応用する取り組みを推進する必要があると述べている。各社が自社のAI基盤の安全性を強化し、悪用を防ぐ仕組みを拡充することも求めている。今回の事案の詳細を公表した背景には、産業界や行政機関、研究者らが自らの防御体制を強化する上で役立てられる情報の共有という意図がある。Anthropicは今後も同様の報告を継続して公表し、得られた知見を外部と共有する姿勢を示している。
ITmedia エンタープライズ",[],[]
NotebookLMとDeep Researchがまさかの“合体”　対応ファイル形式も大幅拡大（ITmedia エンタープライズ）,https://news.yahoo.co.jp/articles/9823121c98711ade8d67a6f764d9d36c657af22e,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20251119-00000022-zdn_ep-000-1-view.jpg?exp=10800,2025-11-19T08:30:13+09:00,2025-11-19T08:30:13+09:00,ITmedia エンタープライズ,zdn_ep,ITmedia エンタープライズ,824,"【画像】NotebookLMでDeep Researchを使ってみた（3枚）
Googleはリサーチアシスタント「NotebookLM」に情報検索機能「Deep Research」を導入した。また、NotebookLMが扱えるファイル形式の拡大も発表した。
「インポート」を押すと、収集した資料が一括で「ソース」に追加される
NotebookLMでのDeep Research利用手順
Deep ResearchはWebの情報検索を自動化する機能だ。ユーザーのプロンプトに応じて調査を計画し、Webの広範な情報源へアクセスし、数分で整理されたレポートを生成する。出力されるレポートはNotebookLMの「ソース」に追加できる。Deep Researchがバックグラウンドで稼働中でも別の資料を追加できる。

　利用手順は以下の通りだ。

　まず「ソースを追加」から「ソースを探す」を選択すると、左ペインにチャットが立ち上がる。次に調査手法として「Fast Research」または「Deep Research」を選び、プロンプトを入力して送信すると調査が始まる。Fast Researchは短時間で簡潔に資料を探す機能だ。Deep Researchはより詳細に調査をバックグラウンドでも実行できる。

　調査が完了すると、収集した資料の一覧が追加される。「インポート」を押すと、収集した資料が一括で「ソース」に追加される。

　併せて、対応ファイル形式の拡張も発表された。「Googleスプレッドシート」や「Google Drive」ファイルのURL、画像、Google Driveに保存したPDF、「Microsoft Word」ファイル（.docx）などを追加でサポートする。

　各機能は発表後1週間以内に全ユーザーへの提供が開始され、画像の取り込み機能に関しては数週間以内に展開される見通しとなっている。
ITmedia エンタープライズ",[],[]
生成AIはデータ流出の主要経路に　従業員がついやってしまう漏えいパターン（ITmedia エンタープライズ）,https://news.yahoo.co.jp/articles/5f92e0bdf958b6d8f1a669d0e5cbd0d68b0f2c81,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20251119-00000006-zdn_ep-000-1-view.jpg?exp=10800,2025-11-19T07:00:12+09:00,2025-11-19T07:00:12+09:00,ITmedia エンタープライズ,zdn_ep,ITmedia エンタープライズ,2048,"（写真：ITmedia エンタープライズ）
LayerX Securityは、顧客から得たブラウジングデータに基づき、企業におけるAI利用とデータ保護の実態を分析した年次報告書「Enterprise AI and SaaS Data Security Report 2025」を公表した。AIはもはや新興技術ではなく、企業データ流出の主要経路となっている実態が明らかになった。
生成AIはデータ流出の主要経路に　従業員がやりがちな漏えいパターン
企業における生成AI活用は急速に進展している。従業員の45％が生成AIツールを業務で利用しており、登場からわずか3年足らずで半数近くに達したことが報告されている。ファイル共有やビデオ会議といった従来のSaaS分野が同程度の普及率に至るまでに10年以上を要したことを踏まえると、その浸透速度は異例といえる。特に92％の利用が「ChatGPT」に集中しており、単一の消費者プラットフォームが実質的な企業AI標準として定着していることが示されている。

　ただ、急速な普及の裏でAIが企業データ保護の死角となっている。従来の電子メールやファイル共有のように統制が確立されている分野とは異なり、AI利用の大部分は企業の認証基盤や管理下を外れており、これが企業における最大のデータ流出経路と位置付けられている。具体的にはどのようなパターンが危険なのか。

　注目すべきは、データ流出の経路だ。多くのCISO（最高情報セキュリティ責任者）はファイルのアップロードを主なリスクと捉えているが、実際にはコピー＆ペースト操作によるデータ流出が多数を占めるという。

　調査結果において、従業員の77％が生成AIにデータを貼り付けており、その82％が個人アカウントからの操作とされている。従業員1人当たりのペースト操作は1日平均14回に上り、そのうち少なくとも3回に機密データが含まれていた。生成AIツールだけで企業から個人アカウントへの全データ転送の32％を占めており、クリップボードが事実上の主要流出経路となっている。従来型のファイル中心の情報漏えい対策（DLP）では検知が困難であり、多くの企業がこの活動を把握できていない状況にある。

　アカウント管理面においても課題がある。同社の分析によると、生成AI利用実態を見ると、その67％が企業の統制が及ばない個人アカウントで行われており、顧客関係管理（CRM）では71％、企業資源計画（ERP）では83％のログインが非フェデレーションということが分かった。

　名目上は企業アカウントであっても、実際にはパスワード認証のみで運用されているケースが多く、個人アカウントと区別が付かない状態となっている。機密性の高い顧客データや財務データへのアクセスが十分に制御されていない。

　LayerXは、AI活用の進展とガバナンスの欠如が反比例している点を問題視している。従業員によるAIツールへのファイルアップロードやプロンプトへの顧客情報入力といった行為が日常的に実行されているにもかかわらず、正式な統制が存在しないという。電子メール分野では長年の監査やDLP導入が進んでいるが、AI分野ではその基盤が欠落している。AI関連の業務活動は既に全企業アクティビティーの11％を占め、従来の主要SaaS分野に匹敵する規模に達しているにもかかわらず、管理体制は整備されていない。

　報告書はCISOに対し、4つの対応策を提示している。

・AIを正式な企業ITカテゴリーとして扱い、電子メールやファイル共有と同等のガバナンスを適用すべきと指摘している
・非フェデレーションのアカウントを「管理外システム」と再分類し、特にERPやCRMなど重要システムに対し即時監査を実施する必要がある
・個人アカウントのアクセスを単純に遮断するのではなく、データ内容を識別し保護するデータ認識型ポリシーを採用することを推奨している。これにより従業員の作業環境を維持でき、機密データの持ち出しを防止できる
・DLP予算を従来のネットワークやファイル解析からWebブラウザレベルの制御に移行することを推奨している。LayerXの分析において、コピー＆ペーストがファイル転送を上回る流出経路となっており（生成AIツールに加え、IMアプリへも同様に機密データがペーストされている）、Webブラウザでのペースト検知や遮断が実効性の高い対策とされている

　LayerXは結論として、「AIが業務に深く組み込まれた今、企業は生成AIの利用を統制すべきか否かではなく、いかに迅速に統制下に置くかが課題」と述べている。AI利用が拡大するほど監視の網が緩むという逆説的状況の中で、クリップボードが新たな情報流出の最前線となりつつある現実が示されている。企業にとって、AIガバナンスの整備はもはや選択肢ではなく喫緊の課題といえる。
ITmedia エンタープライズ",[],[]
