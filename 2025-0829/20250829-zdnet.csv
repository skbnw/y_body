headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
タレス、量子時代における非構造化データ保護の重要性を強調--インパーバ買収による効果は（ZDNET Japan）,https://news.yahoo.co.jp/articles/61aeb15262c85d6655f2eee3e2e8e662918e737f,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250829-35237346-zdnet-000-1-view.jpg?exp=10800,2025-08-29T12:44:00+09:00,2025-08-29T12:44:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,3192,"Thales CybersecurityのCano氏
タレスDISジャパンは8月26日、同社のサイバーセキュリティ事業に関するプレス向け説明会を開催した。

　同社は2023年にウェブアプリケーションセキュリティを提供するImpervaを買収し、ポートフォリオを強化した。今回は、買収によって獲得されたImpervaのテクノロジーの最新のアップデートや、同社が新たな課題と位置付ける「人工知能（AI）」「ポスト量子コンピューティング（PQC）」「デジタル主権」に対する取り組み状況について説明した。

　まず概要説明を行ったThales Cybersecurity サイバーセキュリティ製品部門シニアバイスプレジデントのSebastien Cano（セバスチャン・カノー）氏は、Thalesについて「フランス発のグローバル企業で、全世界で従業員約8万人、年間売上は約200億ユーロ（約3兆4000億円）だが、サイバーセキュリティ製品部門は米国テキサス州ヒューストンに本拠を置いており、約6000人の従業員でグローバル3万社以上の顧客企業にサービスを提供している」と紹介。さらに日本市場については「われわれは日本市場で50年にも及ぶ事業の歴史を持ち、日本を極めて重要な市場だと位置付けている」と語った。

　同社のサイバーセキュリティソリューションでは、買収によって獲得された「Imperva Application Security Platform」、Thalesがもともと強みを持っていた分野である「CipherTrust Data Security Platform」、アイデンティティー管理に関する「OneWelcome Identity Platform」の3つのプラットフォームに、さまざまなセキュリティソリューションを統合して提供している。

　同氏は、従来からのデータセキュリティとImperva由来のウェブアプリケーションセキュリティやデータのモニタリングなどの機能の組み合わせが理想的な補完関係にあると言い、例え話として「家屋や建物のセキュリティに例えるなら、Thalesのデータセキュリティ技術は門や扉の鍵や金庫に相当し、Impervaの技術はアラームやモニタリングシステム、監視カメラに相当する」と説明した。

　Cano氏はデータセキュリティプラットフォームであるCipherTrustの最新状況についてさらに詳しく説明した。現在、同社ではデータセキュリティの分野でデータセキュリティポスチャー管理（DSPM）という概念に基づき、「AI・量子時代におけるデータリスクを能動的に管理・軽減」することを目指している。

　データライフサイクル全体にわたって適切な管理を行う機能をさまざま実装しているが、中でもCano氏が強調したのが「非構造化データ保護の重要性」だ。同氏は「企業データの80％以上が非構造化データ」「IT責任者の76％は、機密性の高い非構造化データの全体像を把握できていない」「生成AIプロジェクトを進める組織の75％が、データセキュリティの重点を構造化データから非構造化データへ移行」といったデータを紹介した上で、「非構造化データは一貫した形式を持たないため、分類・分析・従来ツールによる保護が難しく、従来は監視されていなかった」と指摘した。

　同社でも、構造化データを対象としたアクティビティー監視を提供していたが、2025年6月に「File Activity Monitoring」（FAM）を発表し、非構造化データに対するアクティビティー監視を実現している。もともとImperva由来のデータを対象としたアクティビティーモニタリングの技術を、構造化データだけでなく、非構造化データにも適用できるように拡張し、同氏は「2023年にImpervaを買収して以降、最も重要な技術革新だといえる」とその意義を強調した。

　続いて、タレスDISジャパンのサイバーセキュリティプロダクト事業本部 シニアセールスエンジニアリングマネージャの舟木康浩氏が、DSPMの再定義と耐量子暗号への対応について紹介した。同氏はDSPMについて「データ中心のセキュリティ」だと位置付け、「組織のデータ環境全体を可視化し、データの場所、種類、アクセス権限、リスクレベルを継続的に監視・管理するソリューション」であり、「従来のセキュリティツールが『境界防御』に重点を置いていたのに対し、DSPMは『データそのもの』を中心とした包括的なセキュリティアプローチを提供」するものだと説明した。

　従来は監視対象となっていなかった非構造化データを、アクティビティー監視の対象に含めたFAMも、DSPMの機能強化の一環と位置付けられる。さらに「現実的かつ差し迫った脅威」として量子コンピューターによって既存の暗号方式が破られる可能性を指摘し、「DSPMの見直しと耐量子暗号の戦略的導入」によって「データや鍵管理体制を耐量子暗号に対応」させることが重要だとした。

　現在、既にハーベスト攻撃（HNDL攻撃）が発生しているといい、将来実用的な量子コンピューターが完成した時点で既存の暗号方式で暗号化された情報を解読するため、現時点で流通している暗号化された通信／データを傍受して保存しておくという取り組みが始まっているという。将来の情報漏えいに備えるために、現時点から「価値の高い長寿命データを中心に、量子的に安全な暗号アルゴリズムへの計画的移行を進める」ことが推奨されている。

　同社の米国における顧客企業では、米国国立標準技術研究所（NIST）が現時点で標準アルゴリズムとして選定している3つのアルゴリズムに対応した例があり、Thalesでもこれらの方式をサポートしているというが、日本ではまだ標準化の作業が進行中という段階である。なお、舟木氏は「既存の暗号化方式であるAESでも充分に鍵長を長くすることで耐量子性を持たせられる」ことを紹介した上で、将来のPQCへの移行に備えて鍵管理を明確化するなど、現時点でもユーザー企業がPQC時代を見据えて着手できる作業がさまざま存在していることが指摘された。
Cano氏はPQCに関して、同社が現在独自のPQC対応の暗号処理専用プロセッサーを搭載したハードウェアによるセキュリティモジュールを2026年中の市場投入を目指して開発中だと明かした。

　このモジュールは、将来的な暗号アルゴリズムの進化に対応してアルゴリズムをアップデート可能とすることに加え、PQC対応の独自暗号処理プロセッサーによって複雑で処理負荷の重い耐量子暗号を高速に処理することを目指している。

　現在、同社のハードウェア製品は半導体メーカー製のプロセッサーを採用して暗号化処理を行っているが、新しいプロセッサーは耐量子暗号を高速処理することを目指して同社が独自設計したもので、「数週間前に社内のエンジニアが試作チップを受け取ったばかりというタイミングだが、既に満足のいくパフォーマンスが得られており、スケジュール通りに2026年半ば頃に製品化できる予定だ」という。

　この独自暗号処理プロセッサーによって同社は「耐量子暗号の分野においても暗号処理モジュールのマーケットリーダーとして最良の製品を提供できるものと確信している」とする。

　タレスDISジャパン サイバーセキュリティプロダクト事業本部 本部長の兼子晃氏は、日本ではまだThalesの知名度が低いことが課題としながらも「皆さまの目に見えないところでデータを守っている」と語り、「Thalesを日本で認知して頂き、データセキュリティのマーケットを日本で発展させていく」ことに取り組むとした。",[],[]
グーグル、オンプレミス版「Gemini」を提供開始--法人向けに管理機能を強化（ZDNET Japan）,https://news.yahoo.co.jp/articles/30380e28cd3ae5eb172f2835f54b84feb1212261,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250829-35237342-zdnet-000-2-view.jpg?exp=10800,2025-08-29T10:30:00+09:00,2025-08-29T10:37:26+09:00,ZDNET Japan,zdnet,ZDNET Japan,1491,"グーグル、オンプレミス版「Gemini」を提供開始--法人向けに管理機能を強化の画像
企業による人工知能（AI）の配備に関しては、成功を妨げる障壁がいくつか存在する。具体的には、AIの活用法をよくわかっていない上層部や、AIサービスに与える情報のクリーニングと体系化がこれにあたる。

企業内AI導入促進の起爆剤に

　そんな中、Googleは米国時間8月28日、同社の大規模言語モデルのAIプログラム、「Gemini」シリーズのオンプレミス版の提供を始めると発表した。これは「Google Distributed Cloud」（GDC）のオンプレミス製品によって提供される。同社はこれにより、企業内でのAI導入が促進されることを期待している。

　今回の発表は、Googleの親会社にあたるAlphabetが4月に行った、オンプレミス版Geminiの導入予定に関する当初の発表に続くものだ。「GDCでも顧客にGeminiの提供を開始すると発表できることに、胸を躍らせている。これにより、Googleの最も高性能なモデルを、顧客のデータセンターに直接投入することが可能になる」とGoogleは述べている。

　Googleは、このバージョンをいち早く導入した著名な顧客の例として、シンガポールの戦略的情報通信技術センター（CSIT）や政府技術庁（GovTech）、ホームチーム科学技術庁（HTX）、ならびに日本のKDDIやLiquid C2などを挙げた。

オンプレミスでの利用に向けた新機能

　Googleは今回の発表で、オンプレミス環境での生成AIの利用例として、以下のような新機能を挙げた。

大企業向けの言語翻訳
文書解析のようなツールを利用した迅速な意思決定
チャットボットを通じた24時間年中無休の顧客サポート
Geminiのコード自動化機能を用いた社内でのソフトウェア開発の迅速化
「有害なコンテンツ」の自動フィルタリングによる安全対策、およびコンプライアンスの順守に向けた措置の実施

　GDC製品には、Geminiと連携するいくつかの要素が含まれている。具体的には、Googleのエージェント型AIフレームワーク「Agentspace」、企業向けマネージドプログラミングツール「Vertex AI」、Googleのオープンソース型AIモデルシリーズ「Gemma」、タスク特化型AIモデル、そしてデータセンター向けGPU「NVIDIA　Blackwell 300」などの「Google Cloud」で使用する全ハードウェアなどがある。

　Googleはさらに、同社が持つオンプレミスインフラの管理能力を強調した。「フルマネージド型のGeminiのエンドポイントが、顧客やパートナーのデータセンター内で利用可能で、シームレスでゼロタッチのアップデート体験が得られる。また、Geminiにはエンドポイントの自動ロードバランシングと自動スケーリング機能が搭載されており、これを通じて、高度なパフォーマンスと稼働率が維持される。これは当社のL7ロードバランサーと高度なフリート管理機能によって実現されるものだ」

　また、セキュリティ対策としては、Intelの「Trusted Domain Extensions」（TDX）機能を有効化したマイクロプロセッサーや、NVIDIAが「コンフィデンシャルコンピューティング」と呼ぶ機能を備えた同社製のGPUなどが用いられている。

この記事は海外Ziff Davis発の記事を朝日インタラクティブが日本向けに編集したものです。",[],[]
電通総研、Salesforce活用し、しんきん保証基金のローン申込受付システムを構築（ZDNET Japan）,https://news.yahoo.co.jp/articles/c1f156ad27b29d04eb67315d560c15362bc033e1,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250829-35237329-zdnet-000-1-view.jpg?exp=10800,2025-08-29T10:27:00+09:00,2025-08-29T10:27:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,826,"電通総研、Salesforce活用し、しんきん保証基金のローン申込受付システムを構築の画像
電通総研は8月28日、しんきん保証基金の新たなローン申込受付システムを、「Salesforce Experience Cloud」「Service Cloud」を活用して構築し、80を超える全国の信用金庫で活用を開始したと発表した。

　信用金庫の保証業務を担うしんきん保証基金は、利用者と信用金庫の利便性向上のため、2011年より稼働していた既存のインターネット申込受付システムの刷新を計画。旧システムは、新たな保証商品の追加にシステム改修の時間を要することが課題となっていたため、よりスムーズな融資手続きや商品の拡充、利用者の利便性向上を目指し、Salesforce Experience CloudとSalesforce Service Cloudの活用を決定し、構築パートナーとして電通総研を選定した。

　電通総研をパートナーに選んだポイントは、複雑な業務要件と運用後の拡張性を両立できる点で、豊富な標準機能をもつSalesforce製品を採用し、同様の構成で多くの金融機関に導入実績を持つ電通総研の知見が評価されたという。加えて、金融業務領域での高度なシステム導入実績を持つ電通総研の専門組織が、プロジェクト計画から運用までを一貫して支援できる点も評価された。

　新システムは、全国の信用金庫が利用するローン申込受付の共通プラットフォームであり、住宅ローンや消費者ローンなどの受付から事前審査、契約手続き、シミュレーションまでを一貫して行うことが可能。また、顧客や保証商品、申込情報などを一元管理することで、信用金庫やしんきん保証基金、コールセンターでの活用が可能となり、顧客対応の品質向上と業務効率化を実現する。

　既に80を超える全国の信用金庫で活用が開始されており、2025年12月末までには240の信用金庫が新システムに移行する予定だ。",[],[]
顧客エンゲージメントの新興ベンダーが語る「日本企業の成長のカギ」とは（ZDNET Japan）,https://news.yahoo.co.jp/articles/6439543d6f697bdbf49ea427c3a8eed8cc3e362c,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250829-35237336-zdnet-000-2-view.jpg?exp=10800,2025-08-29T10:20:00+09:00,2025-08-29T10:24:18+09:00,ZDNET Japan,zdnet,ZDNET Japan,3091,"Braze
本連載「松岡功の『今週の明言』」では毎週、ICT業界のキーパーソンたちが記者会見やイベントなどで明言した言葉を幾つか取り上げ、その意味や背景などを解説している。

　今回は、Braze 代表取締役社長の水谷篤尚氏と、Cohesity Japan 執行役員 フィールドマーケティング戦略担当の高井隆太氏の「明言」を紹介する。

「日本企業の成長のカギは“顧客接点力”の強化にある」
（Braze 代表取締役社長の水谷篤尚氏）

　顧客エンゲージメントプラットフォームをSaaSで提供する米Braze（ブレイズ）の日本法人Brazeの水谷氏は、同社が先頃開いた顧客エンゲージメントのデータ基盤「Braze Data Platform」の発表会見で、上記のように述べた。社名と同じ「Braze」と呼ぶ顧客エンゲージプラットフォームと今回発表したデータ基盤が「顧客接点力の強化」に貢献するというわけだ。2011年創業のベンチャー企業だが幅広い分野で注目されており、会見で話を聞いて今後の高成長が期待できると感じたので、上記の発言を明言として取り上げた。

　SaaSであるBrazeはモバイルを活用した「多様に変化する顧客心理に個別に即応する顧客エンゲージプラットフォーム」で、企業はこれを利用することで「消費者行動にリアルタイムで対応し、顧客一人一人にAIがシナリオ設計した最適なコミュニケーションを、最適なチャネルやタイミングで届けることが可能になる」としている。

　同社が今回発表したBraze Data Platformについては発表資料をご覧いただくとして、ここでは水谷氏の発言に注目したい。

　同氏によると、Brazeは米国ニューヨークに本社を置き、グローバルで10カ所超の営業拠点を持つ。顧客社数は2200社を超え、1カ月当たりのアクティブユーザー数は72億人。日本法人は2020年に設立し、2021年にはニューヨーク株式市場に上場した。

　水谷氏は会見の冒頭で、「日本企業の競争力は、ものづくりについては世界をリードしているが、顧客接点力が不足している。日本企業の成長のカギはその強化にある。当社はそれに対してデジタルの力で貢献したい」と力を込めた。冒頭の明言は、この発言から取り上げたものである。

　同氏はBrazeが求められる市場変化と背景について、図1に示すように5つの観点で語った。

　図1の内容については一目瞭然なので説明は省くが、一言で述べられている「変化軸」が非常に興味深い。

　そして、この5つの変化軸に対応すべく、図2に示した5つのことを可能にしたのがBrazeであり、Braze Data Platformである。顧客エンゲージメントを手掛けているだけあって、うまい説明だと思った。

　さらに筆者が注目したのは、国内の主要な導入企業を示した図3だ。国内での活動は4年半ほどで、顧客社数は100社超とのことだが、各分野の有力企業が名を連ねている。

　水谷氏はこの導入企業の動きについて、「当初はECプラットフォームをはじめとしてデジタルネイティブなお客さまが多かったが、その後、店舗を展開されているリテールやアパレル、さらに最近ではトラディショナルな金融分野にも広がっており、顧客エンゲージメント市場のポテンシャルを強く感じている」との手応えを語った。

　ただ、顧客エンゲージメントはこれからますます激戦市場になっていくだろう。そうした中で、Brazeが存在感を発揮し続けるための決め手は何か。会見の質疑応答で聞いてみたところ、水谷氏は次のように答えた。

　「モバイルを使い、AIもフル活用し、時代の変化に対応した最先端の顧客エンゲージメントを提供できているのは、Brazeだけだと自負している。しかもそれを支えるテクノロジーを全て自社で開発しており、当面は他社の追随を許さないと確信している」
　今後、ビッグテックに買収されることなく、さらに大ブレイクすることを期待したい。
「企業はBCPとしてサイバーレジリエンス対策を急ぐべきだ」
（Cohesity Japan 執行役員 フィールドマーケティング戦略担当の高井隆太氏）

　米Cohesityの日本法人Cohesity Japanの高井氏は、同社が先頃開いた「医療機関におけるサイバーレジリエンスの強化と事業継続計画（BCP）を推進した最新事例」をテーマにした記者説明会で、上記のように述べた。BCPとしてのサイバーレジリエンス対策の重要性は筆者もかねて強く感じていたので、上記の発言を明言として取り上げた。

　近年、日本国内でも医療機関を標的としたランサムウェア攻撃やサイバー攻撃が深刻化しており、実際に一部の医療機関では数週間から数カ月にわたる業務停止を余儀なくされる事例も発生している。こうした状況を受け、厚生労働省は全国の医療機関に対し、サイバー攻撃や自然災害からの早期復旧を目的としたBCPの策定をガイドラインとして促している。

　そうした中で、同社は、東京都の北多摩南部医療圏（人口約100万人）を支える基幹病院である武蔵野赤十字病院におけるサイバーレジリエンスとBCP強化の取り組みをCohesityが支援した事例について公開した。高井氏が会見で説明したその内容については関連記事をご覧いただくとして、ここではBCPとしてのサイバーレジリエンス対策という捉え方で考察したい。

　まず、企業におけるBCPの策定率は現在どれくらいの割合なのか。帝国データバンクが先頃発表した「BCPに関する企業の意識調査」の結果によると20.4％で、2016年から毎年実施して以来、初めて2割を超えた。企業規模別に見ると、大企業が38.7％だったのに対して中小企業は17.1％と、格差が広がりつつある実態が明らかになった。企業にとっては費用対効果（ROI）からすると二の足を踏みがちな取り組みだが、筆者の印象としては「まだまだこの程度なのか」といった感じだ。ただ、企業におけるBCPの策定率については、調査によってばらつきがあることを申し添えておく。

　また、どのようなリスクによって事業の継続が困難になると想定しているかを尋ねた帝国データバンクの調査結果では、地震や風水害、噴火などの「自然災害」が70.8％（複数回答、以下同）と突出して高かったが、サイバー攻撃などの「情報セキュリティ上のリスク」も46.1％と2位につけている状況が明らかになった。

　さらに、事業が中断するリスクに備えて実施あるいは検討している内容を尋ねた調査結果では、68.3％（複数回答、以下同）で最も高かった「従業員の安否確認手段の整備」に続いて、「情報システムのバックアップ」が59.9％で2位となった。

　こうした調査結果から、かつてはBCPと言えば災害対策のイメージが強かったが、最近では情報セキュリティ上のリスクに対しても企業の危機意識が高まってきていることが見て取れる。

　会見の質疑応答で、医療機関に限らず、企業におけるBCPとしてのサイバーレジリエンス対策への取り組み状況について高井氏に聞いてみたところ、「バックアップについては対応されているが、迅速かつ確実に業務を復旧できるようにするレジリエンスへの取り組みはこれからというところが多い」とのこと。冒頭の明言はこの流れの発言だ。

　改めて、事業継続はすなわちレジリエンスであることを肝に銘じておきたいところだ。",[],[]
ホーチキ、施工支援システムにミークの「MEEQ SIM」を採用--試験業務を効率化（ZDNET Japan）,https://news.yahoo.co.jp/articles/85c448918278c37811ee088c9a2b429df7673526,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250829-35237326-zdnet-000-1-view.jpg?exp=10800,2025-08-29T10:16:00+09:00,2025-08-29T10:16:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,793,"ホーチキ、施工支援システムにミークの「MEEQ SIM」を採用--試験業務を効率化の画像
防災・防犯事業を手がけるホーチキは、自社開発した火災報知システム施工時の試験業務を効率化するクラウド型施工支援システム「Air-R」の通信に、データ通信サービスなどを手がけるミークの「MEEQ SIM」を採用した。8月28日にミークが発表した。

　火災報知システムの施工現場では、動作確認のために設置された感知器や発信機を一つずつ試験する必要があり、大規模な建物ほど作業にかかる労力と時間が膨大となる。Air-Rは、こうした課題に対応するためホーチキが社内向けに開発した施工支援用システムで、クラウドと無線通信を活用して火災報知システムの試験作業を効率化する。建物内の感知器や発信機のデータ・状態を火災受信機を介してクラウドにアップロードすることで、タブレット端末上のダッシュボードで可視化できる。

　Air-Rには無線通信が不可欠となるが、火災報知システム施工時の多くの現場は建設中であり、安定した通信環境が整っていないことが多い。そこで、安定した通信を確保するために、ミークのMEEQ SIMが採用された。「MEEQ」は、NTTドコモ、ソフトバンク、KDDI回線のデータ通信専用SIMの利用が可能で、顧客側でシステムを用意しなくとも簡単にIoT回線を追加できる。3キャリアに対応していることや、建物竣工（しゅんこう）前の試験作業に必要なグローバル固定IPアドレスを利用可能な点などを評価して採用に至ったという。

　ホーチキでは、3キャリア分のSIMを1セットとして現場に持ち込む運用をすることで、現場ごとに最も通信状態の良いキャリアを選択して作業を進められるようになった。同社はAir-Rの活用を通じて、自社および施工協力会社における施工作業の効率化と省力化をさらに推進していく計画だ。",[],[]
日立、「鉄道電力分析サービス」を開始--鉄道事業者の電力運用を最適化（ZDNET Japan）,https://news.yahoo.co.jp/articles/ae433f7c5f7dff681f1fcdcbb1eefd059eac0b76,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250829-35237323-zdnet-000-1-view.jpg?exp=10800,2025-08-29T10:04:00+09:00,2025-08-29T10:04:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,892,"日立、「鉄道電力分析サービス」を開始--鉄道事業者の電力運用を最適化の画像
日立は、鉄道事業者のエネルギーマネジメントを支援する「鉄道電力分析サービス」を、8月28日から提供することを発表した。

　近年、鉄道業界は気候変動への対応が急務であり、加えてエネルギー価格の高騰による輸送コストの増加も課題となっている。こうした背景から、環境負荷を低減しつつ経済的にも持続可能な輸送事業の実現が求められており、鉄道電力運用の改善が不可欠となっている。鉄道電力分析サービスは、こうした課題を解決するもので、鉄道事業者が保有する車両や設備情報、運行や送電の実績データなどを日立独自の鉄道システム統合シミュレーターで総合的に分析することで、電力運用を最適化し環境負荷低減とコスト削減の両立を目指す。

　サービス開始に先立ち日立は、複数の鉄道事業者とサービスを試行。ピーク時における瞬時最大電力や全体の消費電力量削減の有効性を確認した。特に、電車が停止・減速する際に生み出される回生電力が消費や貯蔵されず、ブレーキの制動力が低下する回生失効の発生は、約70％削減できるという。

　「鉄道電力分析サービス」により、現場データの総合的な分析による課題の可視化ができ、個別の事象からは発見が困難な潜在的な課題についても、鉄道システム統合シミュレーターを用いることで、その原因特定が可能となる。また、車両の運転記録データに依存せず、路線全体の網羅的かつ緻密（ちみつ）な分析ができるため、車両から取得できるデータが限られている場合でも、運行ダイヤなど車両以外の既存データを活用して不足分を補完して路線全体の分析が可能となる。加えて、日立グループが持つ鉄道インフラ各分野の知見を活用し、分析結果に基づく改善検証から施策導入まで、鉄道事業者の課題解決をワンストップで支援する。

　日立は今後も、鉄道事業者における設備やオペレーションの継続的な改善を支援していく方針で、分析環境の高度化や既存システムとの連携による最適な運用計画の立案、状況に応じたエネルギーのリアルタイム制御など、機能の拡充を目指していく。",[],[]
OpenAI、「ChatGPT」の利用者保護を強化へ--10代の自殺をめぐる訴訟を受けて（ZDNET Japan）,https://news.yahoo.co.jp/articles/fd154ecbca2cae7cee2eeb68a1c2daf639fbddfe,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250829-35237322-zdnet-000-1-view.jpg?exp=10800,2025-08-29T09:07:00+09:00,2025-08-29T09:07:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,1842,"提供：Yifei Fang/Moment via Getty Images
「ChatGPT」はこれまで、精神的に苦しんでいる利用者への対応が十分とは言えなかったが、OpenAIは最近発表した幾つかのアップデートによって、その改善に取り組んでいる。

　OpenAIは、チャットボットが困難な状況にある利用者にどう応答するかについて、セーフガードの強化や不適切なコンテンツのブロック方法の見直し、介入の拡充、緊急時リソースの地域対応、必要に応じた保護者の会話への参加などを通じて改善を図っていくという。将来的には、保護者が子どものチャットボット利用状況を把握できるようになる可能性もある。

　人々はさまざまな目的でChatGPTを利用しており、その中には助言を求めるケースも含まれる。しかし、チャットボットは一部の利用者が投げかける繊細な質問に対して、十分に対応できない可能性がある。OpenAIの最高経営責任者（CEO）であるSam Altman氏も、プライバシーの懸念からAIにセラピーを任せることには慎重な姿勢を示している。実際、スタンフォード大学の最近の研究では、チャットボットには人間のセラピストが持つ重要な訓練が欠けており、危険な状態にある人を特定する能力が不十分であることが詳しく述べられている。

　こうした欠点は、深刻な結果を招くことがある。4月には、自殺についてChatGPTと何時間も会話を続けていた10代の少年が、最終的に命を絶ったという痛ましい事件が起きた。少年の両親はOpenAIを訴え、ChatGPTが少年の自殺願望を認識していたにもかかわらず、セッションを終了させたり、緊急対応を開始したりしなかったと主張している。同様の事例として、AIチャットボット基盤のCharacter.aiでも、ボットから自殺を促されたとされる10代の息子を亡くした母親が訴訟を起こしている。

　ChatGPTにはセーフガード機能が備わっているが、短いやりとりでは効果的に機能する一方で、「やりとりが長引くと、モデルの安全訓練の一部が劣化することがある」とOpenAIは発表で述べている。会話の初期段階ではチャットボットが自殺予防ホットラインを案内することがあっても、時間が経つにつれて会話がそれ、セーフガードに反する回答をしてしまう可能性があるという。

　同社は「これこそ、われわれが防ごうとしている事態であり、最優先事項はChatGPTが困難な状況をさらに悪化させないようにすることだ」と強調している。

　このような問題に対処するため、OpenAIはセーフガードの全体的な強化に取り組んでいる。会話が続く中で、チャットボットが利用者の行動を扇動したり助長したりすることを防ぐための対策である。また、不適切なコンテンツの徹底的なブロックも重要な課題であり、これは同社が過去に直面してきた問題でもある。

　OpenAIは「保護機能が適切なタイミングで作動するよう、ブロックの閾値を調整している」と説明している。

　同社は、利用者が自傷行為をほのめかした場合に、チャットボットが緊急サービスや専門家の支援につながりやすくすることを目指している。すでに緊急サービスへのワンクリックアクセスを導入しており、認定セラピストへの接続も検討中である。また、「人々が身近な人に連絡を取りやすくする方法を模索している」と述べ、利用者が緊急連絡先を指定したり、愛する人との会話を始めたりしやすくするための対話設定の導入も検討しているという。

　さらに、OpenAIは「保護者が10代の子どもによるChatGPTの利用状況をより深く理解し、適切に管理できるようにするためのペアレンタルコントロール機能を近く導入する予定だ」と付け加えている。

　最近リリースされた「GPT-5」モデルでは、感情的な依存の回避、過度な追従性の抑制、精神的な緊急事態に対する不適切な応答の防止など、複数のベンチマークにおいて25％以上の改善が報告されている。

　「GPT-5は“セーフコンプリーション”と呼ばれる新しい安全訓練手法に基づいて構築されており、安全性の範囲内で可能な限り有益な応答を提供するよう訓練されている。これは、危険な詳細を避け、部分的または高レベルな回答を提供する」（OpenAI）

この記事は海外Ziff Davis発の記事を朝日インタラクティブが日本向けに編集したものです。",[],[]
OpenAI、新たな音声モデル「gpt-realtime」を発表--「Realtime API」も機能強化（ZDNET Japan）,https://news.yahoo.co.jp/articles/1ada2fa42e1dba6828231f150cb08bb41ab3987a,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250829-35237318-zdnet-000-1-view.jpg?exp=10800,2025-08-29T08:33:00+09:00,2025-08-29T08:33:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,2158,"提供：Elyse Betters Picaro / ZDNET
2025年は、ユーザーの代わりにタスクを実行するAIエージェントが大きな注目を集めている。各社は、ユーザーの作業負担を軽減するための製品開発を継続的に進めており、その競争はますます激しくなっている。

　こうしたAIエージェントとのやりとりを、よりスムーズで違和感のないものにするため、多くの企業がマルチモーダルな技術に力を入れている。中でもOpenAIは、こうした製品の開発をより簡単に進められるよう支援している。

　OpenAIは米国時間8月28日、「Realtime API」のアップデートを実施し、一般提供を開始した。今回のアップデートには、開発者や企業がより信頼性の高い音声エージェントを構築するための新機能が追加されている。Realtime APIは、2024年10月に初めて公開されたもので、当時はパブリックベータ版として提供されていた。また、同社は「gpt-realtime」と呼ばれるSpeech-to-Speechモデルも併せてリリースしている。

　OpenAIのプロダクト担当者であるMiqdad Jaffer氏は米ZDNETに対し、「われわれは音声を次なるメディアだと考えている」と語った。「人々は、自分のしていることを正確に説明したり、話したりすることを好む傾向がある。ときには、テキストで伝えるよりも、音声で伝える方が簡単で自然に感じられるからだ」とその理由を述べる。

　今回のリリース内容は以下の通りである。

RealTime APIのアップデート

　Realtime APIのアップデートには、リモートModel Context Protocol（MCP）サーバーの導入、画像入力への対応、Session Initiation Protocol（SIP）による電話発信のサポートが含まれている。OpenAIは発表時のライブストリームで、MCPは音声コマンドに適しており、ユーザーが接続されたアプリからシームレスにアクションを実行できる仕組みであると説明した。

　これらの機能拡張によって、音声エージェントはより多くのツールにアクセスできるようになり、ユーザーを支援するための情報や文脈をより豊富に持てるようになると期待されている。AIツールは、提供される情報があって初めて有用になるため、AIモデルを適切なデータソースに接続するプロセスを効率化することは、開発者とユーザーの双方にとって大きなメリットとなる。

　さらに重要な点として、MCPはオープンスタンダードであるため、接続の確実性が担保されており、ユーザーのデータとプライバシーが優先される設計となっている。

新しいSpeech-to-Speechモデル

　OpenAIは、新たなgpt-realtimeを、同社で最も先進的で、実運用に対応した音声モデルとして位置付けている。このモデルでは、性能の向上に加え、複雑な指示への対応力や関数呼び出しの精度が改善されている。話している途中で言語を切り替えられる点も特徴となっている。

　デモでは、抑揚を通じて幅広い感情を表現する様子が示され、人間らしさが際立っていた。また、指示への対応も非常に的確であるように見えた。例えば、OpenAIの従業員がシステムプロンプトに矛盾するような操作を試みる「ジェイルブレーク（脱獄）」のシミュレーションを行った際、gpt-realtimeは冷静に対応し、意図された方向へと修正を加えながら、そうした試みに屈しなかった。さらにこのモデルは、写真を分析し、そこに何が写っているかについて会話することも可能である。

　前述の機能は、Jaffer氏が特に気に入っているものの1つである。「私が最もエキサイティングだと感じているのは、モデルの指示への追従性だ。モデルを使って開発する上で重要なのは、信頼できる一連の指示を与え、それをモデルが一貫して実行できるようにすることだ」

　またOpenAIは、「Cedar」と「Marin」という2種類の新しいボイスも追加しており、これらはRealTime APIでのみ利用可能となっている。

　これらの新しいモデルが、OpenAIの主張通りに機能すれば、より自然な音声を生成し、実際にユーザーのタスクを支援できるようになるだろう。その結果、ユーザーはより快適で満足度の高い体験を得られるはずだ。

提供時期

　Realtime APIとgpt-realtimeモデルは、同日から全ての開発者に向けて提供されている。「OpenAI Playground」上でモデルを試すことができ、参考としてRealtime APIのドキュメントを読むことが推奨されている。

　開発者が考慮すべき点について尋ねられた際、Jaffer氏は「ユーザーにとって最善のことを行ってほしい」と述べた。そして続けて、「ユーザーにとって最善のことの1つは、快適で簡単な方法でやりとりできることであり、われわれは音声がその未来だと信じている」と語っている。

この記事は海外Ziff Davis発の記事を朝日インタラクティブが日本向けに編集したものです。",[],[]
Anthropic、「Claude for Chrome」を公開--ブラウザー拡張機能でウェブ操作を支援（ZDNET Japan）,https://news.yahoo.co.jp/articles/7efc11bf7184a7c399cbf6fcce1b814de14194d3,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250829-35237316-zdnet-000-1-view.jpg?exp=10800,2025-08-29T07:27:00+09:00,2025-08-29T07:27:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,1938,"提供：DrPixel/Moment/Getty Images
AnthropicのAIモデル「Claude」は、Perplexityの「Comet」やThe Browser Companyの「Dia」のように、AIをブラウザーに組み込む流れに追随している。Anthropicの最初の取り組みとして、「Chrome」向けの拡張機能がクローズドベータとして提供されている。

　この拡張機能を使うことで、Claudeとチャットできるサイドパネルがブラウザー上に常時表示され、ブラウザーセッションの文脈を保持したまま会話が可能となる。会話型AIとしての機能に加え、ウェブサイトの読み取り、ナビゲーション、アクションが行える。具体的には、「Zillow」で物件を探したり、ドキュメントを要約したり、ショッピングカートに商品を追加したりといった作業を、ブラウザーのサイドバーから直接実行できる。

　Anthropicがこのアプローチを取る理由として、「AIがブラウザーを使うのは必然である」との見解を示している。多くの作業がブラウザー上で行われている現状を踏まえ、Claudeにユーザーが見ている内容を把握させ、ボタンをクリックしたりフォームを入力させたりすることで、AIの有用性が大きく向上すると考えているのだ。

　ただし、この拡張機能をすぐに使えるユーザーは限られている。初期リリースでは、「Claude for Chrome」はClaude Maxプランの加入者のうち、わずか1000人にしか提供されない。Maxプランには2つのレベルがあり、料金は安くない。月額100ドルのプランでは通常の5倍の使用量が、月額200ドルのプランでは20倍の使用量が提供される。加入者はClaude for Chromeを試すためのウェイトリストに登録も可能だ。

　一方で、この拡張機能に対して懐疑的な声もある。「Ycombinator」のあるコメント投稿者は、「Claude for Chromeは“致命的な三拍子”に足を踏み入れているように見える」と指摘している。

　「致命的な三拍子」とは、以下の3つの能力を指す：

ユーザーのプライベートデータへのアクセス--ツールの主な目的の1つである

信頼できないコンテンツへの露出--悪意ある攻撃者が制御するテキストや画像が大規模言語モデル（LLM）に届く可能性

外部との通信能力--データを盗み出す手段として使われる可能性がある（「exfiltration」と呼ばれるが、この用語が広く理解されているかは不明）

　この3つの機能を兼ね備えたエージェントは、攻撃者によって簡単にユーザーのプライベートデータにアクセスさせられ、それを外部に送信させられる危険性がある。

　Anthropicはこうした危険性を認識しており、実際にClaude for Chromeの安全性を確保するために、敵対的なプロンプトインジェクションを広範にテストしている。具体的には、29種類の攻撃シナリオに基づく123のテストケースを評価した。その結果、安全対策を施していない状態では、悪意ある攻撃者による攻撃成功率は23.6％に達したという。

　このような攻撃を防ぐために、Claude for Chromeでは強固な権限管理システムが導入されている。ユーザーは、各ウェブサイトや特定の操作に対して明示的な許可を与える必要があり、購入やアカウント変更といった機密性の高い作業には、より厳格なセキュリティが適用される。また、ユーザーはClaudeが自律的に行動できる場面と、人間の承認が必要な場面を細かく設定できるカスタマイズ可能なコントロール機能も利用できる。

　さらに、Claude for Chromeは金融サービス、アダルトコンテンツ、海賊版コンテンツなど、リスクの高いカテゴリーに属するウェブサイトでは使用できないよう制限されている。

　それでもなお、全ての防御策を講じた状態でも、攻撃成功率は11.2％に達した。これは決して安心できる数字ではない。

　そのため、Anthropicはユーザーに対して、この拡張機能を慎重に使用するよう警告している。プライベートな情報や本格的な業務にこのツールを使うことは避けるべきだと明言しており、リスクを理解した上で試してほしいという姿勢を取っている。つまり、Anthropicは「危険な領域に足を踏み入れることになる」と警告しているわけであり、ユーザーがそのリスクを承知の上で利用することが求められている。

この記事は海外Ziff Davis発の記事を朝日インタラクティブが日本向けに編集したものです。",[],[]
「経費精算のない世界」へ--コンカーが新ビジョンと事業戦略を発表（ZDNET Japan）,https://news.yahoo.co.jp/articles/e70668aa5fa14014a76502881722b719286deb60,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250829-35237303-zdnet-000-1-view.jpg?exp=10800,2025-08-29T07:00:00+09:00,2025-08-29T07:00:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,3858,"コンカー 代表取締役社長の橋本祥生氏（中央）、カスタマー＆ソリューション統括本部 プロダクトマーケティング部 部長の舟本憲政氏（左）、サービス・サポート本部 クライアントサポート 第1グループ マネージャーの遠藤智範氏（右）
コンカーは8月28日、事業戦略に関する記者会見を開催し、新たなビジョン「経費精算のない世界、その先へ」を発表した。併せて、「SAP Concur」で今後リリース予定の新機能や、同社が取り組む人材の成長戦略についても紹介された。

　コンカー 代表取締役社長の橋本祥生氏は冒頭、間接費領域を取り巻く社会課題として「労働生産人口の減少」「低い収益性」「ガバナンスの問題」の3つを挙げた。これらの社会的背景を踏まえ、非競争領域である間接業務の抜本的な対策が急務だと強調した。

　その上で、現在急速に拡大している生成AIは、経費精算領域において大幅な生産性の向上、収益の改善、ガバナンス対策の拡大が見込まれるとした。だが、生成AIは大きな成果が期待される一方で、懸念点も存在する。具体的には、不正確な情報（ハルシネーション）や質の低い情報（多様性の欠如）、個人情報保護や倫理準拠の欠如といった問題である。

　コンカーは、長年にわたり築き上げてきた強固なパートナーエコシステムを生かし、決済データや連携先から得られるデータ、カスタマーサクセスで培った設定・運用のベストプラクティスを保有している。さらに、年間10億件の経費明細や3000万件の出張データといった膨大なビッグデータもその強みの1つであるという。

　これらの資産に、AIエージェントやAIチャットボットといった技術を組み合わせることで、人の手を介さずに業務を効率化し、ガバナンスの強化と自律的な運用を実現する。そして最終的には、企業の成長を支える戦略的なデータインサイトの提供へとつなげていく。

　コンカーでは、近い将来、あらゆる業界で「経費精算のない世界」が完全に実現され、経費精算業務そのものが消滅すると考えている。その実現に向けて、同社は「Vision2028」と題した3つのステップを策定し、今後はこのロードマップに沿って取り組みを進めていく方針である。

　まず目指すのは、経費精算のない世界に向けて、高度な業務効率化とガバナンス強化の両立である。AIエージェントやAIコパイロットを活用することで、利用者・管理者・運用者の業務を自動化・自律化し、ユーザーは手入力をせずに内容を判断するだけで業務が完結する世界の実現を目指している。

　次に、自律運用の実現である。これまで人手に頼っていたSAP Concurの導入・設定・運用をAIが支援することで、作業負担を大幅に軽減する。さらに、国・業種・業界に応じたベストプラクティスを自動または対話型で適用することで、運用効率の飛躍的な向上を図る。

　最後に、データの民主化を推進する。国内外から集められたビッグデータを活用し、データを起点とした業務最適化、ガバナンス強化、収益改善を支える戦略的インサイトの提供を目指している。

　続いて、コンカー カスタマー＆ソリューション統括本部 プロダクトマーケティング部 部長の舟本憲政氏が、SAP Concurで2025年末以降にリリース予定のAI新機能について説明した。

　まず、SAP Concur全体に関わる機能として、「Conversational Help Search with Joule」が導入される予定である。これは、自然言語による会話を通じて業務を支援するもので、ユーザーが知りたい情報について生成AIアシスタント「Joule」との対話を通じて生成AIが即座に回答を作成し、その根拠となるソース情報も併せて表示される仕組みである。

　また、「Administrator Consultation with Joule」では、SAP Concurの設定作業をAIが支援し、監査ルールなどの分析や改善がJouleとの対話だけで完結するようになる。

　「Concur Travel」においては、すでにリリース済みの「Flight Recommendation」が、個人の好みや会社の規定に基づいて最適なフライトを提案する機能として活用されている。さらに、2025年末には「Booking Agent」が登場し、Jouleとの対話だけで出張手配が完了するようになる。これにより、個人の希望や企業ポリシーに沿った最適なフライトの提案が可能となる。

　また、「Meeting Location Planner Agent」では、世界各地にいるチームメンバーのグループ出張を自動で調整し、出張費用の計画・見積もり、最適な会合場所の設定、宿泊施設やフライトの提案までをAIエージェントが担う。

　「Concur Expense」では、「Expense Report Validation Agent」が導入される予定で、経費申請前にAIが抜け漏れを自動検出し、チャットを通じてサポートすることで、正確かつコンプライアンスに準拠した経費精算レポートの提出を支援する。これにより、差し戻しの削減と経理部門の負荷軽減が期待される。

　また、「Policy Trip Tips」では、AIが会社規定を自動的に読み取り、申請者に必要な情報を表示することで、従業員の規定順守をサポートする。

　橋本氏は今後の事業成長のポイントとして、「カスタマーサクセス」「公共向けビジネス」「政策提言活動」の3つを挙げた。
カスタマーサクセスでは、SAP Concurが業界シェア1位を維持している理由として、同社が最先端のサービス提供に加え、導入後も顧客の継続的な業務改革を支援する体制が整っている点にあるとした。単にシステムを導入・稼働させるだけでなく、定期的な状況把握や現状分析を通じて、顧客の行動変容や企業風土の改革を促しているのだという。

　また、独自の「成熟度マップ」に基づく改善提案を行い、最終的な業務改革の実現までを見据えたサポートを提供している。こうした取り組みにより、世界の中でも、日本は特に高い継続利用率を維持している、と橋本氏は語った。

　公共向けビジネスへの取り組みでは、公共団体が抱える3つの大きな課題の解決があるとした。まず、少子高齢化に伴う職員数の減少は「2040年問題」とも呼ばれ、業務効率化や非生産業務の廃止が急務となっている。次に、日本の行政におけるデジタル化の遅れは、他国と比べて顕著であり、改善が求められている。さらに、2024年4月の改正旅費法施行に伴い、旅費運用の見直しを進める自治体が増加している。

　コンカーでは、民間企業で培った間接業務におけるデジタル変革（DX）のノウハウを生かし、日本の公共団体の競争力強化に貢献できると考えている。そのため、日本国内にデータセンターを開設し、「政府情報システムのためのセキュリティ評価制度」（ISMAP）認証を取得するなど、公共団体への導入を着実に進めている。

　政策提言活動では、2024年3月からインボイス制度に関する政策提言活動を積極的に展開している。インボイス制度の導入により、経費精算にあらためて領収書が必要となり、同社の試算では、日本のビジネスパーソンの生産性が年間約1.4兆円損なわれているという。

　こうした課題に対応するため、ビズリーチ、マネーフォワード、ラクスなど同業他社と連携し、「経費MIRAI協議会」を設立。制度と実務の橋渡しを加速し、日本人の業務効率化をさらに推進することを目指している。

　コンカー サービス・サポート本部 クライアントサポート 第1グループ マネージャーの遠藤智範氏が、同社の人材成長について明らかにした。

　同氏はまず、「働きがい」について言及し、現在同社は「働きがい第2章」へと踏み出していると語った。第1章では、フィードバックや感謝、教え合いといった社内文化の醸成に注力してきたが、第2章では、これまで培ってきた文化的資産を社会への価値提供へと転換していく段階に入っているという。技術の進化に合わせて社内文化をさらに洗練させ、AI時代における従業員の業務的価値を高めていくとのこと。

　この転換の中で誕生したのが、全社的なAI活用を推進するタスクフォース「xAI（カケアイ）」である。このチームは、2025年の目標として業務効率を30％向上させ、17万時間の削減を掲げている。これにより、社員はより高付加価値な業務に時間を割けるようになり、働き方の質が向上することが期待されている。コンカーのビジョンは「AIと共生して顧客体験を革新する」ことであり、SAPグループ全体としても「AIファースト」を戦略の柱に据え、全社的に取り組みを進めている。

　遠藤氏は、AI時代にふさわしい「人の価値」を再定義していくことをコミットメントとして掲げている。各社員がリーダーシップを発揮し、人間にしかできない価値を高めていくことが重要だとし、xAIで培ったAI変革の知見や共創型のフレームワークを、顧客やパートナーと共有していく姿勢を示した。こうした取り組みによって、エコシステム全体での共創と成長を実現し、「高め合う文化」を社会にも広げながら、AIと共により良い働き方を築いていくとした。",[],[]
AI導入に“プラグ＆プレイ”は通用しない--成功のカギは業務に即したカスタマイズ（ZDNET Japan）,https://news.yahoo.co.jp/articles/fa5bd95127595e2bf56a93407fcb9d7a98cbd177,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250829-35237276-zdnet-000-1-view.jpg?exp=10800,2025-08-29T07:00:00+09:00,2025-08-29T07:00:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,3528,"提供：Elyse Betters Picaro / ZDNET
人工知能（AI）への憧れと、実際のプロジェクトの成功の間には、大きな隔たりがあるという。マサチューセッツ工科大学（MIT）による最近の調査で、企業に測定可能な価値をもたらす生成AIプロジェクトは5％に過ぎないことが明らかになった。上位5％のプロジェクトは、どこが違うのだろうか。それらに共通するのは、テクノロジーチームがAIを自社のビジネスに合わせて高度にカスタマイズする理論と実践を身に付けている点や、自社単独で進めるのではなく、パートナーシップを育んでいるという点だ。

　こうした企業は非常に深い部分まで掘り下げている。

成功するAIプロジェクトの違い

　成功するAIプロジェクトは、「範囲は限られるが価値の高いユースケースに焦点を当てて、ワークフローに深く統合され、広範な機能セットではなく継続的な学習を通じて拡張している」とMITの調査チーム（Aditya Challapally氏、Chris Pease氏、Ramesh Raskar氏、Pradyumna Chari氏）は記している。「特定の分野の専門知識とワークフローの統合の方が、派手なユーザー体験（UX）よりも重要だ」

　突き詰めると、AIを構築するにせよ、購入するにせよ、単にAIを手に入れることが目的ではない。AIからどうやって利益を得るかが重要だ。「時代遅れのSaaSの手法と格闘する」のではなく、「徹底的にカスタマイズして実際のビジネス課題に即したものにすることで、企業の注目を集める」必要があるという。「目覚ましい成果を上げるには、汎用（はんよう）ツールを構築するのではなく、自らをワークフローに組み込んで、状況に適応し、限定的だが価値の高い基盤を拡張していかなければならない」

　「プラグ＆プレイで利用できるAIは存在しない」。MIT Sloan Executive EducationのIT上級講師であるPaul McDonagh-Smith氏が米ZDNETに語ったこの言葉は、特筆に値する（McDonagh-Smith氏は今回の調査に直接関わっていない）。「外部ツールは時間の節約になるが、真の成果を上げるには、『プラグ＆パーソナライズのAI』、すなわちAIツールをカスタマイズしてワークフローに合わせる作業が必要になる」

　「ChatGPT」のような生成AIツールがパイロットテストで成功した理由は、「その柔軟性にある」と同氏は語る。「だが、ミッションクリティカルな業務では失敗することが多い。その要因として挙げられるのが、記憶能力の欠如だ。これにより、学習能力、適応能力、カスタマイズ性が損なわれ、日常のワークフローに効果的に統合できない」

　MITの調査では、戦略的パートナーシップの確立によって、AIプロジェクトの推進に大きな違いが生まれることが示されている。購入型よりも構築型の取り組みの方がはるかに多く、パートナーシップの成功率は社内開発の取り組みの2倍であるという。そのようなパートナーシップは多くの場合、「価値実現までの時間の短縮、総コストの削減、業務ワークフローへの適合性の向上を実現した。企業は一から構築する場合のオーバーヘッドを回避しつつ、カスタマイズされたソリューションを構築できた」

購入か構築か

　それでも、AIの推進者や開発者は、自社開発が最適なのか、ベンダーやネットワークパートナーなどの外部協力者と連携すべきなのかを、状況に応じて判断する必要がある。その決定において「判断の分かれ目となるのは、スピード、規模、専門知識が求められており、社内チームがビジネスの求める期限に対応できない場合だ」とMcDonagh-Smith氏。「そのプロジェクトが競争力強化のカギを握る場合は、社内開発が理にかなっているが、注意が必要だ。慢心に足をすくわれるおそれがある」

　外部のソリューションを利用すると、必要なカスタマイズの機会が減るという懸念もあるが、これは根拠のない不安だとMcDonagh-Smith氏は考えている。「AIは『プラグ＆プレイ』というより『プラグ＆パーソナライズ』であり、既存や新規のワークフローに適合させるものだ。私の見解としては、AIの成否は外部AIツールの選定で決まるのではなく、AIを自社の考え、業務、行動に適合させる社内の能力によって決まる」

　他の業界リーダーも、AIの成功は個々の状況で決まるという考えだ。Wasabi Technologiesの共同創業者で最高経営責任者（CEO）を務めるDavid Friend氏は次のように述べた。「社内チームを活用するか、他のベンダーにアウトソーシングするかは、AIに何をやらせたいかによって変わる。AIであれ何であれ、企業の中核的な差別化要因となる技術や、価格競争で優位に立てる技術は、社内で開発して管理すべきだ。提供する製品やサービスの核心ではないなら、外注すればいい。他社との違いを出せるものには、自社で対応しなければならない。事業の中核ではないものは外注しよう」

　このプロセスでは、最初に適切な問いかけをする必要もある。「問題は、その技術を構築できるかどうかではなく、構築すべきかどうかだ」。Fisent Technologiesの創設者でCEOを務めるAdrian Murray氏はこう指摘する。「非常に有能で予算が潤沢な技術チームがいたとしても、その能力には本質的に限界があるので、最も価値の高い取り組みに注力する必要がある。力を入れるべきは、他と異なる価値を生み出せる取り組みだ。これらの技術を具体的なビジネス課題に適用しよう。ソリューションベンダーから簡単にライセンスを購入できるコアテクノロジーインフラストラクチャーを構築する必要はない」

　パートナーシップの性質も、AIの成否を決定づける要素だ。単なる取引契約以上の関係を築く必要がある。MITのレポートによると、「優れた買い手は、AIスタートアップをソフトウェアベンダーというよりビジネスサービスプロバイダーとして扱い、コンサルティング会社やビジネスプロセス最適化プロバイダー向けのものに近い基準に照らして評価する」とされている。これには、成果に結びつく社内のプロセスとデータに合わせた高度なカスタマイズが含まれる。

　「既存と新規のワークフローを分解・分析して、生成AIと相性の良い（または悪い）パターンを割り出そう。生成AIの準備ができたら、ワークフローを進化させて、再統合する」とMcDonagh-Smith氏は助言する。
社内における草の根的なAI導入

　今回の調査では、成功するAIプロジェクトの多くが草の根レベルから始まることも示されている。「大きな成果を上げた企業での導入は、パワーユーザーから始まるケースが多かった。つまり、ChatGPTや『Claude』といったツールで個人的に生産性向上の実験をしていた従業員から始まった。このような従業員は、生成AIの能力と限界を直観的に理解し、社内で承認されたソリューションを早い段階から支持していた。成功した組織は、中央集権的なAI機能を利用してユースケースを特定したのではなく、予算を持つ責任者や業務部門のマネージャーに、問題の洗い出し、ツールの検証、導入の主導をさせていた」

　MITのレポートは、エージェント型AIアーキテクチャーの登場についても触れている。これらは「Model Context Protocol」（MCP）、「Agent-to-Agent」（A2A）、「Networked Agents and Decentralized AI」（NANDA）などのフレームワークを基盤としており、エージェントの相互運用と連携を可能にするという。「これらのフレームワークは、新しい『エージェント型ウェブ』の基盤を形成している。エージェント型ウェブは相互運用可能なエージェントとプロトコルのメッシュであり、モノリシックなアプリケーションを動的な連携レイヤーに置き換える」

AI活用で求められる企業文化の変革

　AIベンダーと連携すれば、「取り組みを開始して、重要な初期の勢いを得られるが、大変なのは、AIソリューションを自社のプロセス、ポリシー、慣行、そしてもちろん、人材と企業文化に組み込むことだ」とMcDonagh-Smith氏は述べた。

この記事は海外Ziff Davis発の記事を朝日インタラクティブが日本向けに編集したものです。",[],[]
二次元コード決済が浸透する中国で、アリペイがタッチ決済にこだわる理由（ZDNET Japan）,https://news.yahoo.co.jp/articles/11383f00abd401376059d900f37ddc8818c6c4dd,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250829-35237174-zdnet-000-1-view.jpg?exp=10800,2025-08-29T07:00:00+09:00,2025-08-29T07:00:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,2253,"二次元コード決済が浸透する中国で、アリペイがタッチ決済にこだわる理由の画像
「支付宝」（アリペイ）を運営する螞蟻集団（アントグループ）は、中国国内で近距離無線通信（NFC）によるタッチ決済の普及に力を入れている。2024年7月から本格的に取り組みを始め、店舗にアリペイ対応のタッチ決済機器の設置を進めてきた。導入から約1年が経過した現在も、エレベーター広告を展開する企業と提携し、エレベーター脇に設置された専用機器にタッチすると紅包（金一封）がもらえる仕組みを導入するなど、積極的な普及活動を続けている。

　とはいえ、中国では二次元コード決済が広く浸透している。二次元コード決済は当初こそ操作に手間がかかったが、年々改善され、店舗の販売時点情報管理（POS）システムや自動改札機などの業務用機器でもスムーズに利用できるようになった。現在、決済時に待たされることがあるとすれば、それはユーザーがアプリで二次元コードを表示する操作に時間がかかっている場合がほとんどである。

　では、なぜアリペイはNFC決済の普及を目指しているのか。

　背景には、近年アリペイが騰訊（テンセント）の「微信支付」（ウィーチャットペイ）に押され気味であることがある。現在ではアントと阿里巴巴（アリババ）の資本関係は解消されているが、もともとアントはアリババ傘下であり、アリペイは「淘宝」（タオバオ）の普及、ひいては中国の電子商取引（EC）市場の拡大に大きく貢献してきた。かつて中国のECといえばタオバオやTmall（天猫）が主流で、アリペイを使わなければECを利用できない状況だった。そのため、街中での少額決済ではウィーチャットペイがやや優勢でも、アリペイの市場シェアは揺るがなかった。

　しかし近年では、京東（ジンドン、JD）やTemuの親会社である拼多多（ピンドゥオドゥオ）がEC市場でシェアを伸ばし、中国版「TikTok」である「抖音」（ドウイン）のライブコマースも人気を集めている。さらに、中国政府がECの支払いにおいてアリペイとウィーチャットペイの両方を使えるようにする方針を打ち出したことで、アリババとアリペイの独占的な立場は崩れつつある。こうした状況を受けて、アリペイは新たな戦略としてNFC決済の普及に力を入れている。

　NFC決済の普及には、タッチ対応のスマートフォンが必要となる。2024年時点で、中国市場における新型モデルの約70％がNFC機能を搭載しているという。また、「iOS 18.1」ではサードパーティー製アプリがセキュアエレメントとNFCを活用した独自の非接触決済機能を提供できるようになることも、中国でのNFC普及を後押しする要因となっている。

　アリペイは、「ちょこっとタッチ」といった意味の「〓一下（〓は石偏に並。発音はペンイーシャ）」という言葉を使って親しみやすくアピールし、店舗に機器を無料で導入させた。さらに、消費者がタッチ決済を行うと、消費者と店舗の両方に紅包が配布される仕組みを導入した。これにより、消費者は取引ごとに割引を受けられ、レジ担当者は取引数に応じて収益を得られるようになった。こうしたプロモーションや補助金にかかった費用は、300億元（約6000億円）を超えている。

　技術面では、アントらがNFC技術規格「iTAPプロトコル」の開発と強化を進めている。iTAPの標準化には、アントのほか、華為技術（ファーウェイ）、深セン大学、復旦微電子などが参加しており、既存のNFCプロトコルとの互換性を保ちつつ、より安全でシームレスな、さまざまな利用シーンに対応可能な規格を目指している。

　NFC決済は海外ではすでに広く普及しているため、中国市場への導入は世界的な決済トレンドや標準に接続するアップグレードの好機とされている。中国国内のインバウンド客向けの利用を促進する狙いに加え、アリペイが二次元コード決済の仕組みを海外に展開した実績があることから、将来的にはアリペイ発のNFC決済の仕組みを海外でも採用してもらう意図があるのかもしれない。

　サービスの普及に当たり、利用者や設置者に金銭的なインセンティブを提供する手法は、これまでも中国のキャッシュレス決済や配車サービス、デリバリー、ネットインフラサービスの黎明（れいめい）期においてよく見られた。ただし、今回の競合は自社やウィーチャットペイの二次元コード決済である。二次元コード決済は機器が不要で、スマートフォン1台や印刷された紙1枚があれば、中国の地方の青空市場でも導入できるという強みがある。

　確かにタッチ決済は、アプリを開いたり二次元コードをスキャンしたりする必要がなく、端末にかざすだけでパスワードなしに支払いが完了するため、操作の手間が減る。これは高齢者や視覚障害者にとっても使いやすい。しかし、それだけでNFC決済が広く普及するかどうかは不透明である。今後、iTAPを活用した日常生活に欠かせない便利なアプリやサービスがどれだけ登場するかが、普及のカギとなりそうだ。

山谷剛史（やまや・たけし）
フリーランスライター
2002年から中国雲南省昆明市を拠点に活動。中国、インド、ASEANのITや消費トレンドをIT系メディア、経済系メディア、トレンド誌などに執筆。メディア出演、講演も行う。著書に『日本人が知らない中国ネットトレンド2014』『新しい中国人 ネットで団結する若者たち』など。",[],[]
コンテキストエンジニアリングが変えるソフトウェア開発--「Sentry」と「Cursor」のケーススタディー（ZDNET Japan）,https://news.yahoo.co.jp/articles/3b629bc52364b0fb285472e7d68caa74910c45ce,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250829-35237096-zdnet-000-1-view.jpg?exp=10800,2025-08-29T07:00:00+09:00,2025-08-29T07:00:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,7324,"AIと人間
本連載の第1回では、いま注目を集めている「コンテキストエンジニアリング」について紹介しました。これは「プロンプトエンジニアリング」と並ぶ存在になりつつあり、むしろ高精度で価値あるAIエージェントをつくる上では、「プロンプトエンジニアリング」よりも重要だと言う人もいます。

　実際、多くのエンジニアが魅力的なデモを作り上げても、そのまま本番環境に移行すると期待していたとおりに動かないことがあります。その最大の理由は「コンテキストの設計不足」にあるのです。

　コンテキストエンジニアリングとは、AIエージェントに「正しい情報を、正しいタイミングで、正しい形式」で提供することです。これができていなければ、どんなに高性能なモデルであっても正しい判断を下すことはできません。正確で、関連性があり、きちんと整理されたコンテキストがあってこそ、AIエージェントは本当の力を発揮できるのです。

　AIエージェントを開発するエンジニアや、そのプロジェクトに投資する経営陣は、AIエージェントに「人間と同等の精度」で複雑なタスクをこなすことを期待しています。ですが実際の現場では、情報はさまざまなシステムに分散し、形式もバラバラで、しかも状況は刻々と変わっていきます。エンジニアたちはまさにその現実に直面しつつあります。

　もしAIエージェントが人間と効果的に協働することに成功するのであれば、その開発者である人間は、人間が重要な意思決定を行うのと同じ「情報・状況認識・記憶」を与えてあげる必要があります。そのために欠かせないのが、コンテキストエンジニアリングです。

　前回の記事をまだ読んでいなければ、ぜひこちらからご覧ください。今回のケーススタディーを理解する上で、役に立つ内容になっています。

　第2回では、ソフトウェア開発のライフサイクルから実際のケーススタディーを紹介します。具体的には、不十分なコンテキストが原因でAIエージェントが誤った提案を導き出してしまったケースです。

　その結果、誤った解決策が実装され、「技術的負債（technical debt）」を積み上げてしまうリスクにつながります。技術的負債は、開発チームのコストを増加させるだけでなく、場合によっては顧客体験にも悪影響を及ぼすことにもつながります。

　だからこそ強調したいのは、コンテキストは大規模言語モデル（LLM）の能力に“追加されるオプション”ではない という点です。むしろ、AIエージェントが自信を持って正しい判断を下すか、それとも不確かで推測的な答えにとどまるかを決定づける 最重要の要素 なのです。

Let's Set the Stage

　「Cursor」と「Sentry」は、いずれも開発者に非常に人気のあるツールです。Cursorはわずか数年で年間経常収益（ARR）が5億ドルを超えるまでに急成長し、Fortune 500の企業の半数以上で利用されています。一方のSentryは10年以上の歴史があり、全世界で10万社以上の顧客がいます。

　両社の製品はいずれも、開発者がより高品質なソフトウェアを、より迅速に構築できるよう支援するために設計されています。実際に、両社の開発者は互いの製品を利用しており、それぞれが開発ライフサイクルの異なる側面で強みを発揮しています。

　今回のケーススタディーでは、これらの製品を統合して使うことで、開発者がより効率的に、柔軟にソフトウェアを構築できる様子を紹介します。同時に、AIに与えるコンテキストがその意思決定にどのような影響を与えるかも浮き彫りします。もし開発者がこの点を理解していなければ、望んでいない技術的・ビジネス的な結果を招く可能性があるのです。

ケーススタディーで使用したツール

1. 「Sentry.io」および「Sentry Seer」

　Sentry.ioのプラットフォームは、ウェブアプリケーションとモバイルアプリケーションの両方に対応した、包括的なオブザーバビリティ（可観測性）とエラートラッキング機能を開発者に提供しています。

　このプラットフォームの中には、アプリケーションのエラーやパフォーマンスの問題をデバッグするためのAIエージェントであるSeerも組み込まれています。Seerは、開発者のために次の3つの主要な機能を実行することで、自動的に問題を解析・解決してくれます。

Seerの主な機能

Scans：新しく起きた問題をすべてチェックして、重要度に応じて順番を決めてくれます
Analyzes：問題そのものと周囲のあらゆる情報を分析して、根本的な原因を突き止めます
Writes：解決に役立つコードの修正方法を提案します

Seerが活用する豊富なコンテキスト

　Seerは、Sentryが持つ幅広い情報に自由にアクセスできます。例えば、エラーメッセージやスタックトレース、環境情報（メタデータ）、トレーシング情報、ログやブレッドクラム、プロファイリングデータ、さらにはリポジトリー全体にあるコードの関連部分まで参照します。

　こうした最新で多角的な情報を組み合わせることで、Seerは問題の原因をより正確に突き止め、開発者にとってすぐに使える解決策を提案してくれるのです。

2. 「Cursor」

　Anysphereが開発した、AIを搭載した統合開発環境（IDE）です。主な機能には次のようなものがあります。

Cursorの主な機能

Visual Studio Codeをベースに開発：Cursorは、世界中で人気のコードエディター「Visual Studio Code」（VS Code）をベースに開発されたツールです。大きな特徴は、AI機能を後から拡張機能として追加するのではなく、最初から開発画面そのものに組み込んでいる点にあります
自然言語で操作可能：自然な言葉で操作できるのも大きな特徴です。開発者は指示をそのまま入力するだけで、コードの生成・修正・解説・補完をしてくれます
プロジェクト全体を理解：プロジェクト全体を理解できるのも強みです。個々のファイルだけでなくコード全体のつながりを把握しているので、複雑なプロジェクトを横断的にナビゲートしながら、実装内容を解説してくれます
外部データソースとの連携：外部データソースとの連携も可能です。CursorはModel Context Protocol（MCP）を利用して、データベースや検索ツール、その他の外部サービスとつながることができます。これにより、単なるコード補助にとどまらず、最新のデータや外部情報を取り込みながら、より的確でコンテキストに沿ったサポートをしてくれます

3. Model Context Protocol（MCP）

　Anthropicが設計した技術標準で、AIが外部の情報を安全かつ効率的にリクエスト・取得・活用できるようにする仕組みです。今回のケースでは、MCPを使うことで、CursorがSentryの関連データを直接IDEに取り込み、開発者の作業をよりスムーズに支援できるようになります。

MCPの主な機能

標準化されたデータ交換：AIモデルがツールやデータベース、APIとつながる際に、ばらばらな仕様に悩まされないように共通のやりとりをルール化します
コンテキストの補強：統合された外部ソースから最新かつタスクに特化した情報を取り込み、AIの「作業用メモリー」をその場で補強します
ツール間の相互運用性：複数のシステムをまたいで連携を可能にし、AIエージェントが異なるプラットフォーム間でシームレスに作業できるようにします

　ここからは実際のケースを取り上げ、ソフトウェアのバグをデバッグするときの、2つの異なるアプローチを比較してみます。

ケース1：Cursor＋Sentry MCPサーバーを利用して、Cursor IDEからSentryデータにアクセスする場合

　この場合、開発者はCursorを通じてSentryのデータにアクセスできます。ただし、エラーの根本原因を分析する際に、どの情報を使うかというコンテキストの指定は開発者自身が行う必要があります。

ケース2：Cursor＋Sentry MCP＋Sentry Seerを組み合わせて、Cursor IDEで分析する場合

　この場合、開発者はSentry Seerの分析結果をCursorに取り込みます。どのコンテキストを使うか、またどの情報をより重視すべきかの判断をSentry Seerが自動で行い、根本原因の特定をサポートします。
結果

　まずは結果から見ていきましょう。同じ問題に対して、AIエージェントに与えたコンテキストの違いが、どのようにして2つの異なる解決策を生み出したのかを、この後で詳しく解説していきます。

問題の概要

Issue ID：MCP SERVER-DWS
エラーの種類：write EPIPE（Broken Pipe エラー）
影響：約3カ月間で1098回発生
プラットフォーム：Node.js v20.12（macOS上）

　表からも分かるように、同じ問題でもケース1とケース2では「根本原因」に対する結論が異なっています。

　ケース1（開発者＋Cursor）では、Seerと同じデータにアクセスできたものの、結論は「接続の切断やシグナルを適切に処理できていなかった」という抽象的な内容にとどまりました。一方、ケース2（Cursor＋Sentry Seer）では、より具体的に「サーバーが書き込みを終える前にクライアントが接続を閉じてしまった」ことが原因と示され、さらに「client.close() → パイプ切断 → EPIPEエラー」という正確なエラー発生の流れまで提示されました。

　つまり、ケース1でのCursorの分析はあいまいで、「終了処理や接続終了の検知を改善すべき」といった一般的な提案にとどまっています。対して、Seerは問題の本質をより的確に突き止め、具体的なシーケンスを明らかにしました。

　SeerもCursorもAIによる分析を行っていますが、その結論は「直前にどんなコンテキストが与えられたか」に大きく左右されます。よく言われるように、LLMの「ハルシネーション（幻覚）」はバグではなく性質の一部です。Cursorの分析が間違っていたわけではなく、あくまで開発者が与えた情報と指示の範囲で導き出された結果だったのです。

各ケースの詳細

ケース1：Cursor＋Sentry MCPサーバー

　このケースでは、開発者がMCPサーバーを通じてSentryから必要なコンテキストを取り出し、それをもとにCursorのLLMに根本原因の分析をさせています。実際、開発者はCursorに「この問題をデバッグして」と依頼しただけで、特に詳しい指示は与えていませんでした。それにもかかわらず、Cursorは根本原因を提示し、その結論に至った技術的なポイントまで提示してくれました。

ケース2：Cursor＋Sentry MCP＋Sentry Seer

　次に、Sentry Seerのやり方を見てみましょう。図の赤枠にあるように、Seerは根本原因を導くまでの手順を詳しく見せてくれます。これにより開発者はSeerの考え方をより細かく確認できるのです。

　さらに、図の赤枠部分にあるように、Seerは各ステップでどんなコンテキストをもとに判断したのかを具体的に示してくれます。また、分析の各ステップは図の黄色枠のように簡単に展開でき、その結論に至った根拠を確認できます。

　はっきりしているのは、Seerが結論に至るまでの過程を、より多くのコンテキストと透明性をもって開発者に示しているという点です。その結果、開発者はAIエージェントの判断がより正確であると、より自信を持って受け止めることができるのです。

　これまで見てきたように、CursorとSentryはどちらも開発者を支える心強いパートナーです。つまり「両方のいいとこ取り」が可能なのです。下の図（赤枠）の通り、CursorはSeerの分析結果をそのままIDEに取り込むことができます。Seerが持つ詳細で正確なコンテキストが、Cursorの画面上でそのまま開発者と共有されるのです。

　開発者がSeerの根本原因分析に納得すれば、そのままCursorに指示を出して、Seerの分析内容とコンテキストを基にコード修正を生成させることができます。

　これは開発者にとって理想的な形です。それぞれのAIを「得意分野」に応じて使い分けることが大切です。Sentry Seerもコードを書くことはできますが、本来の強みはデバッグです。一方でCursorもデバッグは可能ですが、最大の価値はコード生成にあります。AIエージェントにも、人間のチームメンバーと同じように「役割」があるのです。営業担当者に人事の仕事を任せないのと同じで、AIもそれぞれの強みを生かしてこそ最大の効果を発揮します。
Seerの成功を支えるコンテキストエンジニアリング

　Sentry MCPサーバーとCursorを組み合わせることで、開発者はSentryに蓄積された膨大なコンテキストやデータにアクセスできます。一見すると「それなら全データをそのままCursorのLLMに渡せば、正しい結論が得られるはずだ」と思うかもしれません。

　しかし実際には、どれくらいの量を渡すか、どのような形式で渡すかがLLMにとって極めて重要です。繰り返しになりますが、コンテキストエンジニアリングとは、正しいデータを、正しいタイミングで、正しい形式でAIに与える技術なのです。

　Sentryの開発者たちは、Seerの設計においてこのコンテキストエンジニアリングに多くの時間を費やしてきました。例えば、AIモデルに渡すデータの形式について、どの形式が最も効果的かを見極めるために数多くの試行を行っています。

　下の図はその一例で、SentryがエラーのスタックトレースをAIモデルに送る前に、どのように整形（フォーマット）しているかを示しています。

Seerに最適なデータ形式

　開発者がCursorやSentryを利用する際によくあるパターンとして、Sentryコンソールに表示された情報をそのままコピーしたり、スクリーンショットを撮ったりしてCursorに貼り付け、LLMに分析させるという方法があります。 イメージすると、次のような形になります。

　見ての通り、これらのフォーマットは大きく異なっています。形式が違えば、AIの答えも変わってくるのは当然であり、その違いがLLMの分析結果に影響を与える可能性が高いことは明らかです。

Seerのコンテキストウィンドウ管理

　コンテキストエンジニアリングにおけるもう1つの重要な要素が「コンテキストウィンドウの管理」です。コンテキストウィンドウとは、AIモデルが一度に処理・考慮できるテキスト量（通常はトークン数で測定）を指します。LLMが扱えるコンテキストには上限があるため、どのくらいの情報を、どのように与えるかが非常に重要になります。

　Seerでは、Sentryの開発者がこのコンテキストウィンドウを包括的かつバランスよく管理する仕組みを設計しました。Seerが呼び出される際、まずは問題の理解に必要な大枠のコンテキストだけを渡し、これによって「何が起きていて」「どんなデータが利用可能か」を把握できるようにしています。ただし、最初から利用可能な全てのコンテキストを詰め込むのではなく、必要な情報を「ヒント」として示し、追加が必要になった時点で段階的に取り込めるようにしているのです。

　この仕組みにより、Seerは複雑な問題の際にはSentry内の情報を深く掘り下げて分析できる一方、簡単な問題や限られた情報で解決できる場合には、余計なデータでウィンドウを圧迫しないという「いいとこ取り」を実現しています。つまり、Seerは柔軟かつ効率的に「必要なだけの情報」を扱えるのです。

結論

　LLMは常に正しい判断を下せると考えがちです。実際、返答はいつも自信満々に見えますよね。しかし今回のケーススタディーで明らかになったように、同じデータにアクセスしていても、2つの異なるAIエージェントは全く異なる結論に至りました。

　人間と同じように、LLMも「ガイド」と「工夫」を必要とします。データをどのように提示されるかによって、その理解や判断は大きく変わります。私たちがチームメンバーに良い成果を出してもらうために、適切なツールや仕組み、トレーニングを用意するのと同じです。AIモデルもまた、そのパフォーマンスを最大限に引き出すために同等の配慮と理解が不可欠です。

　これこそが、LLMを高精度な意思決定に最適化するためのコンテキストエンジニアリングなのです。もし大規模なAI導入を検討しているのであれば、このスキルを習得し、それを持つチームを組織の中に構築することは避けて通れません。それは選択肢ではなく、必須条件なのです。

ジェイ・レヴェルズ
Ichizoku CEO Founder
Informaticaでキャリアをスタートして以来、20年以上にわたり、テクノロジーと組織経営の両面で着実に実績を積み重ねてきた。日本では10年以上にわたり、アドビやマリンソフトウェアなどで、高い技術力と収益性を兼ね備えたチームを率い、エグゼクティブリーダーとして活躍してきた。現在は、日本企業の成長と業績拡大を支えるAIエージェントの構築を目指し、Ichizokuを共同設立。",[],[]
