headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
Perplexity、3つのAIを同時実行し最適な回答を提示する「Model Council」発表（ビジネス＋IT）,https://news.yahoo.co.jp/articles/cf9c737db59fb34da9331dc8d8670db1b0f5b953,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20260207-00180383-biz_plus-000-1-view.jpg?exp=10800,2026-02-07T15:50:06+09:00,2026-02-07T15:50:06+09:00,ビジネス＋IT,biz_plus,ビジネス＋IT,1189,"（画像：ビジネス+IT）
米国発のAI検索・生成プラットフォーム「Perplexity」は2026年2月5日、複数の大規模言語モデル（LLM）を同時に活用する新機能「Model Council」を正式発表した。これはユーザーの同一クエリを複数モデルで並行実行し、その出力を統合する仕組みで、回答の精度と信頼性を高めることを狙いとしている。公式ブログによれば、Model CouncilはPerplexityインターフェース上で選択可能となっており、統合結果を1つの回答として示す。
複数のAIモデルから最適な解を生み出す、Perplexity’「Model Council lとは？（画像：ビジネス+IT）
Perplexityは従来から複数のAIモデルへの切り替え機能を提供し、用途に応じて最適なモデルを選択するアプローチを特徴としてきたが、Model Councilは同時実行・統合という新たな設計を導入した点が最大の特徴である。公式発表では、Claude Opus 4.6やGPT-5.2、Gemini 3.0といった複数モデルに同じ問いを同時に投げ、シンセサイザーモデルが各モデルの出力をレビューし矛盾を解消して1つの回答として提示する仕組みが説明されている。モデル間で一致する部分と異なる部分が明示され、複数視点に基づく合成回答が得られる。


　公式発表は特定の利用シーンとして、投資リサーチや複雑な意思決定、創造的ブレインストーミング、情報検証を挙げており、単一モデルでは見落としや偏りが生じがちな場面で候補の広がりと精度の担保を図る意図が示された。シンセサイザーモデルは単なる多数決ではなく、モデル間の整合性を評価しながら最終回答を生成する点が公式リリースで強調されている。

　複数メディアが報じるところでは、Model CouncilはPerplexity Maxサブスクリプション加入者向けにWeb版で提供中であり、モバイルアプリ対応も近日開始予定とされている。これによりユーザーは単一モデルの限界だけでなく、複数モデルの強みを同時に活かすことが可能になるという。

　Model Council導入の背景には、最新のAIモデル間で性能や特性の差異が大きいことがあるとPerplexityは指摘している。公式発表は、異なるモデルが得意とするタスクや回答の品質が均一でないことを示し、ユーザー自身が最適モデルを選ぶ負担を軽減する狙いを示した。

　一方、複数モデル同時実行には計算資源や応答速度への負担増が避けられないという指摘もある。また、複数モデルが同じバイアスを共有している場合には、その偏りが強化されるリスクも存在するという報道もある。いずれにせよ、AI回答の信頼性と精度向上に対するニーズの高まりを受け、複数モデル統合アプローチは注目を集めている。",[],[]
AIは人間を「ダメにする」装置であることが判明（ビジネス＋IT）,https://news.yahoo.co.jp/articles/98b84bb87812bb0bf716a495b0ae0006bba67c86,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20260207-00180381-biz_plus-000-4-view.jpg?exp=10800,2026-02-07T11:50:05+09:00,2026-02-07T13:20:06+09:00,ビジネス＋IT,biz_plus,ビジネス＋IT,1169,"（画像：ビジネス+IT）
米AI企業Anthropicの研究チームは、同社のAIの会話データ150万件を分析し、ユーザーが自主性を失う「無気力化」の実態に関する調査結果を発表した。研究では、AIがユーザーを「ダメにする」3つの主要なパターンが特定された。特に人間関係などの個人的な話題ではリスクが高まる傾向にあり、利便性と自律性のバランスが問われている。
AIが人間を「ダメにする」３つのパターン（図版：ビジネス+IT）
米Anthropicの研究チームは、AIの利用において人間が自律的な判断力を失う「無気力化（Disempowerment）」のパターンを発表した。同社が提供するAIサービスで交わされた約150万件の会話データを分析した結果、ユーザーがAIに過度に依存し、自らの意思決定や価値判断を委ねてしまう傾向が一部で確認された。


研究チームは、AIとの相互作用によってユーザーの自律性が損なわれる現象を「無気力化」と定義し、主に3つのパターンに分類している。第一に「思い込みや誇大妄想の肯定」である。これはユーザーが誤った情報や妄想的な考えをAIに提示した際、AIがそれを肯定的なトーンで受け入れることで、ユーザーの誤った現実認識が強化される現象を指す。第二に「価値判断や人間関係の依存」である。第三者の行動に対する道徳的な判断や、自身の人間関係における善悪の評価をAIに求め、AIの出力した回答をそのまま自身の倫理的判断として採用するケースが含まれる。第三に「作業や行動の丸投げ」である。個人的なメッセージの作成などをAIに完全に任せ、提案された文面を検討することなくそのまま相手に送信するといった、主体性を欠いた行動がこれに該当する。

定量的分析によると、こうした深刻な「無気力化」の兆候が見られる会話は、全体のおよそ1,000件に1件未満と低い頻度にとどまっている。しかし、人間関係のトラブルやライフスタイル、メンタルヘルスといった個人的かつ感情的な領域の話題においては、その発生率が大幅に上昇することが確認された。また、過去のデータを分析した結果、こうした無力化のパターンを含む対話の割合は経年的に増加傾向にあることも示されている。

分析における重要な発見の一つとして、AIによって自律性が損なわれる可能性が高い対話ほど、ユーザーからの承認評価が高いという傾向が見られた。これは、短期的にはユーザーがAIによる肯定や決定代行を好意的に受け入れていることを示唆しており、ユーザーの短期的な満足度と、長期的な人間の自律性やエンパワーメントとの間に緊張関係が生じている可能性がある。研究チームは、AIシステムが単にユーザーの要望に従うだけでなく、人間の自律性と健全な繁栄を支援するように設計される必要性を提言している。",[],[]
ソフトバンク、OpenAI「Frontier」を企業AIエージェント基盤「クリスタル・インテリジェンス」に採用（ビジネス＋IT）,https://news.yahoo.co.jp/articles/af9649e6fcbaef543d5f9ada3db0076ce1eb0a0d,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20260207-00180380-biz_plus-000-1-view.jpg?exp=10800,2026-02-07T11:15:05+09:00,2026-02-07T11:15:05+09:00,ビジネス＋IT,biz_plus,ビジネス＋IT,1221,"（画像：ビジネス+IT）
ソフトバンクとSB OAI Japan合同会社は2026年2月6日、OpenAIが前日に発表した新たな法人向けAIプラットフォーム「Frontier（フロンティア）」を、両社が展開する企業変革ソリューション「クリスタル・インテリジェンス」の基盤として採用すると発表した。AIエージェントの統合管理と業務システム連携を可能にする新基盤を活用し、日本国内企業への2026年中の展開に向けた体制整備と導入支援を加速させる。
ソフトバンク×OpenAI「企業向けAIエージェント基盤」全体像（図版：ビジネス+IT）
OpenAIが2026年2月5日に発表した「Frontier」は、AIエージェントが部門を横断してタスク実行や意思決定支援を行うための法人向けプラットフォームである 。従来のAI導入では、データや既存システムとの統合、セキュリティやガバナンスの課題により、活用が個人や特定部門にとどまるケースが多かった 。Frontierは、企業のデータウェアハウスやCRM（顧客関係管理）などの業務システムとAIを安全に連携させることで、AIエージェントに「共有されたビジネスコンテキスト」を持たせることが可能となる 。これにより、AI活用を単なる試行段階から、全社的な業務変革や意思決定に直結する実装・定着の段階へと引き上げることが期待されている 。


ソフトバンクらが展開する「クリスタル・インテリジェンス」は、このFrontierを基盤とし、日本企業向けに最適化したAIソリューションである 。同ソリューションでは、顧客企業と並走して設計から運用までを支援する「Forward Deployed Engineer（FDE）」を配置する点が特徴だ 。FDEは、AIエージェント導入のための業務整理やユースケース設計に加え、日本の企業特有の複雑なレガシーシステムとの統合やセキュリティ設計を一気通貫で支援する 。また、SB OAI Japanは、企業ごとの異なる業務プロセスに対応するため、独自のAIエージェント群も提供する予定である 。

ソフトバンクは、顧客への提供に先立ち、自社を「ユーザーゼロ」と位置づけ、社内での先行検証を進めている 。同社では既に全社員がAIエージェントを作成する取り組みを行っており、250万以上のエージェントが社内で生成された実績を持つ 。これらの社内実践で培った運用知見やシステム導入ノウハウを「クリスタル・インテリジェンス」に反映させることで、品質と安全性を高める狙いがある 。OpenAIのForward Deployed Engineering責任者であるコリン・ジャーヴィス氏は、ソフトバンクとの連携について、日本市場向けの最適化と企業の業務プロセス再構築において極めて重要であるとの認識を示した 。両社は今後、2026年中のサービス提供開始に向け、国内の提供体制の整備を急ぐ",[],[]
Google DeepMind、100万文字のDNAを一度に解析するAI「AlphaGenome」を発表（ビジネス＋IT）,https://news.yahoo.co.jp/articles/685c42ef430fc543821c49ba77fa72956cfb343e,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20260207-00180379-biz_plus-000-1-view.jpg?exp=10800,2026-02-07T11:00:06+09:00,2026-02-07T11:00:06+09:00,ビジネス＋IT,biz_plus,ビジネス＋IT,1096,"（画像：ビジネス+IT）
米Google傘下のAI研究企業Google DeepMindは、最大100万塩基（約100万文字）に及ぶ長大なDNA配列を一度に解析し、遺伝子発現やスプライシング（RNAの切断・再結合）、クロマチンアクセシビリティなど、11種類の主要なゲノムに関わる生物学的プロセスを同時に予測できる人工知能（AI）モデル「AlphaGenome」を開発した。研究成果は科学誌 Nature に2026年1月28日付で掲載され、研究コミュニティ向けにソースコードや学習済みモデルの重みが公開された。
GoogleDeepMind AlphaGenome「ゲノムの暗黒物質」を解析するAI（図版：ビジネス+IT）
AlphaGenomeは、DNA配列中の単一塩基の変異が多様な分子プロセスに与える影響を高解像度で予測できる点が最大の特徴だ。従来のゲノム解析AIモデルは数万?数十万塩基程度を対象としていたが、AlphaGenomeは約100万塩基という長大なコンテキストを一度に処理できる能力を備え、遠く離れたエンハンサーやプロモーターといった配列領域間の長距離相互作用を捉える点で優位性を持つ。これにより、非コード領域と呼ばれゲノム全体の約98％を占める部分における変異の機能的な影響も包括的に評価できる。


Nature掲載論文や関連報道によると、AlphaGenomeは遺伝子発現量やスプライシング予測といった主要な評価項目において既存の最先端モデルと同等かそれ以上の性能を示している。特に遠距離制御要素の解析や、複数の分子過程をまたぐ予測において強みを発揮し、従来モデルでは困難だったDNA配列の多面的な理解を推進する。ヒトやマウスのゲノムデータを用いた評価では、26の変異効果予測タスク中25項目で既存モデルと同等以上の性能を確認したという。

Google DeepMindは、AlphaGenomeのソースコードと学習済みモデルを研究用途に公開し、世界中の研究者が再現実験や独自のデータを用いた解析を行えるようにした。これにより希少疾患やがんの原因となる遺伝的変異の理解、さらには遺伝子調節機構の解明にむけた基盤的な研究が加速する可能性があると期待されている。

AlphaGenomeは、DNAの1次元配列情報から高解像度の分子プロセス予測を実行する能力を持ち、将来的には遺伝子検査の精度向上や創薬研究の加速といった応用展開が見込まれている。ただし現在は非商用の研究用途に限定されており、個人ゲノム予測や臨床診断向けの直接的な利用は想定されていないとの指摘もある。",[],[]
