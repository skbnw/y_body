headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
AIブラウザーの台頭とセキュリティリスク--専門家が語る課題と対策（ZDNET Japan）,https://news.yahoo.co.jp/articles/3f7e32cee6e7128486f15ab0e323d062880beab6,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20251026-35239642-zdnet-000-1-view.jpg?exp=10800,2025-10-26T07:00:00+09:00,2025-10-26T07:00:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,5041,"提供：S and V Design / iStock / Getty Images Plus
OpenAIの「ChatGPT」が突如登場したことで、世界中の企業はこのチャットボットや関連アプリケーションを自社の業務に取り入れようと躍起になった。一方、学術界では、学生の提出物にAIによる盗用が含まれていないかを確認する必要が生じた。さらに、画像や音楽の生成などさまざまな分野でAIモデルが次々と登場している。

　数十億ドルもの資金が、ChatGPTのようなチャットボットだけでなく、大規模言語モデル（LLM）や特定用途向けのアプリケーションにも投入されてきた。そして今、AIエージェントとブラウザーが次の進化の段階へと進もうとしている。

OpenAIのChatGPT Atlasが登場

　OpenAIは米国時間10月21日、「ChatGPTが組み込まれたブラウザー」として「ChatGPT Atlas」を発表した。だが、その実態はそれ以上の機能を備えている。Perplexityの「Comet」やThe Browser Companyの「Dia」、「Gemini」を統合した「Google Chrome」などと並ぶAtlasは、まずMac向けに提供され、今後のアップデートによってさらに洗練されていく予定だ。

　OpenAIのチームによれば、AtlasはChatGPTを中心に設計されたAIブラウザーであり、ユーザーが入力する検索クエリーや開いている全てのタブと連携して、それらの情報をもとに回答やタスクを行うという。

　用途としては、オンライン注文、メールの編集、会話の要約、一般的な検索、さらには「GitHub」リポジトリーの分析などが挙げられる。

　OpenAIは、「Atlasがあれば、ChatGPTはウェブ上のどこへでもユーザーと一緒に行動でき、その場にあるウィンドウ内でサポートを行い、ユーザーの意図を理解しながら、コピー＆ペーストやページ移動をせずにタスクを完了できる」と説明している。また、「ChatGPTのメモリー機能が組み込まれているため、過去のチャットや詳細情報を参照しながら新しい作業を支援できる」とも述べている。

　ただし、Atlasを含むAIベースのブラウザーには、セキュリティやプライバシーに関する懸念が付きまとう。これらの問題には、明確な対応が求められている。

プロンプトインジェクション

　AIブラウザーにおけるセキュリティ上の懸念の1つが「プロンプトインジェクション」である。これは、サイバーセキュリティの専門家たちが深刻な問題として捉えている。プロンプトインジェクション攻撃とは、攻撃者がLLMを意図的に操作し、有害な動作を引き起こすものである。こうした攻撃は、ユーザーデータの窃取を目的としており、既存のセキュリティ対策を回避し、開発者の指示を上書きする「本物のプロンプト」として偽装される可能性がある。

　この攻撃には、ユーザーの入力を直接利用する「直接インジェクション」と、ウェブページなどのスクレイピング対象に隠されたペイロードを通じて行われる「間接ハイジャック」の2種類がある。

　Braveの研究者たちは以前、Cometにおける間接的なプロンプトインジェクションの問題を明らかにしたが、その後の調査でCometだけでなく「Fellou」にも新たな攻撃手法が存在することを発見し、これを公表している。

　Braveは、「エージェント型ブラウザーアシスタントは、信頼できないウェブページのコンテンツによってプロンプトインジェクションを受ける可能性があり、その結果、アシスタントはユーザーの認証された権限で動作するため、同一生成元ポリシーなどの保護機能が意味をなさなくなる」と指摘している。さらに、「ウェブサイト上の単純な自然言語の指示、あるいは『Reddit』のコメントでさえ、銀行や医療機関、企業システム、メールホスト、クラウドストレージなどに対してクロスドメインのアクションを引き起こす可能性がある」と警告している。

　Django Web Frameworkの共同制作者であり、専門開発者でもあるSimon Willison氏は、AIブラウザーの動向を綿密に追っているが、エージェント型およびAIエージェントベースのブラウザー全体に対して「深く懐疑的」な姿勢を崩していない。同氏は、ブラウザーにユーザーの代わりにアクションを実行させることを許すと、たとえRedditの投稿の要約を求めるだけであっても、データ流出につながる可能性があると警鐘を鳴らしている。

　米ZDNETはOpenAIに対し、プロンプトインジェクションを防ぐために導入されているセキュリティ対策や、今後の改善計画について質問した。OpenAIは、ユーザーが細かく制御を設定できる方法を解説したヘルプセンターと、最高情報セキュリティ責任者（CISO）のDane Stuckey氏による「X」の投稿を参照するよう回答している。

　Stuckey氏は、OpenAIが「攻撃キャンペーンを認識した際に、それを迅速に特定し、ブロックするためのラピッドレスポンスシステムを優先してきた」と述べており、プロンプトインジェクション攻撃を防ぐために多額を投じていることを明らかにしている。

機密データの取り扱い

　もう1つの重要なセキュリティ課題は「信頼」、つまりブラウザーやLLMに個人データへのアクセスとその処理を許可するかどうかという点である。

　AIブラウザーがユーザーの代わりに特定の作業を行うには、アカウント情報やキーチェーン、資格情報などへのアクセスを許可する必要がある。これに対してStuckey氏は、AtlasにはChatGPTに資格情報へのアクセスを許可しない「ログアウトモード」が用意されていると説明する。また、機密性の高いウェブサイトでエージェントが作業している場合には、「ウォッチモード」により、ユーザーがタブを開いたままにしてエージェントの動作を監視できるという。

　さらに、機密情報を含むタブから離れると、エージェントの動作は一時停止される仕組みになっている。これにより、ユーザーはエージェントが何をしているかを把握し、常にコントロールできる状態を保てるという。これは興味深い仕組みであり、ログアウトモードは初期設定で有効にしておくべきだろう。ただし、こうした情報やアクセスが、どのAIブラウザーでも長期的に安全に管理されるかについては、まだ明確な答えが出ていない。

　また、Aikidoが発表した新しい調査レポートによると、欧州と米国のCISO、セキュリティ技術者、開発者450人を対象にした調査で、回答企業の5分の4がAIコードに関連するサイバーセキュリティインシデントを経験していることが明らかになった。つまり、強力で最新のテクノロジーであっても、必ずしも安全とは限らないということだ。

　Reality Defenderの最高技術責任者（CTO）であるAlex Lisle氏は米ZDNETの取材に対し、ブラウザーに閲覧履歴の全てを信頼して預けることは「愚かな行為だ」と語っている。さらに、「これらのブラウザーでは、毎週のように新たな脆弱（ぜいじゃく）性や悪用手法が発見されている。主要なブラウザーは常にハッキングの対象となっているが、それでも現在のAIブラウザーのエコシステムというパッチワークよりは修正が適用され、より良く維持されている」と付け加えている。
監視

　もう1つの新たな懸念は「監視」の問題である。従来、安全なブラウザーを使って検索することで、ユーザーの行動が記録されたり追跡されたりすることを避けることができた。しかし、AIブラウザーは設計上、フォローアップの質問や閲覧履歴、プロンプトなどを通じて検索クエリーに文脈を加える仕組みになっている。

　ProtonでAIおよび機械学習部門を率いるEamonn Maguire氏は、「検索は常に監視の対象だったが、AIブラウザーはそれをより個人的なものに変えた」と語っている。ユーザーは今や、健康の悩みや財政状況、人間関係、ビジネスプランなど、これまで検索ボックスに入力することのなかったような詳細な情報を共有するようになっている。これは単なるデータ量の増加ではなく、ユーザーがどんな人物で、どのように考え、次に何をしようとしているかを明らかにする、物語性を持った一貫したデータであるという。

　Maguire氏は、検索・ブラウジング・自動化が融合することで、ユーザーの行動に対して「前例のないレベルの洞察」が可能になると指摘している。そして、「透明性が技術の能力に追いつかない限り、AIブラウジングは監視資本主義の最も親密な形態になるリスクがある」と警鐘を鳴らしている。

　同氏は、「解決策はイノベーションを拒むことではなく、それを再考することだ」と述べ、AIによる支援がプライバシーを犠牲にする必要はないと強調している。われわれは、データがどれくらいの期間保存されるのか、誰がアクセスできるのか、集められた活動がモデルの学習に使われるのかといった、重要な問いに対する明確な答えを必要としている。真の透明性とユーザーによる制御が実現されるまでは、AIブラウザーを生産性向上のツールとしてではなく、潜在的な監視ツールとして扱うべきだと述べている。

AIブラウザーを使用すべきか

　アプリケーションのセキュリティに関して、Willison氏は「99％のケースで安全性に問題がある」と指摘する。つまり、どんなに巧妙に設計されたガードレールであっても、それを回避する方法があるなら、悪意のある攻撃者は必ずそれを見つけ出すというのだ。

　現時点では、AIブラウザーの利用に関して多くの「もしも」が存在しており、Willison氏のようなセキュリティやプログラミングの専門家の中には、「多くのセキュリティ研究者が徹底的に検証し、問題点を洗い出すまでは信用できない」と考える人も少なくない。

　将来的には、ゼロデイのプロンプトインジェクションに対する修正が、毎月のセキュリティパッチとは別に、独立したカテゴリーとして扱われるようになる可能性もある。しかし、それがいつ実現するかは誰にも分からない。

　MozillaのシニアプリンシパルエンジニアであるBrian Grinstead氏は、米ZDNETの取材に対し、現在のエージェント型ブラウザーにおける根本的なセキュリティの課題は、たとえ最新のLLMであっても、ユーザーからの信頼できる情報と、ウェブページから取得した信頼できない情報とを明確に区別する能力がないことだと語っている。

　さらに同氏は、最近リリースされたエージェント型ブラウザーでは、プロンプトインジェクション攻撃の成功率が10％前後と報告されており、これは従来のブラウザーにおいては致命的と見なされるレベルだと指摘している。たとえウェブページが丁寧な言葉で指示を出したとしても、ブラウザーの制御を10％の確率で奪うような新しいJavaScript APIをリリースすることは、通常では考えられないという。

　Grinstead氏は、AIブラウザーを試してみたいと考えるユーザーに対し、**個人データへのアクセスを許可しないこと**、そして**信頼できないコンテンツを読み込まないようにすること**を勧めている。ここで言う「信頼できないコンテンツ」とは、疑わしいウェブサイトや安全性に欠けるサイトだけでなく、製品レビューやRedditの投稿など、一見信頼できそうなサイトに含まれる情報も含まれる。

　加えて、ブラウザーのセキュリティ設定、特にデバイスから送信されるデータの内容やその用途、保存の有無についても、しっかりと確認することが重要だと述べている。

　最終的にAIブラウザーを使うかどうかはユーザー次第だが、比較的新しく、十分に検証されていないツールに機密情報へのアクセスを許可する場合、そのリスクは非常に高いと言えるだろう。

この記事は海外Ziff Davis発の記事を4Xが日本向けに編集したものです。",[],[]
