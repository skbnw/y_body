headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
アップル、AirPods Pro 3 旧正月デザインを発売（アスキー）,https://news.yahoo.co.jp/articles/1596f04461cec4c4da3ced656b2e7328b9f7197f,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20260109-00000014-ascii-000-1-view.jpg?exp=10800,2026-01-09T20:00:00+09:00,2026-01-09T20:00:00+09:00,アスキー,ascii,アスキー,355,"アップルは1月5日、太陰暦の正月にあたる旧正月向けデザインの特別バージョンのAirPods Pro 3の販売を開始しました。
写真：アスキー
アップルは1月5日、太陰暦の正月にあたる旧正月向けデザインの特別バージョンのAirPods Pro 3の販売を開始しました。
　
　毎年発売されている限定モデルですが、今年の干支の午年（うまどし）にあわせて本体ケースに馬の絵文字の刻印が、そして外箱にも同じく馬の絵文字が赤色で描かれています。
　
　「欲しい！」と思った人も多いでしょうが、残念ながら旧正月向けデザインのAirPods Pro 3は中国、香港、シンガポール、台湾、マレーシアのみでの販売となります。ただし現地のアップルストアでも購入できるため、どうしても欲しい方はそちらへどうぞ。
　

文● 篠原修司",[],[]
オンプレミス導入向け日本語LLM「リコーLLM 27B」発表　Dify搭載サーバーと組み合わせ販売（アスキー）,https://news.yahoo.co.jp/articles/26f2eec56041fbe84944653e3731321bbcd83b4f,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20260109-00000013-ascii-000-1-view.jpg?exp=10800,2026-01-09T17:10:00+09:00,2026-01-09T17:10:00+09:00,アスキー,ascii,アスキー,3748,"リコーが、小型の日本語LLM（大規模言語モデル）として新たに開発した「リコーLLM 27B」を発表した。エフサステクノロジーズ「Private AI Platform on PRIMERGY（Very Smallモデル）」に搭載したパッケージとして販売する。また、企業の暗黙知を生かすAIエージェントプラットフォーム「H.D.E.E.N」も発表している。
【もっと写真を見る】
写真：アスキー
リコーが、小型の日本語LLM（大規模言語モデル）として新たに開発した「リコーLLM 27B」を発表した。「オンプレミス環境への導入に最適な高性能LLM」と位置づけており、エフサステクノロジーズが提供するオンプレミス環境向け対話型生成AI基盤「Private AI Platform on PRIMERGY（Very Smallモデル）」に搭載。生成AI開発プラットフォーム「Dify（ディフィ）」をインストールし、LLMの動作環境を構築した上で、リコージャパンを通じて販売する。
　
半分以下のパラメータ数で、従来を上回る性能を実現した新たなLLM
　
　リコーLLM 27Bは、Googleのオープンモデル「Gemma 3 27B」をベースに開発された270億パラメータのLLMで、リコー独自のモデルマージ技術を活用することで、ベースモデルから大幅な性能向上を実現しているのが特徴だ。独自開発を含む約1万5000件のインストラクションチューニングデータによって追加学習したInstructモデルから抽出したChat Vectorなど、複数のChat Vectorを統合。OpenAIのgpt-oss-20bをはじめとする、同規模のパラメータ数を持つ最先端LLMと同等の性能を発揮するという。
　
　リコー AIサービス事業本部でデジタル技術開発センター所長を務める鈴木剛氏は、「これまでに開発した『リコーLLM 70B』の半分以下のパラメータ数で、それを上回る性能を実現した。非思考モデルながら、思考モデルに匹敵する推論性能を実現している。とくに執筆能力が高く、Time to First Token（TTFT）が速いため、チャットなどでの利用に適している」と説明する。
　
　270億パラメータのモデルであることから、「NVIDIA L4」のような入手しやすいGPUでも稼働させることでき、消費電力も下がる。これにより、オンプレミスでの動作環境が容易に構築できるという。
　
　また、AIサービス事業本部 AI事業開発センター所長の児玉哲氏は、Private AI Platform on PRIMERGYに搭載して提供することで、「ハードウェア価格を、3分の1から4分の1程度、抑えることが可能だ。タワー型のサーバー筐体なので、オフィスの足元に置いてLLMを稼働させることもでき、個人情報などの機微なデータを活用する際にも適している。IT部門の管理とは別に運用したいというニーズにも対応する」と紹介した。 
　
企業ごとの暗黙知＝“秘伝のタレ”をエージェント化する新たなAI基盤も
　
　リコーでは、AI開発に1980年代から取り組んできた。これまで、独自のOCR技術の開発や、画像とテキストを融合した検索技術の開発などで実績を持つ。2015年以降は、外観検査向けAIや与信判断向けAI、路面性状検査システムなどのほか、自然言語処理AIにより企業内のテキストデータを活用する「仕事のAI」を製品化。営業活動を支援するバーチャルヒューマンも開発した。
　
　生成AI／LLMについても、国内企業としては早い段階で開発に着手していた。2023年3月の「リコーLLM 6B」を皮切りに、2024年1月にはLlama 2ベースの「リコーLLM 13B」、2024年9月にはLlama 3ベースの「リコーLLM 70B」を開発。2025年4月には、このリコーLLM 70BやSwallow、Llamaを統合し、顧客モデルを最適化する技術を確立している。2025年10月には、GPT-5と同等の性能を持つ日本語大規模言語モデルを開発。さらに、図表も読むことが可能な“LMM”（マルチモーダル大規模言語モデル）の開発は、GENIACで採択され、2025年7月から無償公開を行っている。
　
　リコーでは今回、前述した新たなLLMに加えて、“秘伝”を意味する「H.D.E.E.N」という新たなプラットフォーム（仮称）を発表している。これは「Hidden Deep Expertise Engine Nexus」の頭文字をとったもので、「企業特化型LLM」「ドキュメント活用基盤」「マルチAIエージェント活用基盤」を組み合わせたパッケージとして提供する。
　
　同社 AIサービス事業本部長の梅津良昭氏は、「この『秘伝のタレプラットフォーム』は、秘められた（Hidden）深層の専門知識（Deep Expertise）を活用するシステムの中核を担うことになる。企業ごとに特化した知識を持つエージェントが、ユーザーの質問意図を理解して、様々な企業情報から、自律的に最適な回答を導く仕組みを構築できる」と説明する。
　
　H.D.E.E.Nプラットフォームでは、ベースLLM（パブリックLLMやオープンソースLLM、リコー製LLM）を基に個別企業に特化したLLMを開発する環境、テキスト／マルチモーダル／グラフRAGを組み込んだ「ドキュメント活用基盤」を用意。その上で、業種／業務に特化した専門知識を持つAIエージェントの開発基盤と、複数のAIエージェントを統合管理し、より高度なタスクを実行するためのAIエージェントオーケストレーションで構成される「マルチAIエージェント活用基盤」を提供する。開発したAIエージェントは、MCPなどを通じて外部システムとの連携も可能だ。
　
　これにより、“デジタルクローン”を活用した壁打ちや、複数のAIエージェントをひとつの空間に同居させてコミュニケーションを活性化させるコミュニケーション空間の提供、ロボットとの連携によるフィジカルAIの活用などにつなげることができるという。
　
　「社員がAIに問い合わせると、司令塔AIエージェントが、問い合わせの意図を踏まえて最適な専門家AIエージェントを自律的に判断し、タスクを指示。専門家AIエージェントは、ナイーブRAG、マルチモーダルRAG、グラフRAGといった最新RAG技術を駆使して、多様な現場ドキュメントをナレッジ化したなかから最適な回答を行う。様々なRAGを統合していることで、秘伝のタレのAI化が可能になる」（梅津氏）
　
　リコー社内ではすでにこのH.D.E.E.Nプラットフォームを活用しており、500部門が開発したおよそ6000もの専門家AIエージェントを利用できる環境が整っているという。
　
多くの企業が悩む“社内の暗黙知”の活用を後押しする
　
　リコーに対しては現在、国内企業からAI活用に関する問い合わせが増加している。
　
　なかでも多いのが、社内に蓄積した膨大な「暗黙知」の活用に関するものだという。梅津氏は、「企業内には“企業ノウハウの塊”である日報や提案書といった資料があるものの、再利用が進んでいない」と指摘する。企業が持つデータの約70～90％が非構造化データであること、ベテランが持つ暗黙知がデジタル化されていないことが背景にある。
　
　「“秘伝のタレ”とも言える属人化された暗黙知を、活用可能な資産として利用するには、秘伝のタレをAI化していくことが大切だ。AIとデータを掛け合わせることで『知識爆発』と『技智融合』が可能になる」（梅津氏）
　
　こうした「秘伝のタレのAI化」を進めるために、リコーでは、プライベートLLMやRAGを活用して散在する現場知見を形式知化する「技術基盤の構築」、ローコード開発によるAI市民開発文化の浸透や、AIエージェントによる個別業務の自動化を促進する「文化醸成」、バーチャルヒューマンによるコミュニケーション活性空間を実現する「交流活性」、エッジ＝ロボティクス連携によるブルーカラー領域へのAI波及で実現する「生産革新」という4つのステップを提案していくという。
　
　梅津氏は、「企業の秘伝のタレをAI化するために、マルチエージェンティックRAG環境を開発し、複数のAIエージェントを統制。さらに、プライベートLLMによって、企業ごとに最適化し、業界知見や専門用語を正確に解釈し、回答することができるようにした」と語った。
　
　「リコーでは、オフィスのなかでも、工場のなかでも“つまらない仕事”はAIやロボット任せて、人は創造性を発揮できる仕事に集中できるようにすることを目指している。『つまらない仕事はもうやらない』がリコーからのメッセージだ。その第一歩が、現場にあるドキュントを読解し、知識化すること。これが、秘伝のタレのAIを実現するH.D.E.E.Nの役割だ」（梅津氏）
　

文● 大河原克行　編集● 大塚／TECH.ASCII.jp",[],[]
指1本で動かせるらしいモニターアームは本当にスゴいのか　モニター2枚が上下左右に縦に横に（アスキー）,https://news.yahoo.co.jp/articles/14c7229c6664dae337f2db81c28a5074d4c911aa,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20260109-00000012-ascii-000-1-view.jpg?exp=10800,2026-01-09T17:00:00+09:00,2026-01-09T17:00:00+09:00,アスキー,ascii,アスキー,2654,"指1本で動く？ さすがに盛りすぎでは？ そんな半信半疑で「COFO無重力モニターアームPro（上下配置版）」を実際に触って確かめてみました。
【もっと写真を見る】
写真：アスキー
「まるで無重力の操作性」「指1本で自由自在」。「COFO無重力モニターアームPro（上下配置版）」のサイトに書かれたうたい文句に対して、「いやいや、さすがに盛りすぎでは？」という印象を持ったのは確かです。これまでもモニターアームはこれまでいろいろ見てきましたが、軽く動くと言われる製品でも、位置調整にある程度は力を要するものがほとんどですし、そうでないと十分に固定する力が十分ではありません。
　
　だからこそ、本当に指1本で自由自在に動かせるのか、このアームを実際に試したいと思いました。2枚のモニターを上下にも左右にもストレスなく動かせるのか、その自由度と安定性は本物か。しっかり性能を確認しました。
　
■Amazon.co.jpで購入


　
COFO「COFO無重力モニターアームPro（上下配置版）」
　

【目次】この記事で書かれていること：
　
無重力モニターアームのメリットと注意点
　
COFO無重力モニターアームPro（上下配置版）を購入する3つのメリット
1）2枚モニターを自在に配置できる
2）指1本でスムーズに調整可能
3）配線がスッキリするデザイン
　
購入時に確認したい2つのポイント
1）価格は3万円台前半と少々高め
2）長期テストをしていないので耐久性は未知数
　
まとめ
詳細スペック情報
　
　COFO無重力モニターアームPro（上下配置版）は、2枚のモニターを支えながらも、直感的に動かせることをウリにしたモニターアームです。一般的な製品の「一旦位置を決めたら動かさない」タイプとは発想が異なります。
　
　特徴的なのは、頻繁な位置調整を前提としている点です。作業内容に応じて高さや向きを変える、そんな使い方が想定されています。ここからは、このモニターアームのメリットと購入時に確認したい2つのポイントを紹介していきます。
　
COFO無重力モニターアームPro（上下配置版）を購入する3つのメリット
　
ポイント（1）2枚モニターを自在に配置できる
　
　COFO無重力モニターアームPro（上下配置版）は17〜40型（14kgまで）のモニターを2枚取り付けられ、上下・左右の配置どちらにも対応しています。縦向き・横向きの切り替えもスムーズで、作業内容に応じたレイアウト変更が簡単です。
　
　たとえば、上に資料用モニター、下にメイン作業用モニターといった配置も無理なく可能です。単にデュアルモニター環境を使うだけでなく、用途に合わせて頻繁に変えたいという人にも適しています。
　
YouTubeでCOFO「COFO無重力モニターアームPro（上下配置版）」のレビュー動画を見る


　
指1本でスルスル動く！横画面モニターを縦配置にもできるアーム｜COFO無重力モニターアームPro
　

　
ポイント（2）指1本でスムーズに調整可能
　
　最大の特徴は、やはり動かす時の軽さです。実際に使ってみると、たしかに指1本でスッと動かせます。それでいて、止めたい位置でピタッと止まり、アームにあるノブを回すと固定され、勝手に下がることもありません。
　
　トルク調整も工具不要で、手で回すだけ。微調整がしやすく「ちょっとだけ動かしたい」という場面でストレスを感じません。この操作感は、数あるモニターアームの中でもかなり優秀と言えるでしょう。
　
ポイント（3）配線がスッキリするデザイン
　
　アーム自体のデザインはシンプル。さらに、ケーブルをアーム内部に収納できる構造のため、配線がゴチャつかず、デスクもスッキリします。
　
　頻繁に動かすアームだからこそ、見た目が破綻しないのは嬉しいポイントですね。作業環境を整えたい人にも向いています。
　
購入時に確認したい2つのポイント
　
ポイント（1）価格は3万円台前半と少々高め
　
　価格は3万2999円と、モニターアームとしては高額です。一度位置を決めたら動かさない使い方であれば、数千円からモニターアームは購入できます。「動かして使う」ことを重視しない人には、オーバースペックになる可能性がありますね。
　
ポイント（2）長期テストをしていないので耐久性は未知数
　
　頻繁に動かす設計だからこそ、耐久性については気になります。実際に試用した短期間では自在に動かすことができ、好みの位置に留めることも問題ありませんでしたが、今回は長期間テストをしたわけではないので、この無重力感がどこまで維持できるか判断しかねる部分があるのも確かです。
　
■Amazon.co.jpで購入


　
COFO「COFO無重力モニターアームPro（上下配置版）」
　

結論：たしかにかなり無重力だった
　
　COFO無重力モニターアームPro（上下配置版）は、確かに「指1本で動く」という売り文句に応えてくれる製品でした。2枚のモニターを支えながら、ここまで軽快に動かせるアームはそう多くはありません。
　
　価格は高めですが、作業内容に応じてモニター位置を頻繁に変える人にとっては、その価値を実感できるはず。姿勢調整や作業効率の面でもメリットがあります。
　
　一度固定して終わりではなく、デスク環境を「動かしながら最適化したい」人向けのモニターアーム。この無重力感は一度触れるとクセになりますよ。
　
■Amazon.co.jpで購入


　
COFO「COFO無重力モニターアームPro（上下配置版）」
　

COFO無重力モニターアームPro（上下配置版）のスペック
　
サイズ／重量：
　1157.5×115×764、約6.72kg
　
カラー：
　マットブラック、マットホワイト
　
天板厚さ：
　クランプ10〜50mm、グロメット10〜55mm
　
VESA規格対応サイズ：
　75×75mm、100×100mm
　
耐荷重：
　約2.5〜14kg、推奨対応モニターサイズ 17〜40インチ
　
素材：
　スチール、アルミ合金、ABS
　
価格：
　3万2999円
　
■Amazon.co.jpで購入


　
COFO「COFO無重力モニターアームPro（上下配置版）」
　


文● ドリまつ／岡本／ASCII　編集⚫︎ASCII",[],[]
2026年からでも間に合う！　ChatGPTやGeminiの有料プランをお勧めする理由（アスキー）,https://news.yahoo.co.jp/articles/9973ee30f66b4af8e0be114caa148e3415ec9286,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20260109-00000011-ascii-000-1-view.jpg?exp=10800,2026-01-09T15:30:00+09:00,2026-01-09T15:30:00+09:00,アスキー,ascii,アスキー,3792,"本連載は生成AIをこれから活用しようとしている方たちのために、生成AIの基本やコピペしてそのまま使えるプロンプトなどを紹介。兎にも角にも生成AIに触り始めることで、AIに対する理解を深め、AIスキルを身に着けて欲しい。第41回はChatGPTとGeminiの無料プランと有料プランの違いを比較してみる。
【もっと写真を見る】
写真：アスキー
本連載は生成AIをこれから活用しようとしている方たちのために、生成AIの基本やコピペしてそのまま使えるプロンプトなどを紹介。兎にも角にも生成AIに触り始めることで、AIに対する理解を深め、AIスキルを身に着けて欲しい。第41回はChatGPTとGeminiの無料プランと有料プランの違いを比較してみる。
　
　2026年もAIの進化と普及は止まらず、想像を超えるようなことが実現できるようになるだろう。もうChatGPTやGeminiの無料アカウントで、チャットUIに質問や相談を入力するといったことは当たり前の使い方になっており、ビジネスシーンでは周回遅れになっている。そのまま無料アカウントでちょっと使うという状況に甘んじていると、ライバルとのAIスキルの差が広がってしまい、取り返しのつかない事態になりかねない。そこで、今回は生成AIサービスの有料プランがどのくらい便利なのかを具体的に紹介し、契約の後押しをしたい。
　
有料プランにすると制限が大幅に緩和し、賢いAIが使える
　
　ChatGPTは無料版でも一部の推論モデルやDeep Researchを使えるものの、回数に制限があり、本格的に使い始めるとまったく足りない。ChatGPT Plusは月額20ドルで、GPT-5.2 Thinkingによる高度な推論が利用でき、利用回数やメモリ、コンテキストウィンドウが大幅に拡大される。タスクやカスタムGPTというChatGPTならではの便利機能や、動画生成AIのSora、そしてコーディングAIのCodexエージェントも利用できるようになる。
　
　Geminiの無料版も一通りの機能は使えるが、Gemini 3 Flashが基本で上位モデルは回数制限がある。また、動画の生成はできない。Google AI Proは月額2900円で、Gemini 3 Proという賢いAIモデルが利用できる。画像生成AIのNano Banana Proの使用上限が増加し、動画生成AIのVeoも利用できるようになる。
　
　ちなみに、Google WorkspaceユーザーにはGeminiが標準搭載されている。例えば、Google Workspace Standardであれば月額1600円でGoogle AI Pro相当の機能を利用できるのでお得。
　
徹底的な調査を自律的に行ってくれるDeep Research
　
　有料プランで便利なのが、ChatGPT 5.2 ThinkingやGemini 3 Proなどの推論モデルを存分に利用できること。やや出力までの時間が長くなるが、賢いに越したことはない。
　
　また、AIが自律的にインターネット上の情報を深く広く調査し、包括的なレポートを作成するDeep Researchを使えるのも見逃せない。ユーザーが検索エンジンを使って一つ一つページを開いて確認する従来の作業や、チャットボットに簡単な質問をして即答を得るのとはまったく異なる体験だ。優秀な人間のリサーチアシスタントに複雑な調査業務を依頼するような感覚に近く、市場調査や競合分析、学術的な文献調査などで大幅な時短になる。
　
　ちなみに、Deep Researchの利用回数はChatGPTが月間25回、Geminiが1日20回となっている。Geminiの方が多いが、ChatGPTも上限に達すると軽量版Deep Researchに切り替わり、続けて利用できる。
　
ビジネスクオリティに進化した静止画・動画生成AI
　
　画像生成を楽しむなら、ChatGPTは2025年12月16日に公開したGPT-Image-1.5、Geminiは2025年11月20日に公開したNano Banana Proが利用できる。GPT-Image-1.5は人物の一貫性保持に優れ、精密な編集が可能。API価格が安価で、高速動作が魅力。Nano Banana Proは日本語の描写力が正確で、インフォグラフィックや商用ビジュアルに活用できる。4Kの高解像度出力も可能だ。
　
　どちらも、無料でも試せるものの、利用回数や解像度に厳しい制限がある。頻繁に利用するのであれば、有料プランの契約が必要になる。
　
　動画を生成するなら、ChatGPTでは2025年9月30日に公開したSora 2が利用できる。物理法則を理解し、音声も同時に生成できる。動画共有SNSのような「Sora」アプリも公開された。また、2025年12月にはディズニーと提携し、著作権をクリアした状態で画像や動画にミッキーマウスやヨーダを登場させられるようになるのも注目ポイントだ。
　
　Geminiでは2025年10月15日に公開したVeo 3.1が利用できる。こちらも、音声を同時に生成できる。複数枚の画像を入力し、一貫性を保持するのにも強い。映像編集ツール「Flow」も公開している。
　
　動画も画像と同様、無料アカウントでも利用できるが、生成回数や高解像度、高度な機能は有料プランが必要になる。
　
ChatGPTのUI内でPhotoshopやAcrobatなどのアプリが動く
　
　ChatGPTはApps in ChatGPT機能により、他のウェブサービスやアプリと連携することができる。すでに、AcrobatやPhotoshopをはじめ、Canva、Apple Music、Booking.com、Figmaなど、多数のサービスが対応している。こちらは無料アカウントでも利用できるが、上位AIモデルの利用制限にかかると、軽量モデルで動作する点は覚えておこう。
　
　有料プランでは、さらに高度なデータ連携機能が利用できる。GitHubでリポジトリ管理したり、Google DriveやMicrosoft OneDrive、Dropbox、SharePointなどのクラウドストレージにアクセスできるのだ。
　
Googleのキラーコンテンツ「NotebookLM」が超絶便利
　
　ビジネスパーソンならNotebookLMはぜひ活用したい。Googleが提供する検索拡張生成（RAG）技術を活用したAIノートブックツールで、ユーザーがアップロードしたPDFやGoogleドキュメント、Web記事などを情報源として読み込み、その内容に基づいてAIが要約や質疑応答を行ってくれるのが特徴。一般的なチャット型AIとは異なり、回答の根拠が指定した資料に限定されるため、ハルシネーションが抑制され、出典も明示される。
　
　さらに、情報源を元に様々なコンテンツを生成できるのもすごい。現在はポッドキャスト風の音声解説や解説動画、マインドマップ、フラッシュカード、プレゼンスライドなど、多彩なメニューが揃っており、驚くほどクオリティの高い成果物が得られるので注目されている。
　
　無料アカウントでも利用できるが、作成できる個数、情報源として登録できる数、そして1日に会話できる数などが制限されている。NotebookLMを使い倒すなら、有料プランが必要になるだろう。
　
　以上が、ChatGPTとGeminiの無料版と有料版の違いとなる。どちらもフリーミアムなので、無料でもそこそこの機能を利用できるが、利用回数や機能を制限しており、活用するなら有料プランが必要になる。有料プランにもいろいろあるが、まずはその中で安い20ドル前後のプランでも十分だろう。
　
　契約する際、年間契約だと割安になる。ただし、おすすめは月額契約だ。まずは、ChatGPTを契約したものの、NotebookLMの活用度が高まったのでGeminiにしたい、といったときに気軽に乗り換えられるようにするためだ。生成AIシーンの変化はとても激しく、今のベストが半年後に同じとは限らない。そんな時も、月額契約にしておけばロスを押さえられる。
　
　無料の範囲でちょっとずつ利用するのはもうやめて、ChatGPTもしくはGeminiの有料プランを契約して使い倒し、AIスキルを身に着け、高めていこう。業務効率がアップすれば、月に20ドルはすぐに元が取れるはずだ。
　
AIで何とかしたい業務を大募集！
　
「簡単すぎて驚く生成AIの使い方」で取り上げてほしいAIの使い方を大募集。「この作業をAIで時短したい」「こういうことがしたいけどプロンプトはどう書けばいい？」など、お困りのことを解決します。
　
応募はハッシュタグ「
#ASCIIAI連載ネタ
」を付けてXでポストするだけ。ハッシュタグ「
#ASCIIAI連載ネタ
」がついたポストは編集部で随時チェックし、連載記事で取り上げます。高度な内容である必要はないのでお気軽にどんどんポストしてください。
　

文● 柳谷智宣　編集●MOVIEW 清水",[],[]
最大1万円分お得！「PayPay商品券」2026年2月は愛知が熱いぜ！（アスキー）,https://news.yahoo.co.jp/articles/f433f272322ccc6d48ac807cdf5afb40bd8899a7,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20260109-00000010-ascii-000-1-view.png?fmt=jpeg&q=85&exp=10800,2026-01-09T14:45:00+09:00,2026-01-09T14:45:00+09:00,アスキー,ascii,アスキー,555,"PayPayでお得に買い物ができる「プレミアム付きデジタル商品券」。2026年2月受付開始分の自治体として、愛知県豊田市が追加されました。対象地域にお住まいの方は、この機会をお見逃しなく！
写真：アスキー
PayPayでお得に買い物ができる「プレミアム付きデジタル商品券」。2026年2月受付開始分の自治体として、愛知県豊田市が追加されました。
　
　たくさん買うほどお得度がアップするので、対象地域にお住まいの方は、この機会をお見逃しなく！
　
中部
　
●愛知県
　
豊田市「豊田市 家計サポートプレミアム付き商品券」
　
販売価格と額面：
　
・販売価格：1万円／口
・額面：1万2000円分／口
　
使用可能店舗：愛知県豊田市のPayPay加盟店（一部を除く）
　
購入できるユーザー：愛知県豊田市在住の12歳以上のPayPayユーザー（要本人確認）
　
販売方法：抽選制
　
申込期間：2026年2月16日10時〜3月1日23時59分
　
当選発表：2026年3月2日夕方以降（予定）
　
販売期間：当選発表後〜3月31日23時59分
　
利用期間：購入後〜8月31日23時59分
　
最大申込数：5口／人（申込状況により購入可能口数が減る可能性あり）
　

文● スミーレ（@sumire_kon）",[],[]
都立大、不正アクセスで個人情報流出か　教員がフィッシング被害（アスキー）,https://news.yahoo.co.jp/articles/f0f59e7f60c01c64248cfac175bc0860f9234fca,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20260109-00000009-ascii-000-1-view.png?fmt=jpeg&q=85&exp=10800,2026-01-09T14:35:00+09:00,2026-01-09T14:35:00+09:00,アスキー,ascii,アスキー,1328,"東京都公立大学法人は1月7日、東京都立大学の教員が個人で取得したGoogleアカウントが不正アクセスを受け、当該教員が所有していた個人情報が外部へ流出した可能性があることを明らかにした。翌1月8日にも第2報として、より詳しい状況を公開している。
写真：アスキー
東京都公立大学法人は1月7日、東京都立大学（都立大）の教員が個人で取得したGoogleアカウントが不正アクセスを受け、当該教員が所有していた個人情報が外部へ流出した可能性があることを明らかにした。翌1月8日にも第2報として、より詳しい状況を公開している。
　
　外部流出の疑いがある個人情報（概要）は以下のとおり。
　
●外部流出の疑いがある個人情報（概要／2026年1月8日時点）
　
A.東京都立大学 経済経営学部・経営学研究科主催の以下のイベントへの申込者及びアンケート回答者に係る情報（180件）
　
・「平成29年度 外部検定試験受講対策講座」受講申込者（同大の学生のみ）：氏名、学修番号、所属、学年、メールアドレス、住所、電話番号
・「令和5年度 経営学研究科経済学プログラムシンポジウム」参加申込者：氏名、職業、勤務先、メールアドレス
・「令和5年度 経営学研究科博士後期課程入試説明会」参加申込者：氏名、勤務先、メールアドレス、電話番号
・「令和6年度 経営学研究科経済学プログラム入試説明会」参加申込者：氏名、勤務先、メールアドレス、電話番号
・「令和6年度 経営学研究科経済学プログラム入試説明会」アンケート回答者：メールアドレス、職業、年代
　
B.東京都立大学 経営学研究科入試合格者に係る情報（249件／うち6件はAと重複） 
　
・「令和2年度 経営学研究科入学予定者向けプログラム」参加者：氏名、学修番号、所属プログラム、勤務先、メールアドレス 
・「令和3年度 経営学研究科入学予定者向けプログラム」参加者：氏名、学修番号、所属プログラム、メールアドレス
・「令和4年度 経営学研究科入試」合格者：氏名、所属プログラム、勤務先、メールアドレス、住所 
・「令和5年度 経営学研究科入試」合格者：氏名、所属プログラム、勤務先、メールアドレス、住所 
・「令和6年度 経営学研究科入試」合格者：氏名、所属プログラム、勤務先、メールアドレス、住所 
・「令和7年度 経営学研究科入試」合格者：氏名、所属プログラム、勤務先、メールアドレス、住所
　
C.その他
　
・当該教員が過去に送受信したメールに係る情報 ：メールアドレス、本文、添付資料等
　
　本件は1月7日、当該教員のアカウントから、ドキュメント共有を装ったフィッシングメールが送信されたことがきっかけで判明。同法人によると、当該教員は2025年12月2日、海外の研究者のアカウントから送られてきたフィッシングメールに誘導されて、個人で取得したGoogleアカウントの情報を入力していたという。
　
　東京都公立大学法人では今後、該当する関係者に対して説明と謝罪を実施するとともに、個人情報の管理をより徹底するため、全学的な検討と対策を実施するとしている。
　
 

文● スミーレ（@sumire_kon）",[],[]
東武鉄道、3月に磁気定期券の販売終了へ（アスキー）,https://news.yahoo.co.jp/articles/3f48f93f7b607ca644d6e61c6baf169b9f4f69d7,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20260109-00000008-ascii-000-1-view.png?fmt=jpeg&q=85&exp=10800,2026-01-09T13:25:00+09:00,2026-01-09T13:25:00+09:00,アスキー,ascii,アスキー,345,"東武鉄道は1月9日、磁気定期乗車券（定期券）について、一部を除き、2026年3月13日をもって販売を終了することを明らかにした。
写真：アスキー
東武鉄道は1月9日、磁気定期乗車券（定期券）について、一部を除き、2026年3月13日をもって販売終了とすることを明らかにした。
　
　対象は磁気券を使用した通勤および通学定期券で、他の事業者への連絡定期券も含まれる。例外は他の事業者と連絡する「実習用通学定期乗車券」で、こちらは3月14日以降も当面の間、磁気券での販売を継続する。
　
　発行済みの磁気定期券については、販売終了後も有効期限まで利用可能。また、一部の連絡定期券を除き、券売機で磁気定期券をPASMO定期券に変更することも可能だ。
　

文● スミーレ（@sumire_kon）",[],[]
グーグル、GmailにGeminiをがっつり導入へ　メール探しがラクになる？　まずは米国から（アスキー）,https://news.yahoo.co.jp/articles/2bc310b63c6f87fd4f9f1e0af4ac6ab9ba5f31fc,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20260109-00000007-ascii-000-1-view.png?fmt=jpeg&q=85&exp=10800,2026-01-09T12:30:00+09:00,2026-01-09T12:30:00+09:00,アスキー,ascii,アスキー,1113,"グーグルは1月8日、生成AI「Gemini」を活用した「Gmail」の新機能を公表した。同日時点では英語限定かつ米国のユーザーが対象だが、今後数ヵ月以内に対応言語、地域を拡大する方針だ。
写真：アスキー
グーグルは1月8日、生成AI「Gemini」を活用した「Gmail」の新機能を公表した。同日時点では英語限定かつ米国のユーザーが対象だが、今後数ヵ月以内に対応言語、地域を拡大する方針だ。
　
　主な機能は以下のとおり。
　
●メール検索がより簡単に「AI Overview」
　
　「AI Overview」は、受信トレイを開いた状態で検索ボックスに質問を入力すると、Geminiが受信メールに関するシンプルな概要と回答を生成してくれる機能だ。
　
　例えば、過去に浴室リフォームの見積もりをしてくれた業者を探したいときは、検索ボックスに「昨年、浴室リフォームの見積もりをしてくれた業者は誰？」と入力するだけ。これまでのように該当期間のメール一覧から自力で探したり、キーワード検索をかけたりする必要はない。
　
　本機能は1月8日から、米国のGoogle AI Pro／Ultraの加入者向けに提供を始める。
　
●面倒な返信もラクになる？「Help Me Write」「Suggested Reply」「Proofread」
　
　「Help Me Write」は文章の作成をAIが手助けする機能。メールに何を書けばいいか迷った場合や、出来上がったメールをブラッシュアップしたい場合などに利用できる。
　
　「Suggested Reply」は、メールの返信文の候補をAIが提案してくれる機能。会話の文脈に基づき、ユーザーの書き方にあった適切な文面をワンクリックで提案可能だ。
　
　「Proofread」は新しい文章校正機能で、文法、トーン、スタイルなどの高度なチェックに対応。送信前の仕上げ作業と相性がよい。
　
　3機能はいずれも1月8日から米国で展開を開始。Help Me WritとSuggested Replyはすべてのユーザーが、ProofreadはGoogle AI Pro／Ultraの加入者が対象となる。
　
●受信トレイをAIが自動で整理「AI受信トレイ」
　
　「AI受信トレイ」は、AIが受信トレイ内をパーソナライズする機能。具体的には、ToDoリストをハイライト表示したり、メールの送信元や内容を分析して優先順位付けを支援するといったことが可能だ。
　
　こちらは一部のユーザーを対象としたテスト段階で、今後数ヵ月以内の一般公開を予定している。
　

文● スミーレ（@sumire_kon）",[],[]
Google Meetにリアルタイム翻訳機能　1月27日からベータ公開（アスキー）,https://news.yahoo.co.jp/articles/615e2ebf0323b268ff4d60142f8eb59dc2c90722,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20260109-00000006-ascii-000-1-view.png?fmt=jpeg&q=85&exp=10800,2026-01-09T11:30:00+09:00,2026-01-09T11:30:00+09:00,アスキー,ascii,アスキー,786,"グーグルは1月7日、「Google Meet」のリアルタイム音声翻訳機能について、現行のアルファ版を1月27日よりベータ版へ移行し、提供範囲を拡大する方針を明らかにした
【もっと写真を見る】
写真：アスキー
グーグルは1月7日、「Google Meet」のリアルタイム音声翻訳機能について、現行のアルファ版を1月27日よりベータ版へ移行し、提供範囲を拡大する方針を明らかにした。
　
　本機能はGemini for Meetの管理設定が有効な状態で、ユーザーが翻訳機能をオンにした際に起動可能。翻訳がオンになっている間は、他の参加者に翻訳を使っていることが表示されるため、「突然英語がペラペラになった」と勘違いされる心配もない。
　
　このほか、必要に応じて、管理コンソールから組織部門単位で翻訳機能の使用可否を切り替えることも可能だ。
　
　提供対象のユーザーと展開予定時期は、それぞれ以下のとおり。
　
●対象ユーザー
　
以下のプランを契約中のユーザー
　
・Google Workspace Business Plus
・Google Workspace Enterprise Plus
・Google Workspace Frontline Plus
　
・Google AI Pro
・Google AI Ultra
・Google AI Ultra for Businessアドオン
・Google AI Pro for Educationアドオン
　
●展開予定時期
　
■管理者設定
　
・即時リリースおよび計画的リリースのドメイン：2026年1月7日から順次
　
■エンドユーザー向け機能
　
・即時リリースドメイン： 2026年1月27日から順次
・計画的リリースドメイン：2026年2月18日以降
　
 

文● スミーレ（@sumire_kon）",[],[]
Power Platformとkintone　ノーコード・ローコードツール“いいとこ取り”のススメ（アスキー）,https://news.yahoo.co.jp/articles/08962cd812221ece291ed8127a8dce7d3c779503,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20260109-00000005-ascii-000-1-view.jpg?exp=10800,2026-01-09T09:00:00+09:00,2026-01-09T09:00:00+09:00,アスキー,ascii,アスキー,3933,"Microsoftのローコード開発ツール「Power Apps」とサイボウズのノーコード・ローコードツール「kintone」。どちらを導入するか迷っている企業もあれば、両ツールの使い分けを迫られている企業も存在するだろう。
【もっと写真を見る】
写真：アスキー
大企業での採用が多いMicrosoftの「Power Platform」でローコード開発を担う「Power Apps」と、中小企業だけではなく大企業にも利用が広がるサイボウズのノーコード・ローコードツール「kintone」。
　
　どちらを導入するか迷っている企業もあれば、両ツールの使い分けに迫られている企業も存在するだろう。
　
　サイボウズは、2025年10月末に年次イベント「Cybozu Days 2025」を開催。ロート製薬 DX/AI推進室の柴田久也氏と、BizOptimars 代表取締役社長でMicrosoft MVPでもあるりなたむ氏のセッションでは、両ツールを共存させるための勘所について語られた。
　
Power Platformとkintone　“棲み分け”の勘所
　
　最初のテーマは「Power Platformとkintoneは競合サービスなのか？共存できるものなのか？」だ。ここから触れる「共存」とは、目的や用途に応じて部署や部門でツールを使い分けている状態。「共創」とはツールを得意な領域に適用して、互いに連動させている状態を指す。
　
サイボウズ 小島雄一朗氏（以下、小島氏）：まずは、この2つのツールがどういう関係にあるか聞かせてください。
　
ロート製薬 柴田久也氏（以下、柴田氏）：ロート製薬では、kintoneとPower Platformが内包されている「Microsoft 365」を棲み分けて使っています。kintoneは、IT部門や非エンジニアの業務部門がアプリを内製開発する「業務改善プラットフォーム」として、Microsoft 365は日常の業務を回すための「ビジネスアプリケーション基盤」として位置付けています。そのため、弊社の場合は、「共存」もしくは「共創」させている形ですね。
　
りなたむ氏：私は、企業の内製開発を伴走支援する立場ですが、「共存」の形をとる顧客が多いです。特に多くの部署や子会社を抱える大企業では、Power Platformとkintoneを使い分けています。こうした企業も、共創まで進んで欲しいと思っています。
　
小島氏：最初は競合するものだと思っていたら、いつの間にか共存していて、最終的には共創を目指すというイメージでしょうか。
　
りなたむ氏：各部署がDXのためにそれぞれツールを利用し始め、統一されることなく、共存前提でルールも作られるという流れが多いです。
　
小島氏：具体的にどう棲み分けるかの勘所はありますか。
　
りなたむ氏：まず、会社がDXをしたくても、現場サイドは「なんで新しいレイアウト（UI）に合わせないとなんだ」と思ってしまいます。
　
小島氏：慣れ親しんだ紙が良いと。
　
りなたむ氏：「紙に合わせてくれないと困る」と抵抗する勢力は結構いますし、いずれにしてもレイアウトの大幅変更がDXの鬼門になるのは間違いないです。ただ、Power Appsには自由にレイアウトをカスタマイズできるキャンバスアプリがあります。
　
そのため、フロントである現場では、自身らに特化したアプリをPower Appsで作成する。バックエンドであるバックオフィスでは、日本の商習慣にあった仕組みをkintoneで作成するといった棲み分けが考えられます。さらに、公式のカスタムコネクタやCData Softwareの「CData Connect AI」などで、Power Appsとkintoneをシームレスにつなぎ、相互連携するシステム開発も可能です。
　
ライセンスの考え方も同じです。人員の変動が少ないバックオフィスはkintoneで堅実な運用で、雇用が増減しやすい現場はPower Appsで柔軟な運用（※）で最適化することで、ランニングコストを抑えられます。
　
※Power Appsでは、アプリ単位で利用できる「per App」プランや従量課金プランも用意されている
　
小島氏：Power Apps以外でPower Platformとkintoneの連携例はあるのでしょうか。
　
りなたむ氏：自動化ツールの「Power Automate」では、Delegation（委任）の設定ができるので「kintone×Teams」といった連携も可能です。BIツールの「Power BI」でkintoneのデータを分析したり、エージェント開発ツールの「Copilot Studio」でkintoneのMCP Serverと連動させて、部門横断の検索エージェントを実装することも可能です。
　
小島氏：ロート製薬での棲み分けも詳しく聞いてもいいでしょうか。
　
柴田氏：我々はトヨタ式カイゼンをリスペクトする形で、現場が自らの課題を改善する独自の「改鮮活動」に取り組んでいます。これは、弊社の文化である改善意識・自走意識が素地になっています。
　
こうした環境の中で、kintoneは市民開発のプラットフォームとして既に浸透しており、各プロジェクトのナレッジも蓄積してきました。そして、Microsoft 365は、ほぼ全社員が日々利用してため、親近感では優位性があります。
　
ただ、Power Platformは、通常業務を抱える現場がアプリ開発する上で、マニュアルひとつとっても英語がハードルです。一方のkintoneは自習コンテンツが豊富にあり、コミュニティも成熟しています。困った時に頼れる先人がいるという意味でも、kintoneが弊社にとっての最適解になっています。こうした“カルチャーフィット”をすごく大事にしているのです。
　
ツールを選定する方は、予算に収まっているか、サポートは信頼できるか、セキュリティは担保させているかなどはしっかりと比較すると思います。ぜひここにカルチャー、自社に合うかという観点を加えてみて欲しいです。
　
“業務理解”と“意思決定者とのコミュニケーション”の重要性
　
小島氏：Power Platformとkintoneの違いや棲み分けがよく分かりました。どちらかのツールを使っていてサービスを足したい場合に、意思決定者を説得する方法を教えて欲しいです。 
　
柴田氏：まず、意思決定者は現場担当と見ている景色が異なります。現場の実態とは別に、会社として優先したい取り組みやアウトプットがあり、そこにミスマッチが発生します。
　
私の場合、室長（CTOも兼務）やCIOとの密なコミュニケーションを意識しています。とにかく現場の課題や活動内容を積極的にシェアしていくのです。彼らも現場を見ていないわけではないですが、見えない部分を埋めることが、後のツールの棲み分けへの理解につながります。泥臭いですが、意思決定を見据えたキーパーソンとのコミュニケーションが重要です。
　
小島氏：さきほどのカルチャーフィットによる使い分けも説明するのでしょうか。
　
柴田氏：キーパーソンもカルチャーについては体感しているので、よりミクロな情報をインプットしていくイメージです。
　
小島氏：りなたむさんには、まったく使っていない状態から両ツールの導入を説得する方法を聞きたいです。
　
りなたむ氏：まずは、現状の業務を分析しないと、どのツールが最適か分かりません。例えば、データの持ち方やサポートサービスなどを考えると、Power Platformはどうしてもアメリカの商習慣寄りのツールです。それを変えることもできますが、工数を考えると日本の商習慣に合ったkintoneとの使い分けを検討することになります。まずは、業務プロセスやフローを理解して、正しい選択をしなければいけません。
　
小島氏：いきなりどのツールかではなく、まずは何をしたいかですね。
　
ツールはあくまで手段　“適所適材”な選定が第一歩
　
小島氏：最後に、悩んでいる企業を勇気づけるメッセージをお願いします。
　
柴田氏：ユーザーは聞きなれないかもしれませんが、“ベスト・オブ・ブリード”という言葉があります。システム構築においてその場その場で最適なものを選択していきましょうという考え方です。
　
やはり、業務や目的ごとに最適な製品を選択することが大事だと思っています。データがサイロ化してしまう側面もありますが、あくまでツールは手段なため、適材適所ではなく「適所適材」で選ぶべきです。
　
もうひとつは、サンクスコストに捉われないことです。既にコストを払っているから使わなきゃというのはナンセンスで、適所適材でツールを選定するのが第一歩だと思います。
　
りなたむ氏：業務プロセスを理解した上で、柴田さんの言う適所適材で選択していくのが、やはり前提です。バックオフィス側の要請で導入したサービスが、現場側では使いにくいという話はよくあります。両サイドの意見を取り入れて、業務プロセスを改善するという目標のもとで、DXのためのツールを決めて欲しいです。
　
それこそkintoneもPower Platformも機能を試せるプログラムがあるので、まずは開発してみましょう。最初は自分のために作るところから、個人のDXから始めることも大事だと思います。
　

文● 福澤陽介／TECH.ASCII.jp",[],[]
GigaCrystaが新に3つのシリーズ展開に、50周年を記念したXプレゼントキャンペーンも開始（アスキー）,https://news.yahoo.co.jp/articles/a92bbd118a881756935b6d6bb3027e2259f7c496,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20260109-00000004-ascii-000-1-view.png?fmt=jpeg&q=85&exp=10800,2026-01-09T09:00:00+09:00,2026-01-09T09:00:00+09:00,アスキー,ascii,アスキー,1288,"アイ・オー・データ機器は1月8日、50周年記念 記者発表会を開催。ゲーミングディスプレーブランド「GigaCrysta」の新たなシリーズ展開も発表された
【もっと写真を見る】
写真：アスキー
アイ・オー・データ機器は1月8日、50周年記念 記者発表会を開催した。発表会では、代表取締役会長の細野 昭雄氏が登壇し、これまでの50年を振り返りつつ今後の展望を語ったほか、50周年の新たな取り組みについても紹介した。
　
　その中で個人的に1番気になったのが、ゲーミングディスプレーブランド「GigaCrysta」の新たなシリーズ展開。同社によると、今後は3シリーズ構成で製品を展開していくという。
　
　1つ目は、「GigaCrysta S」で、コンセプトは「現実が嫉妬する世界へ。ゲーム体験のファーストクラス」。OLEDやMini LEDといったハイエンドディスプレー向けの技術を搭載した、フラッグシップモデルを展開するシリーズになるという。
　
　2つ目は、「GigaCrysta」で、コンセプトは「迷わず選べる、確かな基準。勝利への最短距離」。高速パネルやハイリフレッシュレートを採用し、実用性が高くバランスのいい製品を展開するシリーズとなる。
　
　3つ目は、「GCF」で、コンセプトは「速さだけを追求して、ラグを脱ぎ捨てろ。速さにフォーカスした別解」。ハイリフレッシュレート、低遅延にフォーカスし、コスパも重視したモデルを展開するという。
　
　この3つのシリーズ展開にしたことで、「どんなディスプレーがほしいのか」に合わせて選びやすくするのが目的だと感じた。最新技術をふんだんに採用したハイエンドモデルが好きという人はGigaCrysta S、高性能なディスプレーがほしいけど、どれを選んだらいいかわからない人はGigaCrysta、競技タイトルをガッツリ遊ぶコスパ重視のディスプレーがほしいという人はGCFを選択すればいいというシリーズ展開なのではないかと予想できる。
　
　発表会会場には、GigaCrysta Sシリーズの4K解像度でMiniLEDを採用した27型「LCD-GDU271JLADQ」、GigaCrystaシリーズの320HzでWQHD対応の27型「LCD-GDQ271RA」、GigaCrystaシリーズでWQHD、かつウェブの動画サービスが利用できる27型「LCD-GDQ271JAWOS」が参考出展されていた。
　
　そのほか、CDの音源をスマートフォンに入れられる「CDレコ」のBlu-rayバージョンとなる「BDレコ」が参考出展されていた。テレビの録画番組を、Blu-ray DiskやDVDにネットワーク経由でダビングできるという。
　
　そのほか、創業50周年を記念した取り組みも実施。第1弾として創業記念日の1月10日から「総額プレゼントキャンペーン」をXにて実施する。また、50周年を象徴するプロダクトとして、同社の各種商品から「50周年記念モデル」を、一年を通じて順次発表していくとのことだ。
　

文● 八尋 編集●ASCII",[],[]
Acer、驚きの「1000Hz駆動ディスプレー」や「Ryzen AI 9」搭載ゲーミングノートPCを発表（アスキー）,https://news.yahoo.co.jp/articles/e725cd09ef1427ddb08dcd79b6bcad913561eae2,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20260109-00000003-ascii-000-1-view.png?fmt=jpeg&q=85&exp=10800,2026-01-09T09:00:00+09:00,2026-01-09T09:00:00+09:00,アスキー,ascii,アスキー,1377,"AcerのPCのスペックには、毎回驚かされてしまう。
【もっと写真を見る】
写真：アスキー
Acerの展示を見てきました
　
　今年も行きました。Acerの秘密の展示室。
　
　米ラスベガスで現地時間1月9日まで開催中のCES 2026では、世界中のテクノロジー関連企業が一斉に展示を行ないますが、この期間に、近隣のホテルや会場などを貸し切って、プライベートな空間で展示を実施するメーカーも存在します。
　
　Acerも、メディアを招待してプライベートな展示を実施するのが恒例。今年はCopilot+ PC対応モデルがずらりと並び、AI機能と同社のノートPCとの高い親和性を示しました。
　
　中でも、インテルから発表されたばかりの最新のプロセッサー「Core Ultra（シリーズ3）」を搭載する14型の「Acer Aspire 14 AI」と16型の「Acer Aspire 16 AI」は注目モデル。
　
　リフレッシュリフレート120HzのOLED、最大32GBのメモリーと最大1TBのSSD、USB4規格のUSB Type-C端子、そしてタッチ操作対応スクリーン、180度の開閉に対応したディスプレーなど、非常に“いまっぽい”スペックです。
　
ゲーミングノートPCも熱い！ 熱いというか欲しい！
　
　ゲーミングノートPCも非常に高い完成度に仕上がっていました。
　
　16型の「Predator Helios Neo 16S AI」はIntel Core Ultra 9 386Hと、NVIDIA GeForce RTX 5070 Laptop GPUを搭載（最大構成時）。ディスプレーはWQXGA解像度のOLED。第5世代の「AeroBlade 3Dファン」と「液体金属サーマルグリス」を採用することで、安定した動作を実現します。
　
　メモリー容量は最大64GBで（DDR5）、ストレージは最大2TBのPCIeに対応。そして、このスペックで、厚さはなんと18.9mm！　非常にスリムです。
　
　同じく16型の「Nitro V 16 AI」は、AMD Ryzen AI 9 465、GeForce RTX 5070 Laptop GPUを選択でき（最大構成時）、リフレッシュレート180HzのWUXGA（1920×1200ドット）ディスプレーを備えるモデル。メモリー容量は最大32GB（DDR5）で、ストレージは最大2TB SSDと、文句なしのハイスペック。
　
　ゲーミングディスプレーも複数モデルを発表。中でも27型の「Predator XB273U F6」は、500Hzという超高速リフレッシュレートを実現。さらに「Dynamic Frequency and Resolution（DFR）」モードを使用+1280×720解像度時にという条件付きではあるものの、最大1000Hzでの駆動も実現しています。
　
　1000Hzすごすぎる。500Hzと1000Hzの違いを見分けられる自信があるかどうかはさておき、1000Hzというロマンある数字にお金を払いたい、手に入れたい。そう思ってしまうのがガジェット好きかもしれません。
　
　今年も、気になるもの、欲しいもの盛りだくさんのAcerの展示でした。
　

文● 貝塚／ASCII",[],[]
“鶏が先か、卵が先か”の議論をやめ、AIを事業成果につなげる年へ　―ネットアップ・斉藤社長（アスキー）,https://news.yahoo.co.jp/articles/11c31a376b2c956a20c00b82b118850a14706950,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20260109-00000002-ascii-000-1-view.jpg?exp=10800,2026-01-09T08:00:00+09:00,2026-01-09T08:00:00+09:00,アスキー,ascii,アスキー,5749,"企業がAI活用を事業成果につなげ、成功させるにはデータ基盤の整備が不可欠である――。昨年からネットアップ（NetApp）日本法人の社長を務める斉藤千春氏は、そう訴える。そうした意識転換が進んでいない日本企業の課題や、その現状をどう変えようと考えているのかを聞いた。
【もっと写真を見る】
写真：アスキー
昨年（2025年）6月から、ネットアップ（NetApp）日本法人の社長を務める斉藤千春氏。9月に行った事業戦略説明会では、企業がAI活用を成功させるためのデータ基盤構築の重要性を訴えるとともに、「日本の企業やSIerはまだその重要性に気づいていない」と指摘。ネットアップが掲げる「インテリジェント・データ・インフラストラクチャー」コンセプトを日本企業に広く浸透させ、その現場導入を進めていく1年にしたいと語った。
　
　AIとデータの活用をめぐる日本企業の現状や課題をどう見ているのか、そこから前進させるためにネットアップは何ができると考えているのか。あらためて、斉藤氏と同社チーフ テクノロジー エバンジェリストの神原豊彦氏に話を聞いた。
　
AIの本格展開を前に“鶏が先か、卵が先か”で立ちすくむ日本企業
　
――先の事業戦略説明会では、「AI活用成功の重要ポイントはデータ基盤の整備」と強調した一方で、日本の企業やSIerはそうした意識が薄く、データ基盤整備への投資意向も低いことを指摘されました。そもそもなぜそうなっているのか、背景をどう見ていますか。
　
斉藤氏：AIに限りませんが、全体としてはやはり欧米の企業のほうが、決断も行動も早いですね。もちろん、日本企業においてもAIへの期待は非常に高まっていて、PoCやトライアル利用は始まっています。ですが、一部の大企業を除いて、「具体的な事業成果」に結びつけるフェーズにはまだまだ達していません。
　
　この「AI活用を事業成果に結びつける」フェーズで、データ基盤への投資が不可欠になると考えています。AI活用を事業成果に結びつけるには、信頼できるデータを用いて、安全かつ迅速に、自社の業務やビジネス課題に適合させていくことが重要だからです。しかし、トライアルの段階では基盤整備が不十分なケースが多いため、事業成果の見通しが立たない。“鶏が先か、卵が先か”という言葉のとおりかもしれません。
　
　日本では、データ基盤への投資を「コスト」と捉える傾向が強く、投資判断も遅れがちです。日本企業に今求められている“次の一手”は、AI戦略の中心にデータの戦略を据え、投資判断をきちんと加速していくことだと、わたしたちは考えています。ここがいま、日本企業にとっての大きな課題ではないでしょうか。
　
――“鶏が先か卵が先か”の議論で立ち止まってしまっているわけですね。そうした現状に対して、ネットアップではどんな解決策を提示しているのでしょうか。
　
斉藤氏：まずは「試してみる」から「本番で活用する」「統制しながら活用を広げていく」までの3段階を、ネットアップが途切れなく支援できます、ということです。ネットアップならば、オンプレミスと主要クラウドを横断する形で、一貫したルールでのデータ管理や強固なガバナンスを持つ“一枚岩のデータ基盤”を構築できます。
　
　それから、データ基盤を通じて「スピード」と「ガバナンス」「ROI（投資対効果）」の3つを同時に引き上げられることも、とても重要だと考えています。どれか1つだけならばそれほど難しくないのですが、この3つがそろわなければ「投資する」という決断までは持って行けないな、という実感があります。
　
――3つを「同時に」という点が難しそうです。そうした新たなデータ基盤の構築は、具体的にはどんな手順で進めるのですか。
　
斉藤氏：まずは顧客企業の経営層の方々にアプローチをして、エグゼクティブブリーフィングというかたちで、現状の認識を再定義します。そのうえで、全社にあるデータの棚卸しと可視化を行い、現状を明確化したうえで、ハイブリッドクラウド／マルチクラウドを前提とした本番運用のアーキテクチャを再構築します。そのうえで、PoC、本番活用、全社展開までを一気通貫で加速していくというのが、現在のアプローチです。
　
　エンタープライズのお客さまの場合、こうした新しいデータ基盤への転換は「3年で結果を出す」ことを目標に進めるケースが多いです。まず1年目はPoCや簡単なテストケースを実施し、2年目に本番運用のデザインを行って、3年目に事業成果を出すというかたちですね。もう少し規模の小さなお客さまでは、そこまで急がず、5年後をめどに事業成果を出そうと考えられることが多いと感じます。
　
AI向けデータ処理もストレージ内で、「AI Data Engine＋AFX」をリリース
　
――ネットアップでは「インテリジェント・データ・インフラストラクチャー（以下、IDI）」というコンセプトを掲げており、今年度はその現場導入を進める「展開の年」にしたいと方針を述べられていました。このIDIというのは、ネットアップが従来アピールしていた「データファブリック」が進化したものと考えてよいですか。
　
斉藤氏：「進化」というよりは、IDIの中にデータファブリックも包含されていると考えてください。IDIの根本的な考え方は、「お客さまが持つあらゆるデータを“AI Ready”なものにする」というものです。そのベースとなるレイヤーに、データファブリックが組み込まれている。そんなイメージです。
　
　AIの価値を最大化するデータ基盤を構築するためには、オンプレミスからクラウドまでシームレスなデータアクセス、データ管理を実現することが必要です。ここで、ネットアップのデータファブリックの優位性が生きてきます。
　
――それでは、IDIで新たに加わった部分、つまりデータファブリックとの“差分”は、技術的にはどんなものでしょうか。
　
チーフ テクノロジー エバンジェリスト 神原豊彦氏：お客さまのデータをAI Readyなものにするために、新たに「NetApp AI Data Engine」が組み込まれています。AIモデルが読み込めるデータにするためにはさまざまな事前処理が必要ですから、それをわれわれのデータ基盤側でやってしまおうと。たとえばデータのベクトル化や、メタデータの管理といったものですね。
　
――今回、ネットアップが単なるデータストレージにとどまらず、そうしたデータ処理まで踏み込んだのが興味深いところです。それはなぜですか。
　
神原氏：従来のAIモデルのトレーニングでは、この図（図A）のようなプロセスが必要でした。左にある各種ストレージからデータをデータレイクに集め直し、ラベリングやベクトル化をしてGPUクラスタにつないでと、準備作業の間に何度もデータのコピーや移動が発生し、多数のツールを使うことになります。この中間処理の部分をAI Data Engineが引き受けることで、ネットアップのデータ基盤内で一括管理することができます（図B）。
　
　もちろん、すでにAIモデル開発を手がけられているお客さまは、こうした（図Aのような）システムを構築されているケースもあるので、それを丸ごとAI Data Engineに変えていただく必要はありません。ただし、こうしたデータ処理にまつわる部分は「NVIDIA NeMo」フレームワークなどで徐々に標準化が進んでいますから、部分的にご採用いただいたり、必要なタイミングで丸ごと入れ替えたりということも考えられるでしょう。
　
――話は戻りますが、IDIのベースとなるストレージ部分の要件は、従来のエンタープライズストレージと変わらないのでしょうか。何か特別な要件はありますか。
　
神原氏：ストレージアクセスのプロトコルを含め、基本的には変わりません。ただし、これまでせいぜい数百台規模だったサーバークラスタが、数千台、数万台というオーダーになってくるので、われわれもスケールアップさせる必要がありました。
　
　そこで今回リリースしたのが「NetApp AFX」という新しいモデルのストレージです。エンタープライズAIワークロード向けストレージとして、たとえばI/Oスループットは4TB／秒、扱えるデータセットの容量は1EB（エクサバイト）以上と、徹底的にAI向けのチューニングが施されています。分散アーキテクチャを採用しており、構成可能なノード数も最大128ノードまで拡大しています。
　
　加えて、本格的にAIモデル開発に取り組んでいるお客さまからの要望が強かったのが「データセキュリティの強化策」です。
　
　AIに対する攻撃手法のひとつとして、トレーニング用データに不正なデータをまぎれ込ませて、誤った判断や回答をするAIモデルを開発させる「データポイズニング」というものがあります。トレーニングデータが10万個あるうち、わずか2個を改竄するだけで実行できるという調査結果もあり、人間がそれを監視し検出するのは困難です。ネットアップでは、以前からランサムウェアの自動検出に取り組んできましたから、その技術を適用して攻撃を検出できるようにしています。
　
――先ほどのAI Data Engineは、このAFX上で動作するのですか。
　
神原氏：そうですね。細かく言えば、AFXのストレージ部分はコントローラーノードとSSDディスクシェルフで構成されますが、そこにAI Data Engine用の「データコンピュートノード」が新たに追加され、この全体がAFXとして機能する仕組みです。
　
IDIのコンセプト浸透は「まだ不十分」、その課題と今後の戦略は
　
――ネットアップでは数年前からIDIのコンセプトを掲げてきましたが、もう顧客企業にも浸透しているのでしょうか。
　
斉藤氏：リアルなお話をすると、まだ市場全体に十分浸透しているとは言えないというのが実感ですね。
　
　もちろん、お客さまがAI戦略を構築していく中で、IDIへの関心は確実に高まっています。企業がデータを戦略的な資産として活用するためには、柔軟性、効率性、セキュリティを同時に確保できるデータ基盤が不可欠です。そこに対して、IDIはすごく“刺さりやすい”コンセプトだと考えています。
　
　ですので、われわれとしてもお客さまの変革をリードする取り組みを作っていく、さらに、IDIを採用されたお客さまでの早期の成功事例を横展開していくといった形で、IDIのコンセプトをもっと浸透させていきたいと思います。
　
――IDIの成功事例は、具体的にいつごろ出てきそうでしょうか。
　
斉藤氏：現在、いくつかのお客さまと成功事例を一緒に作っていきましょうというお話はさせていただいていますので、来年度中に出せたらいいなというのが、わたしとしての期待ですね。
　
――その反対に「IDIのコンセプトは理解したが、現実にはなかなかそこに進めない」といった事例もありますか。どんなハードルがあるのでしょうか。
　
斉藤氏：（システム更改の）タイミングがハードルになることはあると思います。ほとんどのお客さまにとって、データ基盤を一度に全面更改するというのは、費用的にも工数的にも、さらに人員的にも現実的ではありません。また、縦割りの組織、ガバナンス要件、従来の運用の踏襲、クラウドの併存など、社内の複雑な条件がからみあって意思決定を遅らせることもあります。
　
　そうしたお客さまにわれわれが提案しているのが、いきなり全面更改を目指すのではなく、段階的にモダナイゼーションを進めるアプローチです。更改タイミングを迎えたシステムから順に、IDIへのモダナイゼーションを進めていく。これが日本のお客さまに一番合ったプロセスではないかと感じています。
　
　また、“まずは小さく始めてみる”というご提案もしています。サブスクリプション型でIDIの基盤をオンプレミスに用意し、クラウドと接続してハイブリッドな形で展開していくことで、初期投資を抑えてOPEX化もしながら、事業価値を早期に可視化することができます。海外ではデータ基盤を一気に更改してしまうケースも多いのですが、日本市場においては、これが一番良いアプローチではないかと考えています。
　
――IDIの全体コンセプトを聞くと、かなり大きなスケールのデータ基盤をイメージしてしまいますが、小さなスケールであってもそのコンセプトは取り入れられるわけですか。
　
斉藤氏：そうです。IDIというのは“方向性”であって、その動きの中でどの部分を重視するのか、どのくらいのスケジュール感で進めるのかといったことは、お客さまそれぞれの事情や環境によります。そういう意味でも、まずは小さく始めて一度回してみる、そこから徐々にモダナイズを進めるのが良いでしょう。
　
――最後に、9月の事業戦略説明会では、国内のオープンネットワークストレージ市場で「僅差のシェアNo.1」（2025年第2四半期、IDC調査）を獲得したことを受け、成長をさらに加速して、3年後には「ぶっちぎりのシェアNo.1」を目指すと発言されました。どのくらいの「ぶっちぎり」のイメージですか。
　
斉藤氏：わたしの中ではある程度イメージできているのですが、いま数字を言ってしまうとインパクトも大きいので（笑）。ただし、説明会では「3年後」と申し上げましたが、もう少し早く達成できるかなという感覚もあります。
　
　6月に社長に就任してからちょうど6カ月が経ちました。とても刺激的で、毎日を楽しく過ごせていることと、目に見える結果が出てきていることはすごく嬉しく思っています。社内の課題としては、組織的な縦割りが残っているところで、これから社内でのコラボレーションをより強化していく必要はあると考えています。
　

文● 大塚昭彦／TECH.ASCII.jp",[],[]
スーパーエージェント「Qira」やギガワット級AIファクトリーを発表　Lenovo年次イベント（アスキー）,https://news.yahoo.co.jp/articles/93dea1236fbc38c40fe39d692bc551e6c76d6155,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20260109-00000001-ascii-000-1-view.jpg?exp=10800,2026-01-09T07:00:00+09:00,2026-01-09T07:00:00+09:00,アスキー,ascii,アスキー,5213,"Lenovoは2026年1月6日、米国ラスベガスで「Tech World @ CES 2026」を開催した。同社の年次イベントをCESに合わせて開催したもので、会長兼CEOを務めるヤン・ユアンチン氏は、NVIDIA、AMD、Qualcomm、Intelの各CEOなどパートナー企業を招き、自社が進めるハイブリッドAIに向けた戦略を打ち出した。
【もっと写真を見る】
写真：アスキー
Lenovoは2026年1月6日、米国ラスベガスで「Tech World @ CES 2026」を開催した。同社の年次イベントをCESに合わせて開催したもので、会長兼CEOを務めるヤン・ユアンチン氏は、NVIDIA、AMD、Qualcomm、Intelの各CEOなどパートナー企業を招き、自社が進めるハイブリッドAIに向けた戦略を打ち出した。
　
　Lenovo Tech Worldは、同社が毎年開催しているフラッグシップイベントだ。エンタープライズソリューションの発表が中心だが、今年はCESの基調講演も兼ねたことから、PCやMotorolaブランドのスマートフォンなど、消費者向けの製品やサービスも登場した。本記事では、基調講演の内容をエンタープライズソリューションを中心にまとめる。
　
NVIDIAとAIファクトリーがパワーアップ「Lenovo AI Cloud Gigafactory with NVIDIA」発表
　
　ヤン氏はまずAIの急速な進化に触れ、それが特にこれからのビジネスに大きな影響を与えることを強調する。
　
　「テクノロジーと人類が相乗効果を生み出し、デジタルと物理の2つの世界が融合する、新しい時代を迎えている」「（ビジネスにおいては）単なるプロセスの効率化、ワークフローの最適化だけでなく、自社のデータ、プロセス、意思決定ロジックを適用することで、精度の高い洞察を引き出し、価値を創出できる」
　
　Lenovoではこの数年間、一貫して「Smarter AI for All（すべての人にスマートなAIを）」というメッセージを掲げ、製品を展開してきた。今年のTech Worldでもそのメッセージは変わらなかった。
　
　“すべての人”にAIの価値を届けるための、レノボのビジョンが「ハイブリッドAI」だ。具体的には、個人向けにカスタマイズされた“パーソナルAI”、組織のバリューチェーン全体に合わせて設計された“エンタープライズAI”、そして汎用的な“パブリックAI”の3種類を、適材適所で組み合わせられるよう提供する。これも数年前から変わらないビジョンである。
　
　ヤン氏の基調講演で最初に登壇したゲストは、NVIDIAの創業者兼CEO、ジェンスン・ファン氏だ。ファン氏は、PC、インターネット、クラウドといったトレンドに続いて「現在はプラットフォームがAIへとシフトしている」と語る。未来のアプリケーションにとって、AIは基盤レイヤーであり、LLMはOSである、というのがファン氏の主張だ。
　
　こうしたプラットフォームのシフトによって、企業はこれまで30年間に投資してきた数十兆ドル規模のIT資産の再構築とモダナイズに迫られている。ファン氏は「2025年だけで1500億ドルの投資がAIネイティブ企業に流れ込み、巨大企業も従来のR&D手法からAI手法へと研究開発をシフトさせている」と語る。
　
　NVIDIAと提携するサーバーベンダー各社は、NVIDIA GPUを搭載するAI向け統合システムを「AIファクトリー」という名称で提供している。ファン氏は、今回のCESでローンチした最新世代のGPU「Vera Rubin」に触れ、「パワフルであるだけでなく、トークン生成コストを削減しながら生成スループットを向上させる」とアピールした。
　
　実際に、AIモデルの規模は「1年間に10倍」のペースで成長している。推論とエージェンティックAIにより、AIは回答を生成する前に長く思考するようになった。こうした思考プロセスの深化により生成される思考トークンの増加と、モデルサイズの拡大とが相まって、「必要なコンピューティング量は指数関数的に増加している」とファン氏は説明する。
　
　こうした変化に対し、LenovoがAIクラウドプロバイダー向けに提供するのが「Lenovo AI Cloud Gigafactory with NVIDIA」プログラムである。ヤン氏は「AI時代の価値は計算能力だけではない。成果を出すまでのスピードも重要だ」と強調する。
　
　同プログラムでは「ファーストトークンまでの時間（TTFT）」を重要なベンチマークに設定しており、企業のAI投資がいかに迅速に本番稼働可能なAIサービスへと転換されるかを測定する。AIトレーニングおよび推論向けのシステムで、まずはBlackwell Ultra GPUをサポート、将来的にVera Rubin GPUも対応予定だという。ヤン氏は「数十万基のGPUにスケール可能で、兆単位のパラメータを持つLLMにも対応できる」と述べた。
　
　ファン氏は、AI Cloud Gigafactoryが実現した背景として「Lenovoの高い製造能力」を挙げた。「あまり知られていないが、Lenovoはスパコン TOP500ランキングの3分の1を占めている。Lenovoには複雑なシステムの製造と設置のスキルがある」と、ファン氏は評価した。
　
スーパーエージェントの第一歩となる「Qira」を発表
　
　Lenovoでは、ギガワット規模のインフラと並行して、ユーザー体験を変革する技術開発も進めている。ハイブリッドAIを実現するユーザー中心の技術について、LenovoのCTOを努めるトルガ・クルトグル（Tolga Kurtoglu）博士が解説した。
　
　LLMの世界では、すでにさまざまな特徴を持つモデルが登場している。クルトグル氏は「AIの未来はモデルの宇宙であり、私たちが望むようにAIに機能してもらうためには、多様なモデルが必要だ」と語る。
　
　たとえば、軽量なモデルをスマートフォン上で動作させることで、オフラインの状態でも素早く文章を修正したり、簡単な質問に答えたりすることができる。一方、複雑な画像や動画を生成させたり、高度な分析処理を行ったりする場合は、データセンターのハイパワーなサーバーで動作する大規模モデルが必要だ。
　
　それぞれのモデルは特定の用途に特化しており、それを適材適所で使い分けることで、ユーザーの能力を拡張し、生産性を高めることができる。最終的に必要なのは、こうした複数のAI機能を統合し、ユーザーの意図を深く理解して複雑なタスクを自律的に実行できる次世代のAIアシスタント「スーパーエージェント」である。
　
　このスーパーエージェントを実現するためには「3つの要素が必要だ」と、クルトグル氏は語る。
　
　要素の1つ目は、モデル間の調整と協調を図る「インテリジェントモデルオーケストレーション」。専門モデルのプールにアクセスし、ユーザーのニーズに最適なものを特定する。2つ目は「エージェントコア」。パーソナライズされた知識ベースを持つ高度な認知エンジンで、例えば過去6ヶ月間の会議記録から今朝のメッセージまでをレビューし、ユーザーの意図を理解して行動することができる。。3つ目は、複数のAIエージェントが協調動作する「マルチエージェントのコラボレーション」だ。
　
　今回のTech Worldで、Lenovoはスーパーエージェントの初期段階といえる「Qira」を発表した。これは、LenovoとMotorolaが提供するPC、スマホ、タブレット、ウェラブルのデバイスで動作する“統合型パーソナルAI”であり、ユーザーの同意に基づいてデバイス、アプリ、サービス全体で連携するという。
　
ThinkSystemブランドの推論サーバー
　
　NVIDIAとのAI Cloud Gigafactoryに加え、Lenovoは「ThinkSystem」ブランドの推論サーバーも発表した。
　
　ヤン氏は「LLMが主導したAIコンピューティングが現在、推論の時代に入りつつある」と述べる。この変化を、「AIを構築することから、AIを活用することへのシフト」としながら、推論ではオンプレが重要な役割を果たすという。「推論はデータが生成される場所の近くで処理を行う必要がある」とヤン氏。推論とデータ生成が近接すれば、より速い応答が得られるからだ。また、データ主権（ソブリン性）やセキュリティの要件も後押しになる。
　
　エッジAIで推論を行うことで、たとえば工場ではリアルタイムのメンテナンスアラートを受け取ることが可能となり、小売ならば在庫が少なくなったときに即座に通知を受け取り、欠品を防ぐことができる。「オンプレミスにおけるAI推論は、企業に真の競争優位性をもたらす」とヤン氏は強調する。
　
　実際に、Futurumの予測によれば、AI推論インフラのグローバル市場規模は、2024年の50億ドルから2030年には488億ドルへ、年平均成長率46.3％というペースで急拡大する見込みだという。
　
　Lenovoが新たに発表したのは、「Lenovo ThinkSystem SR675i／SR650i／ SE455i」の3機種だ。中でも最上位のThinkSystem SR675iでは、AMDの「Helios Rackscale AIアーキテクチャ」を採用し、AMDのEPYC CPUとInstinct GPU（業界最高レベルの高帯域幅メモリを搭載したMI455X）を統合している。AMDのCEOであるリサ・スー（Lisa Su）氏は、「大量のデータを高速に処理し、大規模なAI処理を効率的に実行できる」と太鼓判を押す。すでに2025年12月、Hewlett Packard Enterprise（HPE）がHelios AIラックを発表済みだが、「Lenovoも最初に（Heliosを）採用するベンダーの1社になる」とスー氏は喜んだ。
　
　こうしたAIシステムに加えて、AIの戦略立案段階から設計、実装、管理まで支援する「Lenovo AI Service」も提供される。さらに、従量課金モデルの「Lenovo TruScale」により、企業は柔軟なスケーリングが可能だという。AIユースケースライブラリの「Lenovo AI Library」には、数百の実証済みソリューションが含まれ、90日以内に価値実現が可能だ。
　
　Lenovo AI Service担当のケン・ウォン（Ken Wong）氏は、AI Libraryで提供するユースケースの例を3つ紹介した。
　
　1つ目は、AI駆動のサプライチェーンプラットフォーム「iChain」だ。Lenovoの「ThinkBook Plus Auto Twist AI PC」は2700点以上のコンポーネントで構成されるが、iChainを利用することで、AIを使用してすべての部品を適切な時に適切な場所に届けることができているという。天候や供給不足などの問題に迅速に対応できるようになり、180市場への出荷を支援していると述べた。
　
　2つ目は、Lenovoが公式テクノロジーパートナーを務めるFIFA（国際サッカー連盟）向けに開発した「Football AI Pro」だ。ペタバイト級のデータ、5000億ページ相当のテキストを数秒で検索する能力を活用するもので、コーチは相手に対する戦術を検討したり、選手は試合分析をパーソナライズでき、アナリストはビデオクリップや3Dアバターを使用してチームのパターンを比較できる。多言語対応により、2026年ワールドカップ出場全チームの言語をサポートしているという。
　
　最後に、AIロボティクスの分野から、世界最大級の電力網のためにAI搭載ロボットを開発した事例を紹介した。このロボットは移動しながら送電グリッドを検査し、98％の精度で問題を検出できるという。危険な環境から人間の作業員を遠ざけることができ、場合によってはその場で修理も行うという。
　
　ヤン氏は最後に、Lenovoの強みを次のように説明した。
　
　「ハイブリッドインフラ、データ、AIモデル、エージェントプラットフォームを統合することで、営業から法務まで、バリューチェーン全体をカバーするAIソリューションライブラリを構築した。これがLenovoのハイブリッドAIの強みだ」
　

文● 末岡洋子　編集● 大塚／TECH.ASCII.jp",[],[]
