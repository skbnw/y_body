headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
ライバルはRay-Banモデル。「Oakley Meta HSTN」レビュー（ギズモード・ジャパン）,https://news.yahoo.co.jp/articles/6a2d2ad939b4f2782cc70d72f25925bd899faec4,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20251007-00000010-giz-000-1-view.jpg?exp=10800,2025-10-07T22:00:01+09:00,2025-10-07T22:00:01+09:00,ギズモード・ジャパン,giz,ギズモード・ジャパン,3222,"ライバルはRay-Banモデル。「Oakley Meta HSTN」レビュー
新モデルでるの早すぎない？と思った人もいるかと思います。そう、MetaとOakleyがコラボしているスマートグラスの話です。8月に発売されたスマートグラス「Oakley Meta HSTN」。まだ出たばかりと思っていたら、9月に開催されたMetaカンファレンスMeta Connectで早くもOakleyとMetaのコラボスマートグラス第2弾「Vanguard」が発表（今月21日発売、日本展開なし）。Ray-Banコラボも第2世代が発表されました。
【全画像をみる】ライバルはRay-Banモデル。「Oakley Meta HSTN」レビュー
わずか数カ月で新しいモデルを出されてしまったHSTNの立場は…？ 日本はMetaスマートグラス全モデルが未発売ですが、もし検討するなら新しいほうがいいの？ Ray-Banモデルとどっちがいいの？

1つわかったのは、HSTNと比較するなら同じOakleyモデルのVanguardではなく、Ray-Banモデルの第2世代だということ。Vanguardとはそもそもデザインが違いすぎます。防水等級もVanguardがIP67なのに対し、HSTNはIPX4。カメラの視野角もVanguardのほうが広いし、スピーカーの音量も上。ただし、性能がいいぶんHSTNより100ドル高い499ドル（約7万5000円）。HSTNは399ドル（約6万円）。Ray-Ban第2世代は379ドル（約5万7000円）。

上記を踏まえて、以下、米GizmodoによるOakley Meta HSTNレビューです。

どれだけガジェットの記事を書き、日々ガジェットのことを考えても、まだまだ驚くことはあるものです。最近、この驚きの気配を強く感じるのがスマートグラス。MetaがRay-Banとコラボしてスマートグラスを出したのがついこの間だと思っていたのに、気がつけば第2世代やディスプレイ搭載ver.が発表されました。Oakleyとのコラボを発表したと思っていたら、すでに2モデル目が発表されました。

スマートグラスの種類が増えるのは、消費者にとっては選択肢が増えるということ。つまり、購入するとき悩むねというお話。スマートグラスが欲しいかどうかはもちろん、どのモデルが欲しいか、自分にあっているかを考えねばなりません。
タイトなフィット感
HSTNは、既存のRay-Ban初代と比べ、スポーツを念頭にデザインされたモデルです。ゆえに、まずそのデザインからスポーティな印象なうえ、アクションカメラを意識した3K動画を撮影できます（Ray-Ban第2世代も3K対応）。

スマートグラスはやはりメガネなので、デザインは非常に重要。スポーツアパレルのOakleyとコラボするからには、Ray-Banとの差別化が必要。Ray-Banが横長レンズに非常にベーシックなフレームを採用しているのに対し、Oakleyのレンズはより丸くフレームに角を持たせるちょっとクセのあるデザイン。Ray-Banのほうがより多くの人に馴染みそうなデザインではあります。

編集部内でみんなで試着してみたところ、けっこうOakleyの丸みレンズは高評価。が、個人的には好きじゃないんですよね。ただ、こうなるとファッションの話なので、アナ・ウィンター氏（元VOGUE編集長）ならともかく、僕がいくら語ったところでまぁ意味もないわけで。デザインが違えば、リーチできる層も増えるのは間違いないことです。

デザインと一緒に気になるのが装着感。これも個人差がありますが、比較として他モデルも装着してみたなかで、HSTNはタイトなフィット感だと感じました。これはスポーツ向けを想定して、動いてもズレにくくするためかもしれません。Ray-Ban初代・第2世代よりも、ツル含め鼻あての部分もタイト。結果、僕個人の意見でいえば、フィット感はあまり好みではないかな。長く装着すると跡がつきそうかも。

Ray-Ban第2世代が発表されてしまった今となっては派手さを欠きますが、少なくともHSTNが発表された時点では3K動画撮影はRay-Ban初代にはない機能であって、大きなアップグレードでした。Ray-Ban第2世代も今月末発売のOakley Vanguardも3K対応ですが、Metaスマートグラスで初めて3K対応したのはこのHSTNなことをお忘れなく！

Ray-Ban初代と第2世代の比較で、1080pと3Kの違いがよくわかりました。が、あくまで動画の画質の話で、写真でいうとRay-Ban初代・第２世代・Oakly HSTN・Vanguardも全て12MGで同じ。

以下、撮影した動画のスクリーンショット比較です。左がRay-Ban初代の1080p、右がOaley HSTNの3K。

発売すぐから使えない仕様が、フレームレート60fpsでの撮影。ただし、HSTNも秋には対応とのことで、もういつアプデ配布がきてもおかしくありません（60fpsは1080p撮影のみ）。
バッテリー持ち
Ray-Ban初代よりもバッテリー持ちがいいのがHSTN。連続稼働時間は8時間です。Ray-Ban第2世代も同じく8時間。充電ケースも両方ともに48時間。

HSTNのバッテリーテストとして、音量75％で1時間音楽を聴き、10分通話し、3K動画の撮影もしたところ、ざっと2時間で100％から70％まで減っていました。実際使った感じだと、Ray-Ban・Oakleyともに、音楽再生がけっこうバッテリー食う気がしました。全体的には公式宣言どおり8時間だと思いますが、音楽を聴きまくる人、音量大きめの人は、もうちょい早めになくなる想定でいた方がいいです。

音楽の話でいうと、HSTNのほうがRay-Ban初代・第2世代よりも音が若干大きい気がします。搭載されているスピーカーは同じとのことですが、たぶんフィット感でそう聞こえるのかな。タイトだから音も少しだけ近くて大きい、のか、な。
他モデルとの比較
Ray-Ban初代と比較すると、3K動画、バッテリー持ち、オーディオと全方位的なアップグレードがされています。が、Ray-Ban第2世代が発表されてしまった今となっては、そのアプグレの強みも同じ。HSTNとRay-Ban第2世代が、同じMetaなのにバッチバチのライバルとなっています。こうなると、あとはデザインとフィット感というもう好みの問題です。

一方で、同じOakleyのVanguardはまた違います。スポーツ・アクションの要素がデザイン的に大きいだけでなく、防水性能がMetaグラスでは最も高いIP67。アクションカメラとしてスマートグラスを欲しいと思っている人なら、Vanguard一択だと思います。

HSTNはシティ型とスポーツ型の間、言ってしまえばRay-Ban第2世代とOakley Vanguardの間（Ray-Ban寄り）の存在ですね。ちなみに、どのモデルでもMeta AIの仕事ぶりは、現時点ではいまひとつです。
総評
Oakley Meta HSTNは、3K動画の撮影もできるしバッテリー持ちもいい。しかし、やはり最新モデルであるVanguardには性能で劣ります。そして、真っ向ライバルとなるRay-Bay第2世代の方が安い。正直、HSTNにスポットライトが当たった期間が短く、けっこう厳しいレースを走らされているモデルだと思のですが…。

いいところ：3K動画、バッテリー持ちがMeta Ray-Ban初代よりは長い、音がいい

残念なところ：フィット感キツめ、デザインが若干偏る、60fps撮影は現時点では未対応、Vanguardの方がIP等級が高い
そうこ",[],[]
で、実際のところ、AIと恋愛したことある？（ギズモード・ジャパン）,https://news.yahoo.co.jp/articles/a59622df125cb32d356776e9950e9c4d8d813ecf,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20251007-00000009-giz-000-1-view.jpg?exp=10800,2025-10-07T21:30:01+09:00,2025-10-07T21:30:01+09:00,ギズモード・ジャパン,giz,ギズモード・ジャパン,1382,"で、実際のところ、AIと恋愛したことある？
ChatGPT台頭で、AIが急に身近な存在となりました。わからないことはAIに質問しちゃお。ちょっとした愚痴はAIに聞いてもらお。人には言えない夜中の相談もAIにしちゃお。そんな人は増えてきているはず。

では、そうやって自分の話をしているうちに、AIと特別な関係になることありますか？
3割がAIと恋愛経験あり？
アメリカのカウンセリングクリニックVantage Pointが調査したところ、アンケートに回答したのは1012人（成人）とほんのわずかですが、なんと3割の人がAIと恋愛関係になったことが1度以上あると回答しました。

人間とAIの関係を調査したのは、何もVantage Pointが初めてではありません。マッチングサービスのMatch.comとインディアナ大学キンゼイ研究所が公開した調査によれば、成人の16％はAIを恋人としてコミュニケーションしたことがあるといいます。

この手の調査はそもそも自己申告である上に、「恋愛関係」や「恋愛的なやりとり」など使われる言葉によって回答者の受け取り方が変わったり、恋愛の個々の定義が異なったりと、人間とAIの恋愛を「正確」に調査するものではありません。また、Vantage Pointがアンケートで使用したのは、SurveyMonkeyというプラットフォームゆえに、科学的リサーチではなく、あくまでもカジュアルな調査です。

それを踏まえたうえで、30％がAIと恋愛。これは多いのか少ないのか…。

Vantage Pointのアンケートでは、「性的なチャット」はするがそれは恋愛関係ではないという、人間同士でも（双方ともに割り切ってないと）揉めそうな回答も見られました。

それぞれの調査では数字に差がでましたが、これ、ある条件を追加するとその差が埋まりそうです。その条件とは年代を区切ること。

Match.comとキンゼイ研究所の調査では、ミレニアル世代で23％、Z世代で33％とその割合が高くなっています。Vantage Pointのアンケート結果は年齢別では公開されていないものの、若い世代ほどAIとの恋愛にオープンであるという結果は明らかにしています。
人間パートナーがいるのにAI恋人がいるのは浮気
ちなみに、Vantage Pointのアンケートでは人間の恋人がいる上でAI恋人を持つことに対して、それを浮気と捉える人の割合は66％、そのうち10％の人は「浮気は浮気だけどセーフ」と考えていることもわかりました。

キンゼイ研究所がDatingAdvice.comと協力して行なった別のアンケートでも、61％の人がAIとの恋愛または性的チャットは浮気と考えているという結果がでています。となると、近い将来「オープン・リレーションシップ」にも、対人間・対AIとさらなる細かいルールがでてくるのかもしれません。

一方で、また別の調査、Family Studies/YouGovによる40歳以下の成人2,000人を対象にした調査では、AIとの恋愛経験者はわずか1％という結果になりました。AIと恋愛してもいいなというオープンな考えの持ち主は7％。調査によってかなり数字に差がありますね。

…で、実際のところ、AIと恋愛したことありますか？
そうこ",[],[]
山や星を教えてくれるUnistellarのAR双眼鏡「Envision」を先取り体験してみた（ギズモード・ジャパン）,https://news.yahoo.co.jp/articles/859229b4dee481384c86dc3a962af809730d4a52,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20251007-00000008-giz-000-1-view.jpg?exp=10800,2025-10-07T20:30:01+09:00,2025-10-07T20:30:01+09:00,ギズモード・ジャパン,giz,ギズモード・ジャパン,2786,"山や星を教えてくれるUnistellarのAR双眼鏡「Envision」を先取り体験してみた
山や星座の位置を識別して双眼鏡を覗くとARで教えてくれるという、次世代のEnvision双眼鏡がKickStarterで登場しました。AR双眼鏡って、一体全体どんな体験を提供してくれるの？ 気になる人は気になる、米Gizmodoによる実機体験記をお届けします。
【全画像をみる】山や星を教えてくれるUnistellarのAR双眼鏡「Envision」を先取り体験してみた
よく登山をするため、山にいる間は今いる山のことをスマホで調べたりしたいのですが、記憶力もないし電波もロクになくて、結局わからないままで、いつも歯がゆい思いをしています。ワシントン州のノースカスケード国立公園で断崖の下に広がる谷の名前や、その近くのマッターホルンのような荘厳な峰の名を知りたいと思っても、よくわからないまま先に進んでしまうのが悲しかったのです。

だからこそ、Unistellarが開発したEnvision双眼鏡にとても興味を惹かれました。この高価な半ARの双眼鏡で何ができるかというと、山を識別できるだけでなく、夜空に輝く星座を教えてくれます。

今回、私はUnistellarの共同創業者兼CEOであるローレント・マルフィシ氏と一緒にトレッキングしながら、このデバイスを実際に試すことができました。ニューヨークから電車で北へ約1時間半、ニューヨーク州オシニングへの小旅行です。実際に今回試したEnvision双眼鏡は、最終製品に搭載される機能がまだない初期プロトタイプです。それでも、このプロトタイプの双眼鏡は、ハドソン川渓谷に沿った近くの山々の頂上をなぞるように線を描いて表示してくれました。そしてその線に沿って、5.7km先にあるフック山から北西のジャッキー・ジョーンズ山、さらにその先の山々まで見つけてくれて、山の名前を表示してくれました。

アパラチア山脈北部の丸みを帯びた山頂の輪郭が描かれましたが、カメラの映像は常に完璧というわけではありません。この双眼鏡はアプリからデータを取得し、GPSと IMU（慣性計測装置）を用いて、景観のランドマークとの位置関係を特定します。描かれた線がずれることもあり、その場合は双眼鏡のボタンで線を正しい位置、または「多分正しい」と思われる場所にドラックして修正する必要があります。右側の接眼レンズに見える赤い線で、オシロスコープを思い出しました。オシロスコープとは、目に見えない電気の動きを、波の線で見せてくれる昔ながらの測定器です。

現時点では、Envision双眼鏡は1つの山脈のラインしか識別できませんが、マルフィシ氏によれば、発売時には2層の山並みまでサポートしたいとのことでした。
いい意味で「つながらない」望遠鏡
Envision を「AR双眼鏡」だと表現することは可能です。でもそれだけだと、他の電子望遠鏡と比べて、いかに「つながらない」存在かをうまく伝えることができません。 

Envision双眼鏡は、熱心なバードウォッチャー向けには設計されていません。もし野生動物を識別したいなら、Swarovski Optikの最新の双眼鏡とかのほうがずっと向いています。Envisionは写真も撮れないし、登山の様子をインスタに投稿することもできません。この双眼鏡はとにかく孤高に探究心を突き詰めるか、または登山仲間に「ちょっと覗いてみ？」と渡すためのものです。

これはあくまで個人のデバイスであり、そういった意味で、個人的には最近手にした中でも、最も楽しめるデバイスのひとつだと感じました。

ニューヨークのブルックリンに住んでいる筆者からすると、「星を見る」日常は存在していません。星を見るにも、何をどう見たらいいのかその知識がなくてよくわかりません。でもEnvison双眼鏡では、星空の観察もARでサポートしてくれます。

アプリから見たい星を選ぶと、双眼鏡がその方向を示す矢印を表示して、角度が正しく合ってくるにつれて、その矢印が大きくなっていきます。また、ターゲット用の照準を設定するボタンもあって、Envision双眼鏡を友だちに渡すときに「ここを見て」と伝えることもできます。それ以外に行なう操作はほとんどありません。

また、Envision双眼鏡は10倍ズームに固定されています。レンズを自分の目に合わせて調整できますが、これは遠くの山や星をくっきり細かく見るための双眼鏡ではなく、「ARで位置や名前を知る」「風景や星座をざっくり把握する」ことを目的にした双眼鏡です。

ARのオーバーレイをオフにするためのボタンもあります。 マルフィシ氏によると、登山道や水源、その他のランドマークを識別する機能などはまだ欠けている要素もあるとのことでした。開発ロードマップはまだまだ道半ばで、最終的にはアプリに文脈の情報を追加して、筆者のように星空に詳しくない人でも、星団や星座に関する情報を学べることを目指しているとのことです。
まだまだ先は長い
もともとUnistellarは、2023年のeQuinox 2や 2024年のOdysseyなど高級スマート望遠鏡のメーカーとして有名です。今回の最新製品のEnvisionは、昨年KickStarterに登場し、早期購入者でなくても小売価格は1,200ドル（約18万円）としていました。Envisionの大量生産は 来年4月に開始予定で、2026年後半の発売を予定しています。早期購入者向けには1,000ドル（約15万円）で提供しますが、実際の希望小売価格は1,500ドル（約22万円）前後になる可能性が高いとのことです。マルフィシ氏は、トランプ関税が価格上昇をさらに悪化させていると率直に語りました。

これはガジェット開発あるあるですが、現在肝心な部品を欧米のサプライヤーからは十分に調達できない状況で、先行予約分の出荷は2026年10月頃に開始予定ですが、一般販売は2027年になる可能性があります。

またUnistellarは、2027年には太陽観察用の専用ソーラーフィルター を別売りとして販売する計画があります（ちなみに太陽観測を行なう場合、必ず高品質な日食観察用メガネを着用する必要があり）。また、マルフィシ氏は月面観察用フィルター についても示唆しましたが、こちらはまだ製造段階に入っていません。

確かに15万円とか20万円の双眼鏡なんて手が出る気もしませんが、たまに自然の中に出かけることができるなら、Envisionはスマホから離れ、自分の目で星や山を学ぶことができるデジタルデトックスとして最適なガジェットになるかもしれません。
mayumine",[],[]
中国のロボに対抗？ テスラの人型ロボもカンフーをマスター（ギズモード・ジャパン）,https://news.yahoo.co.jp/articles/a7a40427aefd70b49118b0592932b2844157afda,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20251007-00000007-giz-000-1-view.jpg?exp=10800,2025-10-07T19:00:01+09:00,2025-10-07T19:00:01+09:00,ギズモード・ジャパン,giz,ギズモード・ジャパン,712,"中国のロボに対抗？ テスラの人型ロボもカンフーをマスター
なんでみんなカンフーマスターを目指すの？ 

各国で人型ロボットのヒューマノイド開発が盛んですが、最近は運動神経のよさを示すのに用いられるのがカンフーという流れができつつあります。

中国Unitreeの「G1」は棒術やコーラの蓋の手刀開栓を披露したり、暴漢をカンフーで撃退する動画を公開。新型「R1」も突然のカンフーで暴れ出し、アチラのお家芸が炸裂しています。
アメリカのロボもカンフー
電動自動車のTESLA（テスラ）も、前々からヒューマノイドの「Optimus（オプティマス）」を作っています。自律稼働で軽作業やダンスもできていましたが、最新の動画はナゼかカンフー。見た目が人間に近いだけあって滑らかな動きを見せています。

映画『マトリックス』の道場シーンみたいですね。オプティマスは押されても倒れず、片足キックでもバランスを崩しません。少し前はポップコーン配りロボだったのが大きな進歩です。
AIで駆動しているそうな
オプティマスは以前、シャツをたたむデモ動画が実は遠隔操作だったことが即バレして総ツッコミを浴びたことがありました。ですが今は遠隔ではなくAIによるものだ、とCEOのイーロン・マスクが公言しています。

動きのキレを見せるのはカンフーじゃなくてもいいでしょうに、イーロンは中国のロボに対抗しているんですかね。もうロボットの性能はカンフー3級とか、黒帯初段とかの検定にしたほうが分かりやすいんじゃない？ 

Source: X (1, 2), TESLA via INTERESTING ENGINEERING, TESLARATI
岡本玄介",[],[]
配送の革命だ。宇宙から1時間で物資が届く爆速デリバリーが現実に（ギズモード・ジャパン）,https://news.yahoo.co.jp/articles/8c0c0483150b7dc28314526f36292e0b51002b77,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20251007-00000006-giz-000-1-view.jpg?exp=10800,2025-10-07T19:00:01+09:00,2025-10-07T19:00:01+09:00,ギズモード・ジャパン,giz,ギズモード・ジャパン,964,"配送の革命だ。宇宙から1時間で物資が届く爆速デリバリーが現実に
翌日とか、1時間以内とか、配送にはいろいろな時間枠があります。速ければ速い方が良くて、追加料金で配送時間が短縮されるサービスも。この配送を、世界、地球、宇宙規模で考えた圧倒的スピーディな配送サービスが、いよいよ始動間近です。

2021年創業、カリフォルニアの宇宙系スタートアップ Inversion Space。そのミッションは、宇宙を物流倉庫かつ配送路として考え、地球への配達をスピードアップさせること。地球のどんなところにも、1時間で荷物を届けることができるといいます。
宇宙拠点「Arc」
Inversion Spaceは、貨物カプセル兼スペースプレーン「Arc」を今月発表。最大225kgまでの貨物を搭載可能。2026年末までに打ち上げを目指します。

地球から宇宙へ物資を配達するのではなく、宇宙から地球へ届けたらいいじゃん！という逆転の発想から生まれたInversion Spaceの物流アイデア。地球軌道上を飛ぶArcは、いわば宇宙物流倉庫であり、オーダーが入ればそこから目的地へ物資を落下する計画です（Amazonみたいな個人宅への配達じゃないですよ）。

カーゴに積む荷物の保存は最大5年。必要に応じてArcは地球に帰還。そのために軌道離脱用エンジンとパラシュート展開自動システムを搭載。大気圏再突入に耐え、パラシュートで地上に着陸することで、再利用が可能な仕組みとなっています。

将来的にはArcで地球低軌道上に宇宙カプセル群を築くことを目標にしており、2028年実現を計画中。クライアントとして最有力なのは軍事系。まずはアメリカ軍をターゲットにしています。

Inversion Spaceは公式Xアカウントにて、「宇宙を新たなグローバル物流の拠点として考え、国家の安全に今まででは考えられないスピード、リーチ、対応力を提供することができます」と語っています。

Inversion Spaceは、今年1月「Ray」という宇宙船をSpaceXで打ち上げ。軌道飛行や大気圏再突入のテストを実施。テストはすべて行なわれたものの、一部のテスト（大気圏再突入）では問題が発生していました。

Source: Inversion Space
そうこ",[],[]
この視点で撮りたかった。耳に掛けるだけで撮影できるMusicCam（ギズモード・ジャパン）,https://news.yahoo.co.jp/articles/f388c697dd6afb03d7f1402195ba4b47651dd6cd,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20251007-00000005-giz-000-1-view.jpg?exp=10800,2025-10-07T13:00:01+09:00,2025-10-07T13:00:01+09:00,ギズモード・ジャパン,giz,ギズモード・ジャパン,1109,"この視点で撮りたかった。耳に掛けるだけで撮影できるMusicCam
工作や料理で手元の撮影も重宝しそう。

GoProをはじめスポーツやアウトドアのアクティヴィティに、今はアクションカメラでの撮影がスタンダード。ユーザーの目線でダイナミックが映像が撮影でき、後から追体験ができるのが魅力です。
【全画像をみる】この視点で撮りたかった。耳に掛けるだけで撮影できるMusicCam
ただ、アクションカメラは身体のどこかに装着するため、何かの拍子に手がぶつかったり重さが煩わしく思うことも…。ちょっとした存在感も質量もありますからね。
ふたつのデバイスをフュージョン
新製品の「MusicCam」は、ワイヤレス骨伝導イヤホンとアクションカメラのハイブリッド。首の後ろから両耳に掛けて、右側のカメラを横に倒してタップで撮影開始です。

ニコイチのデバイスなのに、たったの50gという軽さで存在を忘れそうです。画質は2KのHDで、デュアルマイクはノイズ軽減設計。動画は2時間以上の連続撮影、音楽だけなら15時間の連続再生という長寿命。20m防水で水中撮影も手ぶらで行なえます。

優秀なのが、6軸防振レンズでガタガタ道の揺れまくり映像も補正する点。後から見返して見にくかったり、映像で酔って気持ち悪くなることもありません。
スマホと連携もAIに質問も翻訳まで
動画に限らず、静止画撮影や音声録音も可能。スマホ用アプリとも連携し、それらの選択や音声アシスタント、タッチ操作の設定なども行なえるスマートっぷり。撮影作品をアルバムに保存したり、SNSで共有するのもサクっとできちゃいます。

さらにはアクティヴィティに関する質問や天気予報などAIに質問もできて、100以上の言語でリアルタイム翻訳までこなします。万能すぎやしませんかね？
身体の一部になるカメラ
MusicCamなら、カメラという荷物が1つ減るので身軽になります。準備や装着の手間も減りますよね。スマートメガネにもカメラ搭載型がありますが、視界が狭まるのでメガネ部分は不要だという人にもウケそうです。

また肩や胸にカメラを装備すると、目線がちょっと下がってしまい「コレジャナイ感」が生じることがあります。耳の横なら自分が見たそのままが記録されるのが、見返したときに理想的で良いと思います。
クラファンで出資ができる
MusicCamは現在クラウドファンディングで出資金を募っています。頓挫や延期の可能性もあるので、もし出資する際はご注意ください。

Source: YouTube (1, 2) , KICKSTARTER via YANKO DESIGN
岡本玄介",[],[]
ChatGPTで「アプリ」が使えるように。OpenAI DevDay 2025で発表されたものまとめ（ギズモード・ジャパン）,https://news.yahoo.co.jp/articles/b5f3e38ac1d9e2d2da4e8068608ae935f58274b2,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20251007-00000004-giz-000-1-view.jpg?exp=10800,2025-10-07T12:00:01+09:00,2025-10-07T12:00:01+09:00,ギズモード・ジャパン,giz,ギズモード・ジャパン,2127,"ChatGPTで「アプリ」が使えるように。OpenAI DevDay 2025で発表されたものまとめ
2025年10月7日未明、OpenAIの開発者会議「DevDay」の基調講演がYouTubeで中継されました。盛りだくさんでしたので、ポイントをざっとまとめます。
【全画像をみる】ChatGPTで「アプリ」が使えるように。OpenAI DevDay 2025で発表されたものまとめ
結論から言うと開発者向け・2Bの話がかなり多かったです。その中に1個だけ一般のChatGPTユーザーに関係する話が混ざっていたという感じ。これは見といてもいいかも。AI開発をされている方だと使える/参考になるところがけっこうあると思います。
ChatGPTがSpotifyとつながる。「アプリ連携」でさらに万能に
サードパーティのアプリとChatGPTが「つながる」ようになります。

OpenAIのデモでは、「Spotify（音楽アプリ）でおすすめの曲は？」と尋ねるとChatGPTとSpotifyがつながり、見やすい専用UIでまとめてくれていました。いい感じかは使ってみないとわかりませんが、ChatGPTの知性とSpotifyの視聴履歴から繰り出されるおすすめの精度はすごそうじゃないですか？

デザインアプリとつながってスケッチを綺麗に清書してもらう・学習動画サイトとつながって自分の知りたい内容に合った講座を探してもらう…といったことも可能になります。地図を利用したアプリなどともつながることができ、ChatGPT上で動画コンテンツを視聴できるようにもなります。

連携できるアプリが増えるかがネックですが、増えたら今まで以上に「困ったらChatGPTでOK」って感じになりそう。

「Apps SDK」という「自分のアプリをChatGPTにつなげられるようにする開発ツール」も公開になっており、ソフトウェア開発をする人は一見の価値があるかと思います。詳しくはこちらの記事にまとめてあります。
Sora 2など3つのモデルがAPIで利用可能に
Sora 2・Sora 2 Pro
先日公開になったOpenAIの動画SNS「Sora」内部で利用可能になった新しい動画生成モデルがAPIからも利用できるようになりました。

Sora 2/Proのちがいは、生成できる解像度（Proは1792×1024ピクセルでも生成できる）と料金（生成する動画の長さ×秒単価）です。

縦長・横長のどちらもいけて、生成される映像が音ありな点は共通です。入力はテキストと画像です（動画は不可）。

GPT-5 pro
GPT-5よりも計算リソースを用いることで高度な問題に対してもより一貫した回答を生成できる「GPT-5 pro」もAPIで利用可能となりました。

テキストと画像での入力が可能で、回答はテキストのみです。標準でReasoning Effort: Highに設定されます。

入力の価格はo3-proに比べて下がりましたが、出力の価格が爆上がりしてます（o3-proは80ドル/1Mトークン）。
視覚的にエージェントを作れるツール「Agent Builder」が便利そう
エージェント開発を行う開発者・企業向けに「AgentKit」というツールセットが公開になっています。この中で、個人でも使えそうなものがありました。それが「Agent Builder」です。

Agent Builderは視覚化されたエージェント作成ツールで、ノードを配置・接続しながらワークフローを組む形でエージェントを作成できます。エージェントって実は複数のAIプログラムの組み合わせで、わざわざ1個1個作っていく感じでした。それがまとめて、視覚的に作れるようになるというツールです。

デモが強烈で、基調講演中にOpenAI DevDay用サイトに数分でエージェントを使った機能を追加してました（この動画の21:10～29:00あたり）。

完成したエージェントをpublishすると埋め込みコードが発行でき、それを自分のコードに組み込むと動作します。コード上で開発するより圧倒的に楽ではないかと。OpenAI Platformのダッシュボードからアクセスできます。

ChatKitというAIチャットボットをさくっと作って自作アプリに組み込めるツールもあります。こちらもけっこう使えそう。
Codexが正式リリース。Slackと統合可能に
AIが小人さんばりに裏で開発を進めてくれるツール「Codex」。巷でClaude Codeなどと比較されまくっていたのですっかり忘れてましたが、プレビュー版だったという。それがこの度、正式リリースに。

機能的にはSlackと統合できるようになったのが便利そうです。Slack上でブレストしたあと、@codex で「やっといて」みたいなことができます。

Codex SDKという、Codexを自社の開発システムに統合するツールキットも公開になっています。

Source: OpenAI (1, 2, 3, 4), YouTube
かみやまたくみ",[],[]
30万円で未来派カーをクラシック顔に。ホンダSUVのドレスキット（ギズモード・ジャパン）,https://news.yahoo.co.jp/articles/bae3a1c7f427398742bf68d0c64afc97665d48f1,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20251007-00000003-giz-000-1-view.jpg?exp=10800,2025-10-07T08:30:02+09:00,2025-10-07T08:30:02+09:00,ギズモード・ジャパン,giz,ギズモード・ジャパン,1176,"30万円で未来派カーをクラシック顔に。ホンダSUVのドレスキット
これは渋カッコ良いドレスアップ。

クルマやバイクなど、乗り物は時代によって流行がありますよね。たとえば80年代と2025年の今では、ボディーの角張った感じや、ライトの形状などがけっこう違います。最近はSFロボめいたデザインなのがカッコ良いのですが…似たようなものばかりで逆に没個性的な気がします。
【全画像をみる】30万円で未来派カーをクラシック顔に。ホンダSUVのドレスキット
個性を出すため、エアロパーツの装着やマフラー、ホイール交換といったドレスアップは一般的。塗装でイメージを一新する人もいるでしょうね。
アメリカンに大変身
自動車用カスタムパーツのDAMD（ダムド）が作ったのは、HONDA「WR-V」をジープっぽい見た目に大変身させるキット「REVERB」。前から見るとイマドキのSFロボ風デザインだった「WR-V」が、ちょっとヴィンテージ・アメリカンな雰囲気で全くの別物になります。
顔を変えるキット
「フェイスチェンジキット」は29万8000円で、被せるだけのボンネットカバー、フロントグリルとバンパー、角目ハロゲンヘッドランプおよびハーネスやステー類が一式揃います。

フロント部分だけですでに大変身ですが、別売りで角目2灯をLEDにするバルブ、ボンネットカバーに取り付けるREVERBのレターエンブレム （「RANGE ROVER」の顔部分みたいな文字列）、ウッドパネルみたいなサイドデカール などがあります。

この投稿をInstagramで見る

DAMD Inc.(@damd_inc)がシェアした投稿

ブレーキランプ周辺にくっつけるテールランプガーニッシュに、チェック模様のシートカバーも付ければフル装備。好みとご予算に応じてって感じですけどね。

この投稿をInstagramで見る

DAMD Inc.(@damd_inc)がシェアした投稿
木目ステッカーがアメリカン
かつてL.A.に住んでいた筆者は、1976年製オールズモービル「ヴィスタ・クルーザー」に1年ほど乗っていた時期がありました。横から見るとボディーの下半分が木目調で、やたらアメリカンな雰囲気だったんですよね。このキットを見ていて、懐かしい思い出が蘇ってきました。
WR-Vを買う理由ができたかも
国産でアメリカン風だと、光岡自動車の「Buddy」という選択肢もありますよね。だけどホンダ党や「WR-V」を狙っている／乗っている人なら、30万円ほどでここまで個性を出せるのってイイですよね。今の同じような見た目のクルマから、一歩飛び出してみましょう。

Source: YouTube, Instagram, DAMD, HONDA, MITSUOKA, Wikipedia
岡本玄介",[],[]
「ChatGPTがSpotifyでおすすめを探せるようになる」の意味。Apps SDKで“アプリ連携”が可能に（ギズモード・ジャパン）,https://news.yahoo.co.jp/articles/4a514b1843f982f5c2d3d9447f7479fd44422c1b,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20251007-00000002-giz-000-1-view.jpg?exp=10800,2025-10-07T07:30:02+09:00,2025-10-07T07:30:02+09:00,ギズモード・ジャパン,giz,ギズモード・ジャパン,1530,"「ChatGPTがSpotifyでおすすめを探せるようになる」の意味。Apps SDKで“アプリ連携”が可能に
2025年10月7日未明に始まったOpenAIの開発者会議「DevDay」。YouTubeで基調講演があったのですが、それがだいぶすごかった。
【全画像をみる】「ChatGPTがSpotifyでおすすめを探せるようになる」の意味。Apps SDKで“アプリ連携”が可能に
「ChatGPTがSpotifyのようなサードパティのアプリと連携して回答を生成できるようになる」と同社CEO サム・アルトマン氏が発表したのです。
何がすごい？→ChatGPTがさらに万能になる
ぱっと言われてもイメージしにくいと思うので、OpenAIのデモを何例か紹介します。

ChatGPTに「Spotify（音楽アプリ）でおすすめの曲は？」と尋ねると、接続して見やすい専用UIでまとめてくれていました。いい感じかは使ってみないとわかりませんが、ChatGPTとSpotifyの視聴履歴から繰り出されるおすすめの精度はすごそうじゃないですか？

手書きのスケッチをFigmaで綺麗な図にしてもらったり、アイデア出ししてからCanvaにポスター化してもらう、なんて例もありました。FigmaもCanvaもデザイン系アプリ、その力を借りてさらにいいアウトプットができるわけです。

動画系アプリとの接続も可能です。デモでは「機械学習について知りたいんだけど」と質問したら、「Coursera」という学習動画サービスと接続して近い動画を引っ張ってくる、という例も紹介されました。ChatGPT内で動画が見れて、内容についての質問もOKです。

いちばんつながって欲しいのはYouTubeですが、厳しいだろうなぁ…。

マップ系のUIも表示可能で、Zillowという不動産サイトで家を探しをする、なんて例も。ChatGPTと会話しながら、どんどん条件を増やしていき、いちばん希望に近い物件をさくさくと絞り込んでいました。

ChatGPTから出ずに外部サービスを呼び出せるのは便利ですよね。アプリ移動の手間が減らせるし、ChatGPTの音声入力を使って別アプリのデータにアクセス＆閲覧もできます。その知性と機能を介してアプリを活用できるのは超魅力的です。
ビジネスへの影響：ChatGPTのプラットフォーム化が始まった？
この発表で注目な点は「便利になる」だけではありません。発表内では他サービスへのログインと決済も可能にすると述べられていまして、これは「ChatGPTにApp Storeができる」みたいなものです。ChatGPT上でアプリビジネスを可能にするということでもあるのです。ChatGPTのプラットフォーム化あるいはスーパーアプリ化が動き始めたのではないでしょうか？

ビジネス的には「Apps SDK」という開発ライブラリが公開されたのが非常に重要です。これを使えば、自社のアプリをChatGPTとつなげるようになるのですが、ChatGPTの公称ユーザー数は8億人。それだけの人にリーチできるポテンシャルを秘めた仕組みだとサム・アルトマン氏はアピールしていました。で、今すぐに開発を始められる状態になっていますよ、と。

パートナー企業はまだ多くありません。アプリを公開する企業は増えるのか、実際に便利になるのか。そして、うまくいくのかはまだわかりません。

とりあえず、OpenAIは今後サードパーティ企業向けのマネタイズの仕組みを整えていくとしていて、伸ばす気まんまんでした。

Source: OpenAI (1, 2), YouTube
かみやまたくみ",[],[]
おいiPad Pro、インカメラは1つなのかい？ 2つなのかい？ どっちなんだい（ギズモード・ジャパン）,https://news.yahoo.co.jp/articles/d4f2c266b7079cd9022692e0bcd01a592a99afb8,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20251007-00000001-giz-000-1-view.jpg?exp=10800,2025-10-07T06:00:02+09:00,2025-10-07T06:00:02+09:00,ギズモード・ジャパン,giz,ギズモード・ジャパン,700,"おいiPad Pro、インカメラは1つなのかい？ 2つなのかい？ どっちなんだい
そのアップデートは本当に来るの？

まもなく登場するのでは？ とリニューアルが囁かれているiPad Pro。順当に行けば今年はM5チップ搭載でのアップデートとなると予想されています。

そしてもうひとつ「予想」されているのが、インカメラが2眼になるよ説。

Bloombergのマーク・ガーマン記者は、横向きと縦向きの両方で使いやすくなるように長辺と短辺で合計2つのフロントカメラが搭載されると主張。先日のニュースレターでも、この説を再び発信してるようですね。

となると、単純にチップだけのアップデートではないの…かな？
しかし、現物（らしき）アンボックス動画では？
ところがどっこい。先日、未発表のM5チップ搭載iPad Proのアンボックス動画がYouTubeに投稿されました。

出どころは謎ですが、アンボックスされてベンチマークまで測られている、新型らしきiPad Proの動画では、インカメラは変更なしという指摘でした。

うーん…どういうことかしら？ 可能性としてありえるのが…

・フロントカメラは2つある。この動画がフェイク、もしくは開発版モデル

・フロントカメラは2つない。マーク・ガーマン氏の思い違い

・フロントカメラが2つのモデルと1つのモデルが存在する

あたりでしょうか。

どれもありえる話ですけど、個人的には3番目な可能性もありえるかなぁ？ って。皆さん的にはどう？ カメラ2つあると嬉しいですか？ パワー。

Source: MacRumors, Bloomberg
小暮ひさのり",[],[]
