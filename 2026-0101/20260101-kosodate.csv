headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
生成AIを使った新たな性犯罪「卒アル問題」身に覚えのない自分のポルノ画像がSNSで拡散、子どもを狙った悪質なものも（マイナビ子育て）,https://news.yahoo.co.jp/articles/a0d9a223da52a5431782e30710fddf69e0525e51,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20260101-90042999-kosodate-000-1-view.jpg?exp=10800,2026-01-01T12:11:05+09:00,2026-01-01T12:11:05+09:00,マイナビ子育て,kosodate,マイナビ子育て,3240,"（※画像はイメージです）
私たち親世代は、子どものデジタル機器の付き合い方や、ITリテラシーの教え方にどう向き合ったらよいのでしょうか？ ITジャーナリスト・スマホ安全アドバイザーとして活躍し、自身も二児の母である鈴木朋子さんに教えてもらいます。今回は、生成AIを使った「卒アル問題」について解説してもらいました。
【画像】卒業アルバムやSNSからディープフェイクポルノを作成
■性犯罪者に狙われる子どもたち

2025年3月に起きた、小中学校教員のグループが女子児童を盗撮し、SNSで共有していたとされる事件。同年3月10日に1人目が逮捕され、7人目が11月6日に逮捕されました。犯人らは少女が着替えをする様子などを撮影し、SNSのグループチャットで写真を共有していたとされています。安全なはずの学校で起きた性犯罪に驚きと怒りを感じた人は私だけではないと思います。

内閣府男女共同参画局が2023年6月にまとめた「こども・若者の性被害に関する状況等について」（※1）によると、身体接触や性交を伴う性暴力被害に遭った人は0歳～6歳が約3%、7～12歳は10％前後という結果が出ています。

言うまでもありませんが、子どもに対する性犯罪はその後の人生に重大な影響を与えます。そこで、2024年6月に教育・保育などの子どもに接する場での子どもへの性暴力を防ぎ、子どもの心と身体を守るため、「こども性暴力防止法」が成立しました。この法律は2026年12月25日より施行される予定です。


こども性暴力防止法には、「日本版DBS」と呼ばれる措置が含まれています。DBSとはイギリス司法省管轄の「Disclosure and Barring Service（犯罪証明管理及び発行システム）」の略称で、性犯罪歴をデータベース化し、性犯罪者が子どもに関わる仕事に就かないようにして子どもを守る仕組みです。すでにアメリカ、フランス、ドイツなどでも同様の制度が導入されており、日本でもいよいよ実施されることになりました。

制度が開始されると、事業者は従事者に性犯罪前科の有無を確認することが求められます。不同意性交や児童買春、痴漢、盗撮などの性犯罪が対象です。もし前科が確認された場合は、配置転換などの措置が必要になります。

対象となる事業は、学校や保育所、児童養護施設などです。教員や保育士など、子どもに関わる仕事に従事する人に対して前科の確認などの義務が生じます。放課後児童クラブや学習塾も、国が認定すると制度の対象になるそうです。

早く施行して安心させてほしいところですが、おおよそ一年待つ必要があります。

■生成AI悪用による新たな性犯罪「卒アル問題」

生成AIの進化と普及に伴い、悪用されるケースも増えてきました。そのひとつに「卒アル問題」があります。卒アル問題とは、卒業アルバムの写真を無断でわいせつな画像に加工し、公開する行為です。

日本経済新聞によると、2025年11月、わいせつ画像に加工されることを知りながら卒業アルバムの顔写真を部外者に提供したとして沖縄県立高に勤めていた実習助手が懲戒免職処分になりました。合成された写真はSNSに投稿され、実習助手はその投稿にコメントを添えて再投稿していたそうです。（※2）

この事例のように、卒業アルバムの顔写真があれば、わいせつな画像が生成できてしまうのです。「ディープフェイクポルノ」と呼ばれるこうした行為は、これまでは高度なテクニックや専用のソフトウェアが必要だったため、被害者は芸能人や有名人などの一部の人に限定されていました。しかし、生成AIを利用して誰もが大量のディープフェイクポルノを作成できるようになったため、被害が一般人にも及ぶようになったのです。ディープフェイクポルノは、Webサイトに公開されているサービスでも作ることができると言われています。

こうしたディープフェイクポルノは、本人が知らないところで行われてしまうことが大きな問題です。用心してSNSに画像をアップしていなくても、卒業アルバムや学校行事の写真などから生成されてしまう危険があります。

■ディープフェイクポルノ規制に向けての法整備

「卒アル問題」について個人での対策が難しいとなれば、法律での処罰に期待したいところですが、2025年12月現在、ディープフェイクポルノ被害を直接的に規制する日本の法律はありません。そのため、名誉棄損罪や著作権法違反、わいせつ物頒布等罪などで罰することになります（一部、条例で罰則を規定している自治体もあります）。

しかし、2025年5月に成立、9月に施行された「AI法」により対策が進む可能性があります。児童の画像をAIで加工して作成されたディープフェイクポルノについては、AI法の成立に伴う付帯決議などで対策強化が明言されており、法的な規制が強化される方向に向かっています（※3）。まずは子どもの被害実態について2026年7～9月に取りまとめられることになっています。

■ディープフェイクポルノから子どもを守るためにできること

法整備されるのを待っている間にも子どもは危険にさらされてしまいます。ディープフェイクポルノに関して家庭でできる対策を考えてみました。

顔がはっきりわかる画像や、音声をアップしない

まずひとつめは、「高画質な顔写真を流布しない」ことです。卒業アルバムは防ぎようがありませんが、SNSなどの投稿は自分で制限することができます。顔がはっきりわかる画像はSNSにアップしないようにしましょう。どうしても投稿したい場合は、全体にぼかしたり、スタンプで顔を隠したりするとよいでしょう。「公開範囲を限定すれば大丈夫」と思うかもしれませんが、誰かが流出させるリスクはあります。

また、ネットで知り合った人に画像を送ることも厳禁です。「洋服を着ているから」と油断して送ってしまうと、相手は生成AIを悪用するかもしれません。

音声についても公開しないようにしましょう。生成AIは音声を使って、本当は言っていないことも言わせることができてしまいます。音声が入っている動画を公開すると、わいせつな言葉に変えた動画を作成できてしまいます。

気軽に相談できる親子関係を築く

ふたつめは、相談できる親子関係を構築することです。この連載で何度も言っているので「またか」と思う人もいるかもしれませんが、何かあった時にすぐ相談してくれるような風通しの良い親子関係を築いてほしいと思います。早めに対応することで、被害を最小限に抑えることができます。

■もし、ディープフェイクポルノを作られてしまったら

もしディープフェイクポルノを作られてしまったら、投稿画面などの証拠となるスクリーンショットを撮影したのちに、プラットフォームの相談窓口に報告しましょう。また、警察庁のサイバー事案に関する相談窓口や、性犯罪・性暴力被害者のためのワンストップ支援センター（
#8891
）に相談してください。

この連載は、今回で最終回となります。約3年半にわたってお読みいただき、ありがとうございました。新たなSNSが登場したり、生成AIに翻弄されたりとネットの世界は目まぐるしく変わっていきますが、最大の対策は良い親子関係の構築だということを伝えられていたら嬉しく思います。今後も「安心安全なネット利用」について記事や講演で発信していきますので、どこかでお会いできたら幸いです。

※1　こども・若者の性被害に関する状況等について（内閣府男女共同参画局）
※2　沖縄県立高の実習助手、卒アル写真を外部提供　わいせつ加工目的か（日本経済新聞）
※3　「AI法」成立　児童の画像からAIが作るディープフェイクポルノ対策強化に言及（日テレNEWS）



（文：鈴木朋子、編集：マイナビ子育て編集部）",[],[]
