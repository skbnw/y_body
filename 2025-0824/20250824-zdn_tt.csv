headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
「NVIDIAとも組むし、自社でも作る」GoogleのAI戦略に学ぶ“賢い一手”（TechTargetジャパン）,https://news.yahoo.co.jp/articles/bf41a8897ddf034146e430f6cffa708004cd300c,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250824-00000015-zdn_tt-000-1-view.jpg?exp=10800,2025-08-24T20:00:12+09:00,2025-08-24T20:00:12+09:00,TechTargetジャパン,zdn_tt,TechTargetジャパン,2880,"（写真：TechTargetジャパン）
Googleのクラウドサービス部門Google Cloudでアジア太平洋地域のカスタマーエンジニアリング担当バイスプレジデントを務めるモー・アブドゥラ氏は、2024年から2025年にかけてAI（人工知能）技術を巡る状況が「劇的に変化した」と指摘する。同氏がAI技術について顧客企業と交わす対話の焦点が、実験的な試みから、具体的な事業価値や投資対効果（ROI）の創出へと移り変わっているからだ。

　「かつては『AI技術の活用を試みているが、いつになったら本番運用できるのか』といった“待ちの状態”の声が聞かれた。だが今ではそうした質問はほとんどない。ROIを明確に意識し、AI技術を業務に組み込むことを具体的に計画する企業が現れ始めている」。アブドゥラ氏は先進企業との会話の変化についてそう語る。だがうまくいっている企業ばかりではないのが実情だ。ROIを重視したAI技術活用におけるポイントと、それに対するGoogleの取り組みとは。
AI活用で本当に考慮すべき要素
AI分野では最新モデルばかりが話題にされがちだが、アブドゥラ氏はそれを支えるインフラの重要性を強調する。同氏がGoogleの戦略の柱として挙げるのが、半導体ベンダーNVIDIAとのパートナーシップ、自社専用ハードウェアの開発の2点だ。

　Google Cloudは2025年4月に開催したカンファレンス「Google Cloud Next」で、同社のAIモデル「Gemini」をオンプレミスシステム向けに提供すると発表した。これは、NVIDIAのアーキテクチャ「Blackwell」採用GPU（グラフィックス処理装置）を搭載した仮想マシン「Google Distributed Cloud」を利用し、エアギャップ（インターネットから隔離された環境）でGeminiを稼働させるものだ。この取り組みは政府や防衛、ヘルスケア、金融といった、データ主権やセキュリティ要件が特に厳しい分野のニーズに応えることを目的としている。

　Googleは独自のTPU（テンソル処理ユニット）アーキテクチャも開発しており、アブドゥラ氏はこれをGoogleのAI戦略を支える「中核的な基盤技術」と位置付ける。GPUがこれまでAIモデルの学習で中心的な役割を担ってきたのに対し、TPUはAIモデルの学習や推論で実施する計算に特化した構造を持つため、特に推論で効果を発揮する。Googleが提供するAIサービスのように、一度学習させたAIモデルを膨大な数のエンドユーザーが繰り返し利用するサービスでは、日々の推論処理にかかるコンピューティングリソースや消費電力といったコストの総量が、初期の学習コストをはるかに上回るためだ。

　AI技術の急速な普及は、コンテナオーケストレーションツール「Kubernetes」に代表されるアプリケーション実行環境の標準についても再考を促している。現代のアプリケーション開発に欠かせないKubernetesも、AIワークロード（AI技術に関する処理）特有の要求に適応する中で、重要な転換期を迎えている。

　「AIモデルのように、GPUやTPUといった特殊なハードウェアを効率的に利用するという新たな要求に対し、Kubernetesを根本的な構造から見直すべきなのか。それとも、既存の仕組みは維持しつつ、AIモデル向けの新しい仕組みを追加して共存させるべきなのか」。アブドゥラ氏はこう問い掛け、「GoogleはKubernetesコミュニティーの動向を注視しており、まだ正式な見解は固めていない」と付け加える。

　当面の間、GoogleはマネージドKubernetesサービス「Google Kubernetes Engine」（GKE）の機能を強化することで、AIワークロードをより効率的かつ容易に処理できるよう支援する方針だ。具体的には、AIワークロードの処理先をGPUからTPUに切り替えられるようにするライブラリ（プログラム部品群）の導入、GPUを社内の複数チームが共有できるようにするための詳細なリソース管理機能の追加などがある。

　インフラが進化し、AIモデルが急増する中で、ますます複雑になるシステム管理を支援する中心的な存在として、アブドゥラ氏はGoogleのAIアプリケーション開発ツール「Vertex AI」を挙げた。Vertex AIを利用することで、企業はGoogle製AIモデルだけではなく、オープンソースのAIモデルやサードパーティー製AIモデルを一元管理でき、利用契約からAIモデルの移行までのさまざまなプロセスを簡素化できる。

　企業のAI技術活用における主な課題の一つは、「Gemini 1.5」から「Gemini 2.5」への移行といった、AIモデルの急速なアップデートに追随することだ。Vertex AIはこのプロセスを支援するために、AIモデルのバージョン間で品質が同等であることを保証する評価サービスなどのツール群を提供する。「異なるAIモデル間でのプロンプト（指示）の互換性に悩む企業向けに、Googleはプロンプトの移行を可能にするツールキットを導入した」とアブドゥラ氏は語る。

　アブドゥラ氏は、自律的に思考し、計画を立て、データを参照し、他のシステムと連携して複雑なワークフローを自動化する「AIエージェント」の登場にも言及する。同時に、企業がAIエージェントの扱い方を模索している現状にも触れる。

　Googleは、いち早くAIエージェントの開発ツールを提供した企業の一つだ。同社の「Vertex AI Agent Builder」とオープンソースの「Agent Development Kit」（ADK）は、さまざまなデータソースに接続し、他のAIエージェントと連携できるAIエージェントの作成を簡素化することを目的としている。

　AIエージェントによる生産性向上が期待できる一方、ガバナンス上の課題も生じる。主な懸念は、企業がAIエージェントを中核的な業務プロセスに深く組み込むようになるほど、その権限やアクセス権の管理が難しくなる点だ。

　「基本的なAIエージェントを動かすこと自体は、それほど高度で複雑なものではない」。アブドゥラ氏は、開発ツールの進化をこう表現する。その上で同氏は、AIエージェントの真の進化とは、「単純なタスク自動化能力から、与えられた権限の範囲で、状況を判断しながら複数のツールやデータを連携させて、自律的にタスクをやり遂げる能力を備えたAIエージェントに進化させること」だと話す。

本記事は米国Informa TechTargetの記事「Enterprise AI adoption moving beyond experimentation」を翻訳・編集したものです。一部、翻訳作業に生成AIを活用しています。
TechTargetジャパン",[],[]
