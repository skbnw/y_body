headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
ファクトチェッカーが実践している生成AIによるディープフェイクの見分け方【解説】（日本ファクトチェックセンター）,https://news.yahoo.co.jp/articles/0a60cdcd5e91c2eec4d4d5bb797cbf7324ac78bf,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20260107-00010000-jfactc-000-1-view.jpg?exp=10800,2026-01-07T14:17:14+09:00,2026-01-07T14:17:14+09:00,日本ファクトチェックセンター,jfactc,日本ファクトチェックセンター,2021,"日本ファクトチェックセンター（画像はAI生成）
事件や災害など大きなニュースが報じられるたびに、生成AIで作った「ディープフェイク」が拡散するようになりました。

一見、本物のように見えますが、見分けるコツがあります。日本ファクトチェックセンターが実際に使っている検証手法を解説します。
1.透かしやロゴや投稿者の確認
透かしやラベルが入った動画
最も簡単な手法は、AIで生成したことを示す「透かし」や「ラベル」がついていないかを確認することです。

OpenAIのSoraやGoogleのGeminiなどの生成AIツールで動画を作ると「透かし（ウォーターマーク）」が入ります。また、YouTubeやTikTokなどの動画プラットフォームでは、投稿者がラベルをつけることもあります。

上記の画像の赤丸や黄色線で示しているのが、透かしやラベルです。動画を見たら、まず、これらがないかを確認しましょう。あれば、生成AIです。

また、投稿者のアカウントを見ると「AIアーティスト」などと自己紹介していたり、他にも多数のAI画像を投稿している例もあります。
2.描写の破綻
AI生成に特有の描写が破綻している部分
実際には透かしやラベルがないディープフェイクも多数存在します。そういった場合には、細部を確認して描写に破綻がないかを探します。

例えば、「2026年1月にアメリカによるベネズエラでの軍事作戦を喜ぶ民衆」とされる動画です。実はこれも生成AIで作ったもので、現実の映像ではありません。

描写を確認してみます。まず、中心にいる老人の右後ろに映っている男性が手にもっている旗が突然消えます。

また、細部のデザインが実物と異なっています。例えば、老人の左後ろに映っている旗。色はベネズエラの国旗ですが、星の数が明らかに多すぎます。本物の国旗は、青い部分に8個の星が弧を描いて並んでいます。こんな重大な場面で、わざわざ実物と異なる国旗を掲げる人はいないでしょう。

以前の生成AIは、歯や目や指などの描写が破綻していることがよくありました。進化した最近のAIは人間の描写はかなり自然に近づいてきましたが、複雑なデザインでミスをすることはまだまだあります。

ファクトチェッカーは以下のような点をよく見るようにしています。

・人間の手や指や髪や歯などの描写が破綻している。
・背景の看板に書かれている文字が崩れている。
・連続した動画なのに、一部で画像がカクカクする。
・突然、ものが現れたり消えたりする。
・顔などの輪郭の境界線がぼやけている。
・背景の構造物と影が一致していない。
・直線であるべき構造物が歪んでいる。
3.関連情報との比較
人間の顔の描写が自然になってきたように、細部を確認しても見分けがつかないディープフェイクも増えてきています。そういった際に頼りになるのが「関連情報」です。

例えば、大きな地震があった際に「津波の映像です」という動画を見たとして、それがディープフェイクではないと確認するために調べるべき関連情報は「気象庁の公式情報」や災害報道に定評がある「NHKの速報」です。

そのどちらもが津波の被害を伝えていないとしたら、その動画の信頼性はかなり低いと言えるでしょう。

海外で多いのが、政治家や著名人の言動を捏造したディープフェイクです。そもそも、その人物がそのような発言をする可能性はあるか。その人物はそのときにそこにいたのか。動画だけを見て信じるのではなく、関連情報と比較しましょう。
4.検証ツールの活用
最後に紹介するのが「検証ツール」です。テクノロジーにはテクノロジーで対抗する必要があります。世の中には、ディープフェイクを検証してくれる無料ツールが存在します。

例えば、「Hive Moderation(Hive AI Detector)」は、ウェブサイトから画像、音声、20秒未満の動画などをアップロードすることで、AI生成かどうかを判定してくれるツールです。

これらに気になる画像や動画などをアップロードすれば、AIで作ったり、加工したりした可能性をパーセンテージで示してくれます。

ただし、これらのツールは完璧ではありません。画質を落とした画像では精度が落ちるという弱点もあります。JFCでは最後の確認で使うだけにとどめています。

いずれは精度が非常に高いツールも普及する可能性がありますが、技術のイタチごっこが続くかもしれません。

そのためにも、1~3の手法を個々人が身につけておくことが必要です。

ちなみに記事の冒頭画像は私の顔写真を使って「この人物がディープフェイクの見分け方を教室で教えている画像をつくって」と指示を出したものです。

拡大してみると、スクリーンに映った文字や、手の指などにAI生成的な特徴が見られます。
古田大輔(Daisuke Furuta)",[],[]
