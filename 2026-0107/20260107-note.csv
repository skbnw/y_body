headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
元Metaルカン博士が指摘する生成AIの限界と、行間を読む3歳からの学び―AI時代の親の役割―（note）,https://news.yahoo.co.jp/articles/a56cfd16b70777b326c0ab717d9bb2069c2061a9,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20260107-00010002-note-000-1-view.jpg?exp=10800,2026-01-07T14:49:30+09:00,2026-01-07T14:49:30+09:00,note,note,note,4580,"note
【これはnoteに投稿された崔 真淑/エコノミスト(博士/ Ph.D. in Finance)さんによる記事です。】
3歳の娘との会話から受けた衝撃
AI時代に親や保護者に何が出来るのか、何をすべきなのかが、話題になっています。今回は、AI時代における保護者の役割について考察します。※ここに貼られていた記事のURLは【関連記事】に記載しています
私には3歳の娘がいます。最近いちばん驚いたのが、彼女の「行間を読む力」が、育ち始めていることでした。

娘「ほいくえん、はやおむかえがいい」
私「ん？保育園、嫌いなの？」
娘「ちがうよ。ほいくえんはすきだよ。でも、はやくおかあさんにあいたいの」

　私は「保育園が嫌なんだね」と断定したわけではありません。でもこの問いかけには、うっすらと「早迎え＝保育園が嫌なのかも？」という推測が混ざっています。娘はそれを読み取り、「そこは違う」と修正してきました。
ここで娘が理解しているのは、単語や文法というより、相手（私）が何を前提に推測しているか”です。

　この感覚は、AI研究の第一人者ヤン・ルカン（Yann LeCun）氏の問題提起と重なりりました。ルカン氏は、いま主流の生成AI=LLM（大規模言語モデル）は便利だが、言語中心の学習だけでは限界があるという立場をFTの記事で繰り返し語っています。[1]

　理由はシンプルで、人間の知能は「文章を上手に続ける力」だけではなく、もっと広い――世界がどう動くかをつかみ、次に起きそうなことを予測し、ズレたら直す力に支えられているからです。[1][2]

　では、なぜ私は、娘の「行間を読む」力と、ルカン氏が言うLLMの限界とリンクしたのか・・・。もちろん、幼児が「五感も使って学んでいる」というのは強みです。しかし、もっと大事なのは、幼児とLLMの学び方そのものが違うこととを意識させられたからです。
4つのキーワードでほどく生成AIと幼児の違い
SNS上では「幼児は少ないデータで賢くなるのに、AIは膨大なデータが必要」という指摘が散見されます。このことについて、4つの言葉で整理してみます。
① トークン需要：AIが“覚えるために必要な文字の量”
LLMは、文章を細かい部品（トークン）に分けて、「次に来るトークンは何か？」を当て続けることで賢くなります。この方式は強力ですが、基本的に大量のトークンが必要になりがちです（＝トークン需要が大きい）。[1] そして、LLMが食べてきたデータは2026年から30年の間に枯渇するとの指摘があります。生成AIが大きく変革するためには、データが必要ですが、今のデータ取得方法では限界があるかもしれないのです。

一方、娘はネットの文章を何十億行も読んでいないのに、会話の意図を読める。ここで効いてくるのが次の②③④と推測されます。
② 分布の多様性：経験の“種類の豊かさ”
LLMが学ぶ世界は、主にテキストデータです。テキストは多様に見えても、視線・間（ま）・声色・触った感触・痛み・距離感のような、人間の理解に重要な情報が抜け落ちます。
　幼児の学びは逆で、毎日、五感が同時に入り、相手の表情や声のトーンもセットで経験します。発達研究では、こうした複数感覚の重なり（冗長性）が注意を導き学習を促すことが指摘されています。[4][5]つまり幼児は、文字量ではなく、取得できるデータにおいて分布の多様性（≒データの種類）で勝っているのが強みなのかもしれません。

　（ちなみに①のデータが枯渇する問題においては、生成AIがデータを食べて、新しいデータを吐き出して、またそれを生成AIが食べて学習するということも起きています。しかし、これでは分布が大きく偏ってしまうことが指摘されています。）
③ 学習信号：その場で返ってくる“合ってる／違う／危ない／嬉しい”
LLMの学習信号（≒正解データ取得）は、ざっくり言えば「次の単語当ての正解・不正解」。最近は人間の評価を使って「役に立つ・安全」方向へ寄せる学習も行われます（RLHFなど）。[3]
　でも幼児の学習信号は、もっと太くて、多様と考えられます。うまく伝わった喜び、誤解されたときの違和感、相手の表情、褒められる・止められる、痛い・怖い――要するに身体と社会のフィードバックが、そのまま学習信号になります。

　私と娘の会話もまさにそれではないかと考えられます。
「早迎えがいい」→ 私が“嫌なの？”と推測する → 娘が“違う、会いたい”と修正する。
　この往復の中で娘は、「こう言うとこう誤解される」「こう言い直すと伝わる」を学んでいく。これは暗記ではなく、相互作用が生む学習信号と言えるのかもしれません。
④ モデル：頭の中の“世界シミュレーター”
冒頭の会話の中で、娘は、単に言葉を返しているのではなく、私の頭の中――「私はこう考えがち」「いま私はこう推測している」をうっすら推定し、それを修正しています。これは相手と状況のモデルが育っている、ということです。
　実は、発達分野の研究でも、3歳前後の子どもが、状況から意図を推測する「関連性（relevance）推論」を行えることが示されています。[6][7]

　ルカン氏がFT「テキストデータだけでは足りない」と言うときに出てくるのも、まさにこの“モデル”の話なのかもしれません。言葉の統計だけでなく、世界がどう変化するかを予測するモデルが必要で、動画などから学ぶアプローチも登場して始めているようです。
親がAI時代に子どもにしたいこと
娘との数行の会話は、私にとって「AI時代の学び方」をそのまま見せてくれる出来事でした。賢さは、単に知識をたくさん持っていることではない。むしろ——

知識の量だけで決まらない

分布の多様性（体験の種類）と、学習信号（フィードバック）が学びを太くする

そして核心は、モデル――相手と世界をそれらしく思い描き、次を予測し、ズレたら直す力

この3点を、親としては「育ててあげたい」と思います。

知能は百科事典を頭に詰め込むことではなく、頭の中に“だいたいこうだよね”という地図を持ち、予想して、外れたら地図を更新する力に近いのかもすしれません。娘はもう、その更新を始めている。だから、こちらが驚くのです。

では、親として何をしたいか。私は「正解を教える」より先に、次の3つを意識したいと考えています。

体験の種類を増やす
公園、料理、買い物、工作、植物、電車、会話——「触れる世界」を広げる。言葉の学習は、現実の体験が増えるほど立体的になります。

フィードバックが返ってくる遊びを増やす
積み木、パズル、ごっこ遊び、簡単なルールのある遊び。うまくいった・いかなかったが即座に返る環境は、学習信号が太く、成長が速い。

“言い直し”を肯定する
「違ったら直せばいい」「伝わらなかったら言い方を変えればいい」。この“ズレたら更新”の姿勢こそ、AI時代に人間が強みとして持てる力だと思うからです。

LLMはこの数年で猛烈に伸びました。でも、幼児の学び方（多様な経験×相互作用×太い学習信号）に近づこうとするほど、私はますます思います。
子どもの会話は、AIを理解する最高の教材であり、同時に、人間が磨くべき力を教えてくれる——と。
参考文献
[1] Heikkilä, M. (2026, January 2). Computer scientist Yann LeCun: ‘Intelligence really is about learning’. Financial Times. 
[2] LeCun, Y. (2022). A path towards autonomous machine intelligence. OpenReview. 
[3] Ouyang, L., Wu, J., Jiang, X., Almeida, D., Wainwright, C. L., Mishkin, P., … Lowe, R. (2022). Training language models to follow instructions with human feedback. Advances in Neural Information Processing Systems, 35, 27730–27744. 
[4] Bahrick, L. E., & Lickliter, R. (2002). Intersensory redundancy guides early perceptual and cognitive development. Advances in Child Development and Behavior, 30, 153–187.
[5] Bahrick, L. E., & Lickliter, R. (2000). Intersensory redundancy guides attentional selectivity and perceptual learning in infancy. Developmental Psychology, 36(2), 190–201.
[6] Schulze, C., Grassmann, S., & Tomasello, M. (2013). 3-year-old children make relevance inferences in indirect verbal communication. Child Development, 84(6), 2079–2093.
[7] Abbot-Smith, K., Schulze, C., Anagnostopoulou, N., Zajaczkowska, Z., & Matthews, D. (2022). How do 3-year-olds use relevance inferencing to interpret indirect speech? First Language, 42(1), 3–21.
[8] Shumailov, I., Shumaylov, Z., Zhao, Y., Papernot, N., Anderson, R., & Gal, Y. (2024). AI models collapse when trained on recursively generated data. Nature, 631(8022), 755–759.
[9] Bardes, A., Garrido, Q., Ponce, J., Chen, X., Rabbat, M., LeCun, Y., Assran, M., & Ballas, N. (2024). Revisiting feature prediction for learning visual representations from video (arXiv:2404.08471).",[],[]
「勘と経験の採用」から「科学を使った採用」に切り替えよう（note）,https://news.yahoo.co.jp/articles/3b0aaa0f61efe9ba613e3dded13381c220927fca,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20260107-00010001-note-000-1-view.jpg?exp=10800,2026-01-07T10:11:32+09:00,2026-01-07T10:11:32+09:00,note,note,note,1900,"note
【これはnoteに投稿された碇邦生（九州大学ビジネス・スクールQBS／合同会社ATDI）さんによる記事です。】
書類選考廃止というニュースが突きつけた問い
ロート製薬が新卒採用におけるエントリーシート（ES）の書類選考を廃止する――。このニュースは、日本経済新聞を通じて、多くの人事関係者の目に留まったはずである。生成AIの普及により、応募書類の内容が均質化し、ESでは学生の個性や価値観を見抜きにくくなった。だからこそ、あえて15分間の対話から選考を始める。

この判断は、単なる採用手法の変更ではない。日本の新卒採用が長年抱えてきた構造的な問題を、生成AIという外圧が浮き彫りにした出来事だと捉えるべきである。

【ロート製薬、新卒採用の書類選考を廃止　生成AI普及でES均質化】
※ここに貼られていた記事のURLは【関連記事】に記載しています
AIの普及でESは「判断材料」ではなくなった
論点の一つ目は明快だ。AIの普及によって、ESはもはや評価ツールとして機能しにくくなっている。

文章の構成、言い回し、自己PRの型。生成AIを使えば、一定水準以上のESは誰でも短時間で作れる。結果として、差がつかない。いや、正確に言えば「差が見えない」。

これは学生の問題というより、評価方法が時代に追いついていないことの帰結である。
面接もまた、同じ運命をたどる
では、面接に移行すれば解決するのか。残念ながら、そう単純ではない。

すでに多くの学生は、AIを使って想定質問への回答を準備している。論理的で、よく練られた「模範解答」を話す学生は増えているが、それが本人の言葉かどうかは分かりにくい。

面接官が評価しているのは、学生の本質なのか。それとも、AIと就活ノウハウが生み出した成果物なのか。この問いは、ES以上に深刻である。
ESも面接も「精度が低い」と知られている
そもそも、産業・組織心理学の世界では、ESも、日本企業でよくみられる非構造化面接も予測精度が低いことで知られてきた。

海外の研究では、学業成績や職務遂行能力との相関は限定的であり、「それらしく見える人」が有利になる傾向が繰り返し指摘されている。

にもかかわらず、日本企業では「人を見る目」「現場の勘」といった言葉で、科学的検証を避けてきた歴史がある。
見過ごされてきた無意識のバイアス
人が人を評価する以上、無意識のバイアスは避けられない。性別、出身大学、話し方、表情などだ。評価者は、自覚のないまま判断を歪めてしまう。

欧米では、こうした問題意識のもと、Selection研究が蓄積されてきた。評価基準の構造化、複数評価者の活用、バイアス教育などは、すでに常識である。

一方、日本の採用現場では、こうした知見がほとんど制度に組み込まれてこなかった。
AI時代に学生の能力を見抜く二つの方向性
では、AIが進化する中で、企業はどのように学生の能力を見抜けばよいのか。方向性は大きく二つある。
実際に働いてもらうという選択
一つ目は、インターンシップのように実際に働いてもらう方法である。

欧米の大企業では、入社経路として主流であり、日本でも採用直結型インターンは増えつつある。数百人規模の一斉採用には向かないが、中小企業やスタートアップ、あるいは専門性や幹部候補を見極める場面では極めて有効である。
キャリアの「見える化」というもう一つの道
二つ目は、学生のキャリアの見える化である。

海外では、LinkedInがその役割を果たしている。学生時代の活動、プロジェクト、他者からの評価が蓄積され、採用担当は長期的な視点で候補者と接点を持つ。

日本でも、エン・ジャパンのirootsのようなサービスが登場している。こうしたデータベースが成熟すれば、AIは敵ではなく味方になる。

企業は効率的に人材を探せ、学生も自分のキャリア形成に必要な行動が明確になる。
採用を「科学」に戻す好機として
AIは、日本の採用慣行を否定する存在ではない。むしろ、これまで曖昧にされてきた問題を直視する好機である。

日本の新卒採用は、国際的に見ても特殊性が高い。その一方で、大きな見直しはほとんど行われてこなかった。今起きている変化は、「勘と経験」に依存してきた採用を、「科学を使った採用」へと切り替えるチャンスだといえよう。

ロート製薬の決断は、その第一歩にすぎない。企業が次に問われるのは、対話の先に、どれだけ科学的な設計思想を持ち込めるか、である。
碇邦生（九州大学ビジネス・スクールQBS／合同会社ATDI）",[],[]
AIが当たり前となる中、日本のビジネス文化をどうアップデートすべきか（note）,https://news.yahoo.co.jp/articles/5e1ff5ec9b2f1644d66d2bdffdb55cde04343433,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20260107-00010000-note-000-1-view.jpg?exp=10800,2026-01-07T10:11:10+09:00,2026-01-07T10:11:10+09:00,note,note,note,1706,"note
【これはnoteに投稿された碇邦生（九州大学ビジネス・スクールQBS／合同会社ATDI）さんによる記事です。】
AIは「脅威」なのか、それとも前提条件なのか
日経新聞に掲載された哲学者マルクス・ガブリエル氏のインタビューは、「AIで大量失業が起きる」という通俗的な不安に、静かだが本質的な疑義を突きつけている。AIは思考する存在ではなく、統計的なシステムにすぎない。にもかかわらず、人はなぜそこまでAIを恐れるのか。
この問いは、単なる技術論ではなく、日本のビジネス慣習そのものを再考せよ、というメッセージとして読むべきである。

【「AIで大量失業」は空想、むしろ雇用生む　マルクス・ガブリエル氏】
※ここに貼られていた記事のURLは【関連記事】に記載しています
「この仕事、AIで十分ではないか」という実感
生成AIの普及は、もはや一部の先進企業やIT部門の話ではない。資料作成、要約、翻訳、簡単な企画立案に至るまで、AIを使えば一瞬で済む仕事が増えている。
その結果、多くのビジネスパーソンが「この仕事はAIで十分なのではないか」という感覚を、肌感覚として抱き始めている。これは失業不安というよりも、「自分の仕事の意味が揺らいでいる」という違和感に近い。
AIが使える人と使えない人の分断
さらに現場では、別のストレスも顕在化している。AIを使いこなす人と、そうでない人の生産性の差が、もはや無視できない水準に達している点である。
AIを前提に仕事を組み立てる人から見れば、AIを使わない前提で進める会議や業務は、意図せず足かせになる。この分断はスキル格差というより、「仕事の前提条件のズレ」であり、組織設計の問題である。
新興国と小国がAIに前のめりになる理由
人口規模が小さい国や新興国ほど、AI活用に積極的であるのは偶然ではない。レガシーシステムが少なく、AI導入の摩擦が小さいことに加え、AIによる生産性向上が先進国との差を一気に縮める武器になるからである。
先進国が「AIは本当に安全か」と慎重に議論している間に、追い抜くことができる。これは典型的なイノベーションのジレンマであり、破壊的変化の教科書的な事例である。
「少人数前提社会」としてのAI活用
興味深いのは、オーストラリアやニュージーランド、北欧諸国のAI活用である。これらの国々は、広大な土地に対して人口が少ない。結果として、「少ない人数で社会を回す」ことを前提とした制度や文化を築いてきた。
彼らにとってAIは「人を減らす技術」ではない。「少人数前提の社会を成立させる基盤」なのである。日本がAIを「人手不足を補う道具」「既存業務を維持するための上乗せ」として使いがちなのとは、発想の起点が根本的に異なる。

AIは「少人数前提・高生産性」の制度設計と極めて相性が良い。一人あたりの付加価値を最大化する思想と技術だからだ。この違いは、結果として一人あたり所得や国際競争力に表れている。
一方で、日本が長年強みとしてきた「人間」を起点とした制度設計──手厚い調整、暗黙知、属人的な配慮──は、AI社会と致命的に相性が悪い側面を持つ。
「人間中心」は強みであり続けるのか
ここで誤解してはならないのは、「人間中心」を捨てよ、という話ではない点である。問われているのは、人間中心をどのレイヤーに置くのか、である。
すべての業務プロセスを人間起点で設計する時代は終わった。AIを前提にした制度の上に、人間の判断、倫理、意味づけをどう重ねるか。その再定義こそが、今、企業と社会に求められている。
次の100年の強みをどこに置くのか
マルクス・ガブリエル氏が語る「仕事の再定義」は、技術論ではなく哲学の問題である。日本はこれまで「人間」を強みにしてきた。その成功体験が、今や足かせになりつつある。
AIが当たり前の社会において、日本は何を強みとして次の100年を生きるのか。その問いから逃げず、「人間」を起点とする場所をアップデートできるかどうかが、分水嶺になるのである。
碇邦生（九州大学ビジネス・スクールQBS／合同会社ATDI）",[],[]
