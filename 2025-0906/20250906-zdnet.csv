headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
「Pixel 10 Pro」のカメラはなぜ“世界最先端”なのか--グーグル開発陣が語る技術の核心（ZDNET Japan）,https://news.yahoo.co.jp/articles/3e8b3079a92e5c607a1ece7b2b0b21f6f0aed8ff,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250906-35237561-zdnet-000-1-view.jpg?exp=10800,2025-09-06T07:00:00+09:00,2025-09-06T07:00:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,7392,"提供：Sabrina Ortiz/ZDNET
GoogleのPixel Cameraチームに約10年間在籍しているIsaac Reynolds氏は、2016年に初代「Google Pixel」が発売されたときからチームの一員である。現在はPixel Cameraのグループプロダクトマネージャーを務めており、2025年の「Pixel 10 Pro」に搭載されたカメラ技術ほど強気な姿勢を見せたことは、これまでなかったと言えるだろう。

　この1年でAI技術が大きく進化したことで、Googleは大規模言語モデル（LLM）や機械学習、生成AIによる画像処理を活用し、スマートフォンの写真機能に革新的な進歩をもたらすことができるようになった。

　筆者は、Pixel 10シリーズの発表を終えてひと息ついたReynolds氏にインタビューする機会を得た。そのタイミングは、同氏のチームが2026年に発売予定のスマートフォンに向けて、次世代カメラのアップグレード準備を本格化させている最中でもあった。

　筆者は以前から気になっていた「Pro Res Zoom」や対話型の写真編集、「Camera Coach」、AIモデル、「Tensor G5」チップ、「Auto Best Take」、そしてPixel Cameraチームが抱くさらなる野望について、次々と質問を投げかけた。一方でReynolds氏は、「Telephoto Panoramas」や「C2PA」のAIメタデータ、「Guided Frame」、AIに関する一般への啓発といった、筆者が予期していなかった話題を次々と提示し、議論はさらに深まっていった。

　このインタビューを通じて、GoogleのチームがPixel 10 Proのカメラシステムでいかにして大きな進化を遂げたのか、その核心に迫ることができた。2025年の「Made by Google」イベントや公式ブログで語られた内容をはるかに超え、われわれは新しい写真機能について深く掘り下げることができた。

Pixel Cameraチームの使命

　「われわれがずっと重視にしてきたのは、“写真における根深い課題”と呼んでいる問題である。具体的には、暗い場所での撮影、ズーム性能、明暗の差をうまく表現する力（ダイナミックレンジ）、細部の描写といった点だ。Pixelは世代を重ねるごとに、これらの課題に新しい技術で挑み続けてきた」（Reynolds氏）

Camera Coach

　Reynolds氏によると、「LLMは非常に広いコンテキストウィンドウと高い理解力を持っているため、テクノロジーそのものにはできないことを、人々に教えることが可能になった」という。

　例えば、テクノロジー自体がカメラを4フィート（約1.22m）下に動かしたり、100ヤード（約91.44m）先まで歩かせたり、90度向きを変えたりすることはできない。しかし、Camera Coachはそうした指示を人に与えることができる。これは、写真における根深い課題を解決するための新たなアプローチであると同氏は説明した。

対話型の写真編集機能

　Pixel 10で発表された新機能の中でも特に注目すべきなのが、対話型の写真編集機能である。これは「Google Photos」アプリの機能であり、音声や文字で編集内容を指示するだけで、AIが自動で処理してくれる。例えば、木を消したり、画像を中央に再配置したり、空に雲を追加したりといった操作が可能だ。

　Reynolds氏は同機能について、「対話型編集は従来の操作画面をなくし、自然な言葉で編集の指示ができる仕組みだ」と説明する。例えば、「左にあるものを消して」と言えば、AIが左側にある対象を判断し、「消しゴムマジック」を起動する。「ユタにいたとき、岩はもっと赤かったはず」と言えば、色温度を少し上げてくれる。「中央のものにフォーカスして」と頼めば、被写体の周囲にビネット効果をかけてくれる。

　同機能によって作業時間が大幅に短縮できると、Reynolds氏は強調する。「AIはただ情報を提示するだけでなく、ユーザーの代わりに実際に行動してくれる。これは、AIが“思い出させる”だけでなく、“実行する”という点で、非常に理想的な使い方の一例になる。その効果を目の当たりにするのは、本当に素晴らしい体験だった」

　「AIが写真を見て、『削除した方がよさそうな通行人が数人写っています』と提案してくれる。その提案は小さなチップとして表示され、タップするとその内容がテキストボックスに入力される。つまり、特別な操作があるわけではなく、ユーザーが自分で入力できる内容が自動で入力されるだけだ。音声ボタンもあり、話しかけて編集することも可能。AIは想像していたよりもずっと速く、ずっと優れていた」（Reynolds氏）

Pro Res Zoom

　筆者がReynolds氏と最も話したかったのは、Pro Res Zoomについてである。筆者はスマートフォンで多くの写真を撮るが、長距離のズーム撮影では、ソニーのミラーレスカメラと70～200mmレンズに頼ることが多かった。この新機能は、生成AIを用いてデジタルズームで生じる画像の隙間を埋めることで、スマートフォンでも実用的なズーム写真をより多く撮れる可能性を秘めており、筆者はそのテストを心待ちにしていた。

　Reynolds氏はこの技術の核心について、「根本的な問題は、デジタルズームをどう扱うかだ」と語る。センサーの右隅にあるピクセルと左下にあるピクセルの間を埋める必要がある。従来は補間という手法が使われ、平均的な色で塗りつぶすこともできた。Pixel Cameraでは、マルチフレームのノイズ除去や、より優れた補間を行うために、数世代にわたるアップスケーラーの進化を経てきた。ブロック単位のマルチフレームマージから、確率論的なピクセルごとのマルチフレームへと移行し、『Super Res Zoom』で大きな進歩を遂げた。最新世代のアップスケーラーは、Pixel Cameraで使用された中で最大のモデルであり、非常に優れた補間器であるという。

　同氏は、この新しいアップスケーラーが従来のものとどう違うのかを説明した。「単に、あちらが黒でこちらが白だから中間は灰色だ、と言うだけではない。『この黒いピクセルは、建物のファサードにあるレンガの間の目地のような、より大きな構造の一部だ。だから、おそらくそのポイントまでは黒で、そこから赤に変わるだろう』というように文脈を理解して判断する。これは、『黒と赤だから、とりあえず混ぜていこう』と考えるより、はるかに賢い方法だ。つまり、われわれは本物のピクセルを保持しつつ、その間を非常に高度なモデルで埋めているのだ」

　Reynolds氏は、どんなアップスケーラーにもアーティファクト（画像の乱れ）はつきものだと認める。過去には、シャープな線を持つテキストには強いが、水のように混沌（こんとん）とした対象には弱いアップスケーラーもあった。最新のアップスケーラーにも独自のアーティファクトはあるが、人間の目には認識しづらい。なぜなら、新しいモデルはシーンに対して非常に本物らしいコンテンツを生成するのが得意だからだ。

　ただし、人間の顔の処理には特別な配慮が必要である。「葉であれば完璧に再現できるが、顔の場合は脳の多くの部分が顔認識に特化しているため、わずかなアーティファクトでもすぐに気づかれてしまう」と同氏は説明する。人間の顔をうまく処理するための基準は非常に高く、Pro Res Zoomでは顔を認識した場合、AIによるアップスケールを行わないようにしている。
C2PAメタデータによるAIのラベル付け

　Googleは現在、Coalition for Content Provenance and Authenticity（C2PA）の一員として、Google DeepMindが開発した電子透かし技術「SynthID」を用い、生成AIが使用されたかどうかを示すメタデータを写真に埋め込み始めている。Reynolds氏はこのプロジェクトに深く関わっていた。

　「C2PAのメタデータは、画像がAIによって生成されたかどうかを識別し、その来歴を包括的に示す。それを写真に埋め込むのだ」と同氏は語る。Reynolds氏はこの機能のプロダクトマネージャーを自ら務めた。最近では個人的にプロジェクトを担当することは少なくなっていたが、この問題の重要性と繊細さを理解していたため、自ら引き受けたという。そしてこの機能に深く関わる中で、人々がAIの本質や可能性、進化の速さについてほとんど知らないことを痛感した。

AIに関する一般への啓発

　「世界は、AIがすでにどれほど優れているかを認識するという点で遅れている。だからこそ、ある程度の啓発が必要だ。われわれは、AIの可能性をユーザーが理解すれば、きっと気に入ってくれると確信している」と語る。「Pro Res Zoomの例では、顔には触れないようにしていることで、ユーザーは安心できる。また、AIを使ったバージョンと使っていないバージョンの両方を提示することで、ユーザー自身がAIの処理内容を判断し、受け入れるかどうかを選べるようになっている。実際、圧倒的多数のユーザーはアップスケールされた画像を好ましく感じており、比較する機会がなければその価値に気づかなかっただろう」

　「C2PAのコンテンツクレデンシャル）を使って写真にラベルを付けることで、受け取った人は「これはAIが作ったものかもしれないから、少し疑って見るべきか？いや、コンテンツクレデンシャルが付いている。そこには、AIによるものではないと明記されている。これは信頼できる」と、自分で判断できるようになる。こうした仕組みによって、ユーザーはAIとそうでないものの違いを学び、実際の事例を通じて理解を深めていくことで、時間とともに安心感を持てるようになると考えている。実際にPro Res Zoom機能では、すでにそのような効果が見られており、発売前の調査でも満足度が非常に高かった」

Telephoto Panoramas

　Reynolds氏は、Pixel 10 Proのカメラアプリには公式には語られていない隠れた機能が存在すると明かした。「アプリの至るところに、ちょっとした“おまけ”が隠されている。われわれは、現実的に語り尽くせる以上のものを作っている」

　その一例が、「5x tele-panos」と呼ばれるTelephoto Panoramasである。この機能は、ズームレンズと新しいビューファインダー制御を活用し、360度かつ最大1億画素の高解像度で、映画のような風景写真を撮影できるという。「ズームインしてからパノラマをつなぎ合わせる体験は、言葉にできないほど素晴らしい」とReynolds氏は語った。

　これまでGoogleが語ってこなかったのは、これらのパノラマ画像が従来とは全く異なる方法で撮影されているという事実である。

　Reynolds氏によれば、従来のパノラマは動画をベースにしており、100〜1000枚の画像を撮影し、それぞれからごく小さな縦のスライスを抽出してつなぎ合わせるという手法が取られていた。この方法には2つの問題がある。1つは、スライス単位で処理するために、曲線や伸び、圧縮といったアーティファクトが生じやすいこと。もう1つは、30秒間に最大1000枚もの画像を処理しなければならないという負荷の高さである。

　Pixel 10 Proでは、こうした課題に対して全く新しいアプローチが採用された。動画ではなく静止画を入力として使用し、数百枚ではなく5枚の写真を撮影。その背後では、HDR Plusやコンピュテーショナルフォトグラフィー、夜景モードなど、Googleの画像処理技術がフルに活用されている。写真同士のわずかな重なり部分だけをつなぎ合わせるこの手法は、「Adobe Lightroom」が採用している方式と同様であるという。

　この革新により、夜景モードでのパノラマ撮影が可能となり、最大1億画素という驚くほどディテール豊かな画像が得られるようになった。さらに、これまで有効化できなかったズームパイプラインの一部も活用可能となり、Pixelでは光学品質の2倍ズームが、Pixel Proでは5倍望遠が使用できるようになった。これは、コンピュテーショナルフォトグラフィーを前面に押し出した、写真ベースのパノラマ撮影の新たな形である。

Guided Frame

　Reynolds氏が紹介したもう1つのあまり知られていない機能がGuided Frameである。「これは視覚に障害のある人でも、『Gemini』を使ってどんな写真でもフレーミングできるようにするアクセシビリティー機能だ」と同氏は説明する。

　「カメラを向けてGuided Frameを起動すると、『これは森の風景の写真です。右に木が数本、左に人がいます。人はフレーム内で微笑んでおり、自撮りに適しています』といった音声ガイドが流れ、自動で写真が撮影される。画面が見えづらくても、自撮りや写真の撮影をサポートしてくれる。写真は、視覚に障害があるかどうかに関係なく、人々がコミュニケーションをとるための重要な手段であり、この機能はその力を全ての人に届けるものである」
Auto Best Take

　筆者はまた、前年に導入された「Best Take」から進化したAuto Best Takeについても質問した。この機能は、より多くの機械学習を活用し、洗練されたデシジョンツリー（決定木）に基づいて動作していることを知り、筆者は驚きを隠せなかった。

　Reynolds氏は「Auto Best Takeは、むしろ従来型の処理に近い」と語る。シャッターを一度押して、全員が笑顔でカメラを見ている完璧な写真が撮れたなら、それで完了だという。だが、もしそうでなかった場合には、シャッターを少し長く開け、わずか数秒の間に最大150フレームもの画像をチェックする。より良いものが見つかれば、それを選び、HDR Plus品質で処理して保存する。ギャラリーには「Top Shot」として、その中で最も優れた一枚が表示される。

　Top Shotには、セット内の全ての顔が少なくとも1度は笑顔になっている写真が含まれるよう、意図的に選ばれている。もし150枚の中に完璧な1枚がなかった場合には、ほぼ完璧な複数の写真を保存し、それらをBest Takeに渡す。Best Takeはそれらを合成し、理想的な1枚を作り上げるのだ。とはいえ、150枚も見れば、ほとんどの場合は良いショットが見つかるため、実際にBest Takeまで至るケースは非常にまれである。だからこそ、Auto Best Takeという名称は少し誤解を招くかもしれない。実際には、デシジョンツリーの最終段階に位置しており、頻繁に実行されるわけではないからだ。

　最終的な目標はとてもシンプルだ。それは「シャッターを1度押すだけで、理想的な1枚が撮れること」である。そのためにAIが150枚もの写真を分析してくれるので、ユーザーが何枚も試し撮りする必要はない。Reynolds氏は「シャッターは1度だけ押してください、と伝えたい」と語る。数秒待つと、画面上に顔の周りに枠が表示され、うまく撮れたと判断されるとその枠が金色に変わる。その瞬間が、ユーザーにとって「うまく撮れた」という確かなサインになるのだ。

Tensor G5による違い

　Googleは2025年、Pixel 10に搭載されたTensor G5チップによって、大きな技術的飛躍を遂げた。これまでのサムスン電子による製造から、TSMCの先進的な3nmプロセスへと移行したことで、AI性能の向上が期待されている。

　筆者がその影響について尋ねると、Reynolds氏は処理速度の劇的な向上を挙げた。「Tensor G5による性能向上は、処理のレイテンシーに関して、これまで見てきた中でも最大級の変化だった」と語る。Pro Res Zoomの初期バージョンでは、処理に約2分かかっていたが、Tensor G5が搭載され、全ての不具合が解消された結果、処理時間はわずか数秒にまで短縮されたという。「Tensor G5のTPUは60%以上も強力であり、チームはその恩恵を確実に実感している」

Pixelの写真を支えるAIモデル

　Pixel 10の新機能の多くは、AIの進化によって支えられている。筆者は、Pixel CameraチームがGoogle社内のAIケイパビリティーとどのように連携しているのかについても詳しく聞いた。

　Reynolds氏は「何か1つの巨大なGeminiモデルがあるわけではない」と説明する。用途ごとに、非常に注意深く調整され、テストされたモデルが個別に存在しているという。Googleの内部には、外部からは見えないほど多くのバージョンのGeminiが存在しており、それぞれのユースケースに応じて、プロンプトを与えるか、ファインチューニングするかを決定している。全てがカスタムメイドになっているという。同氏は例として、「消しゴムマジックは生成的な機能だが、Geminiではない」と付け加えた。

最後の考察

　Googleは、先進AIモデルを自社で構築している世界でも数少ない企業の1つであり、スマートフォンも製造している唯一の企業である。そして、Pixel 10 Proによって、そのシナジー効果がいよいよ明確に現れ始めている。

この記事は海外Ziff Davis発の記事を朝日インタラクティブが日本向けに編集したものです。",[],[]
