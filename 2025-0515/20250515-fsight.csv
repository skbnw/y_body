headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
医療現場でChatGPTは使えるか？　診療医視点で確かめた「ここは使える」「これは無理」（新潮社 フォーサイト）,https://news.yahoo.co.jp/articles/966889c83f7ec9a97b78eee36cee785af80b45fd,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250515-00551374-fsight-000-2-view.jpg?exp=10800,2025-05-15T11:32:23+09:00,2025-05-15T17:06:59+09:00,新潮社 フォーサイト,fsight,新潮社 フォーサイト,5650,"ChatGPTは、日常診療を支える「秘書」のような存在だ　（C）Suriyo/stock.adobe.com
ChatGPTの診療現場への応用が模索されている。いくつかの実証研究も報告され始めており、その有用性が注目されている。本稿では、筆者自身の経験も踏まえながら、診療現場におけるChatGPTの活用状況と可能性について考察したい。
どのような臨床応用が想定できるか
まずは海外での動向を見てみよう。米国では、ChatGPTの臨床応用に関する多くの研究が発表されている。その一例が、2月5日に米スタンフォード大学を中心とする研究チームが、英医学誌『Nature Medicine』に発表した研究である。

　この研究では、内科・救急科の医師を対象に、92名を従来の情報源（UpToDateやGoogleなど）に加えてGPT-4（ChatGPT Plus）を併用する群と、従来の情報源のみを使用する群とに無作為に割り付けた。そのうえで、5つの臨床シナリオに基づくマネジメント課題に取り組ませた結果、GPT-4を使用した医師の方が、従来の情報源のみを使用した医師よりも有意に高いスコアを示した（平均差6.5％）。

　この研究は、エビデンスレベルの最も高い臨床研究手法とされる無作為化比較試験（RCT）で実施された。GPT-4の支援によって、複雑な臨床状況におけるマネジメント判断の質が向上する可能性が示唆された。

　スタンフォード大学の研究グループは、他にも同様の研究成果を発表している。3月4日に英医学誌『Communications Medicine』に掲載された論文では、ChatGPTを用いた診断において、患者の性別や人種が与える影響を検証している。これは、AI（人工知能）の学習データが白人男性の症例に偏っている可能性があるという懸念に対する検討である。

　研究では、米国の医師50人が、白人男性または黒人女性の胸痛患者を模したビデオを視聴し、GPT-4の助言の前後で緊急度を判定するトリアージ判断を行った。その結果、GPT-4の助言により、白人男性群では正答率が47％から65％に、黒人女性群では63％から80％に向上し、いずれも18ポイントの改善が見られた。この結果から、GPT-4の活用は人種や性別による診断バイアスを助長せず、公平な診療支援に資する可能性が示唆された。
日本の医師国家試験には「合格」
日本ではどうか。私の知る限り、現時点で無作為化比較試験に基づく臨床研究の成果はまだ報告されていないが、医師国家試験に関してはいくつかの研究グループから興味深い報告がなされている。

　その一つが、大阪大学を中心とした研究チームによるもので、2024年12月に『JMIR Medical Education』誌に発表された。この研究では、2024年に実施された第118回日本医師国家試験の全400問を対象に、GPT-4 Omni（GPT-4o）の性能を評価した。その結果、GPT-4oは全体で93.2％という高い正答率を示した。

　この年の医師国家試験の全体の合格率は92.4％で、一般臨床問題のボーダーラインは正解率76％であった。

　また、医師国家試験は、テキスト問題と画像問題で構成されているが、それぞれの正答率は93.2％と93.5％で、ほぼ同等であった。視診、放射線画像の読影、病理組織の判読といった日常診療で求められる視覚的判断にも、GPT-4oは的確に対応していることがうかがえる。
使ってみて驚いた「明らかな誤り」
ここまで読むと、ChatGPTが今すぐにでも医師の代わりを務められると感じる方もいるかもしれない。しかし、現実はそう単純ではない。私自身も診療の現場でChatGPTを活用しているが、しばしば驚くような誤答に出くわすことがある。

　私は血液内科を専門としている。ある日、かかりつけの患者から「泌尿器科で『ターブロック』という薬を処方されたが、服用に不安がある。主治医としての意見を聞きたい」と相談を受けた。

　ターブロックは、グラクソ・スミスクラインと協和キリンが2020年8月に発売した腎性貧血の治療薬である。この患者は慢性腎不全を患っており、それに伴う貧血が進行していたため、泌尿器科医はその改善を目的として同薬を処方したのだと考えられる。

　腎性貧血の治療を主に担当するのは、腎臓内科医や泌尿器科医である。私は血液内科医ではあるが、専門は白血病や悪性リンパ腫の治療であり、腎性貧血を診る機会はそれほど多くない。念の為にターブロックについて、ChatGPTで調べたが、その回答に驚いた。以下に示すが、これは明らかな誤りであり、典型的な「ハルシネーション（AIによる虚偽生成）」の例である。

「薬効分類：長時間作用型抗コリン薬（LAMA）

適応症：気管支喘息、慢性閉塞性肺疾患（COPD）

製剤形態：吸入薬（吸入用カプセル）」

　ターブロックのような著名な新薬についてすら誤るのに、なぜ医師国家試験で高得点を出せるのか――私には不思議でならない。現時点では、ChatGPTの判断と医師自身の判断が食い違ったときに、AIのほうを信頼する気には到底なれない。
「紹介状」「報告書」作成に力を発揮
それでも私は、ChatGPTを診療の場で活用している。なぜなら、それが診療補助として実に有用だからだ。

　たとえば、他院への紹介状や保険会社への報告書を作成する際、ChatGPTは大きな力を発揮する。電子カルテから病歴をChatGPTにコピーして入力するだけで、医学的に整合性の取れた、自然で簡潔な文書が迅速に作成できる。電子カルテの記載が箇条書きや簡潔なメモ程度であっても、問題はない。

　英語で紹介状を作成する際には、ChatGPTはさらにその力を発揮する。「アメリカの医療機関向けに紹介状を作成して」と指示すれば、医学的に正確で、私の語学力では到底及ばないほどの流暢な英文を出力してくれる。日本で広く使用されている解熱鎮痛薬「カロナール」も、ChatGPTは自動的に国際的に通用する一般名「acetaminophen（またはparacetamol）」に変換し、海外の医師にも正確に伝わるよう記載される。

　もちろん、ときにはハルシネーションが生じることもあるが、その内容を丁寧に読めば不自然さに気づけるため、修正は十分に可能だ。

　こうした機能は、臨床医にとって非常にありがたい。これまで英語の紹介状作成は、ネット検索や『今日の治療薬』などの専門書を引きながら進める煩雑な作業だった。忙しい診療の合間を縫っての対応には、相応の労力と時間を要した。それが、ChatGPTの登場によって大幅に効率化されたのである。

　ただし、現在も多くの医療機関ではChatGPTを活用できていない。その主な理由は、電子カルテがクラウドに接続されていない、あるいは外部サイトへのアクセスが制限されているためだ。クラウド型電子カルテであっても、セキュリティ上の理由から外部接続を禁止しているケースが大半である。

　日本の病院の多くは、患者の個人情報漏洩リスクを懸念し、このような自主規制を敷いていると考えられる。その結果、ChatGPTの診療支援的な利用が広がっていないのが現状だ。

　クラウド型電子カルテを導入する以上、情報漏洩のリスクを完全にゼロにすることはできない。多くの職員が勤務する病院では、不正行為を働く者がいても不思議ではなく、外部との接続を厳しく制限しようとするのは当然の対応だろう。現時点では、こうした慎重な姿勢は妥当と言える。
「患者向けに医師が説明する際に役立つ画像を教えて」
一方で、例外的にChatGPTを柔軟に活用できるのが個人診療所だ。職員数が少なく、院長の判断ひとつで外部接続の可否を決められる環境にある。私自身、茨城県の個人診療所で月に2回診療しており、そこではChatGPTを日常業務において積極的に活用している。

　この診療所では、エムスリーデジカル社が提供するクラウド型電子カルテ「エムスリーデジカル」を導入している。Google Chromeなど一般的なブラウザ上で稼働するため操作性に優れ、CT（コンピュータ断層撮影）検査や他科の診療予約といった総合病院向けの機能はあえて省かれている。その結果、動作は軽快でスムーズだ。この点において、多機能な独自アプリケーションを用い、あらゆる機能を盛り込んだ病院向けクラウド型電子カルテとは対照的である。

　また、カルテを操作しているブラウザを使って自分のGmailやFacebookメッセンジャーもすぐに参照できるため、クラウド上に蓄積された自身の経験を診療に活かすことができる。かつて先輩医師から受け取ったメールやメッセージのやり取りを検索し、必要に応じてカルテに反映させることも可能だ。

　こうした環境下では、ChatGPTの活用は非常に強力な武器となる。たとえば、先日私の外来に来院した40代の女性患者は、20代から花粉症に悩まされていたが、「今年は特に症状がひどく、皮膚までヒリヒリする」と訴えていた。

　この患者は花粉症による鼻炎や結膜炎に加えて皮膚炎も合併しており、単にアレルギー症状を緩和するだけでなく、皮膚へのダメージを最小限に抑えるという美容的観点からも、適切な治療が求められた。採血を行ってアレルゲン検査を実施し、正確な診断のうえで症状に応じた薬剤を処方する必要がある。

　これまでは、こうした内容を外来で口頭にて説明してきたが、患者が十分に理解するには、比較的長い説明が必要になることが多かった。言語情報だけでは、どうしても伝えきれない部分があるのだろう。

　このような場面で、ChatGPTの活用は大いに役立つ。最近では、「花粉症による皮膚炎について、患者向けに医師が説明する際に役立つ画像を教えて」とChatGPTに尋ねるようにしている。「40代女性の場合」「営業職として人前に出る機会が多い場合」など、具体的な条件を付けて指示することも可能だ。

　このような問いかけに対し、ChatGPTは複数のホームページや医療情報サイトを推薦してくれる。私はその中から、患者の状況に最も合ったサイトを選び、診察中に患者に見せて説明している。そこに掲載されている写真や模式図は、私の口頭説明よりもずっと直観的で、説得力がある。

　このような使い方をしている限り、ChatGPTのハルシネーションは大きな問題にはならない。私には基礎的な医学知識があるため、もしChatGPTが不適切な情報を提示したとしても、それを見分けて排除できる。信頼できる情報だけを選択すればよいのだ。

　これまでも、製薬企業や医療機関が患者向けの説明資料を提供してきたが、ChatGPTの登場によって状況は一変した。患者一人ひとりの背景や症状に合わせた情報に、より簡単にアクセスできるようになったからである。こうした個別化された検索は、従来のGoogle検索では困難だった。SEO（検索エンジン最適化）対策が優先されるGoogleでは、本当に必要な情報にたどり着くまでに時間がかかることも多かった。

　診療において最も時間を要し、かつ重要なのは、患者の理解を得ることである。その点において、患者説明に適した画像資料へすばやくアクセスできるChatGPTの有用性は非常に高い。

　診療時間の制約があるため、私は現時点で動画コンテンツを活用してはいないが、今後、医療機関がTikTokなどの動画プラットフォームで発信する医療情報が蓄積されていけば、こうした動画データも外来診療の現場で活用されるようになるだろう。
最大の懸念は情報漏洩のリスク
紹介状の作成にChatGPTを活用していることは前述のとおりだが、紹介先とのやり取りも近年大きく変わってきた。長く臨床に携わっていれば、紹介先の医師も自然と決まってくる。その連絡先は、GメールやFacebookメッセンジャーに登録されており、これらのコミュニケーション・ツールと電子カルテを連携して活用できれば、利便性は飛躍的に高まる。

　ChatGPTで作成した紹介状は、プリントアウトして患者に渡すだけでなく、ファイルとして紹介先の医師に直接送信しておけば、受け入れも一層スムーズになる。実際、紹介先の医師から「上先生から伺っていますよ」と声をかけられると、患者は安心するという。

　私にとってChatGPTは、日常診療を支える「秘書」のような存在だ。現時点で、診断そのものを委ねられるツールではない。スタンフォード大学のモデルケースや医師国家試験の問題と異なり、実際の診療現場は遥かに複雑である。

　人体には未解明の部分が多く、診療時に得られる情報も限られている。問診、身体診察、検査などから得られる情報は、体内で起こっている反応のほんの一部にすぎず、しかも必ずしも正確とは限らない。患者の説明には思い込みや誤解が含まれることもあり、医師はそのすべてを鵜呑みにするわけにはいかない。

　医師の診断力に限界があるように、ChatGPTにも明らかに限界がある。したがって、医療の分野においてChatGPTが医師に取って代わるということは、当面はあり得ないだろう。むしろ重要なのは、この優れたツールをいかに使いこなすかという視点である。

　その際、最大の懸念となるのが情報漏洩のリスクだ。クラウド型電子カルテを通じてChatGPTを活用する限り、そのリスクをゼロにすることはできない。ChatGPTの活用は、医療現場にとどまらず、私たち人類の倫理とモラルが問われる挑戦なのかもしれない。
上昌広",[],[]
