headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
“うそつきAI”はどう管理すべき？　IT管理者が解消すべき3つのリスク（TechTargetジャパン）,https://news.yahoo.co.jp/articles/ca803576a8efa73d59e34a26d36122c010034dc1,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250618-00000011-zdn_tt-000-1-view.jpg?exp=10800,2025-06-18T08:00:12+09:00,2025-06-18T08:00:12+09:00,TechTargetジャパン,zdn_tt,TechTargetジャパン,2810,"（写真：TechTargetジャパン）
近年の発展が目覚ましい人工知能（AI）技術は、企業に業務効率の向上や新たな価値創出といった革新をもたらす。一方で予期しないリスクの温床にもなり、企業にさまざまな場面で悪い影響を及ぼす可能性がある。企業がAI技術を活用する上で把握、対処すべき8つのリスクのうち、特にIT担当者や事業部門の従業員が実務で直面しやすいリスクと解決策を取り上げる。
IT部門と事業部門が特に気を付けるべきAIのリスク
AI技術を導入し、日々の業務で活用し始めると、現場レベルで具体的なリスクが見えてくる。それに対して、IT部門や事業部門の従業員はどのような対処を取ればよいのか。IT管理やデータ管理といった観点でのAI技術のリスクと対策は以下の通りだ。
リスク1．誤情報リスク
AI技術は情報の生成や発信のための効果的なツールに進化を遂げているが、全ての生成情報が正しい情報とは限らない点には注意が必要だ。

ハルシネーション

　AI技術に起因する問題として頻繁に指摘されるのが「ハルシネーション」（幻覚）だ。ハルシネーションは、AI技術が不正確な情報や誤解を招く情報を生成し、あたかも事実であるかのように提示する現象を指す。企業イメージの失墜、経済的損失、技術的問題、法的問題といった、さまざまな種類の深刻な事態を招く恐れがある。ハルシネーションに対処するため、企業はAIモデルが生成した情報がどのデータに基づいているのか、どのようにしてその結論に至ったのかを論理的に説明できる体制を整えておかなければならない。

誤情報と操作

　虚偽情報の計画的な生成など、意図的にAI技術を悪用することは、誤情報や世論操作につながる恐れがある。こうした行動は、AIモデルの学習データに誤ったデータを混入させる「データポイズニング」にもつながりかねない。生成された誤情報は、AI技術を活用する可能性のある政府、企業、公的機関に対する国民の信頼を損なうと同時に、これらの組織が評判や社会的信用を失なうリスクをはらみ、経済への悪影響の要因にもなり得る。

　軽減策としては、他企業と連携したファクトチェックの実施、人による情報の精査、信頼できる情報源の確保などがある。AI技術を使って誤情報のパターンを検出することで、このリスクを回避することも可能だ。
リスク2．IT管理リスク
既存のシステム管理体制にAI技術を導入することは、セキュリティ、データプライバシー、技術的ミスなどのリスクが伴う。スキル低下につながるAI技術への過度な依存は、これらのリスクを悪化させる。

人の無介入

　熟練したIT担当者よりもAI技術を過度に信頼する企業は、AI技術の処理能力を超えた問題が発生した場合、対処できる従業員がいない事態に陥る危険性がある。AI技術によって日常業務を効率化できても、システム設計やトラブルシューティング、インシデント対処といった業務は、経験豊富で十分な訓練を受けたIT担当者ならではの、臨機応変な処置が必要になる場面が大半だ。AI技術への過度な依存という企業文化を育成しないことに加えて、IT担当者も業務をAI技術に委ね過ぎて自身のスキルを陳腐化させないよう注意しなければならない。

技術的ミス

　AI技術が提案したシステム構成や設定を人が確認しないと、技術的ミスに発展する恐れがある。潜在的な問題としては、自動化処理のエラー、コンピューティングリソースの不適切な割り当て、不完全な報告などがある。

　過度な自律性をAI技術に与えないようにすることは、こうしたリスクを軽減するための有効な施策だ。AI技術が関わるプロセスには、人の確認を組み込むべきだ。AI技術の介入なしにシステムを構成、管理、トラブルシューティングできる、経験豊富なIT担当者を確保しておくことも重要だ。有能な人材に居続けてもらうためには、IT管理者のスキルアップやキャリア成長の機会を提供することも必要だ。
リスク3．データ管理リスク
データセキュリティの確保は、あらゆるビジネスの成功にとって重要な課題だ。AI技術はセキュリティ設定を強化したり、さまざまなプロセスを自動化したりする際の助けになるが、同時にデータ管理における潜在的な落とし穴を生む可能性があることに注意を払う必要がある。

データセキュリティ

　顧客情報、企業独自の情報、従業員の個人データなどのデータを管理することは、企業のIT担当者にとって不可欠な業務だ。AI技術は、コンテンツ分析に基づいて情報を分類し、アクセス権限を適切に管理することでデータ侵害や情報流出などの不正アクセス違反を防止できる。これによって企業のデータ管理体制を強化することができる。分類ミスはデータを危険にさらし、企業機密情報や個人情報を権限のないエンドユーザーにさらす可能性がある。

　企業データへの不正アクセスは、機密情報がAIモデルの学習データに混入する原因にもなり得る。このような混入を企業が検出して修正することは困難だ。

　データセキュリティのためにAI技術を取り入れる場合、定期的な監査、人による監視、ペネトレーションテストといったリスク管理策を実施する必要がある。これらの対策は、セキュリティ設定の不備やデータの誤分類を減らすのに役立つ。他のAI技術活用時のリスクと同様に、最終的な管理は人の意思決定者に委ねるべきだ。
その他の注意すべきリスク
AI技術の潜在的なリスクは広範にわたり、変化し続けている。現時点では一般的ではなくても、将来的には深刻なリスクになり得る。AI技術のリスクを評価する際には、以下の問題が自社に関連するかどうかを検討する。

・AI技術の兵器化
・・人々に害を及ぼすことを目的に、軍事的、社会的、あるいは経済的な兵器としてAI技術を意図的かつ悪意をもって使用すれば、計り知れない脅威になる

・制御不能な自己認識型AI
・・自身の存在を認識し、意識を持つ「自己認識型AI」が実現すれば、人に対する潜在的な危険性が懸念事項になる

・環境破壊
・・AI技術が提案した方針が、環境への懸念を考慮していない場合、環境や気候に損害を与える可能性がある

・医療過誤
・・AI技術を医療現場で開発、導入、利用する個人や医療機関が、AIモデルの学習データを適切に管理していなかったり、AIモデルの処理能力を完全に把握できていなかったりすると、医療が患者に危害を与えるものになる恐れがある

本記事は米国Informa TechTargetの記事「Assess and manage the risks of using AI for business」を翻訳・編集したものです。一部、翻訳作業に生成AIを活用しています。
TechTargetジャパン",[],[]
