headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
自動車開発で生成AIはどのように役立つのか、数日かかっていたことを数分に短縮（MONOist）,https://news.yahoo.co.jp/articles/96a80e690137695e013879366ffe8a785d7c2f93,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250827-00000023-it_monoist-000-1-view.jpg?exp=10800,2025-08-27T08:30:12+09:00,2025-08-27T08:30:12+09:00,MONOist,it_monoist,MONOist,4122,"（写真：MONOist）
アマゾン ウェブ サービス ジャパン（AWSジャパン）は2025年8月21日、東京都内で会見を開き、自動車の開発における生成AI（人工知能）の活用事例について説明した。
【ホンダのEV充電の体験価値向上に向けたルートプランニング開発の事例】
同社は同年5月にCASE（コネクテッド、自動化、シェアリング＆サービス、電動化）、7月にSDV（ソフトウェアデファインドビークル）をテーマに、AWSのソリューションが自動車業界に採用されている理由などについて“記者勉強会”の形式で説明した。今回はその記者勉強会の第3回でありテーマに選んだのが生成AI（人工知能）である。
2025年からAIエージェントを活用する段階へ
AIの進化は著しい。2022年11月に「ChatGPT」が発表されて生成AIへの注目が一気に高まり、スマートフォンやPCに生成AIを利用したAI機能が多数搭載されるようになった。企業も生成AIの活用を推進するようになっている。AWSジャパン エンタープライズ技術本部 自動車・製造グループ 本部長の岡本京氏は「生成AIはPoC（概念実証）の段階は終わって実活用するものになっている」と語る。そして足元では、幾つかの生成AIが連携してより高度なタスクをこなす「AIエージェント」を活用する段階に進みつつある。

　岡本氏はAIエージェントまでの進化の流れについて、生成AIの前史に当たる自然言語処理技術（NLP）を起点に説明した。ディープラーニングの登場から進化を続けてきたAIだが、2020年以前はテキスト入力の続きを生成するなどのことができるNLPの開発が進められていた。このNLPを基に2022年に登場したChatGPTに代表される生成AIは、会話形式入力の続きを外部知識と連携して生成することが可能になった。ここで、重要な役割を果たしたのがRLHF（人間のフィードバックによる強化学習）と外付けデータベースとなるRAG（検索拡張生成）であり、生成AIは質の高い基盤として利用されることになった。

　2023年には、外部関数の呼び出しやプログラミングコードの生成にも対応するなどの機能が加わり、質の高い基盤が横にあるツールを使うという形で外部システムとの連携が可能になった。2024年は、論理的な思考プロセスを経て結論を導き出すリーズニングモデルとなり、与えられたタスクの完了に至るまで計画を生成できるようになっている。そして2025年から、タスク完了に至る計画の立案から実行までをカバーするAIエージェントの本格的に活用が始まろうとしている。

　岡本氏は「AIエージェントは、基盤モデルの計画能力と構造データ出力機能により、目的の指示のみでタスクを完了する。これは、自動車をはじめとするモビリティを取り巻くあらゆる体験価値を高める可能性がある」と強調する。
「Amazon Bedrock」でキャズムを越える
ただし、生成AIの活用で常に課題として突きつけられているのが、プロトタイプから本番稼働の間にある「キャズム」だ。AWSはこのキャズムを越えられるように、各社が可能な限り共通に使える道具立てとして「Amazon Bedrock」を提供している。

　Amazon Bedrockは、さまざまなAIモデルを切り替えてアプリケーション化を試すことができる機能を集積している。2025年7月のアップデートで加わった「Agent Core」により、ユーザーが共通的に必要とするであろうコンポーネントの提供も始めている。「当初はどのような共通コンポーネントが求められているかは分からなかったが、ユーザーフィードバックを反映する形で今回サービス化した」（岡本氏）という。

　また、顧客の伴走支援に注力するため、データサイエンスに深い造詣を持つメンバーをそろえる生成AIイノベーションセンター（GenAIIC）への投資を続けている。初年度に世界270万人の学生などを対象に、AIスキル向上を支援するプログラムも実施している。
ホンダは充電ルートプランニングやコールセンター対応でAWSを活用
それでは自動車業界において、AWSのAIソリューションはどのように活用されているのだろうか。会見では「新たなクルマ体験とサービス提供」と「車両開発プロセスの変革」に分けて事例が紹介された。

　「新たなクルマ体験とサービス提供」で紹介されたのはホンダの2つの事例だ。1つは、EV（電気自動車）充電の体験価値向上を目的としたルートプランニングに、Amazon Bedrockと「Amazon IoT Core」を活用した事例だ。EVの大きな課題の一つが、バッテリー充電の不安だ。想定外の遠回りで電力を消耗したり、行先の充電器が故障で使えなかったりといった事態があっても対応できるようなルートプランニングがあれば、EV所有の不安材料を和らげることができる。

　そこでホンダは、Amazon IoT Coreを用いてリアルタイムで車両データを収集し、過去の行動履歴や嗜好性などのデータと合わせて、Amazon Bedrockを用いたAIによりパーソナライズした最適なルートを提案する機能を開発している。この事例を背景にAWSとホンダは2025年1月、次世代SDVの実現と生成AIを活用した充電体験向上のサービス開発で協業することを発表した。

　もう1つの事例は、コールセンター対応のチャットbotだ。消費者向けの製品やサービスを提供する企業にとって顧客からの問い合わせに対応するコールセンターの効率化と品質改善は大きな課題である。ホンダもこれまで、1つの問い合わせチケットの対応に数日間を要したり、回答内容が担当者の経験に基づくため回答品質にばらつきがあったりした。

　そこでAWSのGenAIICは、問い合わせに対するチケットの作成、参照すべき情報やログデータなどを取得するためのAPIリクエストやSQL文の作成と実行、これらの処理をサブタスクとするLLM（大規模言語モデル）に基づくAIエージェントを開発した。そして、このAIエージェントによって問い合わせに対する正しい回答が生成できるかを検証した。実際に、8つのユースケースで平均70％以上の確率で適切な回答が得られるとともに、数分で問い合わせへの対応を完了させられたという。つまり、数日掛かっていたこともある対応が、数分で完了するようになったわけだ。
自動車開発のV字モデルにおいてさまざまなAI適用が検討中
一方、「車両開発プロセスの変革」でもさまざまなAI適用が検討されている。自動車の開発プロセスはV字モデルで表されることが多い。V字の左側では、自動車メーカーが策定した仕様から詳細設計に落とし込み、V字の右側では詳細設計から各コンポーネントやシステム、完成車など対象を広げながら開発と検証を進めていく。

　AWSジャパン 自動車事業本部 プリンシパル ソリューションアーキテクトの梶本一夫氏は「V字モデルで左上に位置する要件管理、一番底にあるコード生成、右上に位置するV&V（検証と評価）において、自然言語認識に強い生成AIの力を生かした自動化に向けた取り組みが進んでいる」と語る。
人手で数日かかる仕様変更が生成AIシスタントに任せると数分で完了
例えば、AWSは2025年1月開催の「CES 2025」において、要件管理への生成AI適用事例となるIVI（車載情報機器）を用いたデモを紹介している。このIVIは、クラウド上の仮想開発プラットフォームである「Amazon Graviton」上に構築されており、仮想ECUによって再現されている。ここで、メータークラスタ左上の速度制限値の表示の枠色を、通常の赤から、EVモデルの場合は緑に変更する例を見てみよう。

　開発担当者はこの仕様変更の指示をテキストで入力する。従来は関連するエンジニアに仕様変更を連絡し関わる業務の割り当てを行った上で変更作業を進めていくことになる。しかし、AWSのデモでは、生成AIアシスタントである「Amazon Q」が仕様変更の指示を受けて、変更の前提となるソフトウェア構成環境について開発担当者に確認を求める。なお、Amazon Qは要求仕様書、詳細設計書、ソースコードの関係性をあらかじめ学習しているため、開発担当者が行うのはその内容が正しいかどうかの確認作業だけで済む。

　確認作業が完了すると、Amazon Qは要求仕様書の変更すべき部分と対応するソースコードの変更を提案する。この提案を受け入れれば、Amazon QはCI／CD（継続的インテグレーション／継続的デリバリー）ツールを用いて、変更した仕様に基づき生成した新たなソースコードと従来のソースコードの比較を提示する。ソースコード確認が終われば、CI／CDツールによってAmazon Graviton上に構築されたIVIに反映され、速度制限の枠色が変わったことを仮想ECU上の動作で確認できる。「従来は人手でやりとりしていた仕様変更に関わる要件管理のプロセスは数日かかることもあったが、生成AIであるAmazon Qに任せれば新たなソースコードを生成してECUに実装するまで数分で完了できる」（梶本氏）。

　この他にもCES 2025では、ADAS（先進運転支援システム）開発における自然言語によるシーン検索や、検証用映像生成、地図情報からの映像生成などのデモも披露した。

　また、自動車ではAIモデルにリアルタイム性の高い応答が求められるためエッジAIが果たすべき役割にも大きな期待がかけられている。クラウドベンダーであるAWSは、大規模なクラウドLLMから自動車に最適なエッジLLMを構築した上で、先述のAmazon Gravitonを用いた仮想ECUでエッジLLMの動作を確認してから自動車に実装し、その利用状況の分析と更新を行えるフレームワークを提供できるという。
MONOist",[],[]
旭化成発のスピンアウトベンチャーがUV-C LD市場拡大に挑む、ノーベル賞学者も参加（MONOist）,https://news.yahoo.co.jp/articles/6e40781a702c84cf4f44e997b68aaa1419878ae9,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250827-00000012-it_monoist-000-1-view.jpg?exp=10800,2025-08-27T07:00:15+09:00,2025-08-27T07:00:15+09:00,MONOist,it_monoist,MONOist,1107,"（写真：MONOist）
旭化成は2025年8月25日、旭化成発のスピンアウトベンチャーとしてULTECが設立されたと発表した。
ULTECのメンバー。左から、張梓懿氏、天野浩氏（名古屋大学 名誉教授 兼 ULTEC技術顧問）、久志本真希氏（名古屋大学 准教授 兼 ULTEC技術顧問）、吉川陽氏［クリックで拡大］ 出所：旭化成
ULTECは、窒化アルミニウム（AlN）を用いたウルトラワイドギャップ半導体技術を基盤に、深紫外線レーザーダイオード（UV-C LD）、遠紫外線LED、深紫外線センサー、高耐圧パワーデバイスなどの開発／事業化を進めるスタートアップだ。このUV-C LD技術は、2025年6月、レーザー技術分野で世界的に権威がある「Berthold Leibinger Innovationspreis（ベルソルト・ライビンガー・イノベーション賞）」で第3位を受賞した。

　同社は、旭化成が持つ先進的な技術の新しい出口戦略の一環というミッションを担い、PoC（概念実証）と社外パートナーシップを通じ、UV-C LDの実用化とマーケットの拡大を目指す。
ファブレスによるアセットライトな事業モデルとして社会実装を推進
旭化成 研究・開発本部と名古屋大学 天野・本田研究室は2017年からUV-C LDの共同研究を進めてきた。2019年には世界初となる室温パルス発振を、2022年には同じく世界初となる室温連続発振を実現（いずれも旭化成調べ）しており、この技術はケミカル／バイオ計測機器や殺菌用途で国内外で注目されている。しかし、将来の市場形成が期待される一方で、まだ確立した市場が存在しない先進的なテーマでもあった。

　このような背景を踏まえ、旭化成は自社における設備投資と技術開発を通じた従来型の事業化手法ではなく、スピンアウトによる非連結会社のスタートアップとして、ULTECを設立した。同社に旭化成が持つ技術をライセンスすることで、意思決定のスピードを高めると同時に、名古屋大学の研究設備や外部リソースを活用し、ファブレスによるアセットライトな事業モデルとして社会実装を進める。なお、ULTEC設立に際しては、経済産業省が提唱する“出向起業”推進の枠組み「大企業等人材による新規事業促進事業」を利用しており、旭化成従業員の吉川陽、張梓懿がULTECに役員として出向している。

　「大企業等人材による新規事業促進事業」は、経済産業省が実施する補助事業で、大企業などに所属する人材が、退職せずに外部資金調達などを行い起業したスタートアップに出向し、新規事業の実践を支援する制度だ。
MONOist",[],[]
NVIDIAは組み込みAIボードもBlackwell世代へ、2070TFLOPSの「Jetson AGX Thor」（MONOist）,https://news.yahoo.co.jp/articles/a6fb4e19b080d55f222bcbdebe924d7799203f8f,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250827-00000022-it_monoist-000-1-view.jpg?exp=10800,2025-08-27T06:15:11+09:00,2025-08-27T06:15:11+09:00,MONOist,it_monoist,MONOist,2349,"（写真：MONOist）
NVIDIAは2025年8月25日（現地時間）、組み込みAI（人工知能）ボード「Jetsonシリーズ」の最新製品となる「NVIDIA Jetson AGX Thor（以下、Jetson AGX Thor）」を発表した。AI処理性能はFP4（4ビット浮動小数点演算）で2070TFLOPSで、これは現行の組み込みAIボードでフラグシップの「NVIDIA Jetson AGX Orin（以下、Jetson AGX Orin）」の7.5倍に達する。Jetson AGX Thorの機能を集約したSoM（System on Module）を専用筐体に組み込んで提供する開発者キットの価格は3499米ドル（約51万6500円）。
【「NVIDIA Jetson AGX Thor」の開発キットの構成】
Jetson AGX Thorは、NVIDIAがサーバやデスクトップ向けに2024年から展開しているGPUアーキテクチャ「Blackwell」を採用した組み込みAIボードである。サーバからPC／ワークステーション、そして組み込み機器に至るまで、NVIDIAの最新製品のGPUアーキテクチャはBlackwellで統一されたことになる。

　Blackwellを採用したJetson AGX Thorは、生成AIモデルを効率的に処理できるトランスフォーマーエンジンを採用している。サーバ向けのBlackwellと同様に、従来よりも量子化を進めたFP4でのAI処理が可能であり、2070TFLOPSという高い性能値はFP4によるものだ。ただし、現行製品であるJetson AGX OrinのAI処理性能である275TOPSに用いられているINT8（8ビット固定小数点）でも、Jetson AGX Thorは1035TFLOPSをたたき出している。なお、GPUの最大動作周波数は1.57GHzで、Jetson AGX Orinの1.3GHzと比べて約20％の増加となっている。

　NVIDIAはJetson AGX Thorについて、汎用人型ロボットの実現に求められる性能を実現するために開発したとしている。汎用人型ロボットでは、多数のセンサーデータを処理した上でそれらを用いてマルチモーダルの生成AIを用いて動作に反映させることになる。つまり、汎用人型ロボットが素早く滑らかに動作するには制御コンピュータによる生成AI処理のトークン発行のレイテンシがリアルタイムと呼ばれる数百msオーダー以下を実現しなければならない。NVIDIAはそのベンチマークとして、LLM（大規模言語モデル）として「Llama 3B」、画像解析AI「Qwen 2.5 VL 3B」を用いて16個のセンサー入力を処理するタスクのトークンを発行するレイテンシを算出した。Jetson AGX Thorは、最初のトークン発行で200ms以下、1トークン当たりの発行時間で50ms以下を実現したという。
消費電力は倍増も「消費電力当たりの性能で大きく上回る」
また、Jetson AGX Thorは、Jetsonシリーズとして初めて、1つのGPUを複数の独立したGPUに分離して扱えるMIG（Multi-Instance GPU）を利用できるようになった。MIGは、Ampere世代のサーバ向けGPUから導入が始まったもののJetson AGX Orinには採用されていなかった。Jetson AGX Thorは、2560個のGPUコアと96個の第5世代Tensorコアを搭載しており、最大10個のGPUインスタンスに分割できる。

　Jetson AGX ThorはCPU性能も向上しており、Armの自動運転システム／ADAS（先進運転支援システム）向けアプロケーションプロセッサコアである「Neoverse-V3AE」を14コア集積している。最大動作周波数は2.6GHzである。

　メモリは最新の256ビットLPDDR5Xを採用しており帯域幅は273GB/s。Jetson AGX Orinの256ビットLPDDR5の帯域幅が204.8GB/sだったので約33％の増加となる。容量も128GBで、Jetson AGX Orinの64GBから倍増した。ネットワークインタフェースとして高速の25GbEを4チャネル搭載している。開発者キットは、25GbE×4チャネルを用いることで100Gbpsの帯域幅に対応するQSFP28の光トランシーバーモジュールを搭載している。

　なお、Jetson AGX Thorの消費電力は40～130Wで、Jetson AGX Orinの15～60Wから倍増した。ただしNVIDIAは、Jetson AGX ThorはJetson AGX Orinと比べてAI処理性能が7.5倍、CPU処理性能が3.1倍、外部接続ネットワークの帯域幅が10倍になっていることなど、消費電力当たりの性能で大きく上回っているとしている。

　Jetson AGX Thorの量産モジュールは開発者キットに組み込んでいる「Jetson T5000」の他に「Jetson T4000」も用意した。Jetson T4000はFP4のAI処理性能が1200TFLOPSなど機能を抑える一方で消費電力は最大で70Wとなっている。価格はJetson T5000が2999米ドル、Jetson T4000が1999米ドル。Jetson AGX Thorの開発者キットとJetson T5000は発表と同時に販売を開始しており、Jetson T4000は2025年10～12月期の発売を予定している。
MONOist",[],[]
