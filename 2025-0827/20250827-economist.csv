headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
AIの進化が問う人間へのアドバイスとプライバシー　長谷佳明（サンデー毎日×週刊エコノミストOnline）,https://news.yahoo.co.jp/articles/06709162cf03be0b47c5788792e01d023afa0658,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250827-00000001-economist-000-1-view.jpg?exp=10800,2025-08-27T09:55:26+09:00,2025-08-27T09:55:26+09:00,サンデー毎日×週刊エコノミストOnline,economist,サンデー毎日×週刊エコノミストOnline,2788,"「Agentic Wallets」を自社サイトのブログで説明するInrupt（同社サイトから）
「AIは私たちの生活を、快適でより良いものにする」。AIを開発するベンダーや活用する企業らは、そう信じて疑わないだろう。実際、身近なサービスのちょっとした改善にも、AIはすでに活用されている。

　オンラインショッピングサイトでは、口コミは商品選択の重要な手がかりだが、多くの本数が掲載されても、確認できるのはせいぜい数件で、せっかくの口コミを生かすことができない。この課題に、アマゾンは「お客様のご意見」として、口コミを生成AIで1本にわかりやすくまとめたサービスを行っている。気になる商品の特長を、ユーザーの視点から簡潔に把握できる便利なサービスだ。

　AIは、今後私たちの生活にさらに浸透すると思われるが、果たして、これは良いことばかりなのだろうか？　今回は著名な研究などを参考に、AI時代のシステムと人間の関係について考察する。

◇心理的リアクタンス

　親しい友人からの助言やAIのおススメに、人間は時折、押しつけがましいと感じることがある。これはどこからくるのか。ヒントになるのが「心理的リアクタンス」という理論である。米国の心理学者ジャック・ブレーム博士（1928～2009年）が1966年に発表した論文「A theory of psychological reactance」で明らかにした。

　人間は自身の行動について、ある程度自由に選択できると考えている。その自由を減少させられたり、減少の脅威にさらされたりすると、人間はそれを取り戻そうと行動する。つまりは、反発したり逆の行動をとったりしてしまうというのが、心理的リアクタンス理論である。友人は良かれと思ってアドバイスしても、それに嫌気がさしたり、結果的には得だとわかっていても、システムからのおススメを無視してしまったりする行動などが該当する。

　心理的リアクタンスは、セールストークやショッピングサイトの推奨など、ビジネスの場面でよく取り上げられるテーマである。しかしAIが高度化し、AIエージェントとして個人の判断に助言するようになると、心理的リアクタンスに関わる問題は、より一層、顕在化するだろう。
たとえ、メリットがある助言でも、適度な回数や適切なタイミングで伝える必要がある。生成AI時代では“伝え方”が重要になる。かつてのAIは、自然言語（ことば）が不得意で、要件を伝えるだけの機械的なメッセージであったり、チャットボットなども、事前に定義されたパターンのやり取りに過ぎなかったりした。しかし、最新のAIは大量の文章を学習した結果、双方向のやり取り、つまり会話が可能となり、アドバイスは格段にユーザーの意図や状況に沿ったものになった。AIエージェントには、ユーザーが心理的リアクタンスを引き起こさない、「会話のデザイン」が求められるだろう。

◇監視資本主義には「ノー」を

　また、AIエージェントがスマートフォンに搭載されるようになって懸念されるのが、過剰な個人情報の収集による「監視資本主義（Surveillance Capitalism）」である。監視資本主義とは、検索エンジンやSNSを運営する企業らが個人情報を必要以上に収集し、消費者の行動を分析。広告などを通じて巧みに誘導するなどして、個人の行動さえも変容させ、自社の利益を獲得する仕組みである。ハーバード・ビジネススクールのショシャナ・ズボフ名誉教授などが、その問題性を指摘している。

　欧州では、個人情報保護などを目的に「GDPR（General Data Protection Regulation: EU 一般データ保護規則）」が2018年5月に施行。2024年2月には、インターネット上のサービスに活用されるアルゴリズムの透明性の確保と説明責任の強化を目的に「デジタルサービス法」が続くなど、個人情報管理や監視資本主義にも関わる法律を整備してきた。

　これらの法律は、問題を後追いする形となってしまったが、AIエージェントがスマートフォンに搭載されるのは間近とされ、欧州委員会は過去の反省から、先んじた規制やルールを策定するだろう。もちろん、AIエージェントが、個人のプライバシーを侵害する新たな監視の手段とならないよう、サービスを開発する企業には、各国、各地域の法規制に則った行動が求められる。
AIエージェントが参照するデータの保護と利活用に向けた具体的な仕組みの開発も始まっている。米国のスタートアップ企業のInruptは「Agentic Wallets（エージェント・ウォレット）」という個人情報を管理するアプリケーションを開発している。

　Inruptは、世界初のWebサイト（World Wide Web、WWW）の構築やHTTP（Hyper Text Transfer Protocol）はじめとしたインターネット関連技術の発明で有名なティム・バーナーズ＝リーが共同設立者兼最高技術責任者を務める企業である。ティムは、一部の巨大企業が大量の個人情報を収集してネットを支配する現状に危機感を持ち、個人が自らの生み出すデータの管理が可能な仕組みとしてデータ・ウォレット「Solid」を開発。個人によるデータ主権の確立を訴えてきた。そして、エージェント・ウォレットは、SolidをAIエージェント向けに拡張したものである。

◇信頼できるAIにするために

　将来、ユーザーは、スマートフォンを介して、いくつものAIエージェントやAIサービスを利用するようになる。その際、エージェント・ウォレットのような技術があれば、ユーザーは、どこまでの情報をどのエージェントに許可するのかなど、主体的にデータを制御できる。信頼できる企業には、その多くを明かし、信用ならない企業には、限定的な情報だけを連携するようになるだろう。

　エージェント・ウォレットは、VISAが25年4月に発表したAIエージェントがユーザーに代わり商品を検索、購入するためのプラットフォーム「Visa Intelligent Commerce」にも採用される見込みで、今後、AIアプリケーションが個人情報を利用する際のデファクトスタンダードとなっていく可能性もある。

　生成AIは、単なる“道具””にすぎなかった人間とAIとの関係を、自分専用の「執事」や「パートナー」、人によっては「友人」へと変える。利便性のような従来の価値観とは、また異なる安心感や心地よさ、信頼感などが求められるようになる。これは、AIが、人に近い“エンティティー（存在）”となっていく始まりともなるだろう。
（長谷佳明氏・野村総合研究所チーフストラテジスト）",[],[]
