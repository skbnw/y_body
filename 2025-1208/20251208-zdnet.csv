headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
実用化へ加速するIBMの量子戦略--新チップ「NightHawk」発表（ZDNET Japan）,https://news.yahoo.co.jp/articles/81eecb37a44f21588ed30b161c1bf0cda1db4299,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20251208-35241367-zdnet-000-1-view.jpg?exp=10800,2025-12-08T16:46:00+09:00,2025-12-08T16:46:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,1914,"実用化へ加速するIBMの量子戦略--新チップ「NightHawk」発表の画像
日本IBMは12月4日、「実用的な量子コンピューティングを世界に提供する」というミッションの下に取り組む、量子コンピューティングの最新状況を発表した。量子優位性の実現などについて進展があったという。

　今回の発表は、11月に実施した年次イベント「Quantum Developer Conference」の内容を日本の記者向けに説明したものになる。

　IBMでは、（1）量子コンピューターのチップ（QPU）や周辺機器、システム、および利用のためのソフトウェア「Qiskit」の研究開発などのプラットフォームの提供、（2）エコシステムを構築し、研究機関や企業と連携して社会実装のためのアプリケーションの研究開発を進める――という2つの柱で量子コンピューティングを提供している。

　現在までに、100量子ビット未満の量子デバイス60台を提供しているほか、古典コンピューターではシミュレーションが困難な100量子ビット以上のデバイス25台を展開している。

　IBM Quantum Japan統括部長 シニア・テクニカル・スタッフ・メンバーの堀井洋氏は「IBMの特徴は量子コンピューターをクラウド上で提供していること。これにより多くのお客さまに提供ができ、稼働率は97％を達成し、最新のチップデバイスである『Heron R2』では、99％の稼働率を維持している。まさに実際の運用を見据えた量子コンピューターを提供できている」と現状を述べる。

　IBMでは、米国ニューヨーク州のポキプシーとドイツにデータセンターを構え、9台の量子コンピューターをオンプレミスで稼働。日本国内においては、東京大学と理化学研究所（理研）にシステムを提供し、理研には、米国外で初となる「IBM Quantum System Two」を、スーパーコンピューター「富岳」と同じ建屋内に導入している。

　ハードの提供とともに、オープンソースの量子コンピューティング向けソフトウェア開発キット（SDK）Qiskitの提供も進める。Qiskitを使うことで、ユーザーは量子コンピューターで実行するプログラムを設計し、IBMのクラウド量子システムやシミュレーター上で実行が可能になる。

　提供を開始して以来、オープンソースソフトウェアの保管庫である「GitHub」のスター数やユーザー数は伸び続けており「量子アプリケーションを開発する上でのデファクトスタンダードの1つとしての地位を確立している」（堀井氏）とし、ソフトウェアの面からも量子コンピューターの実用を後押しする。

　実用的な量子コンピューティングの提供を目指し、IBMではデベロップメントとイノベーションという2つの軸でロードマップを進めている。2023年には、「Eagle」チップにより量子有用性（Quantum Utility）の確立を実証したほか、2026年には、従来のコンピューターでは計算困難な問題を量子コンピューターで計算できることを目指す量子優位性（Quantum Advantage）を実証していく方針。2029年までには、大規模なシステムを提供し、エラー訂正が可能な量子コンピューティングを実現する、フォールト・トレラント量子コンピューターの提供を目指す。

　堀井氏は、量子コンピューターで量子効果を得るために必要な極低温の維持について、東京大学とともに設立したハードウェアテストセンター「The University of Tokyo – IBM Quantum Hardware Test Center」の事例を挙げ、「ロードマップを示すことで、お客さま、研究者、業界関係者の方と協業して課題解決に当たっている。IBMの将来の技術的な方向性を明確に伝えることで、パートナー企業や研究機関はIBMのロードマップに合わせた形で研究開発やデバイス開発を進められる」とし、業界全体の進歩を加速する。

　2025年には新チップ「NightHawk」を発表。133量子キュービットの Heronに対し、NightHawkは129量子キュービットと少し小さいが、接続性を高め、性能向上につなげているという。また、2029年の実現を目指すエラー耐性の高いシステムについては、次世代システムの核となるアーキテクチャーを検証するためのチップ「Loon」を発表している。

　IBMでは、今後も企業や研究機関との共同研究、プロトタイプの開発を推進し、量子コンピューターを支えるサプライチェーンの構築を進めていく。",[],[]
大和ハウス、モジュール型データセータ「Module DPDC」発売--約1年で構築可能（ZDNET Japan）,https://news.yahoo.co.jp/articles/5ade78408d59fccf174dc488894109e9ab88f116,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20251208-35241371-zdnet-000-1-view.jpg?exp=10800,2025-12-08T16:44:00+09:00,2025-12-08T16:44:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,601,"大和ハウス、モジュール型データセータ「Module DPDC」発売--約1年で構築可能の画像
大和ハウス工業は12月8日、モジュール型データセンター商品「Module DPDC」の販売を開始すると発表した。販売開始は2026年1月5日。

　Module DPDCは、1モジュール当たりの延べ床面積が約200平方mで、高さ約6.6m。サーバーラック、電気設備、空調設備を含めたオールインワンパッケージで提供され、電力容量は約1～2MWになる。

　部材の一部を大和ハウスグループの大和リースの工場で製作し、現場で組み立てることで従来の建設プロセスを大幅に効率化していることが特徴。都市部や工業地域などに配電される既存の高圧電力受電のインフラを利用できるため、電力の確保も容易だ。

　一般的な建屋型データセンターでは土地選定から建設完了、大容量の電力引き込みなどに5年以上を要することもあるが、Module DPDCでは、契約から引き渡しまでを約1年に短縮できるとしている。

　鉄骨造のモジュール型で、約1000平方m程度の用地から建設することが可能。構造躯体（くたい）は、日本データセンター協会（JDCC）が定める最高レベル「Tier4」に準拠し、耐震性を確保しているほか、無停電電源装置（UPS）などのバックアップ設備と厳重なセキュリティ管理レベルを完備することで、災害時などにも継続運用できる。",[],[]
リコー、オンプレミス向けLLMを開発--暗黙知を資産にする「秘伝のタレAI化」とは（ZDNET Japan）,https://news.yahoo.co.jp/articles/04dffe96c7fc8a3e5fea66c3bcd41840c4ce59ac,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20251208-35241363-zdnet-000-1-view.jpg?exp=10800,2025-12-08T14:48:00+09:00,2025-12-08T14:48:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,1577,"リコー、オンプレミス向けLLMを開発--暗黙知を資産にする「秘伝のタレAI化」とはの画像
リコーは12月8日、開発・提供する日本語大規模言語モデル（LLM）の次世代モデル「リコー LLM（27B）」を開発したと発表した。Google「Gemma 3 27B」をベースにオンプレミス環境への導入に最適なLLMになっている。

　リコー LLM（27B）は、270億パラメーターのモデルサイズで、PCサーバーなどでの構築が可能。低コストでのプライベートLLM導入を実現する。コンパクトなため、省電力での駆動に対応する。

　リコーは1980年代からAIの開発に取り組み、現在では独自のLLMも開発。「『ChatGPT』が登場した当時は、あまり日本語が得意ではなかったので、リコーはChatGPTを日本語化した『リコーLLM 6B』を発表。以降、ベースモデルを変えながらパラメーター数を増やし、LLMを強化している」（リコー リコーデジタルサービスビジネスユニット AIサービス事業本部 本部長の梅津良昭氏）と現状を説明する。

　合わせて、テキストに埋め込まれた図表や、複雑なフローチャート、技術図面、ヒートマップなどの読解能力を高めた、大規模マルチモーダルモデルLMMの開発も強化しており、文書情報を、図表を含めて全て読み解き、活用可能な資産としての活用を進めている。

　ビジネスにおけるAIの活用が進む中、企業では、検索拡張性（RAG）にLLMを組み合わせ、社内RAGを構築する動きが出てきている。そうした中、環境などへの配慮から、クラウドではなく、自社のオンプレミスサーバーで使いたいというニーズも出てきており、今回のRICHO LLM（27B）を開発したとのこと。

　加えて、図面や画像などの知識化に対する要望も多く、「さまざまなお客さまから暗黙知の資産活用をしたい」（梅津氏）という相談が非常に多いという。ここでいう暗黙知とは、いわゆる非構造化データのこと。「営業担当者であれば、営業日報やお客さま向けの提案書がそれに当たる。ノウハウの塊だが再利用はなかなか進んでいない」（梅津氏）と課題に挙げる。

　リコーでは、これらの課題を解決するため、「秘伝のタレAI化」を推進。これは、企業が持つ現場のデータをAI化していく取り組みで、（1）技術基盤、（2）文化醸成、（3）交流活性、（4）生産革新――4つのステップから成り、これをユーザーにAIトランスフォーメーション（AX）として提供していくという。

　特に、RAGの開発・使いこなしやRAGの統合などを課題と感じるユーザーに対しては、「秘伝のタレプラットフォーム」としてパッケージ化して提供していくという。

　梅津氏は「秘伝のタレと呼んでいるが、まだ名前は付けていない。秘められた（Hidden）深層の専門知識（Deep Expertise）を活用するシステムの中核『Hidden Deep Expertise Engine Nexus』（HDEEN）の頭文字を取ることで、秘伝と読めるので、現在は秘伝と呼んでいる」と明かした。

　秘伝のタレプラットフォームでは、相談事をまず司令塔 AI エージェントが受け付け、そこから専門家AIエージェントに個々の問題を振り分ける。それぞれがテキストRAGやマルチモーダルRAGを使い回答を導き出すという流れ。複数のRAGを駆使することで、実現するという。

　梅津氏は「私たちは2030年に向けて『つまらない仕事はもうやらない』というキーメッセージを打ち出している。オフィスでも工場でも『これはもう人間がやらなくてもいい』仕事はAIやロボティクスにまかせ、人は創造性を発揮するようなところにシフトしていくことを目指している」と、新たな未来を描いた。",[],[]
Cloudera、「Hadoop」からAIとデータの統合プラットフォーム企業へ（ZDNET Japan）,https://news.yahoo.co.jp/articles/fd24f87cc0c846f7667d8bc443b503ac7565bee5,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20251208-35241362-zdnet-000-2-view.jpg?exp=10800,2025-12-08T14:39:00+09:00,2025-12-08T15:36:11+09:00,ZDNET Japan,zdnet,ZDNET Japan,4084,"Clouderaの山賀氏（左）と吉田氏
Clouderaは2026年の展望を発表し、企業が今後に向けてデータ基盤を再評価し、強化することの重要性を語った。

　同社は2026年の企業のAI戦略に関する予測として、「『AIサイロ』が新たな企業課題として浮上」「AIエージェントの実用化が加速」「『プライベートAI』が企業にとって次の優先事項に」「AI人材と責任ある活用におけるギャップの解消」「企業に求められるAI投資戦略の精査」――の5点を挙げた上で、「AIの成功は強固なデータ基盤にかかっている」「データの整備がどれだけ進んでいるかが、企業が安全にスケールし、自信を持ってイノベーションを進め、測定可能なビジネス成果を挙げられるかを左右する」と語る。

　2025年4月に日本リージョナル・バイスプレジデント（RVP）兼カントリーマネージャー（社長執行役員）に就任した山賀裕二氏は「多くの人がClouderaを『Apache Hadoop』の会社だと思っている。間違いではないが、昨今の変化を伝え切れていない」と語り、現在は「AIとデータの統合プラットフォーム」の提供企業として評価されていることを強調した。

　Clouderaは2008年にHadoopのディストリビューターとして出発した企業だ。当時は「ビッグデータ」の全盛時代であり、Hadoopに対する関心も高かったことから同社も成長を遂げたが、その後企業が本格的にクラウドを活用するようになったことでテクノロジーのトレンドが変化したこともあり、同社は2022年にデータの所在にかかわらず、物理的に集約する必要もなく、それを1つのデータレイクハウスとして提供するという、いわゆる“オープンデータレイクハウス”を中心とした新たなプラットフォーム提供にかじを切った。

　さらに、2022年末の「ChatGPT」のリリースから急速に利用が拡大したAIも同社の戦略に大きな影響を与えている。同社は、単にデータのプラットフォームとなるだけでなく、「AIの稼働環境および開発環境をプラットフォーム上に組み込み、新たな『AIとデータの統合プラットフォーム』として提供」している。

　オンプレミスから各種クラウドまで、さまざまなな環境を適材適所で利用可能とする同社のハイブリッド戦略だが、これがデータだけにとどまらず、AIの稼働／開発環境にまで及んでいるのが同社の特徴だと言えるだろう。

　山賀氏は、データ量の増大に伴うクラウド利用のコスト増大やデータ転送に伴うコストやレイテンシー、さらにデータの機密保持などのさまざまな問題が複合する現状を指摘し、オンプレミスやプライベートクラウドとパブリッククラウドなどを組み合わせて適材適所で運用するハイブリッド環境にメリットがあると強調し、同社が「ハイブリッド環境に適した唯一のオープンデータレイクハウスとして、お客さまの最適なAIの活用を支援していく」という方針を示した。

　同社はこの「AIとデータの統合プラットフォーム」という戦略を推進するために企業買収も進めている。2024年11月に買収したOctopaiは、データリネージ（データのライフサイクル全体にわたる追跡や可視化）を実現し、AI時代に向けたデータ管理機能の強化となる。

　その一方で、一見すると少し意図が分かりにくいのが2025年8月に発表されたTaikunの買収だ。Taikunは「ハイブリッドおよびマルチクラウド環境でKubernetesとクラウドインフラを管理する先進プラットフォームプロバイダー」であり、コンピューティング領域の取り組みとなる。

　同社のソリューション・エンジニアリング・マネジャーの吉田栄信氏は「TaikunはKubernetesのマルチハイブリッドクラウドを目指していて、Clouderaはデータプラットフォームのマルチハイブリッドクラウドなので、それが合わさることによってコンピュートレイヤーでのマルチハイブリッドクラウドを実現しようとしている」と説明した。

　同社のアプローチでは、ハイパースケーラー各社の環境を仮想的に統合して扱えるが、実際にそのデータを活用するAIエンジンなどは各クラウドごとに異なるKubernetes環境上で動作しているなど、環境依存の差異が存在する。Taikunを活用することでさまざまなKubernetes環境を一元管理できるようになり、コンテナーアプリケーションの展開が迅速かつ柔軟になるなどのメリットが期待される。
Clouderaをデータ基盤として採用し、AI活用に本格的に取り組んだ例として山賀氏はシンガポールに本社を置くオーバーシー・チャイニーズ銀行（OCBC）の事例を紹介した。OCBCの収益は約100億ドルの規模で、東南アジアエリアの3大銀行の1つだという。

　OCBCでは、顧客向けデジタルサービスの顧客体験向上と社内業務の効率化の両面でAI活用を進めており、既に200超のAIモデルを展開している。パブリッククラウド上の大規模言語モデル（LLM）とオンプレミスのLLMを適材適所で使い分けるなど、Clouderaのハイブリッドマルチ環境対応を生かした利用をしている。

　山賀氏はまた、OCBCの事例から得られた知見として、デプロイするモデル数とコストの関係についても紹介した。概念実証（PoC）段階など、モデル数が少ない段階ではスモールスタートしやすいパブリッククラウドがコスト面で有利だが、モデル数に比例してコストが右肩上がりで増大していくため、約100モデルを超えるあたりでコストが逆転し、以後はオンプレミスのほうが低コストで運用できるという。こうしたデータが集まってくれば、企業がAI活用を進めていく上でどのような環境を整備すべきかも明確な指針が得られそうだ。

　なお、OCBCの事例に関しては2025年8月にシンガポールで開催された同社のプライベートイベント「Cloudera EVOLVE25」にてOCBCのManaging Director ＆ Head of Group Data OfficeのDonald MacDonald氏に話を聞く機会があったのでここで紹介したい。

　OCBCでは20年ほど前からデータ基盤の整備に取り組んで来たという。当初はアプライアンス型のデータウェアハウスを採用しており、構造化データを対象とした分析／レポーティングなどでは満足できる結果が得られていたが、その後AIの発展に伴って非構造化データやリアルタイムデータが増加したため、2015年にClouderaのデータプラットフォームを導入してAI関連処理はCloudera上で実行するようになった。

　2015年の段階では、AIと言えば機械学習や深層学習が注目されていた時代で、生成AIはまだ出現していなかった時代だ。このタイミングでAIを想定したデータ基盤の整備に取り組んだOCBCには先見の明があったと言える。

　MacDonald氏は「将来を予測するのはその時点でも極めて難しかったし、現在でもその事情は大きくは変わらないだろう。2015年の時点では選択肢としてClouderaとHortonworksを比較してClouderaを選んだが、その後2019年にHortonworksはClouderaと合併したので、正しい選択をしたと考えている」と語った。

　Clouderaはオンプレミス環境での運用に強みを持つことから、プライベートクラウドも運用しているOCBCにとってはこの点も高評価だという。AI活用の拡大に応じてGPUに対するニーズも高まっているため、GPUをオンデマンドで利用するためにGPUクラウドの利用量は増えていくと予測されているが、一方でデータセキュリティはコストを考えるとハイパースケーラーのパブリッククラウドは利用せず、オンプレミス／プライベートクラウドを中心としたシステム環境を今後も継続的に利用することになりそうだと同氏は言う。

　こうした背景もあって、仮にシステム選定を2015年ではなく現時点で実施したとしても、やはりClouderaを選ぶだろうと語っていたのが印象的だった。なお、Clouderaとは直接の関連はないが、日本ではたびたび話題に上がる人材不足についてシンガポールの状況を聞いてみたところ、政府主導でデータサイエンティストなどの育成に早くから注力した成果もあって国内で豊富な人材が育っており、OCBCでは人材不足を感じたことはないとのことだった。こうした取り組みについても日本がシンガポールに学ぶべき点がさまざまあるように思われる。

　技術革新はらせん状に進展するという話がある通り、IT業界でも集中と分散が交互に主流になるなど技術トレンドの循環が見られる。かつてはメインフレームに集中していた業務処理が、オープンシステムと呼ばれた比較的小型のサーバーやPCなどのクライアント端末のネットワークによる分散処理に移行し、さらにクラウドに集中するといった変遷も見られた。現在ではAIの普及を受けて、データやAIモデルの処理をオンプレミスで実行したいという揺り戻しの動きが目立ち始めてきている。

　もともとオンプレミスからハイブリッドマルチ環境へと対応を広げたClouderaだが、オンプレミスに対する対応の強みを捨てなかったことでこうしたオンプレミス回帰のトレンドとうまく合致しているようにも見える。さらに、データレイクハウス提供企業の中でもいち早くKubernetes環境の統合にまで踏み込み、コンピューティングレイヤまでカバーする動きを見せるなど、特徴的な戦略を展開している点も興味深いところだ。

　今後AIエージェントの本格的な活用期を迎える中、同社のデータとAIの統合プラットフォームを提供するという戦略がユーザー企業からどう評価されるのか興味深い。",[],[]
Anthropic、AIに関するユーザーの意見を聞き取る新ツールをリリース（ZDNET Japan）,https://news.yahoo.co.jp/articles/ab0d77ec12d6a5922c2a3d1acd138bc864ed52b1,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20251208-35241347-zdnet-000-1-view.jpg?exp=10800,2025-12-08T09:53:00+09:00,2025-12-08T09:53:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,1166,"Anthropic、AIに関するユーザーの意見を聞き取る新ツールをリリースの画像
普及が進むにつれて、人工知能（AI）ツールはユーザーの実際のニーズに合わせてカスタマイズされるというより、互いのコピーのように感じられ始めてもいる。Anthropicは、ユーザーからのフィードバックを収集して、ユーザーがAI製品に本当に求めているものを把握するツールを開発した。

　米国時間12月4日にリリースされた新ツール「Anthropic Interviewer」は、「Claude」ベースのチャットボット体験を提供し、参加者と10～15分のリアルタイムのアダプティブインタビュー（適応型調査）を実施する。その後、人間の研究者がAnthropic Interviewerのトランスクリプト分析に協力し、人々が日常的なワークフローにAIツールをどのように取り入れているかについて理解を深める。

　Anthropic Interviewerのリリースに先立ち、Anthropicは1250人のプロフェッショナルを対象にテストを実施した。同社はこのテストから得られた知見を踏まえて、職場におけるAIの利用状況に関する初期調査結果をまとめたレポートを作成した。しかし、最終目標はAnthropic Interviewerの機能をテストすることだった。

　Anthropicは、Anthropic Interviewerの操作を計画、インタビュー、分析の3段階に分けてツールの仕組みを詳しく説明している。

　最初の計画段階では、多くのインタビューで共通の調査質問を提示するインタビューの枠組みを作成する一方で、インタビュアーごとの微妙な差異に対応する。テストでは、Anthropicがシステムプロンプトを作成し、それをAnthropic Interviewerに入力して、インタビュー方法を策定した。続いて、Anthropic Interviewerが具体的な質問と会話の流れを作成し、人間の研究者がそれを改良した。

　次の段階では、インタビューのベストプラクティスに関するシステムプロンプトに従って、Anthropic Interviewerが大規模なインタビューを実施した。最後に、研究者がClaudeと協力してトランスクリプトを分析し、浮かび上がってきたテーマを特定して、最終レポートを作成した。

　Anthropicは、これらの調査結果に基づき、Anthropic Interviewerの公開パイロット版をリリースした。この調査には誰もが参加でき、参加者の洞察は、社会への影響に関する同社の調査の一環として匿名で分析され、今後のレポートに掲載される。

この記事は海外Ziff Davis発の記事を4Xが日本向けに編集したものです。",[],[]
「テクノロジー史上最大の転換期」にシスコが描くAI時代の戦略とは（ZDNET Japan）,https://news.yahoo.co.jp/articles/6666bc0e3cef1c353b5347d8224038f7a5df5caf,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20251208-35241286-zdnet-000-1-view.jpg?exp=10800,2025-12-08T07:00:00+09:00,2025-12-08T07:00:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,3045,"Cisco SystemsのDave West氏
Cisco SystemsのグローバルスペシャリストでシニアバイスプレジデントであるDave West氏は、AIを中心としたデジタル技術の急速な進化と、それに伴う企業や社会の変容について「テクノロジー史上、これほど大規模なものはない」と述べ、現在を世界の仕組みを根本から変える転換期と位置付けた。

　同社は、この転換期に対応するため、「AI対応データセンター」「将来を見据えたワークプレース」「デジタルレジリエンス」の3つを柱とし、「One Portfolio戦略」を加速する方針を示している。

　Ciscoは、長年にわたりネットワーキング分野で強固な実績を築いてきたが、AI時代においては優れたネットワーキング企業であるだけでは不十分だという。今後はセキュリティ分野においても卓越した存在である必要があり、優れたセキュリティ企業となるためにはAIへの強みが求められる。さらに、AI企業であるためには、データ活用に優れた企業でなければならないと指摘する。

　West氏によると、Ciscoは現在、この変革の途上にある。同社はネットワーキングにセキュリティ、AI、そしてデータを融合させることで、顧客が期待するビジネス成果を提供できる企業を目指している。

　同氏は、AIの進化がビジネスの在り方を根本的に変革すると指摘する。「世界人口は約80億人だが、近い将来、地球上に800億人が存在するかのように感じるだろう」と述べ、人間だけでなく、AIエージェント、AIボット、AIアシスタント、ヒト型ロボットなどが加わることで、労働力は飛躍的に増えるという。

　一方で、現在のネットワーク環境は、急速に進化するAI時代の要件に対応できる設計になっていないという課題がある。Ciscoはこの状況を踏まえ、ネットワーキングの概念、サービスデリバリーの在り方、そしてデジタルレジリエンスの意味を再構築する必要があるとして、その取り組みを進めている。具体的には、ネットワーキングサービスやケイパビリティーを再設計し、デジタルレジリエンスを強化するとともに、AI時代に求められるサービスとインフラストラクチャーの刷新を進めている。

　特にSplunkの買収と統合によって、Ciscoはアプリケーションやセキュリティにとどまらず、ビジネスライン全体でインサイトと可視性を提供できるようになった。West氏は、ネットワークの力にセキュリティ、オブザーバビリティ、そしてコラボレーションを組み合わせることが、AI時代に顧客が期待する価値を真に提供する方法だと強調する。
Ciscoが現在注力しているのは、「AI対応データセンター」「将来を見据えたワークプレース」「デジタルレジリエンス」である。これらは、同社がAI時代における競争力を強化し、顧客に求められる価値を提供するための中核領域と位置付けられている。

　1番目の柱は「AI対応データセンター」である。CiscoはNVIDIAやAMDと提携し、顧客のAI移行を支援している。CPUとGPUを組み合わせたコンピューティングに加え、オープンスタンダードに基づく次世代スイッチングを採用し、さらにVAST Data、Pure Storage、Hitachi Vantara、NetAppといったストレージベンダーと協業することで、次世代AIインフラの構築を進めている。

　このフルスタック戦略では、セキュリティの統合が不可欠になるとWest氏は指摘する。AIの展開にはデータ保護とガードレールが必要であり、同社は「AI Defense」ソリューションを開発した。Splunkの技術を取り込み、フルスタック全体でオブザーバビリティを提供し、セキュアなAI基盤を実現している。

　特徴的なのは、自社製シリコンと400G/800Gに対応する独自の光通信技術（オプティクス）を採用している点である。これにより、AIスタックのオーケストレーションにおいて高度な制御が可能になるとのこと。また、NVIDIAとの連携を強化し、Ciscoのネットワーキング、セキュリティ、オブザーバビリティのソリューションと、NVIDIAのAIコンピューティングプラットフォームを組み合わせた「Cisco Secure AI Factory with NVIDIA」を提供する。

　さらに、NVIDIAの「SpectrumX」をCiscoの「Silicon One」と並べてスイッチに組み込み、両社のフルケイパビリティーを顧客に提供する計画だ。こうした統合により、セキュリティ、コンピューティング、スイッチング、ストレージ、ソフトウェアが一体化し、企業はAIに必要な要素を容易に展開できるようになるとしている。

　2番目の柱は「将来を見据えたワークプレース」である。Ciscoは働き方を再設計し、オフィス、自宅、製造現場、カフェなど、あらゆる場所をワークプレースとして再定義している。

　同社は、どこからでも安全に接続でき、シームレスな体験を提供するため、セキュアな接続性と適切なコラボレーションツールの整備を進める。ユーザーを識別し、安全なアクセスを確保しつつ、帯域幅や接続状況に応じてエクスペリエンスを最適化することが重要となる。

　例えば、オフィスでは自動認識による利便性を提供し、Wi-Fi 7やスマートビルディング技術を活用して持続可能性と接続性を強化する。これにより、コラボレーションツールを含む包括的なサポートを実現する。

　さらに、リモートワーカーとオフィスワーカーの管理などにはAIツールや生成AIを活用する。問題の把握、予測、防止を行い、サービス管理を効率化することで、場所を問わず優れたワークプレース体験を提供する。AIによる可視性と自動化を通じ、こうした取り組みは大規模に進められている。

　3番目の柱は「デジタルレジリエンス」であり、ここでSplunkが重要な役割を担う。企業や市場、業界は、自社のビジネスにレジリエンス（回復力）を組み込みたいと考えている。そのためには、全体の可視性を確保し、何が起きているのかを把握し、ビジネス全体のシステムを活用して潜在的な異常やレジリエンスを阻害する要因を特定することが求められる。

　West氏によると、Splunkはビジネスライン全体を横断的に分析し、「正常な状態」を定義して潜在的な異常を特定する能力に優れている。さらに、ビジネスのレジリエンスを確保するため、より深いフォレンジックが必要な領域を明確にできるという。

　次世代のAIデータセンターや将来のワークプレースへ投資する顧客は、エンタープライズ全体でのレジリエンスを求めている。このため、顧客はあらゆる投資において、インサイト、可視性、オブザーバビリティ、そしてアシュアランス（保証）を重視する傾向にある。Splunkはまさにそれを提供する、とWest氏は強調した。

　「Ciscoは、市場を定義するテクノロジーとプラットフォームベースのケイパビリティーに加え、AI、シリコン、オプティクスを提供している。われわれはAIツールと生成AIの機能を、人間の強みとエンジニアリングの専門知識と組み合わせることで、ネットワーク上のどこで働いていても素晴らしい顧客体験を提供している」（同氏）",[],[]
