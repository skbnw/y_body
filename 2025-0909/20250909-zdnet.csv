headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
レノボ、AI・CAD・映像編集に最適な「ThinkPad」ワークステーションを強化（ZDNET Japan）,https://news.yahoo.co.jp/articles/34772b0aa3be3bc690b4c2ae50d6465bc1598306,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250909-35237761-zdnet-000-1-view.jpg?exp=10800,2025-09-09T14:46:00+09:00,2025-09-09T14:46:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,1051,"レノボ、AI・CAD・映像編集に最適な「ThinkPad」ワークステーションを強化の画像
レノボ・ジャパンは9月9日、モバイルワークステーション「ThinkPad P14s Gen 6」（税込価格：29万8100円～）、「ThinkPad P16s Gen 4」（同：30万9100円～）、「ThinkPad P16v Gen 3」（同：46万4200円～）、「ThinkPad P16 Gen 3」（同：61万6000円～）を発表し、同日より販売を開始した。

　いずれも、「Intel  Core Ultra シリーズ2 Hプロセッサー」と「NVIDIA RTX  PRO Blackwell GPU」の搭載を選択することが可能。AI処理、CAD設計、シミュレーション、映像編集などの業務に最適としている。

　ThinkPad P14s Gen 6は、14.5型のディスプレーを採用し、最大96GBメモリーと最大2TB SSDを搭載可能なモバイルワークステーション。軽量・コンパクトながらCADや解析用途にも対応する性能を備える。

　ThinkPad P16s Gen 4は、16型ディスプレーとテンキーを搭載。入力業務やマルチタスクに最適としている。

　ThinkPad P16v Gen 3は、「Intel Core Ultra シリーズ2 7/9 Hプロセッサー」と「NVIDIA RTX PRO 2000 Blackwell Laptop GPU」を搭載可能で、最大96GBメモリーと最大4TB SSDに対応。コストと処理性能のバランスを確保したモデルになる。

　ThinkPad P16 Gen 3は、「Intel Xeon」または「Core Ultra HXシリーズプロセッサー」、「NVIDIA RTX 5000 Ada世代GPU」を搭載でき、最大192GBメモリーと最大8TB SSDに対応。大規模シミュレーションや映像制作など、高い処理能力が要求される業務に対応するプロ向けモデルになる。

　あわせて、今回の4モデルに対応する「ThinkPad Thunderbolt 5 スマートドック 7500」（同：7万1500円）も発表した。最大120Gbpsのデータ転送と180W Power Delivery 3.1に対応したドッキングステーションで、ワークステーション本体と組み合わせることで、複数の高解像度ディスプレーや周辺機器を同時接続しながら安定した稼働を実現する。",[],[]
NEC、AI強化の新「LAVIE」3シリーズを発表--NPU搭載でCopilot+ PC対応も（ZDNET Japan）,https://news.yahoo.co.jp/articles/6f0ad1e74857a14eaa44c2397265c95fb0d840a0,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250909-35237753-zdnet-000-2-view.jpg?exp=10800,2025-09-09T13:23:00+09:00,2025-09-09T18:05:01+09:00,ZDNET Japan,zdnet,ZDNET Japan,1057,"NEC、AI強化の新「LAVIE」3シリーズを発表--NPU搭載でCopilot+ PC対応もの画像
NECパーソナルコンピュータは9月9日、独自のAIソリューションを搭載したノートPC「LAVIE Direct NEXTREME」（税込価格：24万9000円～）、「LAVIE Direct N14 Slim」（同：17万4000円～）とデスクトップPC「LAVIE Direct DT」（同：17万4000円～）の3シリーズを発表した。NPU搭載でAI機能を強化している。同日から販売を開始している。

　3シリーズ共通で、独自のAIソリューションを備え、AIが利用状況に応じて画面輝度やバックグラウンド処理、通知などを調整する「ロングバッテリーモード」を搭載。通常時は充電を80％に制限し、持ち運び前には自動でフル充電に切り替える「スマート充電」機能を備え、バッテリーの利便性を高めている。

　また、AIチャットで困りごとを解決し、使い方のヒントを提案する「LAVIE AI Plus/Hint」を搭載。ユーザーの利用状況に応じて、約40種類のヒントを表示し、PCの活用方法をサポートする。

　LAVIE Direct NEXTREMEは、約994gの軽量ボディーに最大約40.2時間のバッテリー駆動（アイドル時）を実現。「Intel Core Ultraシリーズ2」を備え、Copilot+ PCに対応する。13.3型WUXGAタッチパネルディスプレーを装備する。

　LAVIE Direct N14 Slimは、「AMD Ryzen 8040 シリーズ」プロセッサー（NPU 最大16TOPS）を搭載したAI PC。背景ぼかし機能、アイコンタクト機能、自動フレーミングなど、「Windows Studio Effects」の一部機能に対応する。

　14.0型WUXGAのタッチパネルを搭載しながら、約1117gの軽量ボディーを実現。約19.4時間（アイドル時）のバッテリー駆動時間を確保している。
　本体にはUSB合計4ポート搭載と豊富なインターフェースを備え、MIL規格にも準拠。バッテリー交換にも対応可能だ。

　個人向けデスクトップPCでNPUを搭載したLAVIE Direct DTはIntel Core Ultraシリーズ2を搭載。幅89mmのスリム筐体を採用し、最大6画面の出力に対応する。USBは合計9ポート備え、Wi-Fi7の選択も可能。高速スクロールに対応するマウスも付属する。",[],[]
Deel、日本法人の社長執行役員に西浦亮氏を任命--事業成長をさらに加速へ（ZDNET Japan）,https://news.yahoo.co.jp/articles/ed26088833c28cf69c40115b8166b8fa0d901e3e,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250909-35237751-zdnet-000-1-view.jpg?exp=10800,2025-09-09T12:58:00+09:00,2025-09-09T12:58:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,895,"Deel Japan 社長執行役員・ カントリーマネージャーの西浦亮氏
オールインワン型の給与・人事プラットフォームを提供するDeelは9月9日、日本法人の社長執行役員 兼 カントリーマネージャーに西浦亮氏を任命したと発表した。西浦氏の指揮の下、同社は日本市場でのさらなる事業拡大を目指す。

　Deelに参画する以前、西浦氏はZoom Japanや日本航空、アメリカン・エキスプレス、エクスペディア・グループ、Tink Labs、Uber Eatsなどで要職を歴任してきた。Deelでは、日本市場におけるGo-To-Market戦略を主導し、事業成長をけん引している。

　今回の人事について、西浦氏は「日本の素晴らしい企業が、グローバルに活躍できるようご支援できることを大変光栄に思う」とコメントしている。また、「Deelのプラットフォームは、これまで煩雑だった国際雇用や給与計算のハードルを劇的に下げ、企業がもっとも重要な『成長』に集中できる環境を提供する。これまでの経験を生かし、チーム一丸となって日本企業のグローバルな挑戦を力強くサポートしていく」とも述べている。

　なお、同社の日本市場における収益は、2024年6月から2025年6月までの期間で前年同期比145％の成長を記録した。今回の就任発表は、この記録的な事業拡大を受けてのものだとしている。

　Deelのプラットフォームは、給与計算、人事情報システム（HRIS）、コンプライアンス、福利厚生、パフォーマンス管理、IT備品管理といった機能を統合している。具体的には、海外法人設立やビザ取得の支援、EOR（記録上の雇用主）としての雇用代行、従業員や業務委託契約者のオンボーディング、日々のグローバルな給与計算やIT機器の管理に至るまで、国際的な事業展開の幅広い段階を包括的にサポートしている。

　また、Deelはオンボーディング、給与計算、HRIS、カスタマーエクスペリエンスの各領域にAIを活用した新機能を大規模に導入している。これにより、日常業務の簡略化ややり取りの削減、スケール戦略の最適化を支援しているという。",[],[]
YKK AP、顧客・配送データを「Salesforce」に集約し、物流の最適化へ（ZDNET Japan）,https://news.yahoo.co.jp/articles/66396be1a9d30f3793db518b4b29d2945b3aa8a8,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250909-35237745-zdnet-000-1-view.jpg?exp=10800,2025-09-09T12:21:00+09:00,2025-09-09T12:21:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,672,"YKK AP、顧客・配送データを「Salesforce」に集約し、物流の最適化への画像
YKK APは、物流の最適化とコストダウンに向けた、物流に関するデータを「Salesforce」に一元化するデータ基盤を構築した。顧客データや配送データを集約することで、情報を標準化し、物流の最適化を目指す。データ基盤構築を支援したSharing Innovationsが9月9日に発表した。

　YKK APのロジスティクス部は、物流領域における本社機能を担い、物流のデジタルトランスフォーメーション（DX）を進めることでコストダウンを目指している。

　住居の窓やドアから、カーポートやテラス、フェンスなどのエクステリア、そしてビルなどの非住居分野にも建築用工業製品（建材）を製造販売するYKK APでは、取り扱う商品サイズが大きく、コストを抑えた物流を実現するには、倉庫内のピッキング作業から、納品に至るさまざまな最適化が必要で、それを実現するには、現状把握のほか、顧客情報や在庫情報、そしてパートナーである輸送業者に関する物流情報の整備が求められていた。

　今回、最初のステップとしてそれまで各拠点で「Excel」やPDFで管理していた顧客データや輸送業者の情報をSalesforceへ集約。物流拠点の全員が、リアルタイムに同じデータを閲覧できるようになり情報の一元化を実現したという。

　加えて、ロジスティクスによる品質管理情報の共有ができるようになったことで、改善に向けた意思決定をするためのデータをタイムリーに得られるようになったという。",[],[]
Gartner、ソブリンAIとAIエージェントが公共機関のAI導入を牽引すると予測（ZDNET Japan）,https://news.yahoo.co.jp/articles/ff5a8160e8ced083e488ad43f09cbdedd8d92aee,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250909-35237742-zdnet-000-1-view.jpg?exp=10800,2025-09-09T11:24:00+09:00,2025-09-09T11:24:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,1433,"Gartner、ソブリンAIとAIエージェントが公共機関のAI導入を牽引すると予測の画像
調査会社のGartnerは9月9日、今後2〜5年以内に、ソブリンAIとAIエージェントが公共機関におけるAI導入をけん引するとの見解を発表した。両技術は「2025年 行政サービスのハイプ・サイクル」で「過度な期待」のピーク期に位置付けられている。

　Gartnerのハイプ・サイクルは、テクノロジーやアプリケーションの成熟度と普及率のほか、それらが実際のビジネス問題の解決や新たな機会の活用にどのように関連するかを図示したもの。時間の経過とともにテクノロジーがどのように進化するかを視覚的に示すことで、特定のビジネス目標に沿った採用判断に役立つインサイトを提供する。

　バイス プレジデント アナリストのDean Lacheca（ディーン・ラチェカ）氏は、「公共セクターのリーダーは、高まる市民の期待に応え、地政学的な不確実性をかじ取りし、より少ないリソースでより多くの成果を挙げなければならないというプレッシャーに直面している。AIエージェントを活用すれば、こうした課題に対処できるが、それを成功させるには、『イノベーション目標』と『政府機関の広範な優先課題』のギャップを埋め、投資がサービス／信頼／レジリエンスの強化につながるようにする必要がある」とコメントしている。

　政府機関にとって高いポテンシャルを持つとGartnerが特定したイノベーションのうち、生成AIの応答品質を高めるための入力設計技術「プロンプトエンジニアリング」は今後2～5年以内に、そして、コンピューター同士が商取引を行う「マシンカスタマー」は5～10年以内に主流の採用に達すると見込まれている。

　ソブリンAIとは、国家が主権を維持するために、自国のAI開発とAI活用に投資し、それらを進展させる取り組み。行政の自動化、業務効率化、市民との関係強化に貢献する。Gartnerでは、2028年までに、世界の政府機関の65％が独立性を高めて他国による規制干渉から守るために、テクノロジー主権に関する何らかの要件を導入するようになると予測。ソブリンAIは、AIの価値を最大限に高めつつ、関連するリスクの軽減を目指す。

　AIエージェントは、自律的に判断・行動するAIソフトウェア。政策の申請、法令解釈、定型業務の自動化などに活用できる。Gartnerでは、2029年までに政府機関の60％が市民とのやりとりの半分以上をAIエージェントで自動化すると予測している。

　ディスティングイッシュト バイス プレジデント アドバイザリの松本良之氏は、日本向けに「日本においても、自治体や中央省庁の現場では、限られた予算や人員の中で多様化・高度化する市民ニーズに応えるとともに、業務の効率化と信頼性を両立することが求められている。こうした状況下で注目されるのが、国家や組織が自らの主権を維持するために、外部に依存せず自国・自組織内でAIシステムを運用・管理する枠組みを指すソブリンAI。セキュリティや規制対応、データ主権といった観点から、公共機関にとって戦略的なテクノロジーの選択肢となり得る。Gartnerでは、日本の公共機関がこのようなテクノロジーを導入・活用する際には、現場のニーズと制度的要請を両立させる『現場主導×戦略志向』のアプローチが今後ますます重要になると見ている」とコメントしている。",[],[]
設立5周年を迎えたOkta Japan、リージョナルCSO任命など独自の取り組みを推進（ZDNET Japan）,https://news.yahoo.co.jp/articles/bb8d91975d23ac46ccf1901f90aad381d495ba41,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250909-35237732-zdnet-000-3-view.jpg?exp=10800,2025-09-09T11:18:00+09:00,2025-09-09T20:27:14+09:00,ZDNET Japan,zdnet,ZDNET Japan,1976,"Okta Japan 代表取締役社長の渡邉崇氏
Okta Japanは、設立5周年を迎えたタイミングで報道機関向けの説明会を開催し、これまでの歩みを振り返った。

　冒頭で流された同社の創業者で最高経営責任者（CEO）のTodd McKinnon（トッド・マッキノン）氏によるビデオメッセージでは、アプリケーション統合基盤「Okta Integration Network」（OIN）でSansan、SmartHR、サイボウズなど日本発のSaaSプロバイダーをサポートしたことや、製品の日本語化にも注力してきた結果、現在では130社以上のパートナー企業と共に日本国内でのビジネス展開を行うに至っているとした上で、Okta JapanのリージョナルCSO（最高セキュリティ責任者）に板倉景子氏を任命したことにも触れた。さらに同氏は急速に進化するAI時代において日本市場の重要性はさらに高まると指摘し、今後も日本市場に注力していくと語った。

　続いて、2020年に日本の第1号社員として入社以来国内事業をリードしているOkta Japan 代表取締役社長の渡邉崇氏が5年間の歩みを振り返った。米Oktaは2009年の創業で、日本法人設立の2020年まで11年ほどたっているが、これは最近のIT企業の日本進出ペースと比べるとかなり遅い。

　この点に関して同氏は「アイデンティティー管理に対する認知が日本市場は米国に比べて3～5年くらい遅れていて、今でもまだその遅れが残っている」との認識を示した。

　一方で、創業時はコロナ禍の真っただ中でもあり、多数のユーザー企業がリモートワークに取り組むなど、同社のソリューションに注目が集まるタイミングでもあった。同氏は「2020年から2025年の5年で、売り上げベースで20倍のビジネスに成長した」という数字を紹介したが、2020年の日本法人創業時点で米本社と代理店契約を締結したパートナー企業が数社存在し、2年ほど販売していた実績があったため、ゼロベースではなく既にある程度の販売実績があったところからスタートして20倍ということで、「日本法人設立当時に米本社と作った日本法人のビジネスプランを上回るペースで、前倒しでどんどん事業成長している」という。

　この間の大きな出来事としてまず挙げられるのは、2021年のAuth0買収（日本法人統合は2022年）だ。エンタープライズ市場中心のOktaと顧客IDとアクセス管理（CIAM）市場向けの「Auth0」は、アイデンティティー管理という基盤技術のところは共通するものの、市場が異なるということで、もともと創業者同士の仲も良かったということでこのタイミングでの統合に至ったという。

　続いて、2023年に発生したセキュリティインシデントによる大規模な情報漏えいも大きな出来事だった。この対応として同社は「Mckinnonが『全ての製品開発を3カ月止める』ということで、四半期丸々製品開発を止めてセキュリティ強化に注力するという取り組みを行った」と話す。

　グローバルでセキュリティ強化に取り組む中で、日本市場特有の学びもあったと渡邉氏は振り返った。「Oktaのセキュリティチームは、アメリカ、EMEA、APACなど各リージョンごとに専門家がおり、何かインシデントが発生した際に問い合わせが来てもセキュリティチーム以外が直接回答することが社内的に禁止されていた。このことはセキュリティの正確な情報を出す上では有効だったが、日本のお客さまに情報を出すのに時間がかかってしまうというマイナス面もあった」という。

　この対策として、渡邉氏がCEOのMckinnon氏に直接掛け合って実現したのが、従来は地域ごとに置かれていたCSOをグローバルに先駆けて国別としては日本が世界で初めて採用するという取り組みだ。この結果、一般の社員ではアクセスできないセキュリティ関連の専門情報にいち早くアクセスできるようになり、日本市場向けの説明が迅速に行えるようになるという改善が図られた。

　また、米国では直販中心だが、日本ではパートナーモデルが中心となるという違いもあるため、米国ではユーザー企業の担当者向けに説明を行うことになる一方、日本ではパートナー向けの情報提供が極めて重要になる。こうした違いを吸収して適切に対応していくためにも、国内にセキュリティ担当者を置いたことが役立っているという。

　これらの経験を踏まえ、次の5年間に向けた取り組みとして同氏は「AI時代のアイデンティティーセキュリティのけん引役へ」「強固なパートナーエコシステムを基盤に、日本のDXを力強く加速」「APJをけん引する組織へ進化し、非英語圏の成功モデルの確立を目指す」という3点を挙げた。",[],[]
マイクロソフト、「エクスプローラー」から直接利用できる「Copilot」の新機能を発表（ZDNET Japan）,https://news.yahoo.co.jp/articles/31dbad37d328094986f22acf506ab2482a5d5ca4,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250909-35237729-zdnet-000-2-view.jpg?exp=10800,2025-09-09T09:33:00+09:00,2025-09-09T09:49:01+09:00,ZDNET Japan,zdnet,ZDNET Japan,1368,"マイクロソフト、「エクスプローラー」から直接利用できる「Copilot」の新機能を発表の画像
「Microsoft 365」のユーザーであれば、かなり前からウェブ上で「Copilot」を使って文書やファイルを分析したり、質問して回答を得たりすることができた。だがこれからは、「Windows」上で直接Microsoftの人工知能（AI）に支援してもらえるようになる。

　Microsoftは米国時間9月4日、「エクスプローラー」から直接利用できるCopilotの新機能を4つ発表した。ユーザーは、「OneDrive」に保存された対応ファイルを右クリックするだけで、Copilotに要約を依頼したり、質問して回答を得たり、FAQを作成したりできる。また、最大5つのファイルを選択して、全てのファイルを比較するようCopilotに指示することも可能だ。

　この新機能を利用するには、「Microsoft 365 Family」プランか「Microsoft 365 Personal」プランに加入している必要がある。また、分析したいファイルがOneDriveに保存され、エクスプローラーに表示されていなければならない。さらに、現時点では特定のファイルフォーマットのみが対象となる。具体的には、Microsoft 365文書（DOC、DOCX、PPT、PPTX、XLSX、FLUID、LOOP）、汎用フォーマット（PDF、TXT、RTF）、ウェブファイル（HTM、HTML）、および「OpenDocument」フォーマット（ODT、ODP）だ。残念ながら、写真や動画はまだサポートされていない。

　この機能を試すには、「Windows 10」または「Windows 11」でエクスプローラーを開き、Copilotで分析したい対応ファイルを右クリックすればいい。Windows 10では、新しいCopilotコマンドがメニューに直接表示される。Windows 11では、OneDriveオプションにカーソルを合わせると新しいコマンドが表示される。ここから、以下のオプションを選択できる。

「Summarize」（要約する）：これを選択すると、Copilotがファイルの内容を簡潔にまとめた要約を生成する。
「Create an FAQ」（FAQを作成する）：Copilotがファイルに関連したよくある質問（FAQ）をリストにまとめる。
「Ask a question」（質問する）：この機能を使えば、ファイルに関して具体的な質問を投げかけることができる。
「Compare files」（ファイルを比較する）：この機能では、まず2〜5個のファイルを選択する必要がある。すると、Copilotがファイル間の違いをまとめた表を生成する。

　筆者が4つの機能をそれぞれ試したところ、Copilotは期待通りの働きをしてくれた。唯一の欠点は、分析がローカルではなく、ウェブ上のOneDriveを介してオンラインで行われることだ。その点を除けば、どの機能もスムーズに動作した。また、Windowsを離れることなく起動できるため、時間の節約にもなる。

この記事は海外Ziff Davis発の記事を朝日インタラクティブが日本向けに編集したものです。",[],[]
L・トーバルズ氏、うんざりするほど増えた「ゴミリンク」に激怒--開発者を悩ませる問題とは（ZDNET Japan）,https://news.yahoo.co.jp/articles/235e61ab800c6fccbd9fc19e3590bd6b59161f34,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250909-35237723-zdnet-000-2-view.jpg?exp=10800,2025-09-09T08:13:00+09:00,2025-09-09T10:27:48+09:00,ZDNET Japan,zdnet,ZDNET Japan,1688,"提供：Maximusnd/iStock/Getty Images Plus via Getty Images
Linuxカーネルのリソースノードのリライトに対する、たった1つの修正がことの発端だった。Linus Torvalds氏は、その修正を見れば見るほど当惑していった。なぜなら、その修正は「実際には何も修正していなかった」からだ。

　同氏は「この無意味なコミットの理由を説明してくれることを期待して、『Link:』引数を確認した。しかし、いつものように、そのリンクはすでに存在するくだらない情報を指し示しているだけで、ただ時間を無駄にした」という。

　その後、Torvalds氏は「もうこのゴミはやめろ」と語り、Linux Kernel Mailing List（LKML）での議論において、当惑から瞬く間に怒りへと変わった。同氏はさらにこう続ける。「私の最初の反応が間違っている理由を説明してくれるような、何か不具合報告などを指し示していることを期待していた」が、結局は期待外れに終わった。

　Torvalds氏は「人の時間を無駄にする無意味なLink引数を追加するのはやめてくれ。“追加”の情報がある場合にのみリンクを追加してほしい」と宣言した。また、「この無意味なリンクは本当に嫌いだ。“役に立つ”リンクは大好きだが、実際に見るリンクの99％は、ただの愚かで役に立たないゴミを指しているだけで、私の時間をただただ無駄にしている。今回もだ！」といら立ちをあらわにした。

　要するに、同氏は「もし私にプルすることを本当に期待しているなら、役に立たないリンクではなく、ちゃんとした説明が欲しい」と語っている。さらに、「そうだ、私は機嫌が悪い。私の主な仕事、いや、本当に唯一の仕事はプルリクエストを理解することだと感じており、だからこそ、自動的に追加され、私の仕事をより困難にするだけのこうしたものが、心底嫌いなのだ」と心情を吐露した。

　他の人々もTorvalds氏の意見に同意している。あるRedditの投稿者は、「Linusの言うことは一理ある。あの元のパッチはAIが書いた要約のように見えたし、問題の説明へのリンクも同じ要約だった」と述べている。

AIプログラミングと経験不足が引き起こす問題

　では、なぜこのような無意味なリンクが繰り返される問題となっているのか。それはAIプログラミングの台頭に伴い、多くのコントリビューターが「GitHub」や「GitLab」などの自動化されたスクリプトやボット、プラットフォームのインテグレーション機能を使用しているためだ。これらのツールは、イシュー、マージリクエスト、パッチの提出などを相互参照するために、自動的にハイパーリンクを生成する。一見、これは良いことのように思える。

　しかし、これらのシステムは、パッチを理解するのに役立つ追加情報や議論の履歴、バグトラッカーのコンテキストなどを提供することなく、パッチのメールや一般的なページにリンクを戻すことが頻繁にある。言い換えれば、彼らはメンテナーの時間を無駄にしているのだ。Torvalds氏だけでなく、ほとんど全てのメンテナーは、余計な手間をかけずとも十分にやるべき仕事がある。

　この問題は、こうしたツールだけが引き起こしているわけではない。経験の浅い、あるいは急いでいる開発者たちが、関連性に関係なく、リンクの使用を推奨または要求する所定のワークフローやテンプレートに従っていることも原因である。ベストプラクティスに対する監督や強制がほとんどないため、多くのリンクが純粋に習慣や規則のためだけに追加され、無意味な参照の拡散につながっている。

　Torvalds氏を喜ばせたいのであれば、やるべきことは非常に単純だ。同氏が求めたことをただ実行すればよい。すなわち、「この自動化された愚行を、どうかやめることはできないだろうか？」ということである。

この記事は海外Ziff Davis発の記事を朝日インタラクティブが日本向けに編集したものです。",[],[]
OpenAI、2026年に自社製AIチップを量産と報道--ブロードコムと100億ドル規模の提携か（ZDNET Japan）,https://news.yahoo.co.jp/articles/8de4315ffe2a7576892b9a090cbafa5af9b0a57b,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250909-35237722-zdnet-000-1-view.jpg?exp=10800,2025-09-09T07:38:00+09:00,2025-09-09T07:38:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,1492,"提供：XH4D/iStock/Getty Images Plus via Getty Images
OpenAIは、外部の半導体企業への依存から脱却するため、業界全体の流れに沿って自社製AIチップの開発に乗り出している。

　同社は、米国半導体メーカーのBroadcomと提携し、2026年に自社製GPUの量産を開始する予定だという。Financial Timesが米国時間9月4日に報じた。このチップは販売目的ではなく、OpenAI社内での使用を前提としているという。

　この報道は、Broadcomの最高経営責任者（CEO）であるHock Tan氏が4日に投資家向けに発表した声明の直後に出されたものだ。同社が新規顧客との間で100億ドル規模のAIチップ製造契約を締結したと述べており、多くのアナリストがその新規顧客はOpenAIであると推測していた。その後、Wall Street Journalの報道がこの推測を裏付ける形となった。

　米ZDNETはOpenAIとBroadcomにコメントを求めたが、すぐには回答を得られていない。

　もともとGPUは、ビデオゲームのグラフィックス描画のために開発されたが、現在では生成AIブームの技術的基盤となっており、「ChatGPT」「Gemini」「Claude」といったチャットボットの動力源として活用されている。これまでの市場はNVIDIAが圧倒的に支配しており、同社は「A100」や「H100」といった業界をリードするチップの需要急増により、現在では世界でもっとも価値のある企業とされている。

　Advanced Micro Devices（AMD）やBroadcomなどの他のチップメーカーも急成長を遂げている。Broadcomは2025年12月に時価総額1兆ドルを突破しており、Google、Meta、ByteDanceとの提携のうわさも浮上している。

　AI市場が少数のチップメーカーによって支配されているため、技術開発企業は新しいチップの注文から納品までに数カ月待たされる状況が続いている。こうした供給の逼迫（ひっぱく）は、価格の高騰にもつながっている。

　このような背景から、Microsoft、Amazon、Metaなどの主要なAI企業は、NVIDIAやその他の外部製チップへの依存を減らすべく、自社でのチップ製造に乗り出している。最近では、Trumo米政権がNVIDIAによる中国への一部チップの販売を再び許可した。これは、Biden政権下で競争を抑制する目的で導入された禁止措置が緩和されたことによるものだ。

　OpenAI CEOのSam Altman氏は、同社が独自チップを開発する必要性について以前から強く主張していたが、その構想が具体的にどう実現されるかはこれまで明らかにされていなかった。これまで同社はNVIDIAやAMDに依存していたが、Reutersは2024年、OpenAIがBroadcomおよび台湾積体電路製造（TSMC）と協力してAIチップの開発を進めていると報じている。2025年3月には、TSMCが米国でのチップ製造に1億ドルを投資することを発表した。

　AIチップの自社調達を目指す業界全体の動きは、同時に進行している巨大なデータセンターの建設ラッシュによってさらに加速している。これらのデータセンターはAIシステムの稼働に不可欠であり、膨大な量の水と電力を必要とする。

この記事は海外Ziff Davis発の記事を朝日インタラクティブが日本向けに編集したものです。",[],[]
IBMの研究最前線に迫る--量子、AI、古典コンピューティングの融合が描く未来（ZDNET Japan）,https://news.yahoo.co.jp/articles/aac83b8bc47d77e2e359d9f1abeabd69c5a4e83d,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250909-35236695-zdnet-000-3-view.jpg?exp=10800,2025-09-09T07:00:00+09:00,2025-09-09T14:22:31+09:00,ZDNET Japan,zdnet,ZDNET Japan,3066,"IBMの研究最前線に迫る--量子、AI、古典コンピューティングの融合が描く未来の画像
米国ニューヨークにある「IBM Research」は、IBMの研究開発部門における中核拠点だ。1961年の設立以来、世界最大級の民間研究機関の1つとして、AIと自然言語処理、半導体やチップ設計など、数多くの研究を手掛けており、現在では量子コンピューティングの研究開発拠点にもなっている。

Think Lab＆Quantum Characterization Laboratoryが担う革新の現場

　施設内には「Think Lab」や「Quantum Characterization Laboratory（IBM量子特性評価ラボ）」といった、最新の研究施設を擁し、未来のコンピューティング基盤を開発。 IBM Think Lab プログラムディレクターのGeorge Tulevski氏は「1961年に完成したIBM Researchの興味深い点は、単なるオフィスではなく、実際に稼働している研究室であること。敷地内の約半分はクリーンルームや液体や試薬を用いるウェットラボ、物理量の測定などを行うメトロジーラボが占めている」と説明する。

　Tulevski氏が担当するThink Labは、2023年に設立。実際に研究開発を行う実験室としての役割を果たすほか、クライアントや協力者を招き、ビジョンを共有するコラボレーションスペースとしても機能している。

3つのコンピューティング技術「ビット（古典）＋ニューロン（AI）＋キュービット（量子）」

　同施設が扱うコンピューティング技術は、（1）高精度・高速計算を担う古典的コンピューティング、（2）大規模言語モデル（LLM）の学習に代表されるAIコンピューティング、（3）前者2つとは全く異なる原理に基づく量子コンピューティング――の大きく3つに分けられる。

　「『ビット（古典）＋ニューロン（AI）＋キュービット（量子）』と表現し、これらの技術をハイブリッドな環境で活用することを目指している。その実現のためには、3つの異なる技術をユーザーが意識することなく利用できる環境が必要だ」とTulevski氏は語る。その役割を担うのが、コンテナープラットフォーム「OpenShift」だ。これにより、ユーザーは各技術の特性を超えて、最適な環境を構築できる。

　古典コンピューティングについては、「性能を支えているのは半導体技術。IBMでは、ニューヨーク州オールバニの研究施設で2nmの半導体を開発しており、これは日本の半導体メーカーであるラピダスと協業している」（Tulevski氏）

　この技術を基に「GAA（ゲートオールアラウンド）トランジスタ」と呼ばれる新しいタイプのトランジスタの開発に取り組んでいるとのこと。GAAトランジスタは電流の制御性に優れており、トランジスタの微細化と低消費電力化に寄与する。今後はさらに高密度化を目指した「スタックドトランジスタ」（垂直FET）の研究も進めるという。

　一方、AIコンピューティングについては、AIアクセラレーターの開発に力を入れる。主に取り組んでいるのは、（1）推論に特化し、GPUよりも大幅に低い75W以下の消費電力で動作する「Spyre」、（2）メモリーとロジックを同一チップ上に配置する独自のアーキテクチャーを採用し、低消費電力に優れる「NorthPole」、（3）アナログAIチップ――の3つ。

　中でも、アナログAIチップは、「より深い領域にある技術。フィールド効果トランジスタ（FET）の代わりに相変化メモリーを使用し、ニューラルネットワークをデバイスに直接コード化する。これは、デジタルAIチップが0と1で処理するのとは異なり、電圧や電流の連続的な変化を利用して処理するもの。このハイリスク・ハイリターンなプロジェクトが成功すれば、デジタル技術よりも約50倍の効率化が期待できる」（Tulevski氏）と説く。

　現在は、IBM Research内で小型のウェハーを製造している段階であり、「エコシステムがまだ確立されておらず、研究開発にはまだ時間がかかる」（Tulevski氏）と研究段階にあることを明かした。
量子コンピューター最新モデルが日本上陸

　量子コンピューターでは、最新の「IBM Quantum System Two」を披露した。これは3つの量子プロセッシングユニット（QPU）を搭載し、制御用電子回路と通信することで量子回路や量子ワークロードを実行する。システムの内部は、絶対零度近くまで冷却して稼働させる必要がある。

　IBM Quantum System Twoは、日本の理化学研究所（理研）に導入されており、また神奈川県川崎市にある「新川崎・創造のもり かわさき新産業創造センター」では「IBM Quantum System One」が稼働している。「日本では、この2つの量子コンピューターが存在している。IBMは、これらの技術を組み合わせ、ハイブリッドなコンピューティング環境を通じてビジネスの課題解決に貢献していく」とTulevski氏は結んだ。

量子プロセッサーの性能評価と品質保証を担う「IBM量子特性評価ラボ」

　「IBM Quantum Characterization Laboratory（IBM量子特性評価ラボ）」は、量子プロセッサーの性能評価と品質保証を担う最先端のラボだ。

　IBMが設計・製造した全ての量子チップは、この場所でテストと評価がされている。代表的な量子プロセッサーである「Eagle」や「Heron」もその対象になる。

　IBM Quantum Research ScientistのDaniela Bogorin氏は、「性能評価だけでなく、急速に進化する量子プロセッサーの性能を検証し、その結果を設計・製造チームにフィードバックすることで、今後の開発につなげる役割も担っている」と説明する。

　量子コンピューターは、量子ビット、ゲート、回路などの要素から構成されるが、その中でも特に重要なのが冷却システム部とマイクロ波制御部だ。冷却システムは、その見た目から「シャンデリア」と呼ばれており、内部は10～150mK（ミリケルビン）に保たれている。

　Bogorin氏は「宇宙空間よりもはるかに低い温度だ。プロセッサーが超伝導材料でできているため、ノイズを最小限に抑えるには冷却が不可欠だ」と話す。

　IBMの量子プロセッサーは、「Falcon」「Hummingbird」「Eagle」と、鳥の名前が付けられている。Falconは27キュービットだったのに対し、Eagleでは127キュービットへと増加した。最新モデルは、従来モデルから性能が約10倍向上するなど、急速に進化している。この性能向上には、「ZZカップリング」と呼ばれるノイズ低減技術が貢献しており、2つキュービットが協働していない場合のノイズを効果的に減らせる。

　テストの評価基準についてBogorin氏は「合格点というものはない。ここに来る量子プロセッサーに悪いものはないが、性能が劣るものがあるという考えでテストに臨んでおり、テスト結果が以前よりも良ければそれが評価基準になる。私たちはクライアントに常に最高のものを提供したい」と話した。

（取材協力：日本IBM）",[],[]
第1回：データとAIの基礎から最新技術まで--未来のビジネスに役立つ情報を徹底解説（ZDNET Japan）,https://news.yahoo.co.jp/articles/34a7bdd2f8138561b97ada9cacdf4034b2aa1ce4,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250909-35237447-zdnet-000-1-view.jpg?exp=10800,2025-09-09T07:00:00+09:00,2025-09-09T07:00:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,9956,"データ活用と生成AIの基礎知識：革新技術の仕組みと可能性
企業データ活用の現状と生成AI活用への期待

　企業のDX推進担当者にとって、蓄積されたデータの活用は重要課題です。多くの企業が膨大なデータを保有しながらも、「データはあるが活用できていない」「どこから手を付ければよいか分からない」といった悩みを抱えています。

　2022年後半に「ChatGPT」が登場したことで、生成AI、特にその中核技術である大規模言語モデル（LLM）によるデータ活用への期待が急速に高まり、「プロンプトエンジニアリング」「検索拡張生成（RAG）」と呼ばれる技術用語が注目されています。

　しかし、このような技術を自社に導入し、AIとデータを連携させるためには、もう少し詳細までその内容を理解する必要があります。 また、これらの技術の発展系である「Model Context Protocol （MCP）」や「Agent2Agent（A2A）」といった新しい概念の検討も世界中で始まっており、それらについても把握しておく必要があります。

　本記事では、生成AIとデータを連携し、AIを業務活用するための技術発展について体系的に解説し、現在のビジネス活用の可能性と、将来の技術発展について解説します。

LLMの基本原理と業務活用課題

　LLMの基本原理を、誤解を恐れずに簡単な表現で説明すると、以下のようになります［1］。
#
LLMの基本原理
LLMは、入力されたテキスト（プロンプト）の、次によく出現していた単語（トークン）を1つだけ選ぶ

　LLMの機能は「次に出現しやすい単語を1つ選ぶ」だけなのです。 このLLMを使って、人間が以下のようなプログラムを開発することで、まるでLLMがテキストを生成しているかのように見せかけました。
#
文章生成プログラム
1. LLMにテキストを入力
2. LLMは次に出現しやすい単語を1つ選ぶ
3. LLMが選んだ単語を、元の入力テキストにつなげて、LLMに再入力する
4. 1～3を繰り返して、十分な長さのテキストを生成する

　上記のプログラムが初期の生成AIによる対話アプリの実装でした。 この初期の文章生成プログラムには「最もらしいうそをつく問題」（ハルシネーション）や「論理的思考ができない問題」が存在しており、まだまだ実用には耐えられないものでした。

　これらの問題を解決し、生成AIの業務活用を可能にしたのがプロンプトエンジニアリング技術です。

プロンプトエンジニアリング技術の発展経緯

　プロンプトエンジニアリングとは、AIモデルへの入力（プロンプト）を設計し、期待される出力を得る技術です。以下に、その技術的発展を時系列順に解説します。

Few-Shot プロンプト（2020年5月）

技術概要

　Few-Shotプロンプトという手法（Few-Shot Learning）は、「GPT-3」の論文「Language Models are Few-Shot Learners」（OpenAI、2020年5月）で提唱された、最初期のプロンプトエンジニアリングと言えます［2］。LLMへの入力プロンプトに、数個の回答例（Few-Shot）を追加することで、回答性能が向上することを示しました。

=== Few-Shot プロンプトの例 ===

ユーザーの質問は「」です。
以下の回答例を参考にして、上記の質問に解答してください。

Q：社内での育休制度について教えてください。
A：当社では、育児休業制度を設けており、従業員が子どもを育てるためのサポートを行っています。具体的には、出産予定日の前後5日間で最大3日まで有給を追加取得できる制度、復職後の時短勤務制度などがあります。
Q：副業申請について教えてください。
A：当社では、副業には事前に上司の承認を得ることが必要であり、業務に支障がない範囲で副業を行うことができます。

この技術の重要性

　Few-Shotプロンプトは、巨額の学習コストが必要なLLMの再学習（ファインチューニング）を行わずに、企業の独自タスクに適応させることが可能であることを示しました。これ以降、各事業会社はプロンプト設計に注力し、業務特化型のプロンプトを開発することで、AIの業務適用を加速させていきます。

Chain-of-Thought プロンプト（2022年5月）

技術概要

　Chain-of-Thought（CoT）は、論文「Large Language Models are Zero-Shot Reasoners」（2022年5月）で発表されました［3］。LLMモデルに「〜を生成してください。まずは生成方法をステップバイステップで検討してください」とプロンプトに付け加えるだけで、AIモデルの論理的思考能力を向上させることを発見しました。

この技術の重要性

　従来のLLMモデルには思考能力がなく、小学生レベルの算数の文章問題すら解けませんでしたが、CoTプロンプトを使うことで、AIモデルは論理的な思考過程を経て答えを導き出すことが可能になります。 この研究では算数の文章問題セットの正答率を比較しており、当時のLLMでは17.9％だった正答率が、CoTプロンプトを追記するだけで58.1％まで改善したことが報告されています［3］。

　さらに、CoTのもう一つの価値は、人間がAIの判断過程を理解できるようになったことです。これにより、企業での実用において重要な「説明責任」を果たすことが可能になりました。

　この利点も、生成AIの業務活用が進んだ大きな要因となっています。
RAGプロンプト

技術概要

　RAGは、Facebook AI Research（現Meta AI）により発表された「Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks」（2020年5月）で提唱されましたが、実用化されたのは2022年以降です［4］。RAGは、生成AIが外部の情報源（ドキュメントやデータベース）を参照して回答を生成するプロンプトエンジニアリング技術です。 例えば、以下のようなプロンプトがRAGの一例です。

=== 実務的なRAGプロンプト例 ===
#
社内FAQ検索システム
あなたは社内のヘルプデスクアシスタントです。
以下の社内規定から該当する情報を見つけて、従業員の質問に回答してください。

【検索結果】

【質問】

【回答条件】
- 検索結果にない情報は「確認が必要です」と回答

　上記のプロンプトを作成するためには、以下の機能が必要になります。 この機能の実装や設定によって、RAGの性能が大きく変わります。

文章管理機能：文章テキストを保存するシステム。テキストファイルだけでなく、PDFやPowerPointファイルなどの非テキストファイルもテキスト化して保存する必要があります。
文章検索機能：文章テキストを検索し、プロンプトに挿入するシステム。多くの場合、ユーザーが入力した質問が検索クエリーとなります。

この技術の重要性

　企業の独自データを、ファインチューニングなどの再学習なしに、生成AIに考慮させることが可能になりました。また、回答に必要な事実情報を適切に挿入することで、ハルシネーションを抑制することができました。

Function Calling プロンプト

技術概要

　Function Callingは、OpenAIが2023年に発表した技術で、生成AIが外部のAPIやツールを呼び出すことを可能にするプロンプトエンジニアリングです［5］。論文としてはMeta AIが発表した「Toolformer: Language Models Can Teach Themselves to Use Tools」（2023年2月）が先行研究としてあります［6］。

　このプロンプトの例は以下のようなものになります。

=== Function Calling プロンプトの例 ===
ユーザーの質問は「」です。
この質問に答えるために、以下の tools から適切なものを選び、同時に適切な inputs を生成してください。

{
  ""tools"": [
    {
      ""name"": ""search_documents"",
      ""description"": ""社内ドキュメントの検索機能"",
      ""inputs"": {
        ""directory"": """",
        ""query"": """"
      }
    },
    {
      ""name"": ""web_search"",
      ""description"": ""Web検索を行うAPI"",
      ""inputs"": {
        ""query"": """"
      }
    }
  ]
}

なお、返答は以下の形式で行ってください。
{
    ""name"": ,
    ""inputs"": 
}

　上記のFunction Callingプロンプトの  に「社内での育休制度について教えてください。」が入力された場合、生成AIは以下のような出力を返します。

=== Function Calling プロンプトの返答例 ===

{
    ""name"": ""search_documents"",
    ""inputs"": {
        ""directory"": ""共有フォルダー/人事/社内規定/"",
        ""query"": ""育休制度""
    }
}

　この出力に従って、社内のドキュメント検索機能を実行することで、ユーザーに対して適切なファイルを提示することができます。 なお、この返答結果を実行するシステムは、別途開発する必要があります。

この技術の重要性

　この技術により、AIは許可されたツールを実行することができるようになり、従来の単なる質問応答システムから、業務実行を代行するエージェントへと進化しました。

ReAct（Reasoning and Acting）プロンプト

技術概要

　ReActは、プリンストン大学とGoogle Researchの共同研究により発表された「ReAct: Synergizing Reasoning and Acting in Language Models」（2022年10月）で提唱された手法です［7］。これまでの技術が「思考」または「行動」のいずれかに特化していたのに対し、ReActは両者を動的に組み合わせる革新的なアプローチです。

　論文としては、上記のFunction Callingプロンプトよりも前に発表されていますが、ReActはFunction Callingを発展させたプロンプトエンジニアリングと考えられるため、Function Callingの後に紹介しました。

　ReActの特徴は、「Thought（思考）→ Action（行動）→ Observation（観察）」のサイクルを繰り返すことです

Thought：ユーザーからの質問と利用可能なツールをプロンプトに挿入し、AIに次の行動を思考させる
Action：Function Calling で外部ツールやAPIを選択させ、その実行結果を得る
Observation：実行結果をプロンプトに挿入し、1のThoughtに戻る

　そのプロンプトの例は以下のようになります。

この技術の重要性

　ReActにより、生成AIが単なる「質問応答システム」から「自律的な問題解決エージェント」へと進化しました。今日における企業のエージェント型AIの開発を可能にした、技術的転換点です。
現在の生成AI活用技術：実用化段階の最新動向

推論モデル（Reasoning model）の進化

技術概要

　2024年9月にOpenAIがリリースした「o1」シリーズはCoTプロンプトの推論能力を内部処理に組み込んだモデルであり、推論モデルと呼ばれています［8］。従来のモデルが即座に回答を生成していたのに対し、推論モデルは数秒から数分間の「思考時間」を要し、複雑な問題を段階的に解決します。

　この推論モデルのメカニズムは、論文などで公開されてはいませんが、OpenAIの公式ブログなどから以下のように推測できます［9］。

CoTプロンプトの自動化：推論モデルは、CoTを人間が設計する必要がなく、モデル自体が内部的に思考プロンプトを生成
自己検証機能：回答の妥当性を自動的にチェックし修正

この技術の重要性

　推論モデル以前のプロンプトエンジニアリングでは、人間がいかにCoTプロンプトを設計するかが重要でしたが、推論モデルではAI自体がCoTプロンプトを設計します。 そのため、人間は「AIが達成すべき目的」をプロンプトとして言語化することに集中し、そのタスク設計および実行はAIが担当する業務スタイルが可能になりました。 このような業務スタイルを「AI駆動型業務」と呼び、企業の業務効率化や新規事業創出に大きな影響を与えると期待されています。

エージェント型AI

技術概要

　エージェント型AIは、人間のように「考えて行動する」AIシステムです［10］。従来のAIが「質問→回答」の1回限りだったのに対し、エージェント型AIは次のようなステップで基本的に動作します。

自ら計画を立てる：
　-CoTプロンプトや推論モデルを活用し、入力された目標に対して、必要な作業を自動的に計画
任意のAIモデルで動作する：
　-推論モデルを設定することも可能で、その高い推論能力を活用できる
許可されたツールを実行：
　-Function Calling＋ReActプロンプトで、AIモデルは外部ツールやAPIを選んで実行できる
　-ツールに、他のエージェント型AIを指定することでマルチエージェントシステムを構築可能

この技術の重要性

　自社の業務に特化したエージェント型AIの開発に成功すれば、AIが単なる「お手伝い」から「同僚」のような存在に変わり、企業の生産性が向上すると期待されています。

MCPの普及とエコシステム形成

技術概要

　MCPは、2024年11月に発表された「エージェント型AIに許可するツールとリソースの共通規格」です［11］。これまではツールごとにAI接続を開発する必要がありましたが、MCPにより統一されました。また、例えば「Google Analytics MCP」のようなプラットフォーマー公式のMCPも登場し、自社のAIに開発不要で接続できるようになります。

MCPの機能：

統一された接続方法：どのAIでも同じ方法で外部ツールを使用可能
安全な接続：セキュリティが確保された通信
ツールの使い回し：一度作ったツールを複数のAIシステムで利用可能。外部プラットフォームの公式MCPを利用も可能

この技術の重要性

　MCPの導入により、自社のエージェント型AIをこれまで以上に簡単かつ安全に開発できるようになります。

開発コスト削減：一度作ったツールを何度でも使い回し可能
豊富なツール選択肢：多くの開発者が作ったツールを簡単に利用
既存システムとの連携：会社の既存システムをAIが簡単にアクセス
セキュリティの統一：企業レベルのセキュリティを標準的に実装（仕様策定中）

　これにより、企業は技術的な複雑さを気にせず、ビジネス課題の解決に集中できるようになります。
将来の生成AI技術発展と投資戦略

パーソナルエージェント型AI（スマートフォン・PC内で稼働するAIモデル）の普及

技術概要

　パーソナルエージェント型AIは、スマートフォンやPCの中でAIが動く技術です［12］。これまでのAIはインターネット経由でクラウドにアクセスしていましたが、今後は手元のデバイスで直接AIが動きます。この技術は、小規模言語モデル（SLM）とNPU（Neural Processing Unit）の組み合わせで実現されます［13］。 すでに、NPUを搭載したノートPCも販売されており、これから数年で普及が進む可能性があります。

プライバシー保護：個人データが外部に送られない
即座に応答：インターネット接続なしでAIが使え、通信の遅延がなく瞬時に答えが返ってくる

この技術の重要性

　パーソナルエージェント型AIの普及により、企業の生成AI活用は大きく変わります。

機密情報が会社の外に出ることなく、AI処理が可能
毎月のクラウド利用料／アカウント費用から、PC購入の一回限りの費用に変更
個々の仕事のやり方、過去の資料、スケジュールなど全てを覚えて最適化

A2Aプロトコル

技術概要

　A2Aプロトコルは、AI同士がインターネット上で直接会話できる仕組みです［14］。これまではAIが人間やツールとやりとりしていましたが、今後は外部のAI同士が連携して作業を進めるようになります。

AI同士の検索：インターネット上にいる他のAIとその機能を検索
作業の分担：自分では難しい作業を得意な外部AIに依頼
協力作業：複数のAIが同じ目標に向かって連携

この技術の重要性

　A2Aプロトコルにより、顧客のスマートフォンに搭載されたパーソナルAIが、企業のエージェント型AIと連携して、より高度なサービスを提供できるようになります。場合によっては、マーケティングや営業活動に大きな影響を与える可能性があります。

企業が開発したエージェント型AIを、パートナー企業（小売店やコールセンターなど）のエージェント型AIと連携し、企業間の業務フローを自動化
顧客のスマートフォンに搭載されたパーソナルAIがスケジュール、住所情報を管理し、企業のAIエージェントと連携。ホテル予約、タクシー手配、資料請求などのタスクを自動化

まとめ

生成AIの技術発展経過から見る投資の方向性

　本記事で解説したプロンプトエンジニアリング技術の発展を時系列で整理すると、明確な技術進歩のパターンが見えてきます。

2020年5月：Few-Shotによるプロンプトエンジニアリングの発見 
2020年5月：RAGプロンプトによる企業データ活用 
2022年5月：Zero-Shot Chain-of-Thoughtによる推論革命 
2022～2023年：Function Calling＋ReActによる業務エージェント化 
現在（2024～2025年）：企業の生成AI活用環境の整備
　　
推論モデルの進化（o1シリーズ）
エージェント型AI（Agentic RAG、マルチエージェントシステム）
標準化プロトコル（MCP）の普及 

将来（2025年以降）：パーソナル化と外部エージェント協業環境
　　
パーソナル（スマートフォン）AI（SLM＋NPU）
エージェント間通信（A2Aプロトコル）

　この経緯を踏まえると、企業は以下の投資について検討を進めるべきでしょう。

現時点で投資を検討すべき項目

既存業務のAI駆動化
　　
既存で使用している業務システムのMCP機能を活用し、AI業務システム（ChatGPTなど）と連携
従業員への生成AI活用スキルの教育トレーニング

独自MCP開発
　　
プラットフォームを使わず自社開発で管理しているデータやシステムをMCP化し、AIとの連携を可能にする

自社の独自エージェント型AIの開発
　　
MCPとAIを連携し、プロンプトエンジニアリング技術を活用して自社の業務に特化したエージェント型AIを開発

エージェント型AI間通信（A2Aプロトコル）の対応
　　
自社のエージェント型AIを外部のエージェント型AIと連携させるためのA2Aプロトコルへの対応
パートナー企業との連携業務をAI化
顧客ユーザーのパーソナルAIとのコミュニケーションを最適化し、ビジネス目標の動的な達成を目指す

　今すぐに全ての項目に取り掛かる必要はなく、想定通りに技術が発展しているかは常に観察する必要があります。 技術への投資、対応判断を適切に行うことができれば、持続可能な競争優位性を構築することができるでしょう。

参考文献・ソース

［1］：Speed Always Wins: A Survey on Efficient Architectures for Large Language Models - arXiv, 2025年アクセス
［2］：Brown, T., Mann, B., Ryder, N., et al. (2020). Language Models are Few-Shot Learners. arXiv:2005.14165.
［3］：Kojima, Takeshi, et al. ""Large language models are zero-shot reasoners."" Advances in neural information processing systems 35 (2022): 22199-22213.
［4］：Lewis, P., Perez, E., Piktus, A., et al. (2020). Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks. arXiv:2005.11401.
［5］：OpenAI Function Calling Documentation.
［6］：Schick, T., Dwivedi-Yu, J., Dessì, R., et al. (2023). Toolformer: Language Models Can Teach Themselves to Use Tools. arXiv:2302.04761.
［7］：Yao, S., Zhao, J., Yu, D., et al. (2022). ReAct: Synergizing Reasoning and Acting in Language Models. arXiv:2210.03629.
［8］：OpenAI o1 System Card. September 2024.
［9］：ReAct: Synergizing Reasoning and Acting in Language Models - Google Research.
［10］：Agentic Retrieval-Augmented Generation: A Survey on Agentic RAG - arXiv, 2025年アクセス
［11］：Anthropic MCP (Model Context Protocol) Announcement. November 2024.
［12］：Microsoft Copilot+ PC Documentation.
［13］：Intel NPU Documentation.
［14］：Survey of LLM Agent Communication with MCP: A Software Design Pattern Centric Review. ResearchGate, 2024.

内田匠
インキュデータ株式会社 R&D室
京都大学卒業後、Web広告代理店での広告設計と効果改善業務、リクルートでのデータサイエンティスト・AIエンジニアとしての経験を経て、2021年よりインキュデータに参画。筑波大学社会人大学院でレコメンドAIの研究を経て博士（システムズ・マネジメント）を取得し、現在は筑波大学非常勤講師。インキュデータでは、生成AIを活用した新規事業および業務効率化の検討など、データとAIに関する専門性を生かしたプロジェクトを推進。",[],[]
