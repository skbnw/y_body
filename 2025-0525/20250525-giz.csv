headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
ストーンヘンジのような古代構造物、ミシガン湖の底で発見される（ギズモード・ジャパン）,https://news.yahoo.co.jp/articles/c36f0754b9cb8c13449a461057b3a170a6449a49,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250525-00000006-giz-000-1-view.jpg?exp=10800,2025-05-25T21:30:02+09:00,2025-05-25T21:30:02+09:00,ギズモード・ジャパン,giz,ギズモード・ジャパン,1370,"ストーンヘンジのような古代構造物、ミシガン湖の底で発見される
イギリスのストーンヘンジよりも4,000年古い！

2007年、ノースウェスタン・ミシガン大学の水中考古学の教授、マーク・ホリー博士がミシガン湖のグランド・トラバース湾あたりの湖底調査を行なっていたところ、水深約12mのところに不思議な円形の配列をした巨石モニュメントを偶然発見。「ミシガンのストーンヘンジ」と名付けられたその巨石群はなんと直径16mにも及びます。円形に並べられた石の大きさはさまざまで、バスケットボールくらいのものから軽自動車くらいのものまであるそうです。
【全画像をみる】ストーンヘンジのような古代構造物、ミシガン湖の底で発見される
いつの時代のもの？
発見後から、ホリー博士の考古学チームは研究を続けています。その中でも注目を浴びているのが、その石に掘られたゾウやケナガマンモスの祖先「マストドン」と思われる絵。マストドンが生きていたのは更新世。となると約9,000年前、氷河時代が終わった直後にまだ湖ではなかった頃にこの場所に配置されたとホリー博士は考えているようです。

9,000年前ということは、およそ5,000年前から建造が始まったとされるイギリスのストーンヘンジよりも4,000年古いことになります。
水中の石の調査は簡単ではない
この場所を保護するために、ホリー博士は迅速に行動を起こしました。その地域に住む先住民族のオタワ族とチペワ族に連絡をし、土地との先祖のつながりに対する敬意を示しました。そして今は、この遺跡の場所・座標は機密扱いとなっています。

ただ、石が水中にあるため調査・研究が思うようにいかないのが課題とのこと。研究者たちは石の構造の謎を解き明かそうと、他の地域にある類似の石の並びと比較しながら調査を進めています。

ミシガン湖の石の目的を解き明かす手がかりは、近隣にある類似の石の構造物からも見つかっています。ミシガン大学のジョン・オシェイ博士は、約9,000年前にさかのぼるミシガン湖のお隣・ヒューロン湖の岩の構造物について研究しています。 ヒューロン湖の構造物は、古代の狩猟でトナカイを特定の方向へと誘導するために使用されていたと考えられています。
周辺の湖や島でも石の構造物が発見されている
また、ミシガン湖で一番大きな島、ビーバー島にも、古代の石の構造物があります。島の西側に氷河によって運ばれた大きな石が円形に配置されており、中には刻印のあるものも見つかっています。穴の開いた石もあり、何らかの実用的な目的があったことを示唆しています。

炭素年代測定などの正式な分析はまだ行われていませんが、これらの石はかつてこの島に住んでいたネイティブアメリカンにとって重要な意味を持っていたと考えられており、暦の目印や天体観測のポイントとして使われていた可能性もあります。

ミシガン湖の石の謎はまだ不明ですが、ヒューロン湖の石構造物と同じようにトナカイ狩猟に使われていた可能性もあれば、ストーンヘンジのように天体の動きと連動した古代のカレンダーだった可能性もあります。まだまだ研究と分析が必要なのですが、水中という環境のせいで難航しています。 

Source: thebrighterside.news
岩田リョウコ",[],[]
激狭キッチンの救世主。ニトリのまな板は1台4役で包丁も研げちゃう（ギズモード・ジャパン）,https://news.yahoo.co.jp/articles/a9ebc69ccd2405a80a18d0cfb5215b1ca8cadc99,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250525-00000005-giz-000-1-view.jpg?exp=10800,2025-05-25T11:30:01+09:00,2025-05-25T11:30:01+09:00,ギズモード・ジャパン,giz,ギズモード・ジャパン,811,"激狭キッチンの救世主。ニトリのまな板は1台4役で包丁も研げちゃう
自炊はしたいけれど、一人暮らしのキッチンが狭すぎる…。

そんな筆者のような環境に暮らす人におすすめしたいのが、ニトリで販売されている「
解凍プレートシャープナー付きまな板
」です。一見ふつうのまな板ですが、実は1枚で4役もこなしてくれます。
【全画像をみる】激狭キッチンの救世主。ニトリのまな板は1台4役で包丁も研げちゃう
食材カットや解凍、すりおろし、包丁研ぎまで
また、板の角についている小さな凹凸。これがすりおろし器になっています。生姜や大根、にんにくなどをすりおろすことができるので、「ちょっと薬味がほしい」というときに活躍します。

そしてまな板の裏面は、アルミ合金の解凍プレート。熱伝導性が高いので、プレートの上に置いた冷凍食材の冷たさを吸収して自然解凍のスピードを早めてくれます。このまな板の場合は、肉や魚が最大5倍速で自然解凍されるとか。電子レンジで解凍しようとして表面だけ火が通っちゃった…なんて失敗とも無縁になりそうです。

持ち手の端についた小さな切れ込み、これが包丁のシャープナーになっています。ステンレス包丁であれば、その場で数回シャシャッとこするだけで切れ味が復活（※セラミックやチタン製は残念ながら非対応）。これがあれば、砥石やシャープナーは不要です。
さよならしたのは、3つのキッチンツール
ということで、このまな板を導入すれば、「薬味用のすりおろし器」「解凍プレート」「包丁シャープナー」が不要に。キッチン収納が少しすっきりするだけで「料理でもしようかな」という気分になりますね。洗い物も減るし、「そもそも上記の3つを持っていないけど」という人は、これで少し料理が快適になります。

狭いキッチンの救世主、厚さはわずか1cmです。吊り下げもできるので、収納場所にも困りません。

Source: ニトリ
yamazaki",[],[]
UGREENのNASにAIが乗る。さらに便利を極めてきた（ギズモード・ジャパン）,https://news.yahoo.co.jp/articles/2016fc05d1fac188b859e1117f831f36a6835539,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250525-00000004-giz-000-1-view.jpg?exp=10800,2025-05-25T10:30:02+09:00,2025-05-25T10:30:02+09:00,ギズモード・ジャパン,giz,ギズモード・ジャパン,1415,"UGREENのNASにAIが乗る。さらに便利を極めてきた
世界最大級のコンピューター関連の見本市、「COMPUTEX TAIPEI 2025」。世界各地からコンピューター関連企業が、最新テックを持ち寄ります。
【全画像をみる】UGREENのNASにAIが乗る。さらに便利を極めてきた
そんな中でも、特に興味深かった製品のひとつがUGREEN（ユーグリーン）のNAS「UGREEN NASync iDX6011 Pro／iDX6011（以下、iDX6011 Pro／iDX6011）」。

このNASの特徴はなんといってもローカルAI（大規模言語モデル：LLM）を搭載している点。クラウドに依存せず、端末上でAIを稼働できるため、プライバシーを保ちながら高度なデータ管理が可能になります。
そもそもNASとは？
NAS（Network Attached Storage）はネットワークに接続するハードディスクやSSDのこと。

それ自体がパソコンのようにネットワーク接続機能があり、Wi-Fiルータに接続すれば家庭のネットワーク内にストレージを追加可能。USBケーブルでパソコンに接続する「外付けHDD」とは違い、ネットワークを通じてアクセスでき、インターネット越しの外出先からも、複数の人やPCがアクセスすることもできます。

ファイルの共有やデータのバックアップなどができるため、最近では、iCloudなどのオンラインデータ保存に代わってNASを自宅に設置するという人もいるみたい。
AIが搭載されるとどうなる？
iDX6011 Pro／iDX6011はLLMを搭載しており、AIをローカルで動作させることができます。これによりAIとのチャットやAIを利用した情報の要約などが利用可能に。

AI検索も可能で、膨大なデータの中からでも欲しい情報を簡単にピックアップ。画像内のテキスト、物体、顔なども自動認識してくれます。

こういった機能があると。大量のデータでも管理がしやすくなりますね。また、軽量であればAIのトレーニングをローカルで行なうこともできるんだとか。

CPUは、インテル®Core™ Ultra 5プロセッサ、メモリは32GBとなっています。AIの性能は最大34TOPSで、NASとしては非常に強力な処理能力です（が最新のPCには遠く及ばないレベル）。

NASにもAIが搭載されるようになる時代。扱うデータが増えたとしても、スマートに管理できそうです。

Source: UGREEN

■イベントで「COMPUTEX」の報告会やります
5月20日～23日にかけて台湾で開催される、コンピューター関連の展示会「COMPUTEX TAIPEI 2025」。 

ギズモードでもCOMPUTEXを取材していますが、その報告会を6月6日のイベント「AI First Lounge Vol.2」で行う予定です。

私達が触れるAIはこれからどこへ向かっていくのか、PCやスマートフォンといったガジェットのトレンドとあわせて、未来を予感できるお話を持って帰ってくるつもりです。

また、「アジアのAI現在地」として、楽天グループの大越 拓さん、電通デジタルの鈴木初実をゲストとしてお招きし、日本でのAI開発のお話をうかがいます。

参加費は無料、ぜひお越しください。  

イベント参加（無料）はこちら
カタヤママコト",[],[]
これであなたも映画監督の気分！ 文字で映像生成できるGoogle Flow登場（ギズモード・ジャパン）,https://news.yahoo.co.jp/articles/c6ab6c30d0fa461094ea2a3226f089ad70cd22c2,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250525-00000003-giz-000-1-view.jpg?exp=10800,2025-05-25T08:30:01+09:00,2025-05-25T08:30:01+09:00,ギズモード・ジャパン,giz,ギズモード・ジャパン,1266,"これであなたも映画監督の気分！ 文字で映像生成できるGoogle Flow登場
AIグラス、AI試着などAI大放出だった今年のGoogle I/O。

だんだん頭が朦朧としてきたところにガツンときました。文字入力で映画ができちゃう新AIツール「Flow」です！
【全画像をみる】これであなたも映画監督の気分！ 文字で映像生成できるGoogle Flow登場
Flowって何？
「Flow」はGoogle（グーグル）の次の3つを合体させたもの。

動画コンテンツ生成モデル「Veo 3」

文字からイメージを生成する「Imagen」

文字入力・プロンプト生成を処理する大規模言語モデル「Gemini」

映像のみならず音声も生成できるので、全部ひとりオペレーションでちょっとした映像作品（最長8分）が作れちゃう。まずは作例から見てみましょう。

…ね？ なんだか自分でも作ってみたくなりますよね。
利用方法
作り方はかんたん。こんな風に「＋」を押して、ぶっ込みたい風景や登場人物の写真をアップしていきます。

材料が足りなければ左上の「Generate」ボタンを押して、欲しいブツの説明を文字で入れることで生成することも可能です。

材料がそろったら、映像作成の指示を入れます。

これだ！というのを選んで、作品全体のストーリーを長々入力すると、映像が勝手に仕上がるってな具合で、まさにレボリューション。

プロだけじゃなくて、素人の方でも使いこなせるように、「カメラ・コントロール」ってのもできました。これで欲しい映像の角度やモーション、視点を選んで、プレビューしたりもできるの。

「一度つくった被写体や場面はほかの映像に使い回しも可能だし、ワンシーンから新たに撮影を開始することもできる」とGoogleは話していました。

ほんとにロケハンも要らない夢のツールですよね。
デモを見た感想
ノートPCと文字入力だけで映像作品つくれるなら映画産業崩壊、ぐらいの話なのですけど、 現実にはアートとは程遠い作品の量産で終わる予感が個人的にはします。Flowのようなツールにはそれを裏打ちする映像哲学が感じられなくて。

PhotoshopもFinal CutもFlowも所詮は道具。ゼロから何かを生み出す部分は結局、自分の頭でやらなきゃダメだって思うし、カタチだけ整っても、伝える中身がないと、映像を見せられる側としても辛い。ロボがそれらしく体裁整えた架空の世界を彷徨うのにも限界感じちゃうと思うんですね。基本、ペシミストなので。

それはGoogleもわかってるっぽくて、Flowの開発に際しては映画監督とパートナーシップを組んでもいます。でもまあ、Flowを便利に使いこなす人はそういうプロとは違う層になるように感じますよ。こんなこと書く自分はラッダイト（新しい技術や機械化に反対する人）か、恐ろしく創作力が乏しい人間なのかもしれないけど。

Flowは今のところ米国オンリー。Google Labsで利用可能です。
satomi",[],[]
GoogleのAIで自分を3Dレンダリングして、服を試着。エージェントが代わりに買い物する機能も（ギズモード・ジャパン）,https://news.yahoo.co.jp/articles/1eee03252d8283cbeb1223e04c6a68d07c31286b,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250525-00000002-giz-000-1-view.jpg?exp=10800,2025-05-25T07:30:01+09:00,2025-05-25T07:30:01+09:00,ギズモード・ジャパン,giz,ギズモード・ジャパン,2271,"GoogleのAIで自分を3Dレンダリングして、服を試着。エージェントが代わりに買い物する機能も
Googleが買い物を手伝ってくれる！

オンラインショッピングって楽だけど、物が多すぎて何を選ぶか、見極めが大事ですよね。検索するので疲れてきちゃうってこともありますし。
【全画像をみる】GoogleのAIで自分を3Dレンダリングして、服を試着。エージェントが代わりに買い物する機能も
そんなオンラインショッピングですが、Google I/O 2025でAIボットが代わりに買い物をしてくれるツールが発表されました。
専属のインテリアコーディネーター
今回のGoogle I/Oでは、Google副社長兼広告・コマース事業部長のVidhya Srinivasan氏がショッピング体験を改善するためにAIを活用してGoogleで買い物をする新しい方法をいくつか発表しています。

最初のAI搭載ショッピング機能は、GoogleのAIモードの一部として、買い物客がGemini AIからの提案やインスピレーションを得られるというもの。

たとえば、リビングのソファに合ったインテリアを選びたいけど、インテリアデザイナーではないので、自分のセンスは信用できないという時、スマホのカメラをリビングに向けて、Gemini AIに「部屋を明るくする家具を見つけて」と言うだけで、あっという間に雑誌に出てくるようなおしゃれなインテリアの提案をしてくれるんです。

AIモードショッピングは、アメリカで今後数か月以内に利用可能になる予定です。Gemini AIに家具やインテリアの提案を聞きすぎると、今の家のもの全部変えたくなって散財しそうで怖いですけどね。特に今はトランプ関税が発動するって時ですからね…。
自分の全身3Dを作って試着させてくれる
次は「Try it on（試着してみる）」という機能について。その名の通り、洋服をバーチャルで試着できます。

ただ、15年くらい前にあったデジタルの服をバーチャルミラーみたいに重ね合わせてくる感じとは全然違います。現代版は、GoogleがAIで服を着たあなたのアバターを生成してくれるんです。

Googleによると、自分の写真を1枚アップロードするだけで、AIが商品画像から作った服を着せてくれ、自分の全身の3Dをレンダリングしてくれるんですよ。Srinivasan氏によると、レンダリングされたアバターの服は、実際に試着した時と同じように、リアルな生地の性質、折れ、たわみ、伸びなども再現しているということです。

Srinivasan氏は「私たちはファッション向けにカスタマイズされた画像生成モデルの開発に多くの時間を費やしてきました。このモデルは3D形状を深く理解しています」と、Google I/O前のビデオブリーフィングでメディアに語っています。

また服を試着した自分のアバターを友人に共有して、似合っているかどうか意見を聞くこともできます。
気になる点もあり
まぁ、さっきも言いましたが、これもさらに購買意欲を高められちゃいますよね。3Dアバターでいい感じだからという理由でポンポンものを買ってしまうことも心配ですが、それよりも3Dボディプロフィールが個人のGoogleアカウントに保存されることのほうがもうちょっと心配です。

プライバシーの問題を置いておいても、Googleはデジタル服を正確に重ね合わせるために、あなたのリアルな体型をレンダリングしていきます。なので、もちろんデジタルで作られた服は、痩せている人と太っている人では異なって表示されます。AIはたった1枚の画像だけから、その人の本当の体つきが知れるんでしょうか？

ネガティブになりたくはありませんが、ショッピングのためだけに体の写真を撮ってGoogleに渡すのは、少し怖い気もします。

もし時間が経って体に変化があったらどうでしょうか？ 減量したり、筋トレしたりして体つきが変わってくるかもしれないですよね。その度に体の写真を撮って送って、最新の3Dアバターを作らなきゃいけないんですかね？ そのあたりは、米GizmodoがGoogleに今問い合わせ中です。

「Try it on」は2025年5月20日からGoogle Search Labsで開始されていますが、展開は今のところアメリカのみです。
買い物を代わりにしてくれる
最後にもうひとつ実用的な機能をご紹介。「agentic checkout（エージェント・チェックアウト）」というもので、簡単に言うとあなたの代わりに買い物をしてくれるAI「エージェント」です。

Googleによると、エージェント・チェックアウトでは、購入したいものの希望価格を設定したり、特定の色やサイズを選択したりできます。事前に設定した要件でその商品が利用可能になると、AIエージェントがショッピングサイトであなたの代わりにカートに入れ、必要な請求・配送情報をすべて入力し、Google Payを通じて購入を完了してくれます。お買い物のお手伝いさんみたいな感じですね。

これは結構いい感じですよね。安く何かを買おうとすると、たくさんのショッピングサイトを開いて、どこが安いかリサーチして、数日後に値段が変わってないかチェックして…という作業をしなくて済みます。

この機能は数ヶ月後にアメリカで展開されるそうですが、どんな反響があるのか楽しみに待つとしましょう。
岩田リョウコ",[],[]
核融合実現へ向けて。米・レーザー核融合施設、生成できるエネルギー量の記録を更新（ギズモード・ジャパン）,https://news.yahoo.co.jp/articles/0e451efc586d6af0248f9f7816fd9784f209e876,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250525-00000001-giz-000-1-view.jpg?exp=10800,2025-05-25T06:00:01+09:00,2025-05-25T06:00:01+09:00,ギズモード・ジャパン,giz,ギズモード・ジャパン,1133,"核融合実現へ向けて。米・レーザー核融合施設、生成できるエネルギー量の記録を更新
二酸化炭素を排出しない新しいエネルギーとして期待されている核融合エネルギー。実現に向けて日々、研究が進んでいます。
核融合がいま注目される理由
核融合とは、原子核が合体すること。2つ以上の軽い原子核同士が結合し、より重い原子核に変わります。このときに大量のエネルギーを放出することから、人類は何十年にもわたってこの反応を人工的に再現し、エネルギーを得ようと研究を進めてきました。

核融合は自然界で発生し、宇宙のエネルギー源となっている反応ですが、地球上では自然には起こりません。太陽がギラギラと輝くのはこの核融合反応によるものです。

核融合反応を促進することは容易ではないですが、世界で脱炭素の流れが加速するなかで、クリーンなエネルギー源としても注目が集まっています。
レーザー核融合実験で点火に成功
そんななか、アメリカのローレンス・リバモア国立研究所は、国立点火施設（NIF）を使ってレーザー核融合実験を行ない、投入したエネルギー量を2倍も上回る出力が得られる「核融合点火」に成功しました。

NIFは2009年から運用されている実験施設です。核融合そのものは目新しいものではありませんが、2022年、NIFが核融合を発生させるため、燃料に投入したエネルギーよりも多くのエネルギーを世界で初めて生成することに成功。この出来事は、核融合における大きなブレイクスルーとなりました。

TechCrunchによると、NIFは最近の実験で核融合による出力を5.2メガジュール（1メガジュール＝238.889キロカロリー）、さらには8.6メガジュールにまで高め、2022年の歴史的な成果を大きく上回るエネルギー放出を達成したといいます。
核融合炉のしくみ
核融合炉を実現する方法はいくつかあります。フランスの国際プロジェクト「ITER」では、磁力を利用して核融合を発生させる方法を採用しています。一方、NIFで行なわれているのは「慣性閉じ込め核融合」と呼ばれる手法で、高出力のレーザーを利用するものです。

NIFでは、凍らせた核融合の燃料が詰まった数ミリサイズのカプセルに対して、周囲に設置した192本の強力レーザー光線を照射。試料が詰まっているカプセル内が超高温・高圧になることで、燃料が内側に一気に圧縮され「星のような爆発」が起こり、核融合反応を引き起こします。

専門家たちは慣性閉じ込め方式が実用的なエネルギー源となるには依然として大きな課題があると見ています。そのため、磁場でプラズマを閉じ込める「磁気閉じ込め方式」によるアプローチを追求している研究チームもいます。
高橋真紀",[],[]
