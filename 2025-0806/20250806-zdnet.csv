headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
国内大企業の約40％がAIエージェントを導入済み--UiPath調査（ZDNET Japan）,https://news.yahoo.co.jp/articles/bd5e69435a5e5fd22160d56a904335daec71802f,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250806-35236416-zdnet-000-1-view.jpg?exp=10800,2025-08-06T17:31:00+09:00,2025-08-06T17:31:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,1399,"国内大企業の約40％がAIエージェントを導入済み--UiPath調査の画像
UiPathは、IDCに委託した調査「エージェンティックオートメーション：シームレスなオーケストレーションの実現によるモダンな企業への進化」で、国内大手企業の約40％がAIエージェントを導入済みで、52％が今後12カ月以内に使用予定であることが分かったと発表した。

　調査報告書によると、AIエージェントの導入は、顧客体験の向上と事業運営の効率向上、組織的リスク管理の改善などのニーズで加速している。日本企業もエージェント型AIの具体的なメリットを実感しているとし、調査では67％が「生産性の向上を支援している」と回答。64％が「より複雑なタスクの処理に役立っている」とした。

　日本でエージェント型AIの導入が進んでいる業界は、製造、小売・卸売、通信・メディア・エンターテインメントになり、2025年に最も有望なユースケースには、「生産性の向上」（67％）や「顧客サポートの自動化」（66％）、「サプライチェーンの最適化」（47％）が挙げられた。

　他方で、AIの広範な導入に向けた課題も浮上。日本では、「AIガバナンスおよびリスク管理」（22％）や「データガバナンスの要件」（20％）、「ITインフラの複雑性」（20％）が主要な課題だとした。

　さらにエージェント型AIでは、「自律的な行動によるセキュリティ上の脆弱（ぜいじゃく）性」（56％）や「データプライバシーの侵害」（54％）、「悪意のある行為者による悪用の可能性」（44％）が懸念されている。導入面では、「データセキュリティの懸念」（67％）、「スキルを持つ社内のIT人材不足」（51％）、「既存システムとの統合」（50％）も挙げられた。

　UiPathは、日本でこうした課題があり、大規模な投資には至っていないものの、導入への取り組みが続いていると述べる。現状では、45％が「初期テストと重点的な概念実証を行っているが、具体的な支出計画はない」、21％が「概念実証のリストを作成しているが、まだ投資は行っていない」という。

　今後の展望として同社は、日本企業がエージェント型AIソリューションを導入する中で、ビジネスリーダーが透明性のある人間とエージェントのエコシステムの構築を優先し、堅固なガバナンスフレームワーク、透明性の高い意思決定機能、データセキュリティとプライバシー標準への厳格な準拠を備えた自動化ソリューションの導入を進める必要があると指摘。同時にテクノロジーリーダーが、企業ニーズに合わせて拡張でき、既存システムやアプリケーションとシームレスに統合できるプラットフォームを優先しながら、適切なエージェント型ツールの評価と特定を行うべきだとした。

　また、AIエージェントの導入を効果的かつ責任ある方法で進めるべく、政府には倫理的なAIの使用に関する明確な政策、基準、規制ガイドラインを確立し、ガバナンスフレームワークを強化する必要があると指摘。データセキュリティ、倫理的な懸念、コンプライアンスの課題に対応するために透明性の高いリスク管理、堅固なセキュリティ対策、ターゲットを絞ったスキルアッププログラムも必要で、人材不足に対処するためのスキルアッププログラムへの投資や官民連携によるインフラコストの削減も重要になるとしている。",[],[]
東陽テクニカ、オンプレミス型量子コンピューターを販売（ZDNET Japan）,https://news.yahoo.co.jp/articles/0d04e021b279ca50b288ff993dccdda74321a54b,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250806-35236415-zdnet-000-1-view.jpg?exp=10800,2025-08-06T17:02:00+09:00,2025-08-06T17:02:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,651,"東陽テクニカ、オンプレミス型量子コンピューターを販売の画像
東陽テクニカは8月6日、フィンランドのIQM Quantum Computers（IQM）と販売代理店契約を締結したと発表した。IQMのオンプレミス型量子コンピューターを国内の企業や大学などに販売する。

　IQMは、超電導型量子コンピューターメーカーで、オンプレミス型システムとクラウドプラットフォームサービスを開発、提供している。販売代理店契約について東陽テクニカは、「IQMの注力技術領域と当社既存事業領域の親和性が高く連携して国内での事業展開を進める」と説明。大学や研究機関、企業への実機導入と量子技術人材の育成、社会実装化を推進していくという。

　販売するのは、5量子ビットの入門モデル「IQM Spark」と20～150量子ビットの「IQM Radiance」の2種類。IQM Sparkは量子技術教育や人材育成、IQM Radianceは材料科学、創薬、環境工学など幅広い分野の先端研究で利用されている。オンプレミス型はクローズド環境で機密性が高く、アクセス制御や物理セキュリティを管理でき、ネットワークを介さないことから応答速度が速くリアルタイム性を要求する処理にも適しているとする。

　東陽テクニカでは、量子技術専門組織「量子コンピューティング・カンパニー」を設置し、ユースケース創出、新ビジネスモデルの開発を推進するほか、実機を使った教育・研究機会の提供、関連企業や団体との連携による量子人材育成と社会実装に取り組む。",[],[]
トレンドマイクロの複数製品に緊急レベルの脆弱性、悪用攻撃も確認（ZDNET Japan）,https://news.yahoo.co.jp/articles/d542bc3ff66228739c94b0fc995152995babbec9,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250806-35236409-zdnet-000-1-view.jpg?exp=10800,2025-08-06T16:43:00+09:00,2025-08-06T16:43:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,773,"トレンドマイクロの複数製品に緊急レベルの脆弱性、悪用攻撃も確認の画像
トレンドマイクロは8月6日、複数製品に存在する2件の脆弱（ぜいじゃく）性情報を公開した。うち1件では悪用攻撃の発生を確認しているといい、注意と脆弱性への対応を呼び掛けている。

　同社によると、脆弱性は、管理コンソールに対するコマンドインジェクションによるリモートコード実行の2件（CVE-2025-54948、CVE-2025-54987）になる。共通脆弱性評価システム（CVSS） 3による評価は、いずれも「9.4」（最大値10.0）で、緊急度も「重大」に指定している。

　脆弱性の影響を受ける製品は、「Apex One 2019 SP1」「Apex One SaaS」「Trend Vision One Endpoint Security - Standard Endpoint Protection」の3つの全バージョンとなる。脆弱性を悪用された場合、各製品の管理コンソールで認証前の攻撃者が悪性コードを管理サーバー上にアップロードして実行できてしまう。既にCVE-2025-54948を悪用する攻撃が発生している。

　同社は、Apex One SaaSとTrend Vision One Endpoint Security - Standard Endpoint Protectionについて7月31日に対策を実施した。一方で、Apex One 2019 SP1には、影響を一時的に緩和するためのツール「FixTool_Aug2025」を提供中。FixTool_Aug2025の適用で悪用攻撃を防御できるが、管理コンソールのリモートインストール機能を利用できない制限を伴うという。Apex One 2019 SP1向けの修正方法を8月中旬に公開する予定だという。",[],[]
ラック、オラクルの「HeatWave GenAI」の導入支援サービスを開始（ZDNET Japan）,https://news.yahoo.co.jp/articles/db5cb7ac87615d44856f621bb21b311a385067d9,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250806-35236406-zdnet-000-1-view.jpg?exp=10800,2025-08-06T16:19:00+09:00,2025-08-06T16:19:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,416,"ラック、オラクルの「HeatWave GenAI」の導入支援サービスを開始の画像
ラックは8月6日、Oracleの「HeatWave GenAI」の導入支援サービスを開始した。生成AI利用の運用コストやセキュリティ課題を解決するとしている。

　同社は、HeatWave GenAIが企業の生成AIで使う拡張検索生成（RAG）の中でも業務データの活用を容易にできる特徴があると説明する。一般的なRAGに比べ迅速に構築でき、運用もシンプルで導入や維持のコストを抑えられるという。データベース内に大規模言語モデル（LLM）を組み込んでいることから、データを外部に出すことなく安全に生成AIを活用できるメリットがあるとした。

　新サービスでは、顧客への要件ヒアリングから概念実証（PoC）、本番展開までを一貫して支援する。業務データの取り扱い方針やシステム構成を含めたセキュリティ設計に対応して、安心な生成AI活用環境を構築するという。",[],[]
ダイキン、米Dynamic Data Centers Solutionsを買収--AIデータセンターに本格参入（ZDNET Japan）,https://news.yahoo.co.jp/articles/07955fd9723e79183757c912d2c47fae5591672d,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250806-35236404-zdnet-000-1-view.jpg?exp=10800,2025-08-06T15:54:00+09:00,2025-08-06T15:54:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,751,"ダイキン、米Dynamic Data Centers Solutionsを買収--AIデータセンターに本格参入の画像
ダイキン工業は8月6日、子会社のダイキンアプライドアメリカズを通じてAIデータセンター向け冷却システムを手掛ける米Dynamic Data Centers Solutionsを買収することで基本合意したと発表した。

　ダイキンは、Dynamic Data Centers SolutionsがAIデータセンター向けにサーバーラック単位による個別空調での独自冷却技術を有すると説明する。AIデータセンターでのデータ処理量の増加に応じたサーバーや周辺機器の電力消費量の増加と発熱の課題を効率的に解決するほか、独自の設備マネジメントシステムでラック単位の消費電力と発熱量の変動をリアルタイムに解析して自動制御する。運転データを学習した最適制御でデータセンターの省エネルギーに向けたソリューションを提供しているという。

　ダイキンは、この買収によりAIデータセンターでのソリューションに本格参入し、データセンター市場での競争力を高め、事業拡大を図ると表明。Dynamic Data Centers Solutionsが強みとする業務用大型空調機器や計装・制御などを組み合わせてデータセンター内の空間を冷却する方式に加え、サーバー個別冷却技術を取り込み、データセンターで求められるトータルなニーズに対応して、顧客の課題解決に貢献したいと述べる

　買収は、必要な手続きを経て8月下旬の完了を予定する。ダイキンは、北米市場を皮切りにグローバルな事業展開を加速して、AIデータセンター市場でのリーダーシップの確立を目指す。買収が完了次第、買収目的や今後の展開などの詳細を発表することにしている。",[],[]
OpenAI、「gpt-oss-120b」と「gpt-oss-20b」を発表--高性能かつ自由に使えるAIモデル（ZDNET Japan）,https://news.yahoo.co.jp/articles/402655c28efae02c2f48a6702b063a277689cf82,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250806-35236393-zdnet-000-2-view.jpg?exp=10800,2025-08-06T13:27:00+09:00,2025-08-06T13:38:56+09:00,ZDNET Japan,zdnet,ZDNET Japan,637,"OpenAI、「gpt-oss-120b」と「gpt-oss-20b」を発表--高性能かつ自由に使えるAIモデルの画像
OpenAIは8月5日、 オープンウェイト言語モデルの「gpt-oss-120b」と「gpt-oss-20b」をリリースすると発表した。推論タスクにおいて同規模のオープンモデルよりも優れたパフォーマンスを発揮する。

　gpt-oss-120bは、単一の80GB GPUで稼働し、コア推論ベンチマークで 「OpenAI o4-mini」とほぼ同等の結果を達成。gpt-oss-20bは、一般的なベンチマークで「OpenAI o3‑mini」と同様の結果を出し、16GBのメモリーを搭載したエッジデバイスで実行可能だ。

　OpenAIの「GPT-4o」などに基づく手法を組み合わせて学習しており、「Mixture-of-Experts（MoE）」を採用。gpt-oss-120bは合計117bパラメーターのうち、トークン当たり51億個がアクティブ、gpt-oss-20bは合計21bパラメーターのうち、トークン当たり36億個がアクティブになる。

 「Responses API」と互換性があり、ウェブ検索や「Python」コード実行などのツール利用が可能。複雑な推論を必要としないタスク向けに、「reasoning_effort」を調整する機能も搭載する。

　「Apache 2.0」ライセンスで提供し、個人利用から企業まで幅広く使える環境を目指す。",[],[]
日立システムズ、AI活用し水道管の劣化状態を分析--老朽化以外の漏水原因も発見（ZDNET Japan）,https://news.yahoo.co.jp/articles/ed28b8f09996e81027afdfee5bcb3b9720a2766f,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250806-35236390-zdnet-000-1-view.jpg?exp=10800,2025-08-06T12:23:00+09:00,2025-08-06T12:23:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,924,"日立システムズ、AI活用し水道管の劣化状態を分析--老朽化以外の漏水原因も発見の画像
日立システムズは8月6日、兵庫県内の水道事業体と連携し、AIを活用した水道管の劣化状態分析を実施したと発表した。老朽化だけでない漏水発生要因と漏水の可能性が高い水道管を確認できたという。

　水道管の劣化状態分析は、「CYDEEN 劣化要因分析支援サービス」を活用し実施したもの。複数の水道事業体が持つ水道管の管種や敷設年度などの諸元データや漏水履歴をはじめとした各種データを基に、CYDEEN 劣化要因分析支援サービスを用いて水道管の劣化要因と漏水発生の可能性をAIで分析したという。

　その結果、水道管の劣化要因が敷設年度だけでなく、管種、管路延長、水圧、地盤などとの複合要因であることを確認。加えて、さまざまな要因に基づいた漏水発生リスクのある水道管を抽出したという。

　これにより水道事業体は、限られた人員・予算の中で、漏水発生リスクの高い水道管から優先順位をつけて水道管の更新を計画できるため、より効果的、効率的な水道管の更新が可能となり、水の安定供給につなげる。

　このAIによる統計分析手法は、日立製作所が開発したデータ分析技術を基にしており、東京大学大学院情報学環「情報技術によるインフラ高度化」社会連携講座にて評価されたもの。異常状態を示すデータが少ない場合でも、データ同士の相関性などを見出すことで、損傷予測や影響度予測が可能だ。

　一般に水道管の劣化は経年が主な要因と考えられているが、実証の結果、（1）耐用年数を超えている敷設年度の古い水道管でも、漏水発生リスクが低いものが存在する、（2）敷設から30年未満の比較的新しい水道管においても、漏水発生リスクがあるものが存在する、（3）敷設年度だけでなく、管種や管路延長、水圧、地盤などが総合的に水道管の劣化に影響している――などが確認された。

　今後も日立システムズは、水圧や流量などのデータを活用した水道管の劣化診断の精度向上や、下水道管を対象にした劣化診断に取り組むなど、CYDEEN 劣化要因分析支援サービスを活用した水道インフラ維持管理に関する研究開発を進めていくという。",[],[]
NTTデータG、売上・利益はほぼ横ばい--クラウド・セキュリティで受注積み上げ（ZDNET Japan）,https://news.yahoo.co.jp/articles/7cd7609d51c706dd53d76458cdc63475e5a4d2b5,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250806-35236354-zdnet-000-1-view.jpg?exp=10800,2025-08-06T11:01:00+09:00,2025-08-06T11:01:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,3616,"NTTデータG、売上・利益はほぼ横ばい--クラウド・セキュリティで受注積み上げの画像
NTTデータグループの2025年度第1四半期（2025年4～6月）連結業績は、売上高が前年同期比0.7％減の1兆1043億円、営業利益は同1.4％減の577億円、税引前利益が同7.2%減の388億円、当期利益が同0.8%減の210億円、当期包括利益は同85.7%減の153億円となった。また、受注高は、前年同期比23.1%減の1兆1256億円となった。

　NTTデータグループ 代表取締役副社長執行役員の中山和彦氏は、「為替による影響は売上高で510億円のマイナスであり、これを除くと実質増収になっている。また、営業利益では為替影響による減益が12億円。これらの影響があっても、売上高、営業利益、四半期利益ともに前期並みの水準となった。受注高は、データセンター事業における大型受注の反動減により減少となった。第2四半期にはデータセンター事業における不動産投資信託（REIT）活用の影響もあるため、通期予想に対しては想定通りの進捗（しんちょく）とみている」と総括した。

　日本セグメントは、売上高が前年同期比8.5%増の4581億円、営業利益は10.6%増の353億円。受注高は577億円増の2312億円となった。「日本セグメントは、全ての項目において前年実績を上回った。公共・社会基盤、金融、法人は、いずれも増収となっている。受注では公共・社会基盤、金融での大型案件の獲得があった」とした。

　公共・社会基盤の売上高が前年同期比8.8%増の1763億円、営業利益は9.0%減の150億円。受注高は104億円増の2312億円。「増収減益となっているのは、前年同期の中央府省向けの高利益率案件の反動や、営業体制強化の販管費が計画通り増加していることが影響した」という。公共分野の今後の動向については、大規模システムの更改、省庁間をつないだシステム開発、官民連携システムの開発が積極的であり、引き合いは強いとしている。

　また、金融の売上高は前年同期比9.5%増の1730億円、営業利益は25.7%増の191億円。受注高は448億円増の1777億円。法人は売上高が前年同期比5.3%増の1394億円、営業利益は11.4%増の147億円。受注高は29億円減の909億円となった。

　海外セグメントでは、売上高は前年同期比6.1%減の6552億円、営業利益は同13.7%減の151億円。受注高は3387億円減の1兆1256億円となった。「為替影響を除くと増収となったが、営業利益では海外事業統合による費用増が30億円あり、減益になっている」という。

　そのうち、North America（北米）の売上高は前年同期比11.4%減の1502億円、営業利益は同17.1%増の89億円。受注高は87億円増の1564億円。「ヘルスケア分野における既存案件の剥落（はくらく）、米国の政権交代による公共案件の縮小が影響したが、受注では大型案件の獲得があった」という。

トランプ政権の影響で受注留保も、デジタル案件の獲得へシフト

　第1四半期には、2024年4月に設置した「Client growth office」を通じて、大手物流企業から案件を受注したという。

　だが、「Client growth officeの効果は出ているものの、本格的な展開までには時間がかかる。トランプ政権の影響があり、受注の最終段階で判断を留保するということが一部で起きている。実際、第1四半期に受注するはずだった複数の案件が、第2四半期にシフトしている。AI関連へのニーズは高いが、受注したものをしっかりと売上につなげられるかもテーマである」とした。政府系案件の縮小に対して、デジタル案件の獲得拡大を目指すという考えも示した。

　EMEAL（欧州・中東・アフリカ・中南米）の売上高は前年同期比6.9%減の2360億円、営業利益は同49.4%減の43億円。受注高は167億円減の2381億円。「為替影響を除くと増収。だが、ドイツなどでの減益が大きく影響した。デジタルトランスフォーメーション（DX）に対する需要があるが、自動車産業が不調である。ドイツの拠点では売上高の過半が自動車産業向けであり、影響を受けている。スペインや中南米は悪くはない。だが、業績予想に対する進捗率が低く、厳しい状況にある。グローバルでのベストプラクティスの活用やコストコントロールなどにより計画達成を目指す」としている。

　APAC（アジア・太平洋）の売上高は前年同期比11.6%減の821億円、営業利益は同10.1%減の62億円。受注高は37億円減の905億円。「減収減益の結果は、事業規模が大きいオーストラリアでの減速が影響している。いくつかの問題案件は終息傾向にあるが、営業体制の強化を行っており、リカバリーに向けて取り組んでいるところである。また、シンガポールやインドのビジネスは順調に進んでおり、クラウドやセキュリティを中心に受注を積み重ねている」と語った。

　また、海外セグメントにおけるGTSS（Global Technology and Solution Services）の売上高は前年同期比2.3%減の2106億円、EBITAは同53.4%増の247億円。受注高は3853億円減と大きく減少し、1154億円となった。

　「売上高とEBITAは、為替影響を除くと増収増益になっている。また、受注残高からの確実な展開も進めており、SAP事業も、堅調なクラウド移行などによって増収になった。EBITA率が増加しているのは、前年同期に利益率が低い初期構築および初期工事の割合が高かったことなどによる反動である。受注高は、データセンター事業で、前年度第1四半期に計上した大型案件の反動減によって大幅な減少になった。大型案件の受注タイミングにより増減が発生している」と説明した。
中期経営計画の最終年度は計画を上回る見通し

　データセンター事業は、売上高が前年同期比7700万ドル増の6億6500万ドル（961億円）、EBITDAが同7500万ドル増の2億6400万ドル（382億円）、営業利益が同6400億ドル増の1億4600万ドル（211億円）となった。

　「データセンター事業の利益率は改善しており、順調に進捗している。データセンターを取り巻く景況感もいい。データセンターに対する投資は、前期並みの水準で実施する」と述べた。

　データセンター事業に関しては、2025年7月に、NTT DC REITへの固定資産譲渡を完了しており、第2四半期に売上高として9億4300万ドル（1443億円）を計上するとともに、ほぼ同額の営業利益を計上する予定だ。第1四半期の投資実績は前年実績を上回る4億9600万ドル（717億円）であり、順調に進捗しているという。2025年6月末時点で、合計で約1500MWを提供しており、2025年度中には、約135MWを新規にリリースする予定だ。

　一方、NTTデータグループの2025年度（2025年4月～2026年3月）の連結業績見通しは据え置き、売上高は前年比6.4％増の4兆9367億円、営業利益は同61.2％増の5220億円、税引前利益が同72.7％増の4300億円、当期利益が同40.4％増の2000億円の増収増益を計画している。受注高は4兆7200億円を見込んでいる。

　2025年度は、中期経営計画の最終年度に当たり、計画を上回る見通しだという。

　なお、海外事業の統合の進捗状況についても説明。中山副社長は、「前年度までは、コーポレート機能の統合や、ITシステムの統合を中心としてきたが、2025年度からは、グローバルの競争力強化に向けて、業務プロセスの高度化、事業運営の最適化に取り組んでいる」とした。

　海外事業統合費用として、第1四半期には45億円を支出し、主にERPの統合を進めているという。2025年度通期では230億円を投下する計画である。

　NTTによる公開買付けの状況については、「2025年5月8日に公表したNTTによる株式公開買付けの結果、NTTは当社株式の81.75%を保有し、本公開買付けは成立した」と報告。「8月29日に開催予定の臨時株主総会における株式併合議案の可決をもって、9月30日にNTTの完全子会社になる予定である」とした。

　その上で、「NTTデータグループとして実行している経営方針などは変わらない。NTTグループ全体のなかで、データセンターへの投資や、合併・買収（M&A）の投資などを進めることができ、大規模な投資も可能になる。その点ではプラスになるとみている」と語った。",[],[]
試合観戦の楽しみを広げる、「Google Cloud」を用いたプロ野球のデータ活用（ZDNET Japan）,https://news.yahoo.co.jp/articles/7d04a25780379c91a69c1931d5fcde064ed6066c,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250806-35236344-zdnet-000-1-view.jpg?exp=10800,2025-08-06T10:10:00+09:00,2025-08-06T10:10:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,2537,"左からソニー 執行役員 平位文淳氏、NPBエンタープライズ 執行役員デジタル事業部長 丹羽大介氏、グーグル・クラウド・ジャパン テクノロジー部門 技術部長 安原稔貴氏
最近のテレビのスポーツ中継などでは、ボールや選手の動きをCGを活用して可視化したり、球速などのデータを数値表記したりすることで、単純な勝敗だけにとどまらず、選手の一つ一つのプレイの意味やそのすごさを視聴者に的確に伝え、その楽しみを大きく拡大するような取り組みが目立つようになってきた。

　大谷翔平選手の活躍でファンを増やした米大リーグ（MLB）の中継でも見られる取り組みだが、日本のプロ野球でも全球団共通のインフラを整備し、さまざまなデータ活用を可能にして既にテレビ中継でも活用が始まっているという。日本のプロ野球で導入されたシステムは、ソニーのグループ企業であるHawk-Eye Innovationsが開発し、さまざまなスポーツで審判補助システムとして活用されているトラッキングシステムから得られるデータを「Google Cloud Platform」上で処理し、テレビ局などに提供する形で実現されている。

　導入の背景を説明したNPBエンタープライズの執行役員デジタル事業部長の丹羽大介氏は、MLBのテレビ中継などで日本の視聴者もリアルタイムデータに基づいて生成されたデジタルコンテンツによって試合観戦の楽しみが増すといった体験をしていることを踏まえ、「データによって、より選手のすごさなどがファンに伝わると同時に、他の選手や過去のデータとの比較など、新しい楽しみ方ができるようになる。また、チームにとってもデータを活用して選手の育成や強化につながる。日本のプロ野球界は、今まさにデータ活用の新しい時代を迎えた」と語った。

　従来のやり方では、各球団が個別にデータを取得し、試合分析や育成強化に活用するといった個別利用の枠を出なかった。しかし、今回はNPBエンタープライズを中心に全12球団のデータを一括で管理する仕組みを構築したことで、野球界全体としてデータ活用を推進し、プロ野球の魅力をさらに高めることが可能になった。

　なお、システム開発にあたってはソニーおよびGoogle Cloudの協力も得て進めている。システム開発は複数フェーズに分けて段階的に進めているとのことだ。大きなビジョンとして「データによって選手のすごさ、プロ野球のすごさを伝えていきたい」とし、その目的に向けて「打球速度やボールの変化量などのデータをほぼリアルタイムで可視化するための自動CGコンテンツ生成システムなどを開発中」だとした。

　次に、ソニー 執行役員の平位文淳氏が、同社のスポーツデータビジネスに関する取り組みについて説明した。ソニーは2011年にHawk-Eye Innovationsをグループ企業に加え、日本でのサービス展開を担当している。

　Hawk-Eyeの審判技術判定支援サービスは、テニスやサッカーなど25種以上のスポーツ競技で審判の判定を支援するために活用されている。トップクラスの競技では審判の判定に対してビデオデータの確認を要求するシーンが見られるが、そうした際にHawk-Eyeのトラッキング技術が活用されており、例えばテニスでは200km/h以上のスピードのサーブがラインを割ったかどうか、ボールの軌道を2mm以内の精度で判定できるという。

　平位氏は「今回のトラッキング技術は、選手やボールの動きを高精度にデータ化し、審判判定や選手のパフォーマンス向上、コンディション把握などを目的として使われている。また、このデータをビジュアライズすることで、今まで見ることができなかったデータを可視化して提供したり、さまざまな角度や視点からプロ野球選手のすごさを伝えたり、そういったコンテンツが提供できる」と語った。

　2024年にプロ野球全12球団の本拠地球場へのHawk-Eye専用カメラおよびサーバなどの周辺システムの設置が完了した。その後ソニーは、Hawk-Eysから得られる打球、投球、選手のモーションなどの膨大なトラッキングデータを活用するためのコンテンツマネジメントシステム（CMS）を開発。さらにNPBと共にデータマネジメントプラットフォーム（DMP）を開発し、全12球団の公式戦のプレイデータを一元管理するほか、CMSにデータを提供し、コンテンツ化して活用できる基盤を整えたという。

　CMSおよびDMPの運用基盤としては、MLBにおけるHawk-Eye活用でも実績のあるGoogle Cloudが選定され、フルマネージド型のサービスプラットフォーム「Cloud Run」、データベースサービスの「Cloud SQL」、非構造化データ保存のマネージドサービスの「Cloud Storage」、API管理の「Apigee」、「Cloud GPU」、そして「Google Kubernetes Engine」（GKE）の運用モードの1つで、クラスタ構成をGoogleが管理する「GKE Autopilot」などが利用されているという。

　グーグル・クラウド・ジャパン テクノロジー部門 技術部長の安原稔貴氏は、Googleから提供されるものとして「技術的な優位性」「パートナーシップ」「リソースの柔軟性」を挙げた。

　プロ野球では同時に開催される試合数が日によって変わるため、Hawk-Eyeから出力されるデータ量も変動することになるが、この変動を吸収してコストを最適化する上でクラウドプラットフォームの利用が合理的となる。また、今回はGoogleが提供する「Tech Acceleration Program」（TAP）も活用されたという。

　TAPは、クラウド ネイティブ アプリケーション プロトタイピングで、内製化を支援するプログラムであり、ソニーの平位氏は「TAPを通じてサービス開発の早い段階からGoogleの各サービス専門のエンジニアの方々にアーキテクチャー設計や課題解決にご協力いただき、効率よく共に開発を進めることができた」と評価している。",[],[]
Cloudflare、PerplexityのAIクローラーがコンテンツを無断で収集と非難（ZDNET Japan）,https://news.yahoo.co.jp/articles/9806e5ea08598a09b774b270a1cbf9cb37023e31,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250806-35236374-zdnet-000-1-view.jpg?exp=10800,2025-08-06T09:08:00+09:00,2025-08-06T09:08:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,1465,"Cloudflare、PerplexityのAIクローラーがコンテンツを無断で収集と非難の画像
大手コンテンツ配信ネットワーク（CDN）のCloudflareが、人工知能（AI）スタートアップのPerplexityを非難している。Cloudflareの主張によれば、Perplexityは公式ボットのアクセスを明示的に拒否しているウェブサイトからコンテンツをスクレイピングするため、ウェブクローラーをひそかに配備してサイトの「クロール禁止」指示を回避しているという。

　Cloudflareによると、Perplexityのウェブクローラーは、サイトがコンテンツのクロールをブロックするために使用しているrobots.txtファイルを検出すると、「Mac」上で動作している通常の「Chrome」ウェブブラウザーのふりをすることで、ボットを防ぐ障壁を回避できるようにしている。

　Cloudflareが調査を始めたのは、複数の顧客から苦情を受けたためだ。これらの顧客は、「robots.txtファイルでPerplexityのクロール活動を禁止した上で、WAF（ウェブアプリケーションファイアウォール）ルールを設定して、Perplexityが公表している2種類のクローラー（『PerplexityBot』と『Perplexity-User』）を明示的にブロックしていた」という。にもかかわらず、自社のコンテンツが依然としてPerplexityに取り込まれていると述べていた。

　そこでCloudflareは、新しいテスト用ドメインを取得し、robots.txtファイルですべての自動アクセスを明示的に禁止するとともに、Perplexityが公表しているクローラーからのクロールをブロックするWAFルールを設定した。すると、Perplexityが同社の公開IPアドレス範囲に含まれていない複数のIPアドレスを交代で使用しながら、ひそかにサイトのコンテンツや記録にアクセスしていることが分かったという。

　Cloudflareは先ごろ、すべてのAIクローラーを自動でブロックするオプションを顧客に提供し始めた。また、AIクローラーのブロック機能を補完するため、パブリッシャーが自社のコンテンツのスクレイピングを希望するAI企業に対して料金を徴収できる「pay per crawl」プログラムも開始している。

　これに対し、PerplexityはCloudflareの主張は完全に誤りだとして、公の場で声高に反論している。同社はブログ記事で、次のように主張した。

この論争は、Cloudflareのシステムが正当なAIアシスタントと実際の脅威を区別する能力をそもそも備えていないことを示している。有用なデジタルアシスタントと悪質なスクレイパーを区別できないのであれば、何を正当なウェブトラフィックと見なすのかについて判断すべきではないだろう。

　これはかなり挑発的な発言だが、さらにPerplexityは次のように記している。「Cloudflareの分析における技術的な誤りは、恥ずかしいだけでなく、専門家としての能力の欠如を示すものだ。数百万件のリクエストの発信元を誤って解釈し、完全に不正確な技術図面を公開し、現代のAIアシスタントの仕組みを根本的に誤解していることを自ら明らかにした以上、この分野の専門家を名乗る資格はない」

この記事は海外Ziff Davis発の記事を朝日インタラクティブが日本向けに編集したものです。",[],[]
バックオフィス担当者の約8割が生成AIを活用--エイトレッド調査（ZDNET Japan）,https://news.yahoo.co.jp/articles/5407d698d587c0121e0d5d9a71c0ffef1c9d0163,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250806-35236375-zdnet-000-1-view.jpg?exp=10800,2025-08-06T09:02:00+09:00,2025-08-06T09:02:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,1062,"戦略を練る人物
エイトレッドは8月5日、バックオフィス業務に携わりDX推進を行っている担当者110人を対象に、AI活用の実態に関する調査を実施したと発表した。調査によると、生成AIを業務に活用している担当者は約8割に上り、特に「文書の確認・校正・チェック」で効果を実感している人が約7割に達した。

　現在のバックオフィス業務における課題としては、「特定の人しかわからない業務がある」が57.3％で最も多く、「デジタル化されていない業務に時間がかかる」（47.3％）、「複数のシステムにデータが分散している」（43.6％）といった声も多く挙がった。また、生成AIによって自動化・効率化したい業務としては、「文書の確認・校正・チェック」（56.4％）、「データ集計・分析」（53.6％）、「データ入力・転記」（51.8％）が上位を占めた。

　情報収集における生成AIツールの活用状況では、「多くの情報収集で活用している」が40.9％と最も多く、「ほぼすべての情報収集に活用している」（7.3％）と合わせると、約半数が積極的に活用していることが分かった。現在のバックオフィス業務全体で生成AIツールを活用している割合は約8割に達し、「ほぼすべての業務に活用している」が6.4％、「多くの業務で活用している」が40.9％、「一部の業務で活用している」が29.1％となっている。

　生成AIツールの導入によって効果を実感した業務では、「文書の確認・校正・チェック」が69.0％で最も多く、「データ入力・転記」（53.6％）、「データ集計・分析」（52.4％）が続いた。一方で、活用における課題としては、「期待する結果を得るための質問の仕方が難しい」が66.7％と最も多く、「生成内容の確認に時間がかかる」（48.8％）、「使い方や研修が不足している」（32.1％）といった声も見られた。生成AIツールを導入していない理由としては、「セキュリティ・機密情報漏洩のリスク」と「生成AIの回答精度への不安」がともに44.0％で最多となった。

　今後の業務における生成AIの活用については、約9割が「拡大予定」と回答しており、「大幅に拡大する予定」が20.2％、「ある程度拡大する予定」が67.9％となった。理想的なバックオフィスの働き方としては、「人間は戦略的・創造的業務に集中」が50.9％で最も多く、「リモートワークなど柔軟な働き方が定着している」（46.4％）、「スキルアップに取り組める」（42.7％）といった回答が続いた。",[],[]
「GPT-5」は真のゲームチェンジャーになれるか--カギを握る重要な機能とは（ZDNET Japan）,https://news.yahoo.co.jp/articles/c6ba71a823327443a1c42e4c7821cac803e48565,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250806-35236371-zdnet-000-1-view.jpg?exp=10800,2025-08-06T09:00:00+09:00,2025-08-06T09:00:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,1548,"提供：Elyse Betters Picaro / ZDNET
2022年に初めて「ChatGPT」が登場して以来、OpenAIはAI開発競争の最前線に立ち、次々と新しい製品やモデル、アップデートを発表してきた。そのため、リリース情報を見逃してしまうこともあるが、「GPT-5」は見過ごせない重要な製品である。その理由について説明する。

　OpenAIの最高経営責任者（CEO）であるSam Altman氏は、2月にGPT-5の登場を予告した際、このモデルの注目すべき機能として、特定のクエリーに対して最適なモデルを自動で選択する仕組みに言及した。この機能は、「o」シリーズの推論モデル（高品質な回答を生成）と「GPT」シリーズのモデル（処理速度が速く効率的）を統合することで実現される。ユーザーがどちらのモデルを使うべきかを自分で判断する必要がなくなることが狙いだ。

　ChatGPTの責任者であるNick Turley氏は米ZDNETの取材に対し、「われわれは、これらのアイデアを全てGPT-5のようなモデルに統合したいと考えている。つまり、ChatGPTは人間同士の会話のように、考えてから答えることもあれば、即座に答えることもある。答えた後も考え続けることがあるだろう」と語っている。

　この機能は、ユーザーにとって大きな助けとなる可能性がある。現在のOpenAIのモデル群には、「GPT-4o」や「o4」など、似たような名称が付けられているが、それぞれ異なるタスクに最適化されている。そのため、どのモデルを使うかによって回答の質が大きく変わるにもかかわらず、適切なモデルを選ぶのは一般ユーザーにとって難しい。

　Turley氏は「われわれの目標は、ユーザーがどのモデルを使うべきか悩まなくて済むようにすることだ」と述べており、GPT-5はユーザーのタスクに応じて最適なモデルを自動で選択することを目指している。

　例えば、簡単な質問であればGPTモデルを選択し、低コストかつ高速に回答する。一方、STEM分野のような複雑な問題には、より深い思考が可能なモデルを選ぶ。なお、パワーユーザーは引き続き使用するモデルを手動で選択することも可能だ。

　GPT-5のリリース時期について、Altman氏は当初、2月の発表から数週間から数カ月以内の公開を予定していた。しかし、開発が思うように進まず、4月にはリリースの延期を発表している。

　Turley氏は、「人々の好みはそれほど単純ではないことが分かった。優れた回答が得られるなら、多少時間がかかっても構わないという人もいるが、それは回答の質が明らかに高い場合に限られる」と述べており、こうしたユーザーの期待に応えるため、時間をかけて慎重に機能開発を進めているという。

　Altman氏が「X」に投稿した内容によれば、GPT-5では推論モデルとGPTファミリーのモデルを統合するだけでなく、「音声」「キャンバス」「検索」「ディープリサーチ」など、ChatGPTの最新機能も全て組み合わせる予定だ。これにより、ユーザーはChatGPTが提供する多様な機能をより効果的に活用できるようになる。中には、あまり知られていないが強力な機能も含まれる。

　課題は残るものの、幸いにもユーザーはそれほど長く待たずに済みそうだ。The Vergeが内部情報筋の話として報じたところによると、GPT-5は8月上旬にリリースされる可能性があるという。

　Turley氏も「目標はおおむね既報通りであり、近日中に詳細を発表する予定だ」と述べている。

この記事は海外Ziff Davis発の記事を朝日インタラクティブが日本向けに編集したものです。",[],[]
BeeX、週末移行を可能にする「SAP S/4HANA」向け新サービスを発表（ZDNET Japan）,https://news.yahoo.co.jp/articles/a7d0875475fb8d32bbd50d070e63b0383cef6a12,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250806-35236373-zdnet-000-1-view.jpg?exp=10800,2025-08-06T08:54:00+09:00,2025-08-06T08:54:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,1196,"BeeX、週末移行を可能にする「SAP S/4HANA」向け新サービスを発表の画像
BeeXは8月5日、SNP Japanとのパートナーシップ締結を発表し、SNPの高度なデータ変換プラットフォーム「Kyano プラットフォーム」を活用した新サービス「BeeX Swifty Moving Service」を発表した。このサービスでは、従来長時間のシステム停止（ダウンタイム）が必要だった「SAP S/4HANA」への移行において、ダウンタイムを通常2日間程度に短縮することで、移行リスクの低減とプロジェクト期間の短縮を実現し、安全かつ効率的な移行を支援する。

　企業のDX推進においては、老朽化・複雑化した基幹システムの刷新が不可欠となっており、特にSAP ERP基盤では、2027年に迫る「SAP ERP 6.0」の標準保守終了を前に、SAP S/4HANAへの早期移行が求められている。しかし、移行プロジェクトの長期化、対応リソースの確保、移行時の業務停止などの課題が多く、移行に踏み切れない企業も少なくない。

　BeeX Swifty Moving Serviceは、こうした課題に対応するため、SAP S/4HANA移行におけるダウンタイムの削減と移行リスクの低減を図るものである。BeeXがこれまでに手がけてきた多数のSAP S/4HANA移行・クラウド移行プロジェクトで培った高度なBASISスキルとノウハウに加え、SNPの「Kyano Move」テクノロジーを活用することで、従来の移行手法と比べて圧倒的に短いダウンタイムでの移行を可能にする。

　Kyano Moveの技術とBeeXのノウハウを組み合わせることで、SAP S/4HANAの移行作業時間（テクニカルダウンタイム）を最大でも48時間程度に短縮。これにより、従来は年末年始やゴールデンウィークなどの長期休暇に限られていた移行タイミングを、通常の週末に実施できるようになり、プロジェクトスケジュールの柔軟な設定が可能となる。

　さらに、システムとデータを分離し、システム部分のみをコンバージョンすることで、非Unicodeシステムからの移行、選択的データ移行、段階的なカットオーバー、システム統合・分割、アドオン削減など、企業ごとの多様なニーズにも対応できる。

　BeeXは今後、Kyano Moveによる「週末マイグレーション」を皮切りに、Kyano プラットフォームが提供する各種サービスや、「Kyano MarketPlace」上に展開されるサードパーティーサービスを活用し、SAP S/4HANA移行プロジェクトにおける各タスクの自動化・効率化を進めることで、移行期間の短縮や必要リソースの最小化を図る。また、移行完了後には、データアーカイブやデータ活用の促進など、関連サービスの拡充も予定している。",[],[]
東レ、「Centric PLM」導入で商品開発の可視化と収益管理の高度化へ（ZDNET Japan）,https://news.yahoo.co.jp/articles/255f4f8ebbe4c86445a9b7930ceb54dd685be686,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250806-35236372-zdnet-000-1-view.jpg?exp=10800,2025-08-06T08:45:00+09:00,2025-08-06T08:45:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,953,"東レ、「Centric PLM」導入で商品開発の可視化と収益管理の高度化への画像
Centric Softwareは8月5日、総合素材メーカーである東レグループの東麗（香港、以下東レ）が、「Centric PLM」の導入プロジェクトを正式に開始したと発表した。今回の導入により、商品開発業務の基盤を強化し、主要顧客のニーズに迅速に対応できる体制の構築を目指す。

　近年、東レでは市場のニーズが多様化・高度化する中、取引先からの要求にも柔軟かつ迅速に対応する必要性が高まっている。従来は部門や拠点ごとに分散していた商品開発・生産に関する情報を集約・可視化することが喫緊の課題となっており、今回のCentric PLM導入によって、商品企画から量産までのプロセスを横断的に一元管理する体制の整備を進める。

　このプロジェクトでは、生産管理の主拠点である東レ香港を対象に、開発の進行状況や収益性、予算と実績のコスト管理の精度向上を図る業務基盤の整備が進められる。これにより、業務プロセスの整流化、コスト構造の透明化、納期精度の向上、さらには部門間・拠点間の円滑な情報連携が可能となる。Centric PLMは、柔軟な構成と高い拡張性に加え、縫製工場やアパレル業界での豊富な導入実績を持つ業界特化型ソリューションである点が評価され、検討段階から社内の多くの関係者の理解と賛同を得て、プロジェクトが正式に始動した。

　東麗（香港） 業務推進部のGeneral Managerである岸耕太郎氏は、「クライアントが求める付加価値を提供するために、開発情報を上流から量産まで一貫して管理できる体制の構築を目指している。Centric PLMは、当社が重視する開発管理能力の強化に対して、柔軟かつ実効性の高いソリューションで応えてくれると確信し、導入を決定した」とコメントしている。さらに、「開発情報の一元化により、業務の透明性と判断精度を高め、継続的な業務改善とクライアントへの価値提供につなげていきたい」と、Centricとのパートナーシップへの期待を示した。

　今後は、PLMを中核とした商品開発プラットフォームの構築を通じて、顧客ニーズへの対応力を強化し、収益性と競争力のさらなる向上を図っていく方針である。",[],[]
「ChatGPT」に長時間利用へのリマインダー機能など導入--重要な選択への応答をより慎重に（ZDNET Japan）,https://news.yahoo.co.jp/articles/5f6b4297e5c5f91fa7ae2432b4b55a9c7eb1ae27,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250806-35236369-zdnet-000-1-view.jpg?exp=10800,2025-08-06T08:21:00+09:00,2025-08-06T08:21:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,1230,"提供：Elyse Betters Picaro/ZDNET
OpenAIは「ChatGPT」の大規模なアップデートを控える中で、安全性と信頼性の向上にも力を入れている。米国時間8月4日に公開されたブログ投稿では、ChatGPTをより役立つ存在にするために行われた、あるいは現在進行中の更新内容が紹介されている。これにより、ユーザーが支援を必要とする場面で、より適切な応答が得られるようになり、長時間の使用時には休憩を促す機能も導入された。

　ChatGPTを使ったことがある人なら、会話に夢中になって時間を忘れてしまった経験があるだろう。その応答は非常に興味深く、自然な会話が続くため、やりとりを止めるタイミングを見失いがちだ。特に、画像を生成して修正し、自分のニーズに合ったものを作るような楽しい作業では、その傾向が顕著である。

　こうした状況に対応するため、OpenAIは長時間のやりとり中に休憩を促す通知を導入した。今後も、この通知がより自然で役立つ形になるよう調整が続けられる予定である。

　近年では、ChatGPTに助言や支援を求める人が増えている。その背景には、会話能力の高さ、いつでも利用できる利便性、そして相手が自分を知らず、判断しないという安心感がある。OpenAIはこのような使われ方を認識しており、幻覚（ハルシネーション）への対処や、共感や認識の欠如を防ぐためのガードレール（安全策）を追加している。

　例えば、「GPT-4o」モデルは妄想や感情的依存の兆候を認識する点で不十分だったが、OpenAIは精神的・感情的な苦痛の兆候を検出するツールの開発を進めており、ChatGPTが適切に応答し、最適なリソースを提供できるようにしている。

　さらに、ChatGPTは今後、重要な個人的決断に関する新しい応答スタイルを導入する予定である。「彼氏と別れるべきか？」といった大きな問いに対しては、即答するのではなく、選択肢を整理しながら考える手助けをするようになる。このアプローチは、最近発表された「学習モード」に似ており、ユーザーが答えにたどり着くまでの過程を、質問を通じて導くものである。

　OpenAIはこうした改善を進めるにあたり、30カ国以上の90人の医師、精神科医、ヒューマンコンピューターインタラクション（HCI）研究者と密接に連携している。また、メンタルヘルス、子どもの発達、HCIの専門家による諮問グループも設置している。

　ただし、これらのアップデートがあっても、AIには幻覚のリスクがあり、機密情報を入力することにはプライバシーやセキュリティ上の懸念が伴う。OpenAIの最高経営責任者（CEO）であるSam Altman氏も先ごろ、ChatGPTに機密情報を入力することのプライバシー懸念について言及している。

この記事は海外Ziff Davis発の記事を朝日インタラクティブが日本向けに編集したものです。",[],[]
グーグル、「Android」上でネイティブ開発を可能にする「Linux」ターミナルアプリを開発中（ZDNET Japan）,https://news.yahoo.co.jp/articles/b81377b54250bd2eccda3d8edde302b3235eb905,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250806-35236366-zdnet-000-1-view.jpg?exp=10800,2025-08-06T07:53:00+09:00,2025-08-06T07:53:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,1277,"提供：Jack Wallen/ZDNET
「Android」には、完全なテキストベースの「Linux」環境を実行できるターミナルアプリが存在する。このアプリは、Androidの「開発者向けオプション」機能から有効化でき、ユーザーはLinuxコマンドやSSHなどを実行可能である。

　しかし、Googleの視点から見ると、それだけでは十分とは言えなかったようだ。

　にもかかわらず、年次の開発者向けイベント「Google I/O」で、LinuxターミナルアプリについてGoogleが一切言及しなかったのは、少々不可解である。ただ、その沈黙の裏では新たな動きがあり、Googleが開発者向けに新しい形のLinuxターミナルアプリをリリースしようとしていることが示唆されている。

　この新しいターミナルアプリでは、開発者がAndroidデバイス上で直接Androidアプリを構築できるようになる見込みだ。従来は、デスクトップOS上でエミュレーターを使って開発する必要があったが、これは大きな転換点となる。

　新ターミナルアプリは、「Android Virtualization Framework」を活用し、仮想マシン上で「Debian」イメージを起動する仕組みとなる。これにより、開発者は必要なツールを使ってネイティブアプリを構築できる、完全なLinux開発環境が提供される。

　ただし、統合開発環境の「Android Studio」はARMベースのCPUに対応していないため、Androidデバイス上のLinux環境では動作しない。この問題を解決するには、GoogleがLinux版のAndroid StudioにARM対応を追加する必要があるだろう。

　さらに、Android Authorityによると、7月末にリリースされたAndroidのCanaryビルドには、LinuxのGUIアプリのサポートが含まれているという。記事によれば、「Pixel 8 Pro」上で「Chromium」「GIMP」「LibreOffice」など複数のGUIアプリが実際に動作したとのことだ。

　つまり、Googleは開発者がAndroidデバイス上で直接アプリを作成・構築できるようにするだけでなく、Linuxのグラフィカルアプリ、さらにはゲームまで実行可能にしようとしている。Android端末を外部モニター、マウス、キーボードに接続して使うことを想像すれば、その可能性は非常に広がる。

　この取り組みは、Googleが進めるAndroidと「ChromeOS」の統合にも関係している可能性があり、従来のデスクトップユーザーやパワーユーザー、ゲーマーに訴求するアプリを開発できる統合プラットフォームの構築につながるかもしれない。

　なお、この機能がいつ正式に展開されるかは明らかになっていないが、まずはPixelデバイスに導入されることになるだろう。

この記事は海外Ziff Davis発の記事を朝日インタラクティブが日本向けに編集したものです。",[],[]
グーグル、AIモデルの性能をゲームで評価する「Game Arena」を発表（ZDNET Japan）,https://news.yahoo.co.jp/articles/25f8679c51c66c39e07f843ddb7d605d05ef7aac,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250806-35236365-zdnet-000-1-view.jpg?exp=10800,2025-08-06T07:30:00+09:00,2025-08-06T07:30:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,2045,"提供：Google
人工知能（AI）の進化に伴い、個々のモデルの性能を正確に測定することがますます困難になってきている。こうした課題に対応するため、Googleは米国時間8月4日、「Game Arena」を発表した。

　同社のブログ投稿によると、これは、AIモデルがさまざまな戦略ゲームで競い合うことで、「その能力を検証可能かつ動的に測定する」ことを目的としたオープンソースのプラットフォームだという。

　Game Arenaは、Google傘下のプラットフォームである「Kaggle」上にホストされている。Kaggleは、機械学習の研究者たちがデータセットを共有したり、さまざまな課題に挑戦して競い合ったりする場として広く知られている。

　この取り組みは、AI分野が人工汎用（はんよう）知能（AGI）に近づきつつある中で、モデルの能力を測定する新たなテスト手法を模索する研究の一環でもある。AGIとは、一般的に人間の脳と同等の認知タスクをこなすことができる理論上のシステムと定義されている。

　Game Arenaの狙いは、既存のAIモデルの能力を押し広げると同時に、それらの性能を分析するための明確で制約のある枠組みを提供することにある。

　同社はブログ投稿で、「ゲームは成功の明確であいまいさのないシグナルを提供する」と述べている。「ゲームの構造化された性質と測定可能な成果は、モデルやエージェントの評価に最適なテスト環境となる。戦略的思考、長期的な計画、そして知的な対戦相手に対する動的な適応など、ゲームがモデルに要求する多様なスキルは、問題解決能力としての一般的な知性を測る強力な指標となる」

　さらに重要なのは、ゲームがスケーラブルであるという点である。難易度を容易に引き上げることができるため、理論的にはモデルの能力をさらに高めることが可能となる。Googleは、「目標は、モデルがより強力な競争相手と対峙（たいじ）することで難易度が増していく、拡張可能なベンチマークを構築することだ」と述べている。

　最終的には、この取り組みがゲームの領域を超えた進展につながる可能性もある。Googleは、モデルがゲームプレーに熟達するにつれて、技術の可能性に対する理解を再構築するような驚くべき新戦略を示すかもしれないと指摘している。また、ゲームにおける計画、適応、そしてプレッシャー下での推論能力は、科学やビジネスといった、より経済的に実用的な分野で複雑な課題を解決するために必要な思考と類似しているとも述べている。

　AIとゲームの関係は、今に始まったことではない。AIという分野は、20世紀半ばにゲーム理論とともに発展してきた。ゲーム理論とは、競合する主体間の戦略的相互作用を数学的に研究する学問である。現在のAIモデルは、基本的に自分自身と何百万回もゲームを繰り返しプレーし、あらかじめ定められた目標（次のテキストのトークンを予測することや、現実世界の物理を描写する動画を生成することなど）をどれだけ達成できたかに基づいて性能を洗練させていく。

　ゲームは、AI研究者がモデルの性能や能力を評価するための重要なベンチマークとして、長年にわたり活用されてきた。例えば、Metaの「Cicero」は、人間がプレーしたボードゲーム「Diplomacy」の何百万ものゲームを分析するように訓練された。CiceroはLLMを用いて、Diplomacyをプレーする際に人間が発言すると考えられる言葉をタイプすることでゲームを進行させた。その性能は、人間ユーザーとのゲームプレーを通じて、戦略的な意思決定能力と自然言語によるコミュニケーション能力によって評価された。

　また、ゲームは一般の人々にとっても理解しやすい文脈を提供する。例えば、AIモデルが人間の専門家を凌駕（りょうが）してコンピューターコードのデバッグを行ったと聞いても、非専門家にはそのすごさが伝わりにくいかもしれない。しかし、チェスのグランドマスターがコンピューターに敗北したと聞けば、1997年にIBMの「Deep Blue」がGary Kasparov氏を破ったときのように、感情的なインパクトは非常に大きい。

　さらに、ゲームはアルゴリズムの新たで予期せぬ振る舞いを明らかにする手段にもなる。AIの歴史の中でも特に有名で、時に物議を醸した瞬間のひとつが、2016年に「AlphaGo」が囲碁のチャンピオンであるLee Sedol氏と対戦した際の「Move 37」である。この一手は当初、人間の専門家たちを困惑させ、「論理に反している」とまで言われた。しかし、ゲームが進むにつれて、この手が実は型破りで創造的な妙手であり、AlphaGoがSedol氏に勝利するためのカギとなったことが明らかになった。

この記事は海外Ziff Davis発の記事を朝日インタラクティブが日本向けに編集したものです。",[],[]
ピュア・ストレージ、進化するDFMとアーキテクチャーでAI時代のボトルネックを解消（ZDNET Japan）,https://news.yahoo.co.jp/articles/82363ef2f9238147e5476418f7f6f1e2dda8a832,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250806-35236287-zdnet-000-1-view.jpg?exp=10800,2025-08-06T07:10:00+09:00,2025-08-06T07:10:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,4040,"Pure StorageのMatt Oostveen氏
現在のITの主役はデータとAIとなり、必然的に、データを保存してアクセスするためのストレージやデータマネジメント機能が脚光を浴びている。動きが速いのはやはりソフトウェアのレイヤーであり、クラウド上で提供されるデータレイクハウスなどに注目が集まる一方、ハードウェアと密接に関わるストレージアプライアンスの領域でもAI時代に対応すべく、さまざまな技術革新が続いている。

　2025年6月にLas Vegasで開催されたPure Storageの年次イベント「Pure//Accelerate 2025」でも、ストレージ関連のさまざまな取り組みが発表された。ここでは、よりユーザーに近い立場から、技術に関して情報を発信する人物から最新動向を聞く機会があったので、紹介したい。

AI時代を見据えたアーキテクチャーの検討

　業界に先駆けて“Evergreen”という消費型モデルでのストレージ提供を始めたPure Storageは、一方でハードウェアの進化に関しても積極的な研究開発を継続しており、ハイパースケーラーを始めとするさまざまなクラウド基盤を支える存在となっている。

　同社はハードウェアの進化にも積極的で、HDDとの互換性を維持したSSDではなく、半導体ベンダーからフラッシュメモリーチップを購入し、独自のモジュールとして組み上げた「Direct Flash Module」（DFM）の開発に注力しており、年々容量を倍増させることでコストパフォーマンスを大幅に引き上げている。

　また、AIワークロードを強く意識した新製品「FlashArray//EXA」では、メタデータの格納領域とデータの格納領域を分離し、メタデータに対するアクセスパターンを踏まえた最適化を行うことで、この部分のボトルネックを解消し、全体のパフォーマンスを引き上げる。一方で、Pure Storageとは異なるアーキテクチャーでAIワークロード向けストレージを設計しているベンダーも存在しており、典型的にはSDS（Software-Defined Storage）に基づく大規模な分散型システムで並列度を高めたストレージシステムがAIデータセンターに導入されている。こうしたアプローチの違いについて、ユーザーはどのように考えていけばいいのだろうか。

　日本を含むアジア太平洋地域（APAC）で技術情報の発信などを担当するMatt Oostveen（マット・ウーストビーン）氏は、大規模なAIデータセンターを構築する際のユーザーの課題として「スケーラビリティー」を挙げた。FlashArray//EXAのアーキテクチャーについて同氏は「データノードとメタデータを分離し、それぞれを最適化してGPUコアから直接通信できるようにするという考え方は極めて論理的に導かれたものだ。まずはわれわれが先陣を切る形になったが、今後さまざまなベンダーが同様のアプローチを採用することになるだろう」と自信を示した。

　同氏は現在のAIを取り巻く状況について、人材も処理能力も不足しているため、期待される成果が実現できていないと指摘する。AIを使えばこのようなことができるはず、というアイデアが次々と浮かぶが、それを実現するためのデータサイエンティストやAI開発者が足りず、また目的に合うようなモデルを考えても、あまりに規模が大きいために学習のための演算性能も確保出来ないなど、現実の制約が足を引っ張っている状況だと同氏は言う。

　そうした状況を改善するためのパフォーマンス向上の手段として、FlashArray//EXAのアーキテクチャーが設計された。目標性能として「NVIDIAのGPUが採用しているインターコネクトのデータ転送速度を上回る」ことを目指した結果、「FlashArray//EXAは地球上で最速のシステムだ」と同氏は強調した。

　また、大規模な分散型SDSとの比較に関してOostveen氏は「それほど大きく異なっているわけでもない」とも言う。並列度を高めていくという基本的な考え方は共通で、FlashArray//EXAも充分なスケーラビリティーを確保している上、進化した「Pure Fusion」を活用することで広域に分散配置したシステムを仮想的に統合して運用管理をシンプル化することも可能だ。

ユーザーの反応

　Oostveen氏は、既にAPAC地域の顧客と対話を重ねており、一部では概念実証（PoC）も始まっていると明かした。同氏は「APAC地域は米国について洗練されたユースケースが豊富な地域となっている。日本、韓国、インドなどだ。台湾もそう言えるが、台湾のユースケースは主に半導体業界におけるEDA（Electoric Design Automation）にフォーカスしている」という。

　日本、韓国、インドのAI関連投資は旺盛で、西ヨーロッパ諸国を上回っているという。そうした積極的な投資の背景にあるのは、処理したいAIワークロードに対して、利用可能なデータセンターをはじめとする演算リソースが圧倒的に不足しているという現実だ。AIデータセンターが不足しているため、建設しなくてはいけない。それと同時に、冷却能力も電力も不足している。

　同氏は「Pure Storageでは、GPUを休みなく動かし続けられるだけのペースでデータを供給できるストレージを開発すると同時に、消費電力の削減にも取り組んでいる。現在のデータセンターでは、消費電力量のうち平均25％がHDDによるものだが、HDDをわれわれのDFMに置き換えることでこの25％の消費電力量は1～2％にまで低下する」と説く。単にパフォーマンスだけに注目するのではなく、消費電力量や運用負荷など、さまざまな要件をバランスよく満たすことが重要だとした。

　現時点ではGPUの性能向上と消費電力量の増加が同時に起こっており、電力の確保は差し迫った課題となっている。AIワークロードを処理するためにはより多くの電力をGPUに回す必要があり、GPU以外の各種リソース、この場合はストレージが消費する電力量は少ないほど良いということになる。つまり、高性能であっても電力を大量に消費するようなストレージは実際には運用できないと言わざるを得ず、単に性能だけを指標にシステムを選定することはできないのだ、という指摘だと理解すべきだろう。

　毎年6月に開催されるPure//Accelerateにおいて、最新のDFMモジュールが披露されることが恒例となっている。フォームファクターは同一ながら、毎年前年の2倍の容量を実現しているDFMの進化はかつてのCPUにおけるムーアの法則をほうふつとさせるものだが、2025年は300TBモジュールの実物を見ることができた。ただし、まだラボレベルの試作品で、現存するのは1つだけという。テストや検証のために同氏が自らハンドキャリーで持ち歩いているという。

　容量やパフォーマンスを向上させつつ消費電力は削減していく、という技術的な難題に対する同社の回答がDFMだとはいえ、スペース効率に関しても大きな優位性を発揮する源泉となっている。
最先端のAIデータセンターでの採用事例

　2025年初頭にPure Storageは「主要ハイパースケーラーにおいてPure Storageが“Design win”を獲得した」と公表した。これはオールフラッシュストレージの歴史の中でもエポックメイキングな出来事であり、さまざまな点で優位でありながらもバイト単価に関してのみHDDに負けている、と考えられてきたフラッシュストレージがついにHDDを上回るタイミングだったと理解していいだろう。

　Pure Storageでハイパースケーラー向けビジネスを担当するBill Cerrera（ビル・セレラ）氏は、Metaの決定について「彼らが選定したのはDFMとそれを制御するためのソフトウェアレイヤーの組み合わせだ」と強調し、単にフラッシュメモリとHDDが比較されたわけではなく、システムとして総合的な評価が行われた結果だと語った。

　その上で同氏は、「もちろんバイト単価も比較検討要素だったが、それ以外にも電力消費量やパフォーマンスの一貫性、レイテンシーや実装密度など、多岐にわたる検討が行われた」という。なお、評価の対象となったDFMは、その時点で実用段階にあった75TBのDFMだという。現在は150TBモジュールが入手可能になっており、こちらを採用すれば性能面でさらに有利な結果が出ることになると思われるため、DFMの容量が毎年2倍のペースで拡大している現在、もはやHDDとの差は開く一方だろう。

　なお、Pure Storageとしては米国ベースのハイパースケーラー各社とのビジネス展開を進めており、Metaに続く採用を獲得すべく活動しているそうだ。そこでまず世界最大級のクラウド事業者との協力によってソリューションを確立し、その後その経験を日本のクラウド事業者などに展開していくことになるだろうとした。

　日本でも世界レベルのシステムが存在しているHPC／スーパーコンピュータの領域についての取り組み状況について聞いてみたところ、「そうしたユーザーの要求は確かにハイパースケーラーと同様の部分があるが、ストレージベンダーとしての立場からいうと、HPC／スーパーコンピュータの構築は数年に1回しか起こらないイベントなのでハイパースケーラーとはモデルが異なってくる」との回答だった。日本国内では同社が直接動くのではなく、パートナーを介してさまざまなユースケースが開拓されることになりそうだ。

（取材協力：ピュア・ストレージ・ジャパン）",[],[]
Anthropic、「Claude Opus 4.1」を発表--前モデルから3カ月で性能向上（ZDNET Japan）,https://news.yahoo.co.jp/articles/7cbc30ab02552a53efd69aa3bf2420c2f7e7b240,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250806-35236363-zdnet-000-1-view.jpg?exp=10800,2025-08-06T07:00:00+09:00,2025-08-06T07:00:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,1342,"提供：Anthropic / ZDNET
Anthropicは5月、「Claude Opus 4」をリリースした。このモデルは「これまでで最も強力なモデル」であり、「世界最高のコーディングモデル」と位置付けられている。そして、わずか3カ月後には、その性能をさらに高めた「Claude Opus 4.1」が登場し、前モデルの称号を引き継ぐ形で発表された。

　Opusシリーズは、複雑な課題に対応するために設計された、Anthropicの中でも最も高度で知的なAIモデル群である。その中でも、米国時間8月5日にリリースされたClaude Opus 4.1は、エージェント型タスクの遂行、実世界のコーディング、推論能力において、前モデルを上回る性能を発揮すると同社は説明している。

　このモデルの発表は、OpenAIの「GPT-5」のリリースを間近に控えているタイミングでもあり、注目を集めた。

　Opus 4の最も印象的な活用例のひとつが、「SWE-bench Verified」でのパフォーマンスである。これは、「GitHub」から抽出された実際のソフトウェアエンジニアリング課題に対する大規模言語モデル（LLM）の解決能力を評価するベンチマーク「SWE-bench」の中でも、人間によってフィルタリングされたサブセットである。Opus 4はこのベンチマークで非常に高い評価を得ており、「世界最高のコーディングモデル」との主張を裏付ける結果となった。そして、今回のOpus 4.1は、その性能をさらに上回る成果を示している。

　Opus 4.1は、他のベンチマークでも前モデルを上回っている。例えば、多言語能力を測る「MMMLU」、高校レベルの数学競技問題に対する厳密性を測る「AIME 2025」、大学院レベルの推論能力を評価する「GPQA」などが挙げられる。さらに、OpenAIの「o3」やGoogleの「Gemini 2.5 Pro」といった競合モデルとの比較においても、SWE-bench Verifiedを含む複数のベンチマークで優れた成績を収めている。

　このリリースに際し、Anthropicはモデルに関する「システムカード」も公開している。これは、モデルに対して実施された安全性評価や検証、そしてその弱点やリスク、限界などを詳細に記した22ページの文書である。概要によれば、Opus 4.1は、同社の「Responsible Scaling Policy（責任あるスケーリング方針、RSP）」に基づき、「AI Safety Level 3（ASL-3）」の基準で展開されているが、依然として従来モデルと同様の脆弱（ぜいじゃく）性を抱えているという。

　このモデルを試してみたい場合は、有料のClaudeプランを通じて誰でも利用可能である。月額20ドルの「Claude Pro」や、月額100ドルの「Claude Max」などがあり、APIをはじめとして「Claude Code」「Amazon Bedrock」「Vertex AI」などを通じてアクセスできる。

この記事は海外Ziff Davis発の記事を朝日インタラクティブが日本向けに編集したものです。",[],[]
グーグルのAIエージェント型IDEがアプリ開発を加速--「Firebase Studio」を試してみた（ZDNET Japan）,https://news.yahoo.co.jp/articles/b07467f9ef67bd99a98617b6bb8530af30f8f354,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250806-35236340-zdnet-000-1-view.jpg?exp=10800,2025-08-06T07:00:00+09:00,2025-08-06T07:00:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,1935,"提供：MarinaZg/Getty Images
Microsoftの「Visual Studio Code」（VS Code）は長きにわたり、市場で人気のある統合開発環境（IDE）の1つだ。無料で使用でき、開発者の作業に必要な機能が全て備わっている。

　だが、Googleが「Project IDX」（後に「Firebase Studio」に改称）を発表したとき、Microsoftは震え上がったかもしれない。

　Firebase Studioは、開発プロジェクトの加速を目的としたフルスタック（フロントエンドとバックエンドの両方）の人工知能（AI）ワークスペースだ。ウェブベースなので、どのウェブブラウザーでも使用できる。この新しいエージェント型IDEでは、「GitHub」「GitLab」「Bitbucket」などのほか、ローカルマシンからも既存のリポジトリーをインポート可能だ。

Firebase Studio対VS Code

　このツールとVS Codeを比較するなら、Firebase Studioに軍配が上がる。勝因はエージェント型AIとプロトタイピングツールだ。これにより、開発、デバッグ、展開が格段に容易になる。さらに、VS Codeがシステムリソースを大量に消費するのに対し、Firebase Studioは全てをクラウドで処理するため、ユーザーはFirebase Studioが処理を実行している間も作業を続けられる。

　Firebase Studioで最も印象的なのは、AIプロンプトを使用してアプリを開発できる「App Prototyping」エージェントだ。このAIには、ユーザーから受け取ったクエリーを改善して、最適な結果を得られるようにする機能もある。

　Firebase Studioはまさに大変革をもたらすIDEだ。筆者は性能を確認しようと、かんばんボードアプリを作成してみたところ、初めて試したというのに非常に良い出来で驚いた。具体的には、App Prototypingエージェントを使用して、「Googleカレンダー」と連携するかんばんボードアプリを作成するようFirebase Studioに指示した。Firebase Studioは筆者の最初のクエリーに基づいて、人間が読める入力を改善し、はるかに具体的で効果的な内容に変えた（ヒント：入力内容は具体的であればあるほど良い）。

　Firebase Studioが動作する様子を見るのは興味深かった。数分後には、かんばんボードアプリが表示され、すぐにテストを開始できた。また、アプリを共有して、モバイルデバイスでテストできる状態になった。

　Firebase Studioが黙々とかんばんボードアプリを構築している間、筆者のコンピューターの動作が遅くなることは一度もなかった。なぜなら、全てがクラウドで処理され、システムリソースには影響がないからだ。Firebase Studioがアプリを構築している間に考えていたが、もしこの作業をローカルで実行したら、筆者の「System76 Thelio」はRAMとCPUを使い切って、ダウンしていただろう。

　このクラウドベースのエージェント型IDEなら、そうはならない。

　アプリが完成したら、Gitリポジトリーにプッシュしてから、ローカルマシンにプルして、さらなる開発が可能だ。

利用料金

　本稿執筆時点で、Firebase Studioは無料で利用できる。料金が発生するのは、アプリを同サービス経由で公開する場合だけだ。Firebase Studioに無料の「Gemini API」を生成させることもできる（Prototypingエージェントに必要）。

　無料で利用できる範囲について説明すると、AI搭載IDEなどの基本的な機能へのアクセス、最大3つのワークスペース（「Google Developer Program」のメンバーは最大30）などがある。Gemini APIも、無料使用枠を超えない限り無料で利用できる（超過すると料金が発生）。

　アプリを公開するには、「Cloud Billing」アカウントが必要だ。料金は使用量によって異なる。Firebase Studioの料金の詳細については、こちらを参照してほしい。

　開発ワークフローにAIを組み込むことに関心があるなら、Firebase Studioを試しもしないというのはもったいない。非常に優秀であるだけでなく、使いやすいサービスだ。

この記事は海外Ziff Davis発の記事を朝日インタラクティブが日本向けに編集したものです。",[],[]
パナソニック コネクト、生成AI活用の進化と展望--エージェント型AIと独自コーパス構築を推進（ZDNET Japan）,https://news.yahoo.co.jp/articles/bdad77ab5d73e3ac8289de1eab29c527684ca594,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250806-35236307-zdnet-000-1-view.jpg?exp=10800,2025-08-06T06:00:00+09:00,2025-08-06T06:00:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,2861,"パナソニックコネクト AI＆Dataプラットフォーム部 シニアマネージャーの向野孔己氏
パナソニック コネクトでは、2023年2月から国内社員1万2200人に生成AIアシスタント「ConnectAI」を展開している。当初掲げた「業務生産性の向上」「社員のAI活用スキルの向上」「シャドーAI利用リスクの軽減」という3つの目的はおおむね達成され、特に業務生産性においては約45万時間の削減につなげている。

　パナソニック コネクト AI＆Dataプラットフォーム部 シニアマネージャーの向野孔己氏によると、生成AIの利用回数は2024年に前年比71％増となる240万回に達した。削減時間に至っては同140％増の44.8万時間となった。

　削減時間がこれほど増加した要因は、利用回数の増加に加え、1回当たりの削減時間の増加（20分→28分）が挙げられるという。「より複雑で付加価値の高い業務にAIが活用されるようになったことがうかがえる」（向野氏）

多様なAIモデル活用と社員の選択眼の進化

　ConnectAIでは、OpenAI、Google、Anthropicの主要な生成AIモデルを社員が自由に選択して利用できる環境となっている。向野氏によると、モデル間の満足度に大きな差は見られないものの、社員の利用傾向には明確な特徴があるという。

　「デフォルト設定のOpenAIのモデルが半数以上で利用される一方、プログラミングなど専門性の高い業務ではAnthropicのモデルを選択する傾向が強い。これは、業務の性質に応じて最適なモデルを使い分ける社員のスキルが向上していることを示している」（同氏）

　また、社員は回答速度よりも精度を重視する傾向を強めており、簡単な質問には高速なモデルを、戦略的な検討が必要な複雑な課題には高精度なモデルを選ぶ傾向があるという。「OpenAIのモデルは率直に答えるが、Googleのモデルは理路整然としているといったそれぞれの個性も理解し、その人の好みによって使い分けている」

　ConnectAIには、あるモデルの回答に対してワンクリックで別のモデルに同じ質問を投げかけ、回答を比較・検証できる独自機能が搭載されている。この機能により、複数の視点から情報の正確性を確認できるため、ハルシネーションのリスクを抑える効果がある。

　こうした継続的な改善の成果として、ユニークユーザー率は前年の34.8％から49.1％へと大きく伸びており、社員の利用意欲や活用の幅が着実に広がっていると向野氏は分析する。

「聞く」から「頼む」へ--生成AI活用が深化

　AI活用のスタイルは、「聞く」から「頼む」へと変化している。向野氏は、「単に情報を『聞く』だけであれば、検索エンジンでも代替可能であり、生産性向上への効果は限定的だ。しかし、AIに具体的な作業を『頼む』使い方は、業務の効率化に直結し、実際の成果につながっている」と述べている。

　例えば、「プレスリリースに関する想定問答集の作成」や「サービス合意書の抜け漏れチェックリストの作成」といった業務は、従来であれば人が多くの時間をかけて対応していたものである。これらをAIに任せることで、数時間単位の業務削減が可能となっており、実務への貢献度は非常に高い。

　実際、2023年5月時点では「聞く」が62.2％、「頼む」が31.9％だったのに対し、2025年5月時点では「聞く」が45.9％、「頼む」が41.7％と同等の割合まで増加している。プロンプトの文字数も同期間に109文字から273文字へと2.7倍に増えた。

　「これは、より具体的で詳細な指示をAIに与えるようになった、社員がAIを単なる質問応答システムではなく、仕事のパートナーとして捉えるようになった結果である」と向野氏は話す。

AI技術の進化が新たな業務支援を可能に

　この2年半で、生成AI技術そのものも飛躍的な進化を遂げ、扱える情報量（トークン数）は導入当初の4096から100万へと200倍以上に増加した。また、テキストだけでなく画像、ドキュメント、音声など多様な情報を扱えるマルチモーダル化も進展している。

　こうした技術進化を背景に、新たな活用事例も次々と生まれている。その1つが「画像生成」であり、削減時間は通常（28分）を上回る36分に達している。「プレゼン資料などに使用するイラストや画像の作成・探索作業は多くの社員にとって大きな負担だったが、画像生成AIはテキストでイメージを伝えるだけで高品質な画像を生成できるため、この課題を解決し、社員の創造性を引き出すツールとして定着しつつある」（向野氏）
エージェント型AIが業務をナビゲート

　パナソニックコネクトは、AIによる業務変革を3つのステップで段階的に進めている。第1段階は汎用（はんよう）AIを全社員に提供し、基本的なAI活用リテラシーの向上と業務効率化を図った。第2段階では、汎用AIに社内データや業務知識を学習させた「特化AI」を開発・導入し、専門分野でのより自社状況に即した支援を可能にした。

　そして現在、第3段階としてAIエージェントの業務プロセスへの統合（業務AI）が始まっている。AIが自律的に業務を遂行するこの取り組みは、単なるツールとしてのAIから、社員の業務をナビゲートし、代行するパートナーへの進化を目指している。

　AIエージェントには「ナビゲーター型」「ワークフロー型」「汎用エージェント型」の3つのタイプが想定されており、現在は実現可能性の高い「ナビゲーター型」のエージェントを経理、法務、マーケティングなどの部門で導入している。

　例えば、経理部門の「決裁エージェント」は、社員が購入したい物品やサービスを伝えると、AIが対話形式で質問を重ねながら、複雑な決裁区分の特定や申請理由の作成を支援する。これにより、不慣れな申請業務でも社員は経理担当者に問い合わせることなく、スムーズに処理を進めることが可能となる。

　「従来の生成AIが社員主導で質問に答える形式だったのに対し、AIエージェントはAI主導で業務プロセスに沿って必要な質問を投げかけ、社員を導く点が最大の違い」（向野氏）である。

独自コーパスの構築へ向けた構想

　向野氏が現在構想するのは、「パナソニックコネクト コーパス」と呼ばれる独自のデータ基盤の構築である。社内の業務プロセスや各種データをAIが参照・活用できる形に整備することで、業務におけるAI活用を加速させる狙いだ。

　「このような環境が整えば、社員は情報探索の手間から解放され、本来の創造的な業務に集中できるようになり、AIが真に社員のパートナーとなる未来の実現を目指している」（向野氏）

　この構想の実現には3年から5年、あるいはそれ以上の時間を要する可能性があるが、すでにその歩みは始まっているという。",[],[]
