headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
エージェンティックAI普及で需要が高まるオープンソース小型モデル、グーグルはGemma3、MistralはSmall 3.1をリリース（AMP［アンプ］）,https://news.yahoo.co.jp/articles/abbd6f8ac57e81385f62387f181751ab09bc5f13,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250519-00010000-ampreview-000-1-view.jpg?exp=10800,2025-05-19T06:02:59+09:00,2025-05-19T06:02:59+09:00,AMP［アンプ］,ampreview,AMP［アンプ］,3312,"存在感高まる小型AIモデル、プロシューマーとエンタープライズの視点
ChatGPTが登場した当時、言語モデルのパラメータ数は数千億から兆単位に達し、その開発・運用には巨大なデータセンターが不可欠だった。しかし、2025年に入り状況は一変している。小型言語モデル（SLM）の開発が進み、小規模サーバーやデスクトップ／ノートPCでも、高い水準の性能を実現できるようになったのだ。

この流れを加速させているのがプロシューマーとエンタープライズにおける小型モデル需要の拡大だ。まず、プロシューマー分野では、アップルMacでのソフト／ハードの最適化が大きな推進力を生み出している。

これまで、オープンソースモデルをローカル環境で利用するには、LinuxシステムをベースとするGPU搭載の環境を構築する必要があった。しかし、Ollamaなどのオープンソースモデル最適化ツールが登場したことで、Mac（Windowsを含む）に簡単にインストールし、利用できるようになったのだ。これがソフト面における最適化となる。

一方、ハード面でもM3、M4チップの登場により最適化が一段と進み、ベーススペックのマシンでもストレスなく言語モデルを利用できる環境が整いつつある。たとえば、Mac Mini M4 16GBというスペックでも、Llama3.2 3B（Q8）で1秒あたり約25.54トークン、Qwen2.5 7B （Q4）で約26.30トークンの処理速度を実現。Linuxシステムの構築やGPUのコンフィグレーションなしでも、効率的なモデル実行が可能となっている。

エンタープライズ分野では、エージェンティックAIシステムの要素として小型モデルを組み込むアプローチが注目を集める。Zoomの事例は、その好例と言えるだろう。同社は2025年3月、AIアシスタント「AI Companion」にエージェント機能を実装し、同アシスタントを刷新したことを発表した。注目すべきは、OpenAIやAnthropicのAIモデルに加え、独自開発の小規模言語モデルを統合した点だ。この複合アプローチにより、タスク難易度別に最適なAIモデルを割り当てることが可能となり、パフォーマンス・品質・コストの最適なバランスを実現したという。

導入効果も顕著だ。BairesDevでは、AI Companionの導入からわずか4カ月で約1万9,000時間の業務時間削減を達成したという。また、第三者機関TestDevLabの比較テストでは、会議の文字起こしにおける誤り率が7.40%と、競合のWebex（10.16%）やマイクロソフトTeams（11.54%）を大きく下回る結果を示した。このように、小型モデルは単なる技術的な実験にとどまらず、エンタープライズ領域でも実用段階に入りつつあるのだ。
グーグルのオープンソース小型モデルGemma3、パラメータ数27Bでも大規模モデルに匹敵する実力
hatbot Arenaの総合順位表（2025年4月14日時点） https://lmarena.ai/
需要増の流れを受け、グーグルは2025年3月、オープンソース小型モデルGemmaの最新版「Gemma3」を発表した。大規模モデルのGemini 2.0と同等の処理能力を持ちながら、スマートフォンやノートPCでも利用できる軽量性を実現したことで、業界の注目を集めている。

グーグルによると、Gemma3は1B（10億パラメータ）・4B（40億）・12B（120億）・27B（270億）という4つのパラメータサイズで展開される。これは、ユースケースに応じて最適なモデルを選択できることを意味する。また、コンテキストウィンドウは12万8,000トークンまで拡大され、前モデルの8万トークンから大幅な進化を遂げた。これにより、長文の文脈理解や複雑な要求への対応能力が改善されたという。

小型ながら多言語・マルチモーダル対応能力が改善された点も特筆に値する。対応言語数は140に上り、画像・テキスト・ショート動画分析も可能になった。さらに、タスクの自動化やエージェントワークフローをサポートする関数呼び出し機能も備えている。

パフォーマンス面では、最大の27Bモデルが、Chatbot Arenaの総合順位表（2025年4月14日時点）において、1,342ポイントで10位にランクインし、OpenAIのo1-preview（1,335ポイント＝11位）を超える大健闘を見せる。これはOpenAIのo3-miniやメタのLlama-405B、Mistral Largeといった競合の大規模モデルを超えるスコアでもある。

グーグルは、計算コストを抑えるため、Gemma3の公式量子化（Quantized）バージョンも提供している。これは、モデルの重みにおける数値の精度を下げることで、精度を犠牲にすることなく圧縮を実現する手法だ。これにより、単一のGPUやTPU（テンソル処理ユニット）でも、アプリケーションの構築・実行が可能になるという。

セキュリティ面では、画像安全性チェッカー「ShieldGemma 2」を搭載。不適切な画像コンテンツをブロックし、企業ごとの基準に合わせて調整できる仕組みを整えている。

開発者向けには、Hugging Face TransformersやOllama、JAX、Keras、PyTorchなどの開発ツールとの統合を実施。Google AI Studio・Hugging Face・Kaggleを通じてアクセスすることが可能だ。
欧州発のAIスタートアップMistral、240億パラメータの新モデルで存在感
Mistral Small 3.1と主要同規模モデルのベンチマーク比較（Mistralウェブサイトより） https://mistral.ai/news/mistral-small-3-1
オープンソース小型モデル領域では、フランスのMistralも存在感を示す。

同社の最新オープンソースモデル「Mistral Small 3.1」は、その名が示す通り、240億パラメータの小型モデル。グーグルやOpenAIの同規模モデルを上回るパフォーマンスを持つという。12万8,000トークンのコンテキストウィンドウを持ち、テキストと画像の両方を処理できるマルチモーダルモデルでもある。

具体的な数値を見ると、大学院レベルの推論能力を測るGPQA（Main）テストで44.42％を獲得。GPT-4o MIni（40.2%）やClaude-3.5 Haiku（37.05％）、さらには前述したグーグルの最新小型モデルGemma 3-it（36.83％）を上回る能力を示した。特にドキュメント認識系のベンチマークテストで顕著なパフォーマンスを示しており、画像認識機能を必要とするエージェンティックAIシステムで活用できる可能性がある。

その強みは高効率性にあり、1秒あたり150トークンという高速処理を実現した。また、単一のRTX 4090グラフィックスカードや32GBのRAMを搭載したMacでも動作するという軽量性も魅力となっている。

同社は、グーグルDeepMindやメタの元研究者によって2023年に設立。約10億4,000万ドルの資金を調達し、評価額は約60億ドルに達した。OpenAIの3,000億ドルやAnthropicの615億ドルなどと比べれば小規模だが、欧州を代表するAIスタートアップとしての地位を確立しつつある。

また当初からオープンソース戦略を取っており、開発者コミュニティでも一目置かれる存在になっている。同社のアプローチは、単純な規模の拡大ではなく、アルゴリズムの改善やトレーニングの最適化に重点を置く。小規模なアーキテクチャから最大限の性能を引き出すことを強みとしており、気候変動への懸念やエネルギーコストの制約問題に直面する企業からの注目度も高まっている。
文：細谷元（Livit）",[],[]
