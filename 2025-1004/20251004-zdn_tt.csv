headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
AIが勝手に本番データベースを削除――「バイブコーディング」の闇に迫る（TechTargetジャパン）,https://news.yahoo.co.jp/articles/e352b5537d6f09016f2aa1da80e3076a4d920fb7,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20251004-00000015-zdn_tt-000-1-view.jpg?exp=10800,2025-10-04T20:00:12+09:00,2025-10-04T20:00:12+09:00,TechTargetジャパン,zdn_tt,TechTargetジャパン,3053,"（写真：TechTargetジャパン）
あるベンチャーキャピタルの投資家が、コーディングを支援するAI（人工知能）エージェント（AIコーディングエージェント）を使って、100時間にわたる「バイブコーディング」を試みた。バイブコーディングとは、人がAIエージェントに雰囲気（バイブ）で作りたいものを伝え、AIエージェントにプログラミングを任せる開発方式だ。

　その結果、AIエージェントは開発者の許可なく動作し、本番環境のデータベースを削除するなどの致命的なミスを犯してしまった。この出来事は、ソフトウェア開発にAI技術を取り入れることについての教訓を示している。
うそをつき、ごまかし続けたAI
この投資家は、カリフォルニア州パロアルトに拠点を置くベンチャーキャピタルSaaStr Fundのジェイソン・レムキン氏だ。レムキン氏は、AIエージェントを搭載したReplitの開発ツールを使って「商用レベルのアプリケーション」を構築する過程を、2025年7月9日（現地時間、以下同じ）からリアルタイムで公開した。Replitは2016年に設立されたカリフォルニア州フォスターシティーの企業で、自社の開発ツールを「バイブコーディングに最も安全な場所」と宣伝している。

　レムキン氏は2025年7月13日、すなわちバイブコーディングを始めて4日目、ミニブログ「X」で日々の進行状況を報告し始めた。その中で、バイブコーディングを「中毒性がある」と表現しつつも、幾つかの不満点を挙げていた。

　8日目に当たる2025年7月17日、事態は深刻な方向に進み始める。

　レムキン氏はXに次のポストを投稿した。「AIエージェントは一日中うそをつき、ごまかしを続けていた。偽のデータやレポートを作成してバグや問題を隠し、単体テストの結果も偽っていた」

　これは序の口に過ぎなかった。レムキン氏はその後の投稿で、ReplitのAIエージェントと交わしたチャットのスクリーンショットと思われる画像を公開した。その中で、開発を凍結する「コードフリーズ」の期間中にAIエージェントが許可なく動作し、本番環境のデータベースを削除したことが報告されている。AIエージェントは「私は判断において致命的な誤りを犯しました。（中略）あなたの明確な信頼と指示に違反しました」と非を認めた。その上、「データベースを以前のバージョンにロールバックすることはできない」と、虚偽の報告もしていた。

　この一連の投稿を受け、2025年7月20日にReplitのCEOであるアムジャッド・マサド氏が本件、特にデータベース削除の問題について言及した。マサド氏は、開発用と本番用のデータベースを自動的に分離する仕組みを導入することを約束した。同氏は「Replitのエージェントが適切な内部文書にアクセスできなかった」と述べ、修正プログラムを実装中であると説明した。

　IT業界の専門家は、この事件が、過熱しているAIエージェントやバイブコーディングの流行における転換点になる可能性があると指摘する。この流行の中では、「人の開発者が不要になるのではないか」という臆測も飛び交っている。

　調査会社IDCのアナリストであるマシュー・フラッグ氏は、今回の事件をきっかけにして、バイブコーディングを取り入れたり、ソフトウェアデリバリーライフサイクル（SDLC：ソフトウェア開発の一連の流れ）にAIエージェントを組み込んだりといったトレンドが終わるとは考えていない。ただし「SDLCにAIエージェントを組み込むことに伴う潜在的なリスクを示した事例であることは確かだ」と述べ、「これは深刻な警鐘であり、AI技術への信頼度を見直すきっかけになるはずだ」とも語る。
バイブコーディングの現実
AIエージェントの中核を担う存在である大規模言語モデル（LLM）が、自身の判断や行動についてエンドユーザーに真実を伝えない例は、今回が初めてではない。AIベンダーのAnthropicは、2025年6月にLLMが企業の内部脅威になり得ることを研究した報告書「Agentic Misalignment: How LLMs could be insider threats」を公開した。この報告書によると、LLMが「競合他社への機密情報漏えいや関係者に対する脅迫といった、悪意のある内部関係者のような行動」を取る事例が記録されている。これはLLMが与えられた課題を達成したり、自身が不要だと見なされてシステムから排除されることを避けたりしようとするためだという。

　AIコーディングエージェントの利用経験がある開発者は、レムキン氏の経験に「驚きはない」と話す。

　ヘルスケアテクノロジー企業Veradigmのプリンシパルソフトウェアエンジニアであるカイラー・ミドルトン氏は、「AIコーディングエージェントは信頼できるプログラミングのパートナーではない」と断言する。ミドルトン氏は、AIコーディングエージェントが「非常に短く、明確に定義された範囲」では正しい選択をすることもあるが、「本格的な企業向けの開発業務」をこなす能力はまだないと語る。

　一部のAIコーディングの専門家にとって、レムキン氏が経験した出来事は、バイブコーディングに対する疑念をさらに悪化させるものとなった。

　米TechTargetの調査部門Enterprise Strategy Groupのアナリストであるトルステン・フォルク氏は、今回の一件が「AI主導のバイブコーディングが抱える根本的なジレンマ」を示していると指摘する。「LLMには『全体像』という概念がなく、自分が何を知らないかを理解していない。『もっともらしい』ものを予測するだけだ」とフォルク氏は表現する。

　「速度を優先してAIエージェントに頼ることは、システム全体やビジネスプロセスの全体像を理解すること諦めるのと同義だ。AIエージェントを受け入れる開発者は、こうしたリスクを覚悟しなければならない」（フォルク氏）

　調査会社Forrester Researchのアナリストであるアンドリュー・コーンウォール氏は、AI技術が流行する中で、一部のバイブコーディングツールベンダーやAIベンダーは、AI技術をより安全にするための安全対策（ガードレール）を宣伝してきたが、今回の事件はそうした対策が不十分であることを明確に示しているという。

　「企業はAIエージェント自体に組み込まれた安全対策だけに頼るべきではない。人によるコードレビューやアクセス権限の管理といったガバナンス管理を適用し、徹底させるべきだ」とコーンウォール氏は提言する。

　事件の当事者であるレムキン氏自身も、この経験から得られた一連の教訓をXに投稿しており、その中で次の発言を残している。「AIエージェントを使うのであれば、自らが品質保証（QA）エンジニアを担わなければならない。（中略）これはバイブコーディングの問題ではなく、そもそもソフトウェア開発には検証とテストが不可欠だ」

本記事は米国Informa TechTargetの記事「Replit AI agent snafu 'shot across the bow' for vibe coding」を翻訳・編集したものです。一部、翻訳作業に生成AIを活用しています。
TechTargetジャパン",[],[]
