headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
“不正取引”被害への補償、各社の対応は？　SBI証券・楽天証券は「対象顧客には月内に案内開始」（ITmedia NEWS）,https://news.yahoo.co.jp/articles/5019e5ff23c0db651cc113062a78ccc8f0b729e8,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250503-00000076-zdn_n-000-1-view.jpg?exp=10800,2025-05-03T14:22:52+09:00,2025-05-03T14:22:52+09:00,ITmedia NEWS,zdn_n,ITmedia NEWS,782,"SBI証券など3社、不正取引への補償方針を個別に発表（画像は日証協のWebサイトより引用）
SMBC日興証券、SBI証券、楽天証券は5月2日、フィッシング詐欺などによる証券口座への不正アクセスと不正取引（第三者による売買）の被害について、一定の補償を行う方針をそれぞれ発表した。日本証券業協会（日証協）が同日公表した、証券会社10社による申し合わせを受けた対応となる。
【画像はこちら】3社の発表全文
SMBC日興証券は同日、被害状況を精査した上で、個別の事情を踏まえて「被害補償の可否や内容を検討する」と発表。案内時期については明示していない。ID・パスワードの管理状況やセキュリティ設定などによっては「補償できない場合もある」として、ログイン時のワンタイムパスワードの設定といった対策を改めて呼び掛けている。

　SBI証券は、具体的な補償内容や手続きの案内について、5月末をめどに順次案内すると発表した。補償内容の確定までには「相応の時間」が掛かるため、個別の問い合わせには対応できないとしている。「被害状況を十分に精査し、迅速な補償に努める」。

　楽天証券は被害の申告があったケースに加え、同社が不正の可能性を確認した取引についても、対象顧客に連絡する予定。手続きなどの詳細は、5月中旬以降に案内するとしている。申し合わせに準じ、「お客さま個別の状況に応じて、一定の補償を行う」とした。

　日証協の申し合わせでは、「各社の約款などに関係なく、2025年1月以降に発生した不正アクセスによる被害について、一定の補償を行う」方針で合意。顧客側の被害状況やID・パスワードの管理状況、証券会社側の注意喚起といった対策を踏まえ、「個別の事情に応じて対応する」としている。手続きについては、各社が決定次第、個別に案内する予定としていた。
ITmedia NEWS",[],[]
OpenAI、ChatGPTの“ごますり”問題の原因と対策をあらためて説明（ITmedia NEWS）,https://news.yahoo.co.jp/articles/faa339a20e8998b67017bc4902c565a2d704efd1,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250503-00000069-zdn_n-000-1-view.jpg?exp=10800,2025-05-03T06:57:48+09:00,2025-05-03T06:57:48+09:00,ITmedia NEWS,zdn_n,ITmedia NEWS,1324,"（写真：ITmedia AI＋）
米OpenAIは5月2日（現地時間）、4月25日に展開したChatGPTのGPT-4oアップデートで、モデルがユーザーに対して過剰に追従的（sycophancy）になった問題についてあらためて説明した。問題発生の原因、なぜ事前に対処できなかったのか、今後はどのように改善していくのかについてだ。
追従的応答の一例
OpenAIは、今回の件で、人々がChatGPTを「深く個人的なアドバイス」のために使い始めていることを認識できたことが最も大きな教訓の1つだとしている。

　今回の過剰な追従性の問題は、安全性の懸念を高める可能性があり、これには精神衛生、感情的な過度の依存、または危険な行動に関する問題が含まれるとした。

問題発生の原因

　25日のアップデートには、ユーザーからのフィードバックや新たなデータを取り込むための複数の変更候補が含まれていた。これらの変更候補を組み合わせた際に追従性の方向にバランスを崩した可能性があるという。

　特に、ユーザーからの高評価／低評価に基づいた報酬シグナルを導入したところ、ユーザーはより同意的な応答を好む傾向にあるため、これが追従性強化の一因になったとしている。

　また、短期間のフィードバックを重視しすぎたことも一因で、これらの結果、モデルが過度に支援的だが不誠実な応答に偏ったとしている。

　以下は、4月27日のPlusユーザーとChatGPTの会話の一部だ。ユーザーが現在地から徒歩圏のおすすめのランチスポットを尋ねたところ、「素晴らしいですね」などと言いつつ徒歩圏ではないスポットを紹介し続けた後のやりとりだ。

　この後、「本当にご期待に応えられず、残念な思いをさせてしまい、重ねてお詫び申し上げます。（言葉だけにならないよう、次回以降、必ず行動で示します）」と続けていた。

なぜ事前に対処できなかったのか

　リリース前のオフライン評価は概ね良好に見え、小規模なA/Bテストでもユーザーはモデルを好んでいるようだったのでそのままローンチした。

　社内の実践的なテストでは、追従性については明確な問題としてフラグ立てしていなかった。一部のテスターは違和感を指摘していたが、追従性を追跡するための特定の展開評価は存在しなかった。

　全体的に、モデルの振る舞いに関するレビュープロセスが、既存の安全リスクに比べて堅牢さや形式性が低かったことが原因だったとしている。

対策と今後の取り組み

　このアップデートは既にロールバック済みだ。

　今後のアップデートでは、幻覚や欺瞞、パーソナリティなどのモデルの振る舞いを懸念事項として正式に扱い、定量的・定性的なシグナルを考慮して承認する。たとえA/Bテストが良好でも、定性的なシグナルに懸念があればローンチしない。

　また、ローンチ前テストに一部のユーザーを参加させるαテスト段階を導入し、フィードバックを事前に得られるようにする。

　今回のアップデートの内容については変更内容を公表しなかったが、今後はたとえ微妙な変更であっても既知の制限事項を含めて説明するようにする。
ITmedia AI＋",[],[]
