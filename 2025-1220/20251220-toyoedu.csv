headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
女子生徒のSNS画像をAIで裸の画像に加工…《ディープフェイクポルノの被害者、中学生が5割超》卒業アルバムの悪用は自衛が難しい、どうすれば（東洋経済education×ICT）,https://news.yahoo.co.jp/articles/45f40f55ec4d06f3c67d69d9b6fdb05ed5bd6fc6,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20251220-00924887-toyoedu-000-1-view.jpg?exp=10800,2025-12-20T08:00:57+09:00,2025-12-20T08:00:57+09:00,東洋経済education×ICT,toyoedu,東洋経済education×ICT,3072,"写真：東洋経済education × ICT
生成AIが急速に浸透し、誰もが画像や動画を簡単に作成できる時代が訪れました。同時に、「ディープフェイク」と呼ばれる精巧な偽画像や動画が作成できるようにもなりました。
【写真】顔を交換するアプリは多数存在する
ディープフェイクとは、「ディープラーニング（深層学習）」と「フェイク（偽物）」を組み合わせた造語です。ディープフェイクの中には、ポルノ画像や動画の顔や声を別の人物に入れ替える「ディープフェイクポルノ」と呼ばれるものがあり、子どもがターゲットにされるケースが問題視されています。
ディープフェイクポルノの被害者、中高生が8割超
2025年12月5日、名古屋市の元小学校教師の男がディープフェイクポルノを所持したとして児童ポルノ禁止法違反の罪で在宅起訴されました。生成AIによる画像所持に児童ポルノ禁止法違反が適用されたのは全国初とのことです。

在宅起訴された男は、元教員ら7人による児童盗撮グループ事件のメンバーです。彼らは盗撮した画像や動画をSNSで共有し、逮捕されています。
さらに警察庁が、12月18日に初公表したディープフェイクポルノに関する被害相談の実態によると、今年1〜9月で警察に約80件の相談が寄せられ、被害者の8割超が中高生でした※。内訳は、中学生が51.9％、高校生が31.6％、小学生が5.1％と、中学生が最も多くなっています。

また、加害者は同級生・同じ学校の生徒が多く53.2％、SNSなどを通じた知り合いが6.3％とのこと。すべてが生成AIと判明しているわけではないのですが、AIによるものが多いと推測されています。

あわせて警察庁からディープフェイクポルノに関する5つの実例が挙げられました。



・生成AIを使用した性的画像の作成を有料で請け負う成人男性が、男子高校生から女子生徒の画像の加工依頼を受けて性的画像を作成するとともに、男子高校生の承諾を得て当該画像をSNS上で公開し、拡散したもの。

・成人男性が、何らかの方法により性的に加工された女子生徒の画像を掲示板サイトに投稿して拡散したもの。

・男子中学生が、女子生徒のSNS投稿画像を使用して生成AIにより裸体の画像に加工し、他の男子生徒に販売したもの。

・男子中学生が複数名で、学校のタブレット型端末で閲覧可能な行事アルバムから女子生徒の画像を使用し、生成AIにより性的な画像を作成してグループ内で共有したもの。

・男性実習助手が、勤務先である高校の卒業アルバムの女子生徒の画像を第三者に提供し、同人が何らかの方法により性的な画像に加工してSNSに投稿。当該投稿を男性実習助手が再投稿する形で拡散したもの。

どれも悪質極まりない事例ですが、10代は被害に遭うだけではなく、ディープフェイクポルノの加害者になっていることがわかります。

また、「卒業アルバム」や「行事アルバム」といった本人が流出させたものではない画像が使われており、被害者が自分を守り切れない状況で被害に遭っています。

※調査対象は、警察が把握した生成AIなどを悪用して児童（18歳未満）の性的画像を作成した事案で、相談・被害申告時に相談・被害者が20歳未満であるもの。
故人をデジタルで蘇らせることも
ディープフェイクでは、実在の人物のデータを学習させて顔や音声を入れ替えることができるため、笑った顔を悲しい顔に変えたり、発言していない言葉を話させることができます。

例えば、故人となった俳優をデジタルで蘇らせる、英語が話せない人に英語でスピーチをさせるなど、さまざまな活用法があります。

AIで顔を入れ替えるサービス「Reface」は、画像や動画の顔と別の顔を入れ替えることができます。ほかにも、顔を交換するアプリは多数存在し、Webサイトから画像を送るだけで生成できるサービスもあります。
2022年3月にはウクライナ軍の投降を呼びかけるゼレンスキー大統領の動画がSNSに拡散されました。

これはディープフェイクで作られた偽動画ですが、一見本物かと思うほど精巧にできており、戦争が情報戦に突入したと恐れられました。日本でも政治家のディープフェイクがまん延しており、高市早苗総理のなりすましが投資を促す詐欺広告も出現しています。

これまで、ディープフェイクは高度な技術や本格的な機材が必要だったため、ターゲットとなる人物は有名人や著名人などに限られていました。しかし今は、生成AIアプリやWebサイト経由のサービスで簡単にディープフェイクが完成します。つまり、一般人でもディープフェイクの被害に遭う可能性が高まっているのです。
防ぎきれないディープフェイクポルノ
特に、ディープフェイクポルノ、児童の画像を基にしたものについては国も問題視しています。

2025年9月に全面施行となった「人工知能関連技術の研究開発及び活用の推進に関する法律」（AI法）は、AIのイノベーションを促進しつつ、リスクに対応するための法律です。

この附帯決議に児童の画像などを使ってAIで作り出したディープフェイクポルノについて、厳正な取り締まりや被害者の保護、サイト管理者への違法な情報の削除依頼強化などが盛り込まれました。

また、警察庁は「児童の性的ディープフェイク被害・加害防止のための広報啓発資料」を公開し、注意を呼びかけています。

ディープフェイクポルノは卒業アルバムなどから作成されてしまうため、避けることが非常に難しいのですが、高い解像度の写真や動画をネットに投稿しないことは最低限の守りになります。
SNSに自分や家族の写真や動画を投稿しないように気をつけましょう。警察庁の発表では小学生以上の被害実態が明らかになっていますが、「まだうちの子は小さいから」と幼いお子さんの成長記録をSNSに投稿すると、意図しない使われ方をしてしまうかもしれません。
被害に遭ったらどうすればいいのか
もし自分や家族が実際にディープフェイクポルノの被害に遭ってしまったら、どうしたらいいのでしょうか。

まずは証拠となる画像や動画を保存し、拡散されている場合は掲載先のプラットフォームに報告しましょう。

相談窓口を利用することもできます。性犯罪被害相談窓口「
＃8103
」（ハートさん）、性犯罪・性暴力被害者のためのワンストップ支援センター「
＃8891
（はやくワンストップ）」や、法務省の「インターネット人権相談受付窓口」、警察庁の「サイバー事案に関する相談窓口」などがあるので、被害実態にあう窓口に連絡してください。

また、拡散された画像を消すために、成人の場合は「StopNCII」、18歳未満の場合は「Take It Down」に相談することができます。

デジタルデータは簡単に複製できてしまうため、一度ネットに漂ってしまったものは誰が保存しているのか、完全に把握することは不可能です。しかし、ハッシュ（デジタル指紋）を生成することで、その後もハッシュと一致する画像を探し出して削除してくれます。完全に削除することは難しいのですが、知らないうちに拡散され続けることは避けられます。

ディープフェイクポルノは誰でも簡単に生成できるため、わが子が加害者になる可能性もあります。軽い気持ちで生成すると、罪に問われることをしっかり話しておくことが大切です。
鈴木 朋子 :ITライター・スマホ安全アドバイザー",[],[]
