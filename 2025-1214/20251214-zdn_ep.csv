headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
プロンプトインジェクションを防御に応用？　シャドーAI対策に新提案（ITmedia エンタープライズ）,https://news.yahoo.co.jp/articles/e9469a61a46911cf62ae9ddc20ecb1bd6edbc72b,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20251214-00000002-zdn_ep-000-1-view.jpg?exp=10800,2025-12-14T07:00:12+09:00,2025-12-14T07:00:12+09:00,ITmedia エンタープライズ,zdn_ep,ITmedia エンタープライズ,1854,"（写真：ITmedia エンタープライズ）
Eye Securityは、企業内で拡大する「シャドーAI」への新たな対策として、「Prompt Injection for the Good」と題した研究成果を公表した。

　「ChatGPT」や「DeepSeek」「Microsoft Copilot」などの大規模言語モデル（LLM）は文書作成や会議の要約、意思決定の補助など、多くの業務領域で利用が進んでいる。しかし社内で承認されていない個人用ツールに機密情報や顧客データが入力されると、情報が統制外の環境に流出する危険がある。このような状況が「シャドーAI」と呼ばれており、企業の情報管理上の課題として注目されている。
プロンプトインジェクションを防御に応用　シャドーAI対策に新たな一手
Eye Securityの研究チームは、従来は攻撃目的に使われてきたプロンプトインジェクションを、教育的かつ防御的な手法として活用できないかを検証している。プロンプトインジェクションとは、生成AIに意図しない動作を引き起こさせる命令文を入力データ内に埋め込む手法だ。Eye Securityはこの手法を利用し、企業文書内に警告や注意文を隠して埋め込み、AIツールが文書を処理する際に自動的に警告を表示させる試みを実施している。

　初期実験において「Confluence Cloud」のPDFエクスポート機能に隠しヘッダを設定し、社内のAIツールがその文書を要約した際、画面上部に警告メッセージが表示されることを確認した。このメッセージは人間の目には見えないが、AIに読み取れる形式で埋め込まれており、情報漏えい防止の注意喚起として機能したという。

　「Microsoft Purview」の感度ラベルを活用して「Microsoft Word」「Microsoft Excel」「Microsoft PowerPoint」、PDFなどの文書に警告を付与する方法を試し、「Google Workspace」の「Google ドキュメント」や「Google スプレッドシート」「Google ドライブ」、メールサービスでも同様の仕組みを検証している。

　「HubSpot CRM」や「Microsoft Exchange Online」を通じた電子メールへの組み込みもテストしている。結果はおおむね良好であり、主要なLLMの多くが明示的な警告文を認識して表示したとされる。ただしフォントサイズを極端に小さくしたり、白文字で隠したりするやり方では成功率が低く、特にOCR処理を利用するAIでは検出されないことが確認されている。

　Eye Securityはこれらの試行を効率化するために、オープンソースの試験用ツール「Prompt Injection for the Good」を開発して「GitHub」で公開している。このツールでは複数のAIモデルに同一文書を一括でテストし、どのモデルが警告を正しく処理できるかを確認できる。ユーザーは異なる形式の文書を生成し、ChatGPTや「Claude」、DeepSeekなどのAIに読み込ませ、警告の表示精度や一貫性を評価できる。

　Eye Securityはテストを通じて、単純な警告表示や出力制限など基本的な防御プロンプトは多くのLLMで機能したと述べている。一方でWebdingsなどの特殊フォントやリンクを使った複雑な手法は不安定で、AI側がセキュリティの理由から無視する場合もあった。外部リンクを誘導するような命令は拒否される傾向が強く、AIの防御機構が防御的なプロンプトまで遮断するケースも確認されているという。

　今後の課題として、条件付き命令の処理可否やフロントエンドとAPI間での挙動差、この技術が悪用される可能性などを挙げている。AIベンダー側がプロンプトインジェクションへの対策を強化する中で、防御目的の命令までブロックされる可能性があるため、透明性の確保が重要だとしている。

　Eye Securityは今回の試みをシャドーAIを根本的に解決するものではなく、AIガバナンスを強化し、従業員にデータの取り扱いの意識を促すための新しい発想と位置付けている。攻撃技術を転用して防御に活用する創造的AIセキュリティの取り組みとして、企業が生成AIの利便性を保ちながら安全性を確保する一助となる可能性が示されている。
ITmedia エンタープライズ",[],[]
