headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
"「AI幻覚」で4,400万円返金　Deloitteの失態が示す“汎用AI95％失敗”の現実（AMP［アンプ］）",https://news.yahoo.co.jp/articles/882606cc0e91b58f7c603f005863ea5d75ab7af7,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20251214-00010000-ampreview-000-1-view.jpg?exp=10800,2025-12-14T06:00:23+09:00,2025-12-14T06:00:23+09:00,AMP［アンプ］,ampreview,AMP［アンプ］,4635,"「4,400万円一部返金」──AI幻覚が引き起こした前代未聞の失態
「AI幻覚」で4,400万円返金
コンサルティング会社大手のDeloitte（デロイト）が、AIの落とし穴を身をもって示す事態となった。同社オーストラリア法人は2025年10月、オーストラリア政府の雇用・職場関係省向けに提出したレポートに、AI生成による重大な誤りが含まれていたことを認め、契約金44万豪ドル（約4,400万円）のうち最終支払分の返金に応じた。

問題のレポートは、同省が運用する福祉制度の自動化システムを検証するもので、2025年7月に公開されていた。しかし、シドニー大学の研究者クリストファー・ラッジ氏が精査したところ、引用文献に深刻な欠陥が浮かび上がった。存在しないシドニー大学法学教授による架空の論文が12回も引用され、スウェーデンの教授による実在しない研究も2件参照されていたのだ。さらに、重要なロボデット訴訟に関する連邦裁判所判決の引用も誤っており、判事の名前すら誤記されていた。Deloitteは後に、Azure OpenAI GPT-4oを使用して一部の分析を行ったことを認めている。

この種の「AI幻覚」は、Deloitteに限った話ではない。2025年5月、米国の有力紙シカゴ・サンタイムズが夏の読書リストを掲載したが、そこには実在する著名作家に架空のタイトルを組み合わせた偽書が多数含まれていた。ブリット・ベネット氏の『Hurricane Season』やミン・ジン・リー氏の『Nightshade Market』など、もっともらしい書名が並んでいたが、いずれも存在しない作品だ。同紙はフリーランサーがコンテンツパートナーと協力してAIを使用したことを認め、特別セクションを電子版から削除する措置を取った。この誤った読書リストは、フィラデルフィア・インクワイアラーなど他紙にも配信されていた。

AIの精度は日進月歩で大きく向上しているものの、現在でも人間による精査は欠かせない。たとえば、Amazonが2023年末に投入した法人向け生成AIツール「Q Business」は、初年度の内部評価で「混合的な成功」と評され、主要機能で競合他社に「著しく」後れを取っていたことが判明した。内部文書によれば、表形式データやスプレッドシートの処理に苦戦し、Accenture（アクセンチュア）やINTUIT（イントゥイット）、Smartsheet（スマートシート）といった大手顧客から苦情が寄せられていた。会話の流れを維持できず、不完全な回答を返すケースも頻発していたという。

KPMGの調査では、生成AIを使用する従業員の6割近くが、AIのエラーによって業務上のミスを犯したことを認めている。プロフェッショナルサービスから報道機関、テクノロジー企業まで、業界を問わずAI幻覚との格闘が続いているのが現状だ。
失敗の同日に47万人への展開発表──矛盾ではない「攻めの戦略」
返金騒動の渦中にありながら、Deloitteは後退するどころか、AI投資を大幅に加速させている。同社は2025年10月、オーストラリアでの返金発表と同じ日に、Anthropicとの提携拡大を公表した。AI技術企業AnthropicのチャットボットClaudeを、全世界47万人の従業員に展開する計画だ。この規模の展開は、Anthropicにとって過去最大のエンタープライズ導入となる。

この一見矛盾した動きには、明確な戦略がある。Deloitteが目指すのは、単なる汎用チャットボットの配布ではない。同社は会計士向け、ソフトウェア開発者向けなど、職種ごとに異なるAI「ペルソナ」を開発する方針を打ち出した。各部門の業務特性に合わせてカスタマイズされたAIエージェントが、専門性の高い作業を支援する仕組みだ。

この取り組みを支えるのが、大規模な人材育成プログラムである。DeloitteとAnthropicは共同で、1万5,000人の専門家をClaude活用の認定者として養成する計画を進めている。これらの認定者が、全社的なClaude導入とDeloitte自身のAI変革を牽引する役割を担う。さらに、Claude活用の専門知識を集約する「Claude Center of Excellence」を設立し、実装フレームワークの開発や技術サポートを提供する体制も整える計画という。

投資の方向性は、規制の厳しい業界への対応にも向けられている。DeloitteとAnthropicは、金融サービス、ヘルスケア、ライフサイエンス、公共サービスといった規制業界向けに、コンプライアンス機能を組み込んだAIソリューションを共同開発する。これらの業界では、AIの判断プロセスの透明性や説明責任が特に重視される。Deloitteの「Trustworthy AI」フレームワークとClaudeの安全性重視設計を組み合わせることで、企業がAIを安心して導入できる環境を提供する狙いだ。

監査業務への適用も具体化している。Deloitteは2025年7月、グローバル監査プラットフォーム「Omnia」に一連のAI機能を追加したことを発表した。監査文書の初期レビュー、財務諸表の高度な分析、会計メモの下書き作成など、生成AIが監査プロセスの各段階を支援する。さらに、複数のAIエージェントが連携して動作する「エージェント型AI」をOmniaに統合し、データ収集の自動化や異常検知などのタスクを実行させる計画も進んでいる。

Deloitteのランジット・バワ最高戦略・技術責任者（米国）は、顧客から「Deloitte自身もAIを使っているのか」と問われることが多いと明かす。自社での実践を通じて得た知見が、顧客へのアドバイスの信頼性を高める。こうした実践的な学びを重視する姿勢が、返金という代償を払いながらもDeloitteがAI投資を継続する背景にあるのかもしれない。
過信が招く惨事──専門家が警鐘を鳴らす「人間の責任」
Deloitteの返金騒動が突きつけたのは、AI活用における「人間の責任」という根本的な課題だ。

ジョージア工科大学のニッキー・マッケンジー准教授は「AIがどれほど賢くなったかという話を聞き続けるうちに、人々は過度に信頼するようになる」と指摘する。専門家の間では、AIを最終的に判断する人間の能力向上こそが急務との認識が広がっている。

この問題に関連して、ボストンコンサルティンググループ（BCG）の2025年調査が示すのは、AIの可能性・リスク・限界を知る機会が全体的に足りていない事実だ。同調査では、適切な研修を受けた従業員とそうでない従業員との間に、劇的な差が生じることが判明。少なくとも5時間以上のトレーニングを受け、対面指導やコーチングを利用できる環境にある従業員は、AI活用の頻度が大幅に高くなる。しかし現実には、適切な訓練を受けたと感じている従業員は全体の3分の1にとどまっている。

ガバナンス体制の構築も、AIによる失敗を防ぐための不可欠な要素となる。法律事務所Ward and Smithは、企業にAI監査の実施を推奨している。部門横断チームを編成し、IT、製品開発、人事、財務、法務、リスク管理の各部門が連携して、現在のAI利用状況と潜在的なリスクを洗い出す必要がある。特にリスクの高い用途、たとえば機密性の高い個人データや重要な業務判断に関わるAI利用については、監査期間中の一時停止も検討すべきだという。

リスク評価では、個人への影響、判断の重要性、データの機密性、バイアスや誤りの可能性といった要素を総合的に考慮する。雇用、信用、医療、法的判断などに影響する高リスクなAI活用には、強化された監視と統制が求められる。こうしたAIリスクは、企業全体のリスク管理フレームワークに統合し、他の事業リスクと並んで適切な注意を払う必要がある。

一方、日本では野村総合研究所（NRI）が、責任あるAI活用に向けた具体的な枠組みを提示している。

同社が示す10の要素には、戦略的位置付け、専任組織の設置、ポリシー策定、リスク評価、ルール整備、運用体制、セキュリティと品質管理、データガバナンス、人材育成、専門人材の確保が含まれる。特に重要なのが「AI CoE（Center of Excellence）」と呼ばれる専門組織の設立だ。各部門に分散するAI利用を監督し、ルール策定、教育提供、基盤整備、外部連携を担う司令塔として機能する。

結局のところ、AI活用の成否を分けるのは技術そのものではなく、それを使う人間の判断力と組織の体制にあると言えるだろう。Deloitteの事例は、そのことを改めて教えてくれる。
汎用AIは95%失敗、特化型は2%──明暗を分ける導入の違い
Deloitteが掲げる部門別AIエージェント戦略は、日本企業にとっても現実的な選択肢として浮上している。実際、国内大手企業では、部署ごとの業務特性に合わせたAI活用が着実に進み始めている。

NTTドコモは2023年8月、グループ3社横断で「LLMバリューアッププラットフォーム」を立ち上げ、全社的なAI活用基盤を整備した。このプラットフォームには、不適切な出力を防ぐ倫理チェック機能や検索拡張生成（以下、RAG）機能が組み込まれ、安全な業務利用を実現。さらに、プロンプト知識がなくてもAIアプリを作成できるAllganizeの「Alli LLM App Market」を導入し、各部門が独自のニーズに応じたAIツールを開発できる環境を構築した。

具体的な活用例を見ると、サポートセンターでは、ドコモショップのスタッフと支援センター間の問い合わせチャットログから、Q&Aを自動生成するアプリを開発。これにより月10時間の作業時間削減を達成している。地域事務所では、総務部門への一般的な問い合わせに対応するRAG搭載アプリを試験運用中だ。翻訳や議事録作成といった定型業務でも、AIが生産性向上に貢献している。

技術的な成果も印象的だ。Alli LLM App MarketのRAG最適化機能を使った検証では、回答精度が30%向上したという。ワークショップでは、わずか1時間のミーティング中にサポートセンター向けアプリを構築し、その場でテストまで完了させた事例もある。スピード感のあるアプリ開発が、現場の課題に即応できる体制を支えている。

ソフトウェアレビュープラットフォームG2が2025年10月に発表した調査によれば、BtoB企業の57％がすでにAIエージェントを本番環境で運用しており、展開後の失敗率は2％未満にとどまることが明らかになった。特定業務に特化したAIエージェントの場合、問題が明確になっている場合が多く、失敗率は低くなる傾向がある。

一方、主に汎用的な生成AIツールによる投資対効果を分析したMITの調査によると、95％の企業がゼロリターンという結果に終わっていることが判明している。これは、リサーチやレポート作成のような汎用用途では、投資対効果が出にくいことを示唆する数字で、Deloitteの失敗もこの範疇に入るのかもしれない。
文：細谷 元（Livit）",[],[]
