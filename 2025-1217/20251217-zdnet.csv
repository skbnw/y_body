headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
NTTPCら、水冷GPUサーバーの商用利用に向け実証実験--コンテナー型DCでpPUE 1.114を記録（ZDNET Japan）,https://news.yahoo.co.jp/articles/4398d0ad49e8fb227122e578dbbdac952a41abb9,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20251217-35241765-zdnet-000-1-view.jpg?exp=10800,2025-12-17T17:22:00+09:00,2025-12-17T17:22:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,878,"NTTPCら、水冷GPUサーバーの商用利用に向け実証実験--コンテナー型DCでpPUE 1.114を記録の画像
NTTPCコミュニケーションズ（NTTPC）、ゲットワークス、フィックスターズは12月17日、水冷GPUサーバーの運用効率を向上する概念実証（PoC）に成功したと発表した。

　生成AIやハイパフォーマンス・コンピューティング（HPC）の活用に伴い、高性能GPUサーバーの需要は急増している。稼働させるには水冷GPUサーバーへの対応が必要になるが、国内においては、空冷式のデータセンターが一般的で、水冷GPUサーバーの事例はまだ少ないのが現状だ。

　今回のPoCでは、コンテナー型データセンター内に水冷GPUサーバーを設置。データセンター、GPUサーバー、ソフトウェアを統合的に調整した環境下で多様な負荷を与え、各種データを計測した。あわせて、水冷GPUサーバーと空冷GPUサーバーとの性能比較も実施した。

　検証の結果、コンテナー型データセンターにおける水冷GPUサーバーの商用利用の有効性を確認した。また、データセンター、GPUサーバー、ソフトウェアの各レイヤを統合的に連携させることで運用効率の最大化を実証し、水冷GPUサーバー環境として高効率なpPUE 1.114を記録した。今回の検証では、稼働環境として設置しやすいコンテナー型データセンターを利用していることが特徴。水冷GPUサーバー本来の能力を最大限に発揮させることに成功したという。

　実証実験においては、ハードウェアエンジニアリングの部分をNTTPCが担い、ゲットワークスがキャッピング（空調気流の制御）などの調整を行い、最適なサーバー稼働環境を構築した。フィックスターズは、水冷GPUサーバーおよび冷却設備を実証実験用に提供したほか、コンテナー型データセンター内の環境・ハードウェア・ソフトウェアを一元管理する統合モニタリングツールを構築した。

　今後も3社は連携し、日本国内のコンテナー型データセンターにおける水冷GPUサーバーの商用利用拡大に向け取り組んでいく。",[],[]
サイオス、米Starburst製品の販売開始--データガバナンスの複雑化に対応（ZDNET Japan）,https://news.yahoo.co.jp/articles/902cefd612044e2b12cc8c8088c2952115e2fa38,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20251217-35241746-zdnet-000-1-view.jpg?exp=10800,2025-12-17T16:30:00+09:00,2025-12-17T16:30:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,1576,"サイオス、米Starburst製品の販売開始--データガバナンスの複雑化に対応の画像
サイオステクノロジーは、米Starburst Dataと日本市場での戦略的パートナーシップを締結した。12月16日から日本国内の販売代理店としてStarburst製品の販売を開始した。

　大規模データ分析やAI活用のためのデータ収集のニーズが急速に高まり、社内外の多様なデータへの迅速なアクセスと統合的な活用を求められている。しかし、従来のデータ活用基盤は、分析に必要なデータを集めて統合するために抽出、加工、配信（Extract / Transform / Load：ETL）処理を必要としており、データ準備に要する時間、データ収集・管理にかかる費用、データガバナンスの複雑化といった課題を抱えるようになっている。

　Starburstは、クラウド、オンプレミスまたはハイブリッド環境などあらゆるデータソースに高速かつ直接アクセスし統合的に分析できるデータ分析基盤を提供している。サイオスが提供する「API・AIエコシステムデザインソリューション」と組み合わせて、迅速にデータを分析できるようにするとしている。

　「Starburst Enterprise Platform」と「Starburst Galaxy」は、いずれもビッグデータ分析のためのオープンソースクエリーエンジン「Trino」（旧PrestoSQL）をベースにしたデータ分析基盤。Enterprise Platformはあらゆる環境で使用でき柔軟にカスタマイズ可能なセルフマネージド型サービス。Galaxyはクラウド環境で運用負荷を最小限に抑えたい企業向けのフルマネージド型クラウドサービスだ。

　これらのプラットフォームの主な特徴として、統一されたデータアクセスが挙げられる。高いセキュリティとガバナンスを維持したまま、必要なときに元のデータへ直接アクセスできるため、データをコピーしたりストレージに集約したりするETL処理が不要で、データ活用での運用負荷の軽減とインフラコストの削減が可能となる。

　高性能なクエリーエンジンであるTrinoを採用することで、大規模で複雑なクエリーでも高速な処理性能を発揮。これまで数日かかっていた複数システムのデータ準備がわずか数分で完了するため、分析担当者は煩雑なデータ集約ではなく、分析そのものに集中できるようになるという。

　AIエージェントへのコンテクスト提供機能も備えている。クラウド、オンプレミス、国境をまたいでガバナンスの効いたデータプロダクトと統一されたアクセスを提供し、断片化したデータを信頼できるインテリジェンスに転換できるという。チームとAIエージェントはどこに存在するデータであっても、より速く安全に発見し、信頼し、活用できるとしている。

　セキュリティ面では、認証・認可、監査、ガバナンス、ロール管理など本番環境で求められる制御機能を提供し、Amazon Web Services、Azure、Google Cloud Platformといった主要クラウドとネイティブに統合することで、オンプレミス、クラウド、ハイブリッドのいずれの環境でも安全に運用できるという。

　「Apache Iceberg」などのオープンソーステーブル形式を採用することでベンダーロックインが回避と説明。豊富なコネクタで多様なデータに接続できるため、センサーやIoTからのリアルタイムデータと業務データを同時に分析し、異常検知や生産調整などを即座に実行できるとしている。

　両社は、導入支援から運用代行、保守まで一気通貫したサービス提供を通じて、顧客企業の次世代データ分析基盤の構築と、AIやデータの戦略的な活用を支援していくとしている。",[],[]
プロンプトインジェクションが2026年のセキュリティ主要課題に--クラウドストライク（ZDNET Japan）,https://news.yahoo.co.jp/articles/9b49afa0a1776b76150a3a8eededb899600419bf,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20251217-35241772-zdnet-000-1-view.jpg?exp=10800,2025-12-17T16:03:00+09:00,2025-12-17T16:03:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,1611,"プロンプトインジェクションが2026年のセキュリティ主要課題に--クラウドストライクの画像
クラウドストライクは12月17日、2026年のサイバーセキュリティ業界予測を発表した。同社 最高技術責任者（CTO）のElia Zaitsev（エリア・ザイツェフ）氏は、プロンプトインジェクションがセキュリティの主要課題になると予測している。

　攻撃者はセーフガードを回避し、エージェントの乗っ取りやデータ窃取、モデルの操作を行うために隠された指示を埋め込んでいる。これにより、AIの対話レイヤーが新たな攻撃面となり、プロンプト自体が新たなマルウェアになりつつある。

　これを踏まえ、2026年には、AI Detection and Response（AIDR）が、EDR（エンドポイントの脅威検知・対応）と同様に不可欠な存在になるという。組織は、プロンプトやレスポンス、エージェントのアクション、ツール呼び出しをリアルタイムに可視化し、AIの悪用が拡大する前に封じ込める必要がある。

　また、AIを利用して攻撃を高度化している攻撃者に対応するため、防御側は単なるアラート対応者からエージェント型セキュリティオペレーションセンター（SOC）を統率するオーケストレーターに進化する。

　「セキュリティ・オーケストレーター」は、推論・判断・アクションを機械速度で実行するエージェント群を、人間が指揮する。これにより、攻撃者と防御側のパワーバランスを変え、セキュリティ成果を大きく加速するという。

　この進化には、エージェントとアナリスト双方に、環境の完全なコンテキストを提供し、あらゆるシグナルに即時対応できることや、熟練SOCの判断を学習した実践投入できるエージェント群によって、煩雑で時間がかかる作業を高速かつ精密に自動化できるといった前提条件が欠かせない。

　ほかにも、エージェントの効果性を証明するベンチマークと検証の実施や、組織がニーズに合わせてエージェントを構築できる能力、人間の専門性を軸に、エージェント同士やアナリストとの協調を1つのシステムに統合することも条件として挙げている。

　Zaitsev氏は、AIのアイデンティティー（ID）管理も重要になると説く。2026年には、AIエージェントや非人間IDが企業内で爆発的に増えるとし、これらのエージェントはOAuthトークンやAPIキーをはじめ、これまで分断されていたデータへ継続的にアクセスできる高い権限を持つ存在として動作するようになると指摘する。

　従来のIDセキュリティでは対応しきることが難しく、セキュリティチームにはリアルタイムの可視性、即時の封じ込め、全てのエージェントのアクションを、それを作成した人間にまでさかのぼって追跡する能力が求められるとしている。

　クラウドストライク Counter Adversary担当シニアバイスプレジデントのAdam Meyers（アダム・マイヤーズ）氏は、2026年に、AIによってゼロデイ脆弱（ぜいじゃく）性が急激に増加する可能性を示唆している。

　AIはソフトウェアの欠陥を発見する能力にたけており、特に、自動化を用いて欠陥を洗い出す「ファジング」を劇的に進化させるという。AIはファジング手法を最適化し、膨大なクラッシュレポートを高速に分析し、悪用できる欠陥を明らかにする恐れがある。

　既に攻撃者はこの研究に投資している兆しがあり、脆弱性の発見と兵器化に必要なコストは下がり続けているという。脆弱性を狙ったエクスプロイトは、初期侵入を行うために使用する鍵となっており、防御側はAIを攻撃者と同じ速度と精度で活用し、ゼロデイを検知し、パッチを適用し、積極的にハンティングしなければならない。「ゼロデイが見つかるスピードと同じ速さで対処することが求められる」とMeyers氏は述べている。",[],[]
日本総研とパーセフォニ、GHG排出量算定など情報開示の支援サービスを開始（ZDNET Japan）,https://news.yahoo.co.jp/articles/944bfe6e450aa61feeafae85bad42273debd1023,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20251217-35241770-zdnet-000-1-view.jpg?exp=10800,2025-12-17T15:18:00+09:00,2025-12-17T15:18:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,696,"日本総研とパーセフォニ、GHG排出量算定など情報開示の支援サービスを開始の画像
日本総合研究所（日本総研）とPersefoni Japan（パーセフォニ）は12月17日、温室効果ガス（GHG）排出量算定やサステナビリティー（持続可能性）情報開示への対応を支援するサービスを共同で開始すると発表した。クラウド活用と運用体制の構築で、関連データの収集・集計・開示業務の効率化と高度化を図るという。

　国内では、2027年3月期から東京証券取引所プライム市場の上場企業のうち時価総額3兆円以上の企業にサステナビリティ基準委員会（SSBJ）公表の「サステナビリティ開示基準」などに基づく情報開示が義務化される予定となっている。

　両社は、SSBJ基準ではスコープ3（サプライチェーン全体）のGHG排出量の開示が求められる一方で、第三者認証を含めサプライチェーン全体の多岐にわたるデータ収集や複雑な算定を取りまとめる体制構築が容易ではないとし、現時点で開示できていない企業が少なくないと指摘する。

　新サービスでは、パーセフォニが第三者認証・監査を前提とするスコープ1～3のGHG排出量の算定・開示と脱炭素化への計画策定および削減目標達成を支援するクラウドサービスを提供。日本総研が収集データを活用したGHG排出量の削減やサステナビリティー経営のための戦略策定と実行に関するコンサルティングを行う。

　パーセフォニのサービスは、グローバルでのGHG排出係数をプリセットしているほか、AIエージェントによるユーザーへの助言や異常値の検知、海外の各種関連法規制などに開示情報作成などができるという。",[],[]
日本IBM、材料開発に特化したサービスを提供--数十億の化合物データを事前学習（ZDNET Japan）,https://news.yahoo.co.jp/articles/5a1072814d189d25778ad39b08ce1c62c81f7cb4,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20251217-35241743-zdnet-000-1-view.jpg?exp=10800,2025-12-17T13:00:00+09:00,2025-12-17T13:00:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,978,"日本IBM、材料開発に特化したサービスを提供--数十億の化合物データを事前学習の画像
日本IBMは12月16日、材料開発に特化した新サービス「IBM Material DX」の提供を開始した。

　ものづくり産業の現場では、データが分散し統合が困難、材料設計は専門家頼みで試行錯誤しているなど、属人的で変化への即応が難しい状況にある。こうした中でMaterial DXは、IBM Researchの先端技術を中核に同社のコンサルティングサービスや高度な技術基盤を融合した、素材開発に特化した伴走型サービスを提供。材料探索から設計・導入までを一気通貫で支援することで、開発スピードを高め、ESG対応や規制物質リスクの事前回避につなげる。

　設計・構築では、顧客の課題やニーズに応じて、以下の4つの柱を組み合わせる。

　1つ目はデータマネジメント。IBM Researchが構築した膨大な公開文献データ基盤に顧客の材料や製品情報を統合し、社内外の情報を横断的に解析して新材料開発を戦略的に支援する。

　2つ目はAI・基盤モデル。数十億の化合物データで事前学習した基盤モデルと先端最適化技術で材料候補のスクリーニング、構造設計、合成経路探索などを飛躍的に効率化し、開発スピードを数倍に高める。

　3つ目は、大規模言語モデル（LLM）・対話型インターフェース。材料開発に特化したAIエージェントと、材料分野の専門家と会話するような自然なインターフェースで専門知識がなくても必要な情報やインサイトを素早く取得できる。

　4つ目は柔軟なインフラ環境。オンプレミスのIBM FusionやIBM Cloudを含むマルチクラウド、ハイブリッドクラウドのそれぞれの環境に対応し、機密情報を外部に出さずに運用可能で、顧客のニーズにあわせた柔軟な構成を選択できる。

　ESGリスク判定ツール「IBM Safer Material Advisor」でPFASなど規制強化が進む物質のリスクをAIが事前に可視化。量子コンピューターの材料開発への適用に向けた教育・共同開発など長期視点での支援も提供する。

　日本IBMは、新製品投入の高速化、情報活用基盤の構築、研究開発人材の生産性向上などを通じ、企業のデジタルトランスフォーメーション（DX）加速を支援していく考えだ。",[],[]
消費者は「AIによる顧客対応にメリットを感じていない」--クアルトリクス調査（ZDNET Japan）,https://news.yahoo.co.jp/articles/ecfaf047c4e1a69120522a0b2e9b20addcf34f83,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20251217-35241740-zdnet-000-1-view.jpg?exp=10800,2025-12-17T12:30:00+09:00,2025-12-17T12:30:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,1522,"消費者は「AIによる顧客対応にメリットを感じていない」--クアルトリクス調査の画像
体験管理（XM）プラットフォームを提供するクアルトリクスは12月16日、年次レポート「2026年消費者トレンドレポート」を発表した。14の国と地域の約2万人（日本1500人含む）を調査した。調査では、以下の4つのことが明らかになった。

AIを活用したカスタマーサービスにメリットを感じていない
日本の消費者は悪い体験後も購入を継続する傾向
半数以上が悪い体験を何も伝えない
パーソナライゼーションに必要なのは「より多くの信頼」

　1つめは、AIを活用したカスタマーサービスにメリットを感じていない。一般的なAI活用領域の中で、カスタマーサービスにおけるAIは最低評価で、利用した消費者の約5人に1人が「メリットはなかった」と回答している。

　特に利便性や時間短縮、有用性の各項目で評価が低く、「AIアシスタント」はそれらよりさらに低評価だった。消費者が最も懸念しているのは個人情報の不正利用で、この懸念を持つ日本の消費者は55％に上る。39％の消費者がAIへの移行によるやり取りの質の低下を懸念し、34％が提供される情報の信頼性に疑念を抱いてることがわかった。

　2つ目は、日本の消費者は悪い体験後も購入を継続する傾向にあるということ。ブランドスイッチが容易な業界では、満足度や信頼、ロイヤルティが大きく改善された。一方で、公共サービスのように乗り換えが難しい業界では、消費者体験の改善ペースは緩やかだった。

　日本では、満足度や信頼度、推奨意向、追加購入意向のすべてで世界平均に比べてポイントが約2倍に上昇。46％が「価格に見合う価値」を求めたが、日本の消費者の場合は30％と企業や商品を選ぶ理由について決定打がないことが浮き彫りになった。

　3つめは、半数以上が悪い体験を「何も伝えない」ということ。「悪かった体験を企業に直接伝える」という日本の消費者は10％で、2021年から4.5ポイント減少。さらに「何も伝えない」という顧客は54％で、2021年から13.6ポイント増加した。

　企業がこれまで以上にインサイトを必要としている一方で、消費者からのフィードバックは減少している。こうした状況下でSNSなどの間接的なフィードバックの重要性が高まっているとしている。

　4つ目は、パーソナライゼーションに必要なのが「より多くのデータ」ではなく「より多くの信頼」。個々の体験に寄り添って対応してくれる企業から商品を購入したいと考える日本の消費者は44％にのぼっている。ただ、個別の体験を望むために個人情報を提供することには消極的で、企業が個人データを適切に取り扱うと信頼している人は29％にとどまり、「詐欺」（22％）、「個人情報の売買」（20％）への懸念が大きいという結果となった。

　一方で、消費者の購買習慣を学習するために個人データを使う場合は比較的受け入れやすいという結果と出ており、例えば、「コーヒー注文やおすすめアイテムの提案などに利用の際は許容できる」と27％が回答。38％が「パーソナライゼーション全般に抵抗感を抱く」と回答し、パーソナライゼーションの浸透が低い水準にとどまっていることが明らかになった。ただ、56％が「データの使用を自分で管理できるようになれば、データ提供に前向きである」と回答している。

　クアルトリクスでは、「データセキュリティーについて説明があれば納得する」（45％）と回答していることから、消費者の信頼を取り戻すには、透明性の確保とユーザーによるコントロールの提供が不可欠との考え方を示している。",[],[]
グーグル、検索ページから「AIモード」を利用しやすく（ZDNET Japan）,https://news.yahoo.co.jp/articles/8216c3e88d4f13292b97f087a6b73ef652e489c7,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20251217-35241737-zdnet-000-1-view.jpg?exp=10800,2025-12-17T09:21:00+09:00,2025-12-17T09:21:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,978,"グーグル、検索ページから「AIモード」を利用しやすくの画像
「Google検索」に変更が加えられ、「AIモード」が使いやすくなった。

　大々的な告知もなければ、公式発表すら見当たらないが、Googleはメインの検索ページに小さなプラス記号を追加した。ここにマウスカーソルを合わせると、「ファイルまたは画像をアップロード」と表示される。続けてクリックまたはタップすれば、ファイルをアップロードしてAIモードで詳しく分析できる。

　ファイルや画像をアップロードできる機能は以前からあったが、AIモードに入るための操作が必要だった。しかし、この新しいボタンにより、メインの検索ページから直接AIモードを利用できるようになった。これにより、人工知能（AI）に警戒感がある人を含め、より多くのユーザーにこの機能が広まることが期待される。

今すぐ試す方法（デスクトップのみ）

　AIモードで何かを分析するには、プラス記号をクリックまたはタップして、ファイルをアップロードすればいい（ただし、アップロードできるファイルの数は一度に1つだけだ）。

　この機能をちょっと試してみるため、筆者は地元の非営利団体のためにセキュリティ助成金の要件をまとめた文書をアップロードした。この文書にはドアの仕様に関する記述があったのだが、正確な内容を思い出せなかった。そこでAIモードに尋ねたところ、文書内の該当箇所を見つけ出して、詳しい内容を教えてくれた。

　今回の変更は小さなものだが、Googleが何を重視しているのかを示している。それは、さまざまな製品にAIを導入し、ユーザーに活用してもらう機会を確保するということだ。また、すでにこの機能を利用している人にも、手順が1つ省けるというメリットがもたらされる。

　Googleに詳細を確認したところ、広報担当者は次のように述べた。「デスクトップ版のGoogle検索バーに画像やPDFを直接アップロードし、AIモードでそのファイルについて質問できるようになった。これは、どこからでも、どのようなことでも質問しやすくするための新たな一歩だ」

　この機能は今週中に、AIモードがすでに提供されているすべての地域で利用できるようになる予定だ。

この記事は海外Ziff Davis発の記事を4Xが日本向けに編集したものです。",[],[]
キヤノンMJとサイバートラストが協業--電子文書の安全性を強化（ZDNET Japan）,https://news.yahoo.co.jp/articles/c0463474b32fa7da7191c5ccf6bc52448d70a276,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20251217-35241726-zdnet-000-1-view.jpg?exp=10800,2025-12-17T07:00:00+09:00,2025-12-17T07:00:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,816,"キヤノンMJとサイバートラストが協業--電子文書の安全性を強化の画像
キヤノンマーケティングジャパン（キヤノンMJ）とサイバートラストは12月16日、企業のデジタルトランスフォーメーション（DX）支援とトラストサービス領域での協業を発表した。キヤノンMJが提供する文書管理クラウドサービス「Digital Work Accelerator（DWA）」で管理するPDF形式の電子文書に、サイバートラストの「iTrust リモート署名サービス」を活用した「eシール」自動付与機能を提供する。サービスの開始は2026年1月下旬。

　内閣府が提唱する「Society 5.0」の実現には、AI活用やデータ連携が不可欠だが、フェイクニュースや文書偽造など情報の信頼性が課題となっている。eシールは、企業や組織が発行する電子データの「発行元の証明（なりすまし防止）」と「非改ざん性」を担保するもの。総務省による認定制度の整備が進む中、適格請求書や品質証明書など、対外的な文書流通における信頼性確保の手段として注目されている。

　今回、DWAとサイバートラストの「iTrust リモート署名サービス」をAPI連携させることで、ユーザーはDWAの指定フォルダにPDFをアップロードするだけで、自動的にeシールが付与されるほか、基幹システムから出力される帳票データに対しても、既存のワークフローを変更することなくeシールの付与が可能となる。署名に必要な秘密鍵の管理や署名処理はサイバートラストのクラウド基盤上で行われるため、ユーザー企業側での複雑な鍵管理が不要となるなど、セキュアな環境も提供する。連携時にはPDFファイルのハッシュ値に対して電子証明書を組み込むため、機密情報の外部流出リスクを低減する。

　今後は製造業における品質証明書や、企業間で発生する請求書や見積もり書など、対外的に信頼性が求められる文書への活用が想定されるとしている。",[],[]
JEITA予測、2030年の国内DC市場は5.6兆円規模へ--「データと電力は半導体に次ぐ戦略資源」（ZDNET Japan）,https://news.yahoo.co.jp/articles/8d7e41547ff7a16b575d7fc5c42eba6148325642,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20251217-35241722-zdnet-000-1-view.jpg?exp=10800,2025-12-17T07:00:00+09:00,2025-12-17T07:00:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,4189,"JEITA予測、2030年の国内DC市場は5.6兆円規模へ--「データと電力は半導体に次ぐ戦略資源」の画像
電子情報技術産業協会（JEITA）は、データセンターサービス市場の見通しについて発表した。日本においてデータセンターを通じて提供されるサービスの市場規模は、2030年に5兆6500億円となり、2025年の4兆3453億円から、年平均5.4％増で成長すると予測した。

　2030年の市場規模の内訳は、クラウドサービスが4兆190億円（2025年見込みは2兆8267億円）、ハウジングが6800億円（同6340億円）、ホスティング／通信回線／共同利用などが9550億円（同8846億円）としている。

　JEITA 会長の漆間啓氏（三菱電機 代表執行役 執行役社長 ＜代表経営責任者＞CEO）は、「日本のデータセンターサービス市場は、堅調に推移する見込みである。産業のデジタル化やAI活用の広がりによって、高度なデータサービス需要が、国内でもより拡大することから、設備の高性能化や効率的な運用などが求められるようになる。経済安全保障の観点から見ても、基盤インフラたるデータセンターを日本国内に確保し、盤石な体制を整備することは極めて重要である」と述べた。

　また、2030年におけるデータセンターサービス世界市場は1兆7200億ドルとなり、2025年に比べて2倍超の規模に成長すると予測した。また、サーバーや半導体、電子部品などのデータセンター関連製品市場は、2030年に1兆6907億ドルになると予測。2025年比で約2.5倍になる。日本市場よりも、世界市場の成長率のほうが高い。

　漆間会長は、「日本は、GAFAM（Google、Amazon、Facebook、Apple、Microsoft）などが開発する大規模言語モデル（LLM）などに追随することは難しい。また、データセンターに利用できる土地の広さにも差がある。だが、日本には、制御系システム（OT）領域のデータを活用することで、特化型AIや関連ソリューションに注力ができるという強みがある」と述べた。

　北米を中心にした大規模投資によって、世界のデータセンターサービス市場は大きく成長するのに対して、日本では、特定市場におけるユースケースの創出が中心となり、それが世界と日本のデータセンターサービス市場の成長率の差になっている。

　今回の調査は、JEITAが毎年発表している「電子情報産業の世界生産見通し」において実施した「注目分野における動向調査」によるものだ。

　「電子情報産業の世界生産見通し」は、2007年から実施している調査であり、JEITA会員企業だけでなく、国内外の関連企業や団体の協力を得てまとめている。一方で、「注目分野における動向調査」は、毎年、テーマを決めて深掘りした調査を実施。2025年の調査テーマとして、「データセンターの動向」を取り上げた。

世界のデータセンター投資をクラウドサービスや生成AIなどが後押し

　JEITAでは、「データセンターの国内外の動向をまとめ、データセンターサービスおよび関連製品の市場見通しを発表した。主要国政府の政策や海外先進企業の動向など、公知情報の分析と、国内外先進企業へのヒアリングを基に需要を推計している」という。

　また、「データセンターサービスの世界市場では、SaaSやIaaS、PaaSなどのクラウドサービスが大きく伸長する。さらに、生成AIの普及のほか、クラウドサービスを中心としたサービス利用の加速、動画配信やゲームなどデジタルコンテンツ需要の拡大、AIの学習や推論に対応するGPUサーバーや高速ネットワークの需要拡大なども、複合的に作用して、世界中のデータセンター投資を強力に後押しすることになる」と分析した。

　データセンター関連製品市場の成長については、「2030年までの成長は、データセンターサービス市場を上回る大きな伸びとなっている。インフラの高度化に向けた投資により、GPUや冷却水分配装置（Coolant Distribution Unit：CDU）、サーバー、ネットワークスイッチ、SSDといった主要コンポーネントが市場をけん引する」と予測している。

　2030年のデータセンター関連製品市場の内訳は、サーバー（GPU搭載サーバー含む）が8326億ドル（2025年見込みは3479億ドル）、GPUが2874億ドル（同1194億ドル）、ネットワークスイッチが1278億ドル（同481億ドル）、SSDが830億ドル（同295億ドル）、CDUが44億ドル（同17億ドル）となっている。

　同協会では、2030年には膨大なAI処理需要に対応するため、GPU搭載サーバーがデータセンターの主力となると予測。2030年における汎用（はんよう）型サーバーの出荷台数を1750万台とし、そのうち、21.9％に当たる490万台がAI型サーバーになるとみている。2026年までに半導体供給が安定し、投資は順調に進むと見込んでおり、2027年以降はAIビジネスの収益性や学習用教材の枯渇を背景として投資は落ち着くとも予測した。

　また、AI用途でGPUの需要は加速し、2030年に向けて高性能化が進み、特に、クラウド事業者の大量調達がGPU市場の成長を牽引すると予測。ネットワークスイッチは、AIクラスターの構築で400Gの高速スイッチ需要が増加すると見込んだほか、2030年には、高帯域および低遅延スイッチが標準化し、大規模AIモデルの並列処理を支えることになるとみている。

　さらに、SSDはAI用途で高速ストレージの採用が進み、2030年には学習データの高速読み込みや、推論レスポンス向上のために、高容量・高性能SSDが標準化し、安定成長を続けるとみている。加えて、CDUの市場拡大を予測。GPU搭載サーバーの高発熱対策として液冷冷却装置が増加。省エネや効率化に対する要求が強まるとみている。

　メガクラウドベンダーにおけるクラウド事業売上高見通しも発表している。

　2030年におけるメガクラウドベンダーによるクラウド事業の売上高は8330億ドル（2025年見通しは4180億ドル）と予測。内訳は、Microsoftが2750億ドル（同1650億ドル）、Amazon Web Services（AWS）が2700億ドル（同1270億ドル）、Salesforceが1100億ドル（同430億ドル）、Googleが1000億ドル（同530億ドル）、Oracleが780億ドル（同300億ドル）と予測した。

　同協会では、「メガクラウドベンダーによるクラウド事業の売上高は、2030年までの年平均成長率は14.8％と高い。AIインフラ競争の最前線にいるメガクラウドベンダーはデータセンターに対する大規模な先行投資を継続的に行うことになる」としている。
「AI時代の成長は、もはや、データと電力の戦略的確保が決める」

　一方で、データセンターの高度化に伴い、電力消費の増大や発熱への対応、冷却効率の向上といった課題が顕在化していることも指摘。さらに、電力需要の拡大や脱炭素化への対応など、複合的な社会課題の解決も強く求められていることにも言及している。

　データセンターにおける総電力需要は、2030年に946TWhに達すると予測。2023年の361TWhから、年平均14.8％で増加するという。

　漆間会長は、「データセンターの整備を図る上での課題は電力供給である。指数関数的に上昇する処理能力への要求に応じて、データセンターの電力需要は、2030年には、現在の2倍以上になることが予測されている。電源の確保と省エネ技術の革新は、今後ますます重要となり、電力供給がサプライチェーンのボトルネックにならないように、産学官の連携が必要不可欠である」と指摘。

　さらに、「AI時代の成長は、もはや、データと電力の戦略的確保が決めると言っても過言ではない。データセンターと電力は、半導体に次ぐ、国家の戦略資源であるという視点を持たなければ、日本のデジタル競争力は維持できないだろう。日本の産業競争力、国際的なプレゼンス、そして国民生活の利便性は、この基盤を確保できるかどうかにかかっている」とも述べた。

　一方、JEITAの漆間会長は、「国際情勢が不透明さを増す中、経済安全保障の重要性はかつてなく高まっている。エネルギー、半導体などと並び、データとデジタル基盤は、国家の機能を左右する『新たな戦略資源』になりつつある。特に、データセンターは、行政、産業、国民生活の全てを支える『基盤インフラ』となる」と指摘したほか、「今後のAI活用による経済発展には、各産業分野が現場で保有するデータの重要性が一段と高まる。とりわけ、日本の産業分野の現場で生まれるOTデータは、極めて高品質で、有効なデータである。これらは領域特化型AIを活用した生産性向上と付加価値創出の源泉であり、産業競争力と経済安全保障を支える鍵である」とした。

　データ活用の促進に向けた新たな取り組みとして、JEITAでは、同協会内に、2026年5月に、デジタルエコシステム検討会を発足させる計画を発表した。

　漆間会長は、「日本の生産性を高めるには、製造現場のデータとAIを組み合わせることで、付加価値を高め、ものづくりの強化につなげていくことが重要である。日本が競争力を取り戻せるかどうかは、ソフトウェアとデータに本気で投資できるかに尽きる」と前置きし、「デジタルエコシステム検討会は、JEITA会員企業にとどまらず、企業や業界の枠を超え、複数の組織や企業が互いに信頼できる仕組みの下、安全かつ自由にデータを活用できる産業データスペースを目指すものになる。現在は準備フェーズにあるが、産業界で進めている取り組みをベースに、将来のユースケース創出につながる検討課題やアクションなどの整理を進めている」とした。

　2025年6月に発足したデジタルエコシステム官民協議会と検討内容を共有しつつ、官民一体で産業分野のデータ活用を進めるという。",[],[]
AI時代のキャリア戦略--技術スキルよりも重視される「エコシステムを読み解く力」（ZDNET Japan）,https://news.yahoo.co.jp/articles/575ec990b0af1afb40b42919d1900c0cf61a12b1,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20251217-35241702-zdnet-000-1-view.jpg?exp=10800,2025-12-17T07:00:00+09:00,2025-12-17T07:00:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,3364,"提供：Naige Schulte/iStock/Getty Images Plus
Gartnerが発表した2026年以降の戦略的テクノロジートレンド上位10項目から、人工知能（AI）がオペレーショナルエクセレンスとデジタルトラストに与える影響が明らかになった。同社が示したトレンドと予測により、エージェント型AI時代における人材獲得の主要な傾向も浮き彫りになっている。未来の仕事はハイブリッドになり、人間とAIエージェントが手を取り合って、全ての利害関係者のために価値を創造するという。

　Gartnerの予測では、2028年までに顧客対応業務プロセスの80％にマルチエージェント型AIを利用する企業が優位に立つとされている。同時に、対企業（B2B）購買の90％をエージェントが仲介するようになり、AIを活用した取引で15兆ドル以上が動く見通しだ。

　人材の確保に関しては、2027年までに、採用プロセスの75％に職場でのAI運用能力に関する認定やテストが含まれるようになるという。同社はまた、生成AIの使用に伴う批判的思考力の低下を背景に、世界の企業の50％が2026年までに「AI不使用」のスキル評価を実施すると予測している。

　では、あらゆる企業で自律化が進み、デジタルレイバーを駆使して競争を勝ち抜こうとする世界で、人間が存在感を示して採用を勝ち取るには、どうすればいいのだろうか。

真の面接

　もし履歴書が話せるとしたら、どんなストーリーを語るだろうか。多くのビジネスパーソンの場合、スキルや実績の列挙になるだろう。しかし、転職希望者が増加している現在、そうした履歴書では採用への扉が開かなくなっている。

　DeRecco Lynch氏が「Invisible Interview Era」（見えない面接の時代）と呼ぶ時代が到来しつつある。これは、自分の知識だけでキャリアが形成されるのではなく、自らの価値をデジタルエコシステムでどのように示すかによってキャリアが形作られる時代だ。

　本稿の執筆に協力したLynch氏は、シンシナティ大学の入学管理担当アシスタントバイスプレジデントを務めている。同氏はSalesforceでの20回の面接と20回の不採用という経験を通じて、身をもってそのトレンドを学んだ。そして、その経験が再設計の青写真となった。

　Salesforceの求人には、年間約200万件の応募がある。Lynch氏は、シニアソリューションズエンジニア兼HBCUエンゲージメントオフィサーとして2021年にSalesforceに入社した。

　「全ての『ノー』がデータになった。不採用のたびに、私のストーリーに磨きがかかった。その過程で、真の面接とは採用担当者と行うものではなく、見えない経済の中で毎日起きているのだということに気づいた」（Lynch氏）

見えない経済の台頭

　Lynch氏は著書「The Invisible Interview」の中で、技術の進歩を映し出す根本的な考え方の変化について説明した。

　従来のキャリアを支えていたのは、学歴と直線的なキャリア形成だったが、現在の成功はエコシステムを読み解く力、すなわち業界を形作るプラットフォーム、人間関係、技術を深く理解しているかどうかにかかっている。

　この変化は、自律的な企業で起きている変化と似ており、アウトサイドイン（外から内）の設計と適応型インテリジェンスが、硬直化した管理構造に取って代わりつつある。今や個人も組織と同様に、応答性の高いシステムとなって、新しいシグナルに順応し、迅速に方向転換でき、相手に合わせて価値を語れることが求められている。

　Lynch氏はこれを「ジャンルレスになる」と呼ぶ。分野の枠を越えて自分の経験を応用する能力のことだという。同氏は「私は高等教育を捨て去ったのではない。捉え直したのだ」と述べ、自身の考えを強調した。さらに、「再設計とは、過去を焼き尽くすことではなく、得た教訓を今後に生かすこと」であると説明した。

不採用は判定ではなくシグナル

　産業革命の原動力は機械だった。このAIによる変化の原動力となっているのは、フィードバックループだ。Lynch氏は著書の中で、不採用に終わった面接でも、採用担当者が別の道を示し、その後メンターになったケースもあったと記している。

　1つ1つの「ノー」が、AIシステムで言うところの訓練データセット、つまり次回のパフォーマンスを向上させる入力の役割を果たした。「不採用は終わりではない。方向転換だ。どんな会話も、方向性をすり合わせるための小さな学びになる」

データとしてのストーリーテリング

　AIはデータセットを分析するときにパターンを探す。人間の面接も同じだ。Lynch氏によると、最も強力な差別化要因は技術スキルではなく、同氏が「アーティファクトデッキ」と呼ぶものを通して、自分の影響のパターンを示す能力であるという。アーティファクトデッキとは、自分のストーリーを視覚と感情の両面から伝える5枚のスライドのことだ。

　Lynch氏が採用担当者の記憶に残ったのは、明確なシグナルを示し、価値、適合性、意図についての一貫性のあるストーリーを伝えたからだった。アルゴリズムと応募者追跡システムの時代において、ストーリーテリングは履歴書よりも速く伝わる構造化データとなる。
転職者が見落としがちなこと

　「The Invisible Interview」の補足章には、「知っておくと役立つこと」が書かれている。この戦術的な教訓は、自分自身のキャリアに関する製品リリースノートのように読める内容だ。

　以下に挙げたそれらの教訓は、大手企業の採用手法と一致している。固定的なチェックリストに印を入れていくのではなく、エンゲージメント、適応力、シグナルの強さを見極めるものだ。

1回試すだけでは足りない
肩書きではなく、職務を表す動詞を読み解く
推薦は懇願するものではなく、築き上げていくもの
及び腰にならず、好奇心を持つ

未来の仕事の主役は人間

　ビジネスにおいて、自律型システムが真価を発揮するのは、周囲の世界を感知したときだ。この原則は個人にも当てはまる。現在の成功は、環境インテリジェンス、すなわち自分の分野を形作っているネットワーク、技術、人間のシグナルを理解できるかどうかで決まる。

　この見えない経済では、好奇心がセンサーであり、ストーリーテリングがデータアーキテクチャーであり、再設計がOSだ。

　企業も人間も、外側から内側に向かって自らを設計する者が勝利をつかむ。単に未来に適応するのでなく、未来と関わり合う必要がある。

再設計のための戦術

　Lynch氏は、再設計に向けた10段階のロードマップで著書を締めくくっている。自身の20回の面接の経験に基づくこのロードマップは、多くの点で、現代のビジネスを推進するアジリティーのフレームワーク、すなわちテスト、学習、反復を反映している。

　AIモデルを強化する適応の原則によって、人間のキャリアのレジリエンスも高まる可能性がある。以下がその10の段階だ。

方向転換を決意する
エコシステムに興味を持つ
意図的にスキルアップする
自分のデジタルブランドを確立する
アーティファクト（成果物）を作る
目的意識を持って関係を構築する
拒絶の受け止め方を変える
適した場所を見つける
メンターシップを利用する
最初からやり直すのではなく、再設計する

新たな現実

　今は、誰もが目に見えない面接を受けている時代だ。あらゆる投稿、プロジェクト、プレゼンテーションによって、自分が何者なのか、何を成せるのかが、ひそかに発信されている。そのようなシグナルを意図的に発信する術を学んだ者が、未来の採用を勝ち取るだろう。

　その理由をLynch氏は次のように指摘する。「新たなスタートを切るのに、最初からやり直す必要はない。経験を積んだ初心者として一歩を踏み出すだけだろう」

この記事は海外Ziff Davis発の記事を4Xが日本向けに編集したものです。",[],[]
見えないWi-Fiトラブルを可視化、100台の同時接続に対応する「AirThreads」（ZDNET Japan）,https://news.yahoo.co.jp/articles/d0385ea7d74ae336faff93df05c960b371575357,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20251217-35241655-zdnet-000-1-view.jpg?exp=10800,2025-12-17T07:00:00+09:00,2025-12-17T07:00:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,4106,"ネットワークのイメージ
今やWi-Fiは社会インフラと位置付けられており、都市部ではサービスが提供されていて当たり前といった認識になりつつある。とはいえ、電波の状況は目には見えないため、アクセスポイントの配置などが適切なのかどうかの判断は誰にでもできるというものではないし、パフォーマンスに悪影響を及ぼすような遮蔽（しゃへい）物やノイズ源の存在が問題になることもある。

　来場者へのサービスの1つとして無償提供されるWi-Fiサービスの場合は、利用者側の期待値があまり高くないこともあるかもしれないが、企業のオフィスや「GIGAスクール構想」でネットワーク整備が進んだ学校などでは、ネットワークにトラブルが生じるようでは業務や授業を円滑に進めることができなくなってしまう可能性もある。

　まさにミッションクリティカルなインフラとして設置／運用に万全を期す必要があるが、特に学校などではITやネットワークの管理を専任で担当する人材が確保できないことも珍しくない。ユーザーから使い勝手やパフォーマンスに関して不満の声が上がっても、何が悪いのかもどうすれば改善できるのかもわからない、ということがあちこちで起きていそうだ。

　こうした状況を踏まえ、エーピーコミュニケーションズは、無線ネットワーク同時IP通信テストソリューション「AirThreads（エアスレッズ）」をアップデートし、最大100台の同時接続に対応できるようになったことを発表した。今回、AirThreads事業を担当する同社の先進サービス開発事業部 執行役員の國森修氏にAirThreadsの概要やアップデートの詳細について聞いた。

　AirThreadsは、「企業や教育機関、公共施設などの大規模な無線ネットワーク構築において、専門スタッフが現地で同時IP通信テストの実行から運用・評価・改善までをワンストップで支援するオンサイトサービス」だと説明する。実際に現地に赴き、通信状況を確認した上で問題箇所の特定や改善案の提示などを行う。

　國森氏はサービス開発の背景について、「われわれが無線ネットワークを構築する際に、電波強度などを測定するツールはあったためヒートマップなどを作成することはできたが、実際にネットワークを構築してIPレベルで通信を開始してみると遅かった、という問題が往々にしてある。しかし、IPレベルで通信ができているのかどうかをテストするには、無線端末を30台、40台と用意して一斉に接続するといった作業を実際に行ってみる必要がある。そのため、機材や人員を用意するのが難しいという課題があった」と明かす。

　実際の運用現場では、「そもそも接続できない」というトラブルはあまり目立たないとのことだが、「つながるけど遅い」という声は非常に多いそうだ。この場合、実際にユーザーが使用する時の環境条件をしっかり再現しないと原因を究明することはできない。

　設置の時点では実際の利用環境を想定してアクセスポイントの台数や配置を適切に設計しているはずで、想定外の大人数が同時に接続したということであればともかく、本来の想定から大きく異なるわけではない状況でパフォーマンスが低下するのは何かがおかしいわけだが、この状況を再現するためには多数の端末が必要になってしまうため検証は簡単ではない。

　実際にパフォーマンス劣化に悩んでいた学校では「学級活動の時間を利用して、生徒全員に普段通りの端末操作を実行してもらって確認するという話もあった」と言う。端末を普段と同じ台数分集めてそれを同時に操作するとなると、テスト用に機材や人員を確保するのも大変であるため、普段の利用状況で確認する方が手っ取り早いということにはなるが、本来であれば業務や授業に使いたい時間を、ネットワークのトラブルシューティングのために割くのは本末転倒であり、こうしたメンテナンス作業は放課後などの空き時間を使って済ませておきたいところだ。

　こうしたニーズに応えるために同社では専用のハードウェアを用意している。もともとテスト自動化ツールを作成していたこともあり、無線ネットワークに対しても一斉に接続してまとめて負荷を掛けられるような機材を用意し、組み合わせたサービスを作ってみたという経緯だ。

　開発されたハードウェアは、USB接続の無線モジュールを4つ搭載した4台のマイクロサーバーの計16クライアントが1つのユニットとしてまとまった形で、これを必要な数だけ現場に持ち込む。有線ネットワークのRJ45コネクターやUSBコネクターのサイズ感から想像できる通り、マイクロサーバー自体はほぼ手のひらサイズであり、100端末分でも7ユニットで対応できる。

　当初は最大40接続でサービスを開始したが、今回ユーザーからの要望に応える形で最大100接続に拡大された。GIGAスクール構想の主役である小中学校では1クラス当たりの生徒数はおおよそ40人だが、例えば大学の大講堂や学食などでは100端末規模のテスト環境も必要になってくる。同氏は「ユーザーからの要望もあり、100台規模まで拡大したら案件の受注が始まったというのが正直なところ」だと明かす。

　約40台規模だとユーザーには響かなかったようだが、やはり企業でも学校／教育機関でも100台規模くらいになると、テスト環境の準備ができなくなるようで、こうしたテスト環境が使えるのであればぜひ、という反応が目立って増えてきたようだ。

　このハードウェアを使い、同社のエンジニアが現地に赴き各種テストを実行し、結果を解析して改善点などの提案を行うというサービスになっている。基本的に、現地で1日作業を行う場合、40クライアント規模であれば約30万円から、100クライアントになると約90万円からが金額の目安となるそうだ。テストは自動化されているが、テストシナリオの実行にはおおよそ2～3時間が必要となるため、午前に1シナリオ、午後に2シナリオを実行するくらいが標準的な作業量となる。

　AirThreadsでは、テスト用のマイクロサーバー群を必要なクライアント数に合わせて持ち込み、実際にIPレベルでの通信を実施する。通信相手となるサーバーは現地に物理的なハードウェアとしてオンプレを設置することも、Amazon Web Services（AWS）などのクラウドを設置することも可能だ。クラウド設置にした場合には、インターネット上のサービスに到達するまでの通信経路のどこかに問題がある場合の解決に役立つだろう。逆に、アクセスポイントの配置や設定など、Wi-Fi環境そのものに問題がある場合にはオンプレ設置でも迅速に突き止められると期待できる。

　確認可能な内容は「全体スループット」「クライアントごとのスループット」「Ping応答時間」「パケットロス率」「電波情報（SSID、BSSID、周波数、チャンネル、信号強度）」で、現在対応しているWi-Fi規格は「Wi-Fi 6（IEEE 802.11ax）」までとなっている。すでに「Wi-Fi 7」が市場に出回り始めているタイミングではあるが、ユーザーが接続に利用する端末側の対応はまだこれからというところで、実際の利用ではWi-Fi 6が圧倒的に多いことから、現状把握という意味では問題ないだろう。

　まだリリースから間もないタイミングということもあって実際に利用した例は多くはないが、製造業のユーザーで100人近い人数が集まって研修や会議をビデオ会議経由で行う際にパフォーマンスが悪いということでAirThreadsで調査したことがあるという。この場合は、各端末当たりのビデオストリームがおおむね1Mbpsで、それを100台アクセスポイントに接続して対応できるかどうかを検証し、何台までなら実用的かや、100台つなぐなら1台当たりの帯域をどのくらいに制限すべきかといったデータが得られた。

　また、やってみないとわからなかったであろう知見としては、複数のアクセスポイントを設置していたが、それぞれが接続を受け付ける端末数には極端な偏りがあり、極端な場合は9対1といった比率になってしまうこともあった。あるアクセスポイントが過負荷に陥っている一方で、ほかのアクセスポイントは遊んでしまっているようなことも起こっていたという。

　アクセスポイント間の負荷分散の問題は解決が難しく、同社内のWi-Fiネットワークの状況を調査した際にはやはりユーザーから「遅い」という声が出ていたそうだが、複数あるアクセスポイントのうちの一番遠いアクセスポイントにつながってしまうという例が見つかったそうだ。このほか、アクセスポイントの仕様を見比べても特に違いはないものの、実際に接続してみるとパフォーマンスに差が出る例もあるとのことで、アクセスポイントのテストにも利用できると思われる。

　今後の計画として國森氏は、「ショッピングモールやスタジアムなどでは300台位の接続テストのニーズがあると聞いているので、その規模までカバーできるように拡張していきたい。そして、最新のWi-Fi規格への対応も考えている」と語った。

　昨今は急速にデジタル化が進展したことで、あらゆることをソフトウェアで解決できるようなイメージができあがりつつあるが、物理的なデバイスを大量にそろえて実際にやらないと分からないこともある。

　AirThreadsは、何が起こっているのか、なぜパフォーマンスが出ないのか簡単には分からないことも多いWi-Fi環境のトラブルシューティングに、実際に多数のユーザーが同時に接続する状況を再現するという、ある意味単純ではあるが、実現するのは簡単ではないテスト手法をサービスの形で利用できる。

　GIGAスクール構想で校内にWi-Fi環境が構築されたものの、トラブルシューティングまでは手が回らない先生方にとっても有用なサービスと言えるのではないだろうか。",[],[]
アイデア創出プロセスにAIを組み込む--AIを活用したイノベーションの創出に向けて（ZDNET Japan）,https://news.yahoo.co.jp/articles/e74047c5b6ef375f67505420d676a07d5d6b6a20,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20251217-35241588-zdnet-000-1-view.jpg?exp=10800,2025-12-17T07:00:00+09:00,2025-12-17T07:00:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,3567,"アイデア創出プロセスにAIを組み込む--AIを活用したイノベーションの創出に向けての画像
ビジネス環境の変化が著しい中、企業にはイノベーションが求められており、AIやデジタル技術を活用した業務効率化や既存事業の高度化にとどまらず、ビジネスモデルや新サービスを創造することが期待されています。企業は、新規事業の立案や新サービスの構想化のあらゆるプロセスにおいてAIを活用し、アイデアの質と量を高めていくことが推奨されます。

イノベーションに向けたアイデア創出のアプローチ

　本連載の前回「日本企業はAIでイノベーションを起こせるか--新規価値創出における国際競争力」では、AIやデジタル技術を活用した新規事業や新サービス創出に対する取り組みにおいて、日本は他国に後れを取っていることを指摘し、AIやデジタル技術から不連続型イノベーションを生み出すことの重要性について述べました。

　新規事業創出などの不連続型イノベーションでは、これまでの業務改善や漸進型イノベーション以上に発想の転換が必要であり、未来志向の「問題発見型」のアプローチが有効です。

　問題発見型のアプローチでは、未来における外部環境を起点とすることがポイントとなります。そこでITRでは、将来視点の外部環境の変化を起点としたアイデア創出プロセスを考案しました。この手法は、前連載シリーズ「新規ビジネスを創出するアイデア発想法--不連続型イノベーションの進め方と着眼点」で紹介したもので、（1）外部環境の分析、（2） 課題・ニーズの抽出、（3） 外部環境と課題・ニーズのひもづけ、（4） ビジョナリーワードの定義、（5） 解決策・施策の立案、（6）目指すべき未来像の描写、（7） ビジネスモデリング、（8） ビジネスモデルの評価の8つのステップを踏むことでイノベーションのアイデアを創出するものです（図1）。

　これは、多くの企業に対して新規事業創出やビジネスモデル革新のためのワークショップや実習などで長年実践してきたもので、従来は3～5人程度のチーム討議によって実施されてきました。一方、生成AIの台頭により、アイデア創出のプロセスにも革新的な変化が求められています。そこで、ITRが考案したアイデア創出プロセスに生成AIの活用を取り入れた新たなアプローチを紹介したいと思います。基本的には、従来のアイデア創出の8つのステップの全てにおいて、生成AIを活用することができ、それを「AI駆動型アイデア創出プロセス」と呼んでいます（図2）。

AIを活用したアイデア創出の8つのステップ

　AI駆動型アイデア創出プロセスの8つのステップについて、順を追って説明していきましょう。「（1）外部環境の分析」および「（2）課題・ニーズの抽出」では、生成AIなどに搭載されているDeep Researchを活用し、対象とする業界や自社の状況をプロンプトとして入力することで、客観的な事実や公表されている予測などを洗い出すことができます。ただしこの際、不確実な情報や古い調査結果を情報源としないように、AIに対して出典元や参照ウェブサイトを示すよう指示し、情報の信憑性を確認することが重要です。

　「（3）外部環境と課題・ニーズのひもづけ」では、（1）および（2）のアウトプットを基に生成AIがそれらの関係性を整理することができるでしょう。（1）から（3）までのプロセスは、一般的な事実や過去の分析に基づくものであるため、その思考プロセスやアウトプットは社内のほかの人々にも役立つ知識となっているはずです。これらを組織のナレッジとして蓄積・共有することで、再利用可能となり、さらにAIの強化学習にも活用できるようになるでしょう。

　課題やニーズを満たした先の未来の姿を簡潔な言葉で表現する「（4）ビジョナリーワードの定義」と、課題やニーズに着目し、それらにデジタル技術のシーズを掛け合わせる「（5）解決策・施策の立案」では、生成AIから示されるさまざまな観点からのアイデア候補案を基に、何度も“壁打ち”を行うことでアイデア創発が促されるでしょう。「（6）目指すべき未来像の描写」および「（7）ビジネスモデリング」では、（5）までのアウトプットをプロンプトとして生成AIに入力することで、目指すべき未来像を図・表などで具体的に表現したり、ビジネスモデルキャンバスの作成支援を受けたりすることができるでしょう。「（8）ビジネスモデルの評価」では、技術動向や市場動向を踏まえた技術的およびビジネス観点からの実現性や、市場性（強み・課題・市場規模など）の抽出と客観的な評価に加えて、収益のシミュレーションを生成AIから引き出すことができます。

　（4）から（8）までのプロセスは、プロンプトを与える人や条件によって多様なアイデアが得られるため、生成AIとの対話を繰り返しながら試行・観察・学習のアイディエーションサイクルを何度も回すことによって、より優良なアイデアが生み出されていくでしょう。

　企業は、新規事業の立案や新サービスの構想化において、このようにあらゆるプロセスにおいてAIを活用する「AI駆動型アイデア創出プロセス（AI-Driven Ideation Process）」を構築し、アイデアの質と量を高めていくことが推奨されます。
AI駆動型アイデア創出プロセスの例

　アイデア創出プロセスにおけるAI活用の具体例をひとつ紹介しておきましょう。従来型の「（5）解決策・施策の立案」では、課題・ニーズと技術シーズを掛け合わせて、「（4）ビジョナリーワードの定義」で作成した未来の姿（ビジョナリーワード）を実現する解決策のアイデアを考えて、アウトプットを作成します（図3）。この例では、「地域の足が奪われる」という課題と「地域の利便性と安全性を高めたい」というニーズに対して、「バスのように気軽に、タクシーのように自在に！」というビジョナリーワードによって未来のありたい姿を掲げています。これに、GPS、自動運転車、運行データ、スマホ予約といった技術シーズを掛け合わせることで、「自動運転車による巡回乗り合いタクシー」という解決策のアイデアを導き出しています。

　従来型の新規事業創出ワークショップやデジタルトランスフォーメーション（DX）実習などでは、3～4人のグループワークで、付箋（ふせん）紙などを使って発散（洗い出し）と収束（取りまとめ）を繰り返すことによりアウトプットを作成していますが、このような解決策・施策の立案の場面において、生成AIを活用することができます。

　例えば、図3で示した図をそのまま生成AIに読み込ませて、同じような掛け合わせのアイデアを求めたところ、瞬時に幾つかのアイデアを列挙しました（図4）。この例では、特に条件を絞らずにアイデアを求めたため、食料品や建設現場など幅広い分野から解決策を列挙していますが、プロンプトにおいて「医療分野」「物流問題」などと業種やテーマを指定することで、的を絞ったアイデアを求めることもできます。

　ただし、生成AIによって導き出されたアイデアは、既知の情報を基にしているため必ずしも新規性は高くありません。従って、すでに世界のどこかで類似した事業やサービスが展開されているものが少なくないのです。一方で、自分では思いつかないような意外な組み合わせが示されることもあるでしょう。生成AIが列挙したアイデアをヒントにすることで、自らの知識の幅や視野を広げて異なるさまざまな要素を掛け合わせて発想することが推奨されます。生成AIが示したアイデアをヒントとして、自らの異なる視点で問いを立て、何度も“壁打ち”を行う過程で、AIに自分の思考パターンや検討プロセスを記憶させることができ、独自性の高いアイデアが導き出されることもあるでしょう。生成AIにアイデア創出を委ねるのではなく、自らの知識の幅や視野を増幅するためのパートナーとして活用することが推奨されます。

内山 悟志
アイ・ティ・アール 会長／エグゼクティブ・アナリスト大手外資系企業の情報システム部門などを経て、1989年からデータクエスト・ジャパンでIT分野のシニア・アナリストとして国内外の主要ベンダーの戦略策定に参画。1994年に情報技術研究所（現アイ・ティ・アール）を設立し、代表取締役に就任しプリンシパル・アナリストとして活動を続け、2019年2月に会長／エグゼクティブ・アナリストに就任 。ユーザー企業のIT戦略立案・実行およびデジタルイノベーション創出のためのアドバイスやコンサルティングを提供している。講演・執筆多数。",[],[]
