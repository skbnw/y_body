headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
サーバをそのままオイルにどぼん　PUE 1.03の液浸冷却技術（EE Times Japan）,https://news.yahoo.co.jp/articles/f06422c3f79551e4b4e089ca63cbd95e0681fabd,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20260114-00000056-it_eetimes-000-1-view.jpg?exp=10800,2026-01-14T20:35:09+09:00,2026-01-14T20:35:09+09:00,EE Times Japan,it_eetimes,EE Times Japan,1948,"（写真：EE Times Japan）
分散型のエッジデータセンターの開発および運営を手掛けるQuantum Meshは「CES 2026」（2026年1月6～9日、米国ネバダ州ラスベガス）のENEOSブースにて、商用のコンテナ収容型液浸冷却システム「KAMUI（カムイ）」を展示した。コンテナ収容型液浸冷却システムの商用化は「日本国内では初」（同社）だという。
ENEOSのブースに展示した「KAMUI」の外観。左側が本体（コンテナ）で、そのサイズは高さ1200mm×幅1400mm。この1台で16Uまでのサーバを運用できる。展示用なので右側にチラーがあるが、実際の運用ではチラーは必要ない
KAMUIはQuantum Meshが独自に開発した単相液浸冷却システムだ。サーバの熱で温まった冷却液（オイル）を、地下水を利用した熱交換によって冷却し、その冷却されたオイルでサーバを冷やし続ける。

　具体的には、サーバそのものを冷却液に浸す。サーバの熱で温まった冷却液は、冷却槽のすぐ隣にある熱交換器により水で冷やされ、再びサーバの冷却に使われる。Quantum Meshによれば、冷却液は約55℃で冷却槽を出ていき、約25℃に冷やされて再び冷却槽に入ってくるという。温度が高い物体から低い物体へと熱を移動させる熱交換を用いて冷却するので、冷却に必要な消費電力を極めて低く抑えられることが特徴だ。同社は「データセンターの電力使用効率を示す指標であるPUE（Power Usage Effectiveness／1.0に近づくほどよい）は、現在の空冷方式は1.7～1.8、導入がこれから本格化する水冷方式は1.4くらい。それに対し、KAMUIは1.03～1.04を達成している」と語る。

　KAMUIは、40kW/ラックの高密度ラックを安定して冷却できる能力を持つ。

　冷却液にはENEOSの液浸冷却液「IXシリーズ Type J」を使用している。「IXシリーズ Type Jは絶縁系オイルで酸化しにくい。5～10年に一度くらいの頻度で交換すればよい」（Quantum Mesh）

　KAMUIは既存のサーバにも対応できるが、2点だけ変更が必要だ。ファンレスにすることと、SSD仕様にすることである。オイルに浸すので、ファンやHDDのように回転するようなメカニカルな機構があると不具合が起きてしまうからだ。
NVIDIA CEOは「水冷装置不要」とコメントも、液浸冷却には追い風
データセンターでは、現在主流の空冷方式が行き詰まりを迎えつつあるとQuantum Meshは説明する。効率よく冷却するためには、10℃や5℃といった低い温度の風が必要だが、日本では16℃以下の風だと結露を起こす。そのため風量を上げるしかないが、消費電力やGPUサーバの発熱量を考えると、それも限界に達しつつある。

　そのため、次世代のデータセンター冷却技術として水冷方式の導入が始まっている。空冷方式よりもPUEが優れている一方で、冷却プレートを用いてプロセッサを間接的に冷やすため、冷却水を通す細い配管が必要で、水漏れが起きる可能性がある。工事も複雑で、水冷専用のラックも必要だ。その分コストも上がる。

　さらに、CES 2026の開幕前となる2026年1月5日（米国時間）には、NVIDIA CEOのJensen Huang氏が次世代GPUである「NVIDIA Rubin」の仕様について講演。「温水で冷却できるので、データセンターには水冷装置が不要になる」と発言し、話題を呼んだ。

　Quantum MeshはEE Times Japanの取材に対し「この動きは、将来的に新設されるハイパースケーラーのPUEを下げる可能性を示唆するものではあるが、大規模データセンターが必要とする電力そのものが減ることを意味するものではない」とコメントした。

　「先進国では構造的に電力供給が不足している。さらに、データセンター用GPUの納品が現時点では十分に進んでおらず、データセンターの本格稼働は後ろ倒しになるであろうこと、DLC（Direct Liquid Cooling）などの水冷方式は、水漏れによるサーバ破壊のリスクが残ることなどから、KAMUIのような液浸冷却の需要は拡大する方向に働くとみている」（Quantum Mesh）

　Quantum Meshは2023年に設立された企業だ。災害が多い上に、10MWクラス以上のデータセンター用電力の確保が難しい日本において、2MWクラスの高圧電力を確保できる立地に絞って、分散型エッジデータセンターを提供する戦略を取っている。
EE Times Japan",[],[]
新たなプロセス開発でエッチング速度を5倍向上、名古屋大ら（EE Times Japan）,https://news.yahoo.co.jp/articles/6f3e640230baf6779297ffa8bd572259e7798b2a,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20260114-00000059-it_eetimes-000-1-view.jpg?exp=10800,2026-01-14T17:32:45+09:00,2026-01-14T17:32:45+09:00,EE Times Japan,it_eetimes,EE Times Japan,812,"（写真：EE Times Japan）
イオン強化表面自己触媒反応により、エッチング反応が加速

　名古屋大学低温プラズマ科学研究センターのシャオ シーナン特任教授および堀勝特任教授らの研究グループと東京エレクトロン宮城は2026年1月、ウエハーを冷却しフッ化水素（HF）プラズマを用いる反応性イオンエッチング（RIE）プロセスのメカニズムを明らかにしたと発表した。SiO2（二酸化ケイ素）膜のエッチング速度を従来プロセスに比べ5倍も向上させた。エッチングガスにHFを用いるため環境負荷も低減できるという。
疑似ウェットHFプラズマエッチングモデルにおけるイオン強化表面自己触媒反応の概略図 出所：名古屋大学
GAA（Gate-All-Around）トランジスタや3D NANDフラッシュメモリのように、微細で複雑な構造のデバイス製造において、これまでのRIE技術だとエッチング速度が大きく低下するという課題があった。そこで今回は、ウエハーを冷却しHFプラズマを用いる新たなプロセスを提案した。

　基板温度を－60℃などの低温に保つと、エッチングガスのHFと、反応生成物である水（H2O）がSiO2表面に吸着した。このH2Oが触媒となって、SiO2のエッチング活性化エネルギーをほぼ「ゼロ」にすることが分かった。

　さらに、イオン照射エネルギー（バイアス電圧）を大きくすると、H2Oの量が増え、これが表面に吸着しHFを引き付ける「自己触媒サイクル」が加速される。こうした「イオン強化表面自己触媒反応」によって、エッチング反応が飛躍的に加速されることから、従来技術に比べ超高速で高スループットなエッチングが可能となった。

　研究グループは、「新たなプロセスにより、SiO2膜のエッチングスループットは、従来の室温または低イオンエネルギー条件と比べ約100倍に向上することを実証した」という。
EE Times Japan",[],[]
25年の世界半導体市場は21％増の7930億ドル、トップ10でIntelだけ減収（EE Times Japan）,https://news.yahoo.co.jp/articles/74dd2ea56e1d2badc222913cca50115c0f092e4a,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20260114-00000058-it_eetimes-000-1-view.jpg?exp=10800,2026-01-14T17:32:20+09:00,2026-01-14T17:32:20+09:00,EE Times Japan,it_eetimes,EE Times Japan,1258,"（写真：EE Times Japan）
米国の市場調査会社Gartnerは2026年1月12日（米国時間）、2025年の世界半導体売上高（速報値）が前年比21％の7934億4900万米ドルになったと発表した。トップのNVIDIAは同63.9％増の1257億300万米ドルで、半導体売上高が1000億米ドルを越えた初のベンダーになった。トップ10社のうち4位のIntelのみ減収（3.9％減）だった。他9社はいずれも2桁成長を見せている。

　市場をけん引しているのはGPUを中心としたプロセッサ、広帯域メモリ（HBM）、ネットワーク部品を含む「AI半導体」だ。GartnerのシニアプリンシパルアナリストであるRajeev Rajput氏は「AI半導体は、半導体市場において前例のない成長をけん引し続け、2025年には売上高全体の約3分の1を占める見込みだ。AIインフラ支出が2026年に1兆3000億米ドルを超えると予測される中、この支配的地位はさらに高まるだろう」とコメントしている。同社によると2025年、HBMがDRAM市場の23％を占めて売上高300億米ドルを突破し、AIプロセッサの売上高も2000億米ドルを超える見込みだという。Gartnerは、AI半導体が2029年までに半導体総売上高の50％以上を占めると予測している。
NVIDIA、2位に対するリードを530億ドル拡大
ベンダーランキングのトップ10社をみると、前年から顔触れは同じだが、5社で順位の変動があった。1位、2位は、それぞれNVIDIAとSamsung Electronics（以下、Samsung）が前年の順位を維持した。Samsungは、非メモリ分野の売上高は前年比8％減となったもののメモリが同13％増と好調で、半導体全体の売上高は同10.4％増の725億4400万米ドルに成長した。ただし1位のNVIDIAも同63.9％増と大きく伸びた結果、Samsungに対するリードを約530億米ドルに拡大している。

　前年4位だったSK hynixはAIサーバにおけるHBMの需要拡大を受け前年比37.2％増の606億4000万米ドルを記録。Intelを抜き3位に躍り出た。4位に順位を下げたIntelは、トップ10の中で唯一のマイナス成長となる同3.9％減の478億8300万米ドルになった。GartnerによるとIntelの2025年の半導体市場におけるシェア（金額）は6.0％で2021年の半分にまで低下しているという。

　このほか、前年7位だったMicron Technologyが、前年比50.2％増の414億8700万米ドルと急拡大し、QualcommとBroadcomを抜いて5位に躍り出た。QualcommとBroadcomもそれぞれ同12.3％増の370億4600万米ドル、同23.3％増の342億7900万米ドルと2桁成長したものの、この影響で前年から順位を1つ下げる形になった。
EE Times Japan",[],[]
ナノサイズの磁気メモリスタでシナプス機能を模倣、産総研とNIMS（EE Times Japan）,https://news.yahoo.co.jp/articles/86559fabdce5017723c6be0c3409f79ec7975ea3,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20260114-00000055-it_eetimes-000-1-view.jpg?exp=10800,2026-01-14T17:31:15+09:00,2026-01-14T17:31:15+09:00,EE Times Japan,it_eetimes,EE Times Japan,1254,"試作したMTJの断面構造 出所：産総研
「ブレインモルフィックシステム」への応用に期待

　産業技術総合研究所（産総研）と物質・材料研究機構（NIMS）は2026年1月、鉄－マンガン基合金の磁性超薄膜を用いて磁気メモリスタを開発するとともに、これらを使って脳におけるシナプスの機能を模倣することに成功したと発表した。脳の機能をハードウェアで模擬する「ブレインモルフィックシステム」への応用に期待する。
磁気記憶層の磁気特性 出所：産総研
磁気トンネル接合（MTJ）素子を利用した磁気メモリテスタは、高速動作と書き換え耐性に優れている。磁気メモリ材料としては、コバルト－鉄－ボロン（Co-Fe-B）合金が実用化されているが、メモリスタ材料として機能させるには、素子を数マイクロメートルレベルの細線状に加工する必要があり、集積化には適していなかったという。

　産総研は今回、スピノーダル分解を示す材料「鉄－マンガン基合金」に着目し、磁気メモリスタ素子の開発に取り組んだ。試作した鉄－マンガン基合金のMTJ断面を透過型電子顕微鏡で観察した。熱処理前は、平たんな磁気記憶層の中に、鉄元素が均一に分布していることを確認した。

　特定の条件で熱処理した後は、鉄－マンガン基合金がスピノーダル分解し、磁気記憶中に周期的な鉄元素の組成ゆらぎが現れた。しかも、スピノーダル分解の前後で、MTJのミクロな膜構造や結晶構造に変化は生じず、きれいな積層構造を保ったままだという。

　開発した磁気記憶層の磁気特性を評価した。スピノーダル分解で磁化が小分けにされた鉄－マンガン基合金は、50mT程度まで磁化の状態が保持された。磁化強度を高めていくと、中間状態を伴いながら緩やかに磁化反転が進むことを確認した。

　研究グループは、試作したMTJを直径200nmの円形ピラー素子に加工し、磁気メモリスタでシナプスの機能を模倣した。実験では、磁気メモリスタに同じ極性パルスを連続印加することでコンダクタンスが上昇する「長期増強」と、極性を反転させたパルスを連続印加することでコンダクタンスが減少する「長期抑制」を再現できた。これらは数ナノ秒のパルス幅で制御できるという。

　さらに、磁気メモリスタで「スパイクタイミング依存可塑性（STDP）」を再現指した。磁気メモリスタには時間差を変えながら、「のこぎり波状のスパイク」と、「極性が反対のパルス2つつなげたスパイク」を印加した。この結果、2つの時間差が小さいほど、コンダクタンスが大きく変化した。また、時間的な前後関係によって、変化の向きが逆転することを確認した。

　今回の研究成果は、産総研ハイブリッド機能集積研究部門の山本竜也主任研究員、野崎隆行研究グループ長、エレクトロニクス・製造領域も湯浅新治上級首席研究員らと、NIMS電子顕微鏡ユニットの埋橋淳主幹エンジニア、磁性・スピントロニクス材料研究センターの大久保忠勝副センター長らによるものだ。
EE Times Japan",[],[]
SDV向け新プロセッサ「S32N7」をNXPが発表、5nmプロセス採用（EE Times Japan）,https://news.yahoo.co.jp/articles/23577cfcb3102bbbedc84977211028b4258bd5fd,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20260114-00000054-it_eetimes-000-1-view.jpg?exp=10800,2026-01-14T17:30:25+09:00,2026-01-14T17:30:25+09:00,EE Times Japan,it_eetimes,EE Times Japan,800,"（写真：EE Times Japan）
Arm Cortex-A78AEコアやCortex-R52コアなどを搭載

　NXP Semiconductorsは2026年1月、自動車の機能をソフトウェアで定義するSDV（ソフトウェア定義型自動車）に向けたプロセッサ「S32N7」シリーズを発表した。Boschは自動車統合プラットフォームにS32N7を採用した。
S32N7の搭載イメージ 出所：NXP
S32N7は5nmプロセスで製造され、車両の中核にソフトウェアやデータを集約するよう設計されている。安全性やセキュリティも確保した。プロセッサとしてスプリットロック機能を備えた最大8個のArm Cortex-A78AEコア（動作周波数は最大1.8GHz）や、最大12個のArm Cortex-R52コア（動作周波数は最大1.4GHz）を始め、RISC-Vベースのアクセラレーター、eIQ Neutronニューラルプロセッシングユニット（NPU）などを集積している。

　S32N7を採用することで、多くのハードウェアモジュールを省くことが可能となり、配線や電子部品、ソフトウェアの効率を高めることができる。この結果、自動車メーカーでは総所有コストを最大20％も削減できるとみている。

　また、S32N7シリーズは高性能データバックボーンを備えている。このため、将来的に最新のAIシリコンへ置き換える場合も、車両を再設計する必要がないという。なお、S32N7シリーズとして32種類の製品を用意する。最上位モデルの「S32N79」については既にサンプル品を出荷中だ。

　Boschは、自動車統合プラットフォームにS32N7を採用した。NXPと共同でレファレンスデザインやセーフティフレームワークの開発、ハードウェアの統合作業などを行っていて、システムへの早期実装を目指す。
EE Times Japan",[],[]
NVIDIA、次世代AIプラットフォーム「Rubin」発表　26年後半から提供予定（EE Times Japan）,https://news.yahoo.co.jp/articles/4691ba7f84c3cf39cdc9c0ad51fb8da6b0c97f38,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20260114-00000019-it_eetimes-000-1-view.jpg?exp=10800,2026-01-14T08:10:54+09:00,2026-01-14T08:10:54+09:00,EE Times Japan,it_eetimes,EE Times Japan,1475,"（写真：EE Times Japan）
NVIDIAは2026年1月5日（米国時間）、「CES 2026」（2026年1月6～9日、米国ネバダ州ラスベガス）において、次世代AIプラットフォーム「NVIDIA Rubin」（以下、Rubin）を発表した。
出所：NVIDIA
本製品は、「Vera CPU」「Rubin GPU」「NVLink 6 スイッチ」「ConnectX-9 SuperNIC」「BlueField-4 DPU」「Spectrum-6イーサネットスイッチ」という新設計のチップ6個で構成される。

　大規模AIファクトリー向けCPUで最も電力効率に優れるというVera CPUに加え、第6世代NVLinkインターコネクトテクノロジー、第3世代Transformer Engine、第3世代Confidential Computing、第2世代RAS Engineという5個の最新世代技術によって、「NVIDIA Blackwell」プラットフォームと比べ、推論トークンを最大10分の1のコストで提供し、MoE（Mixture of Experts）モデルのトレーニングに必要なGPU数を4分の1に削減できるという。

　推論コンテキストをギガスケールで拡張するために設計されたという、次世代のAIネイティブストレージインフラ「NVIDIA Inference Context Memory Storage Platform」を導入する。BlueField-4 DPUの搭載により、AIインフラ全体でKVキャッシュデータを効率的に共有および再利用することが可能。応答性とスループットが向上し、エージェント型AIの予測可能で電力効率に優れたスケーリングができるとする。

　またBlueField-4 DPUでは、システムレベルのトラストアーキテクチャ「ASTRA（Advanced Secure Trusted Resource Architecture）」も導入している。

　Spectrum-6イーサネットスイッチシステムは、従来の方法と比較して信頼性を10倍、稼働時間を5倍に向上させつつ、5倍の電力効率を実現したという。
2026年後半からRubinベース製品の提供開始予定
Rubinプラットフォームは、72個のRubin GPU、36個のVera CPUなどを搭載するラックスケールソリューション「Vera Rubin NVL72」と、8個のRubin GPUをNVLinkで接続するためのサーバボードシステム「HGX Rubin NVL8」で提供される。

　すでに量産段階に入っていて、2026年後半から、パートナーによるRubinベース製品の提供が始まる予定だ。Vera Rubinベースのインスタンスを最初に展開するクラウドプロバイダーには、AWS（Amazon Web Service）やGoogle Cloud、Microsoft、OCI、CoreWeave、Lambda、Nebius、Nscaleなどが含まれる。

　NVIDIAの創業者兼CEOのJensen Huang氏は「トレーニングと推論の両方におけるAIコンピューティングの需要が急増している中、Rubinは絶好なタイミングで登場した。新世代のAIスーパーコンピュータを年次サイクルで提供し、6チップにわたる緊密な協調設計により、RubinはAIの次のフロンティアに向けて大きな飛躍を遂げる」とコメントしている。
EE Times Japan",[],[]
DONUT LABが量産車向け全固体電池を公開　年間1GWh規模で生産へ（EE Times Japan）,https://news.yahoo.co.jp/articles/c1b881b471fd62f8ef8fccfd811577ee34331c5e,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20260114-00000018-it_eetimes-000-1-view.jpg?exp=10800,2026-01-14T08:10:11+09:00,2026-01-14T08:10:11+09:00,EE Times Japan,it_eetimes,EE Times Japan,655,"（写真：EE Times Japan）
フィンランドDONUT LABは「CES 2026」（2026年1月6～9日、米国ネバダ州ラスベガス）で、「世界初」（同社）とする量産車向けの全固体電池を公開した。
DONUT LABが公開した全固体電池
展示した全固体電池のエネルギー密度は400Wh/kg。5分間でフル充電し、サイクル寿命は最大10万だという。DONUT LABの担当者は、正極、負極、固体電解質の材料やプロセス技術について「非公開」とした。「特に材料とプロセス技術は当社の競争力の源泉で、一切コメントできない。ただし、地政学リスクを抑えられる材料ではある」（同社）。コスト／価格についても明確な数字は公開できないとし「リチウムイオン電池よりも安価」と述べるに留めた。全固体電池はフィンランドの工場で生産され、生産能力は年間1GWhだという。

　DONUT LABの全固体電池は、2026年第1四半期から、フィンランドの電動バイクメーカーであるVerge Motorcycleの現行モデル「Verge TS Pro」に搭載され、公道を走行することになる。Verge TS Proには、4台の全固体電池（上記の写真の物が4つ）が搭載されるという。「Verge TS Proは過去数年間、リチウムイオン電池を搭載していたが、今回、全て全固体電池に置き換えた。内部の構造を大きく変えることなく、そのまま置き換えられるのが、われわれの全固体電池の利点だ」（DONUT LAB）
EE Times Japan",[],[]
CESで繰り広げられたHBM4開発競争　Samsungも巻き返しアピール（EE Times Japan）,https://news.yahoo.co.jp/articles/c0f8183dccd1a53e261a46895a47775c1347d295,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20260114-00000017-it_eetimes-000-1-view.jpg?exp=10800,2026-01-14T08:09:42+09:00,2026-01-14T08:09:42+09:00,EE Times Japan,it_eetimes,EE Times Japan,2984,"（写真：EE Times Japan）
「CES 2026」（2026年1月6～9日、米国ネバダ州ラスベガス）において最大の目玉となったのは、最新のAIシステムの中でも特に、大規模トレーニングモデルを実行するための重要なコンポーネントとされる広帯域メモリ（HBM）だった。メモリ3大メーカーであるMicron Technology（以下、Micron）とSamsung Electronics（以下、Samsung）、SK hynixは、それぞれHBM4の切り札を持っており、AIスケーリングの進展を阻む「メモリの壁（memory wall）」に対応することが可能なHBM4デバイスの準備態勢が整っていることを大いにアピールしていた。
「CES 2026」で展示した16層HBM4デバイスの構造の模型 出所：SK hynix
HBM4は、HBM技術の最も重要なアーキテクチャの全面的な見直しを実行することにより、このメモリの壁に対する解決策になると期待されている。メモリの壁とは、データ処理速度が、そのデータをプロセッサに伝送するためのメモリ性能を超えてしまうというボトルネックだ。HBM4は、次世代AIアクセラレーターやデータセンターワークロード向けに、帯域幅や電力効率、システムレベルのカスタマイズなどの大幅な向上を実現すべく開発された。

　第6世代のHBM技術であるHBM4は、こうした課題に対応すべく、漸進的な速度向上の枠を超えて、メモリインタフェースの完全な再設計を実現する。最初に生成AIブームの波を引き起こした初期のHBM3デバイスと比べて、約3倍の性能向上を達成するという。

　HBM4は、ロジックダイを統合し、メモリスタックをコプロセッサとして機能させ、基本データがメインのAIプロセッサに到達する前の段階での処理を可能にすることから、メモリアーキテクチャにおけるもう1つの抜本的な移行を実現する。これは、メモリが受動的なストレージから能動的なコンポーネントへと変化すると同時に、計算だけを行っていた時代が終えんを迎えたことを示している。

　HBM4の熱狂を巻き起こす主な要素となったのが、NVIDIAのGPUプラットフォーム「Rubin」だ。Rubinは、現在生産が始まっており、初期のHBM4デバイスの最初の独占的な消費者として位置付けられている。報道によれば、MicronとSamsung、SK hynixは、既にNVIDIA向けにHBM4のサンプル出荷を開始していて、2026年にはHBM4チップの量産を開始する予定だという。
48GBの16層HBM4を披露したSK hynix
現在の世界HBM市場で50％超のシェアを握っている業界リーダーSK hynixは、CES 2026において、容量48ギガバイト（GB）の16層HBM4デバイスを発表した。DRAMを最大16層まで積層することにより、容量と速度の両方を大幅に向上させ、2TB/秒を超える帯域幅を達成したという。同社は2026年第3四半期に、このHBM4デバイスの量産を開始する予定だとしている。

　同社は、独自開発技術「MR-MUF（Mass Reflow Molded Underfill）」を適用し、JEDECの厳格な高さ制限である775μmに対応すべく、個々のDRAMウエハーで30μmという驚異的な薄さを実現している。MR-MUF技術は、HBM製品に垂直積層された全てのチップを相互接続することで、さらなる効率化を実現するという。

　SK hynixの16層HBM4デバイスに関するもう1つの注目すべき点は、同社がTSMCとの協業により、12nmロジックをベースダイとして搭載し、HBM4スタックの制御ロジックやブレーンとして機能させているという点だ。このようなメモリベースのノードからロジックノードへの移行により、HBM4は実質的に、特殊なAIワークロード向けに適合させることが可能なカスタムメモリソリューションへと進化することになる。
Samsungは巻き返しをアピール
SK hynixがHBM4のロジックダイでTSMCと手を組んでいるのに対し、Samsungは、自社ファウンドリーの4nm世代プロセスノードでロジックダイを製造し、3次元（3D）パッケージングも全て社内で行っている。これによりSamsungは、シリコンから最終的なパッケージングまでスタック全体を制御可能なターンキーソリューションを提供する、唯一のHBM4サプライヤーとなっている。

　さらにSamsungは、SK hynixが既存のMR-MUF技術を適用して16層HBM4を製造しているのとは異なり、ハイブリッドボンディングで急成長を遂げている。ハイブリッドボンディングは、既存のマイクロバンプを使用せずに銅電極を直接接合するプロセスであり、スタックの高さを大幅に縮小し、放熱も改善できることから、業界では次世代製造の課題に対応する長期的な解決策になると考えられている。

　しかし、Samsungの関係筋によると、HBM4分野における同社の最も注目すべき飛躍は、エネルギー効率の大幅な向上を実現する1c世代のDRAMプロセス技術を採用したことだという。データセンター事業者は現在も、1000Wを超えるGPUの熱需要に苦戦していることから、これは非常に重要なアドバンテージとなる。TrendForceによれば、Samsungは既にこの1c DRAMの製造を開始しており、同社の量産目標である歩留まり80％をほぼ達成しつつあるという。

　Samsungは、NVIDIAのRubin AIアクセラレーター向けにサンプル出荷を開始していて、SK hynixとMicronよりも先に採用される可能性が高いとされる一方で、既にGoogleの最新世代TPUに向けたBroadcomのSiP（System-in-Package）テストを通過したという。こうしたことからSamsungは、ここ数年間はSK hynixに後れを取っていたものの、今やHBM3eでの敗北から復活しつつあるといえる。
HBM4メモリをめぐる戦い
3大HBMメーカーの1社であるMicronも、NVIDIAのRubin AIアクセラレーター向けHBM4仕様に準拠しており、最終顧客向けにサンプルを提供している。米国アイダホ州ボイシに拠点を置くMicronは、2048ビットインタフェースを搭載する36GBの12層HBMデバイス向けに、生産能力を積極的に拡大しているところだ。2026年末までに、HBM4の製造専用として、ウエハー生産能力1万5000枚の達成を目指すという。

　一方、業界レポートによると、NVIDIAは2025年第3四半期に、同社のRubin GPU向けのHBM4仕様を修正し、ピン当たりの速度要件を11ギガビット/秒（Gbps）以上に引き上げたという。そのためMicronとSamsung、SK hynixは、HBM4のサンプルを再提出しており、NVIDIAの厳格化する要件に対応すべく、引き続き設計を改善していくという。

※米国EE Timesの記事を翻訳、編集しました。
EE Times Japan",[],[]
