headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
GPT5.2が理論物理学の定説を覆し、シンプルな新公式を発見（ビジネス＋IT）,https://news.yahoo.co.jp/articles/409f5df554232025b0ab3aa48b2116d80e53a38c,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20260215-00180888-biz_plus-000-1-view.jpg?exp=10800,2026-02-15T21:55:05+09:00,2026-02-15T21:55:05+09:00,ビジネス＋IT,biz_plus,ビジネス＋IT,1002,"（画像：ビジネス+IT）
米OpenAIは2026年2月13日、同社の最新AIモデル「GPT-5.2」が理論物理学における未解決問題を解明したと発表した。素粒子物理学の「グルーオン散乱」において、従来は発生しないとされていた相互作用の存在を特定し、その数学的公式の発見から証明までを自律的に遂行した。プリンストン高等研究所などの専門家による検証も完了しており、AIが科学的発見の主体となり得ることを示す歴史的な事例となる。
GPT5.2が理論物理学の定説を覆す（図版：ビジネス+IT）
OpenAIおよび複数の報道によると、今回の発見は素粒子物理学の根幹に関わる「散乱振幅」の計算に関するものだ。具体的には、原子核内の強い相互作用を媒介する素粒子「グルーオン」の振幅計算において、特定の条件下（ヘリシティ構成）では相互作用がゼロになるとする従来の教科書的な定説が存在した。しかし、GPT-5.2はこの定説に反し、特定の条件下（half-collinear regime）において相互作用が非ゼロとなり、かつ極めてシンプルな数式で記述できることを突き止めた。


　この発見プロセスにおいて、GPT-5.2は単なる計算機以上の役割を果たした。まず、GPT-5.2 Proモデルが、人間が計算した複雑な数式を劇的に簡略化し、そこに潜むパターンを特定して一般公式を「推測（Conjecture）」した。続いて、内部の推論強化モデルが約12時間にわたる自律的な思考を行い、その公式が正しいことを数学的に「証明（Proof）」した。AIが仮説の立案から厳密な証明までを一貫して行った点は、従来の科学研究支援AIとは一線を画す成果だ。

　この結果は、Nima Arkani-Hamed氏（プリンストン高等研究所）ら著名な物理学者によって検証され、正しいことが確認された。Arkani-Hamed氏は、GPT-5.2と人間の専門家の協働が厳密な科学的探究の基準を満たすモデルケースになると評価している。

　また、研究チームは既にこの手法を重力を媒介する理論上の粒子「グラビトン（重力子）」の研究にも応用し始めており、さらなる物理法則の解明に向けた一般化が進められている。今回の成果は、AIが既存の知識の検索や整理にとどまらず、人類が未だ知り得ない科学的真理を独自に発見できる能力を有していることを実証したといえる。",[],[]
OpenAI、リアルタイムコーディング向け高速モデル「GPT-5.3-Codex-Spark」を発表（ビジネス＋IT）,https://news.yahoo.co.jp/articles/6b40124a0cf75d4fe70d503678a26de3ccfe3cf0,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20260215-00180887-biz_plus-000-2-view.jpg?exp=10800,2026-02-15T21:00:05+09:00,2026-02-15T21:25:05+09:00,ビジネス＋IT,biz_plus,ビジネス＋IT,1329,"（画像：ビジネス+IT）
米OpenAIは2026年2月12日、AIチップ開発企業Cerebras Systemsとの提携に基づき、推論速度と応答性に特化した新たなコーディング用AIモデル「GPT-5.3-Codex-Spark」のリサーチプレビュー版を公開した。同モデルはCerebras製の巨大プロセッサ「Wafer Scale Engine 3」上で動作し、毎秒1000トークンを超える生成速度を実現することで、開発者が思考を止めることなく対話的にコード編集を行える環境を提供する。
リアルタイムコーディング向け「GPT-5.3 Codex Spark」発表（図版：ビジネス+IT）
米OpenAIは2026年2月12日、リアルタイムのソフトウェア開発作業に最適化された小型かつ高速な新モデル「GPT-5.3-Codex-Spark」を発表し、有料プラン「ChatGPT Pro」のユーザー向けにリサーチプレビューとして提供を開始した 。

　このモデルは、同社が先日リリースした「GPT-5.3-Codex」の小型版に位置づけられ、長時間に及ぶ自律的なタスク遂行を得意とするメインラインのモデルとは異なり、開発者がコードエディタ上で対話的に行う修正やリファクタリングといった即時性が求められる作業に特化している 。最大の特徴は、AIハードウェア開発企業であるCerebras Systemsとのパートナーシップにより、同社の巨大チップ「Wafer Scale Engine 3（WSE-3）」を推論インフラに採用した点にある。


　WSE-3は単一のシリコンウェハー上にメモリと演算回路を集積したプロセッサであり、従来のGPUクラスタで発生していたチップ間の通信ボトルネックを解消することで、毎秒1000トークンを超える超高速なテキスト生成を可能にした 。

　加えてOpenAIは、クライアントとサーバー間の通信に持続的なWebSocket接続を導入し、リクエストから応答までのパイプライン全体を刷新することで、ラウンドトリップのオーバーヘッドを80%削減し、最初のトークンが表示されるまでの時間を半減させるなど、徹底した低遅延化を図っている 。これにより、ユーザーはAIの生成をリアルタイムで遮ったり、方向修正したりといった「ペアプログラミング」に近い直感的な操作感が得られるとされる。

　機能面では、テキスト入力のみに対応し、コンテキストウィンドウは128kトークンとなっている 。高速化に特化したトレードオフとして、複雑な推論能力やサイバーセキュリティ分野での高度な能力については、フラッグシップモデルである「GPT-5.3-Codex」と比較して意図的に抑えられており、OpenAIの安全性評価においてもサイバーセキュリティや生物学的な脅威を生じさせるリスクは低いと判断されている 。

　提供形態については、現時点では「Codex」アプリ、コマンドラインインターフェース（CLI）、およびVisual Studio Code拡張機能を通じて利用可能であり、APIに関しては一部のパートナー企業から順次提供範囲を拡大していく予定である。",[],[]
NVIDIA ロボット世界モデルAI「DreamDojo」発表、人間の動画からロボットが学習（ビジネス＋IT）,https://news.yahoo.co.jp/articles/120574b1f435d2d15c25672ab71d764cf0a9430a,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20260215-00180885-biz_plus-000-1-view.jpg?exp=10800,2026-02-15T09:30:06+09:00,2026-02-15T09:30:06+09:00,ビジネス＋IT,biz_plus,ビジネス＋IT,2047,"（画像：ビジネス+IT）
NVIDIAの研究チームは2026年2月、ロボットが物理世界での行動結果を予測・学習するための汎用世界モデル「DreamDojo」を発表した。同モデルは、44,000時間におよぶ人間の一人称視点の動画から物理法則を学習しており、従来の最大規模のデータセットと比較して期間で15倍、シーン数で2,000倍という圧倒的な規模を誇る。特定のロボットハードウェアに依存せず、複数のヒューマノイドロボットで動作が実証されており、製造や物流など実社会への応用が期待される。
人間の動画からロボットが学習、NVIDIAの世界モデル「DreamDojo」とは？（図版：ビジネス+IT）
人間の44,000時間の動画からロボットが学習、物理法則や作業動作を理解
NVIDIAが率いる研究チームは、UC BerkeleyやStanford大学などと協力し、ロボットの自律制御を飛躍的に高める新たな基盤モデル「DreamDojo」を開発した。本モデルの最大の特徴は、ロボットの学習データとして従来一般的だった「ロボット自身による試行錯誤データ」ではなく、YouTubeなどに存在する「人間の行動動画」を大規模に活用した点にある。学習に使用された「DreamDojo-HVデータセット」は44,000時間の人間の一人称視点動画で構成されており、これは2024年に発表された他社の世界モデルが使用したデータ量の約49倍に相当する。


　DreamDojoは、この膨大な映像データから物理的な因果関係や物体の操作スキルを事前学習（Pre-training）し、その後、特定のロボットの身体に合わせて微調整（Post-training）を行う2段階のプロセスを採用している。これにより、異なるメーカーのロボットであっても、共通の物理的常識を適用することが可能となった。実際にFourier Intelligence社のGR-1やUnitree Robotics社のG1、AgiBot、YAMといった複数のヒューマノイドロボットにおいて、多様な環境下での物体操作や移動が確認されている。

　また、実用面における処理速度の課題も克服しており、10 FPS（毎秒10フレーム）でのリアルタイム相互作用を実現した。これにより、ロボットは1分以上の長期間にわたる動作生成（ロングホライゾン・ロールアウト）を安定して行うことができ、コストのかかる実機テストを行う前に、高精度な仮想シミュレーション内での動作検証が可能となる。NVIDIAのジェンセン・フアンCEOは、AIロボティクスを「一世代に一度の機会」と位置づけており、産業界全体での資本支出が拡大する中、本技術はロボット開発の効率化に大きく寄与するとみられる。
ロボットや自動運転に応用、生成AIの進化系「世界モデル」とは何か？
DreamDojoの中核技術である「世界モデル（World Model）」とは、ロボットやAIが物理世界での行動結果を予測するために脳内に構築する「内部シミュレーター」と定義される。人間がコップを落とせば割れることを直感的に理解できるように、世界モデルを持つAIは、実際に物理的な行動を起こす前に「こう動けば世界はどう変化するか」という因果関係を仮想的に試行し、予測することができる。


　現在主流の生成AIである大規模言語モデル（LLM）と比較すると、その性質の違いは明白である。LLMはテキストデータから単語の並び順や文脈といった「意味論」を学習するのに対し、世界モデルは映像やセンサーデータから重力、摩擦、物体の変形といった「物理法則（General Physics）」そのものを学習する。LLMがトークン処理を行う一方で、DreamDojoのような世界モデルは、映像のフレーム間変化を「潜在アクション（Latent Action）」としてベクトル化し、人間の手とロボットの手の動きを抽象的な物理作用として統一して処理する。

　この技術の産業的意義は、現実世界での失敗コストを劇的に下げられる点にある。製造ラインや自動運転のような環境では、実機による試行錯誤は破損や事故のリスクを伴うが、世界モデル内であれば何万回ものシミュレーションを高速かつ安全に実施できる。また、従来はシミュレーション環境の構築に膨大な手間を要したが、世界モデルはカメラ映像などから環境の特性を自律的に学習するため、未知の環境への適応能力が高い。

　DreamDojoの登場は、特定のロボット専用に垂直統合で開発されていた従来のAI開発手法から、多様なロボットに汎用的に適用できる水平分業型のプラットフォームへの転換を示唆している。製造、物流、災害対応など、複雑な物理的相互作用が求められる領域において、ロボットが人間のように「見て学ぶ」能力を獲得することは、労働力不足の解消や生産性向上に向けた重要な技術的マイルストーンとなるだろう。",[],[]
【15億人に拡散】TikTok バイトダンスの動画生成AI「Seedance2.0」登場、ディープフェイク物議（ビジネス＋IT）,https://news.yahoo.co.jp/articles/fc8757d77739ef3686e0cf4e96e1b7fe4d820ef1,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20260215-00180884-biz_plus-000-2-view.jpg?exp=10800,2026-02-15T08:05:05+09:00,2026-02-15T08:25:05+09:00,ビジネス＋IT,biz_plus,ビジネス＋IT,2054,"（画像：ビジネス+IT）
TikTokを運営する中国のバイトダンスは2026年2月上旬、新たな動画生成AI「Seedance 2.0」のベータ版を公開した。この新モデルは、OpenAIの「Sora 2」や快手の「Kling 3.0」に匹敵するとの評価を受けており、動画生成AIの開発競争が激化している。全世界で15億人が利用するTikTokと連携しており、高市首相やトム・クルーズの動画が無許可で生成され拡散されるなど、物議をかもしている。
【画像付き記事はこちら】TikTok バイトダンスの動画生成AI「Seedance2.0」の実力（図版：ビジネス+IT）
TikTokのバイトダンスの動画生成AI「Seedance2.0」が登場、Sora2越え
Seedance 2.0の最大の特徴は、動画、音声、画像といった複数の要素を組み合わせるマルチモーダルな生成能力にある。ユーザーはテキストプロンプトだけでなく、人物の顔写真、ダンス動画、音楽のリズムなどを同時に入力し、それらを融合させた一貫性のある動画を生成できる。特に解像度においては、競合のSora 2が最大1080p（Pro版で1792×1024）であるのに対し、Seedance 2.0はネイティブで2K解像度の出力をサポートしており、映画レベルの美学と鮮やかな色彩表現を実現しているとされる。


　技術的な比較において、Seedance 2.0は生成速度でも優位性を見せている。バイトダンス独自の「Volcengine（火山エンジン）」による最適化により、5秒の動画を60秒未満で生成可能であり、これはバージョン1.5と比較して30%の高速化にあたる。一方、物理的な挙動の再現性（重力、流体、衝突など）や、25秒におよぶ長尺動画のストーリーテリングに関しては、依然としてSora 2に軍配が上がるとの分析もなされている。

　同モデルは、バイトダンスの動画編集サービス「CapCut」のクリエイター向けスイート「Dreamina」などに組み込まれるほか、他のAIソフトウェアへの提供も計画されている。またTikTokの動画加工アプリのCapCutと連携できるのと、TikTokにも最適化して投稿ができる機能を備えている。「Seedance2.0」真インパクトはこの「TikTok連携」にあるといえる。

　世界15億人に向けて拡散できる動画生成AIプラットフォームとして、すでにSNS上では、Seedance 2.0を用いて作成されたリアルなダンスシーンやアクション映像が拡散されており、そのクオリティの高さが注目を集めている
TikTokでディープフェイク動画拡散、高市首相やトム・クルーズ動画が物議
革新的な技術の一方で、Seedance 2.0はリリース直後から深刻な著作権侵害やディープフェイクの問題を引き起こし、国際的な批判に直面している。

　
　米国では、アメリカ映画業界団体モーション・ピクチャー・アソシエーション（MPA）のチャールズ・リブキン会長兼CEOがバイトダンスに対し、著作権侵害行為の即時停止を求める声明を発表した。SNS上では、わずか2行のプロンプトで生成されたトム・クルーズとブラッド・ピットが格闘する映像など、ハリウッドスターや既存の著作物を無断使用した動画が大量に生成・拡散されている。リブキン氏は「たった1日で米国著作権作品を大規模に無断使用した」とし、バイトダンスがクリエイターの権利を無視していると強く非難した。映画脚本家のレット・リースは、AIによって誰もがハリウッド映画並みの作品を作れるようになる現状に対し、「我々は終わりだ」と悲観的な見解を示している。

　日本国内でも同様の懸念が高まっている。ウルトラマンや名探偵コナンのキャラクターが「高市総理」と戦う動画などが生成され、インターネット上で拡散されている事態が確認された。これを受け、小野田知的財産戦略担当大臣は「著作権者の許諾なく既存の著作物が活用される状況は看過できない」と強調した。小野田氏は関係省庁と連携して事案の精査を行うとともに、バイトダンス社に対して改善を求めるよう実務担当者に指示を出したことを明らかにしている。

　さらに、プライバシー上のリスクも浮上している。Seedance 2.0（中国名：Jimeng）には、顔写真を1枚アップロードするだけで、その人物の声を極めて高い精度で再現する機能が含まれていたが、本人の許可なく声が生成されることへの懸念から、バイトダンスはこの機能を緊急停止した。テックメディアのMediaStormによるテストでは、許可のないデータで創業者の声がほぼ完全に再現されたことが報告されており、詐欺や社会的信用の失墜につながる恐れが指摘されている。バイトダンスは現在、実在の人物のような写真や動画をリファレンスとして使用することを制限し、本人確認のプロセスを導入するなど、対策に追われている。",[],[]
