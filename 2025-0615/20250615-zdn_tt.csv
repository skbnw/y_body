headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
「生成AI」ブームで問われるビジネス価値　高額な導入費用をどう回収する？（TechTargetジャパン）,https://news.yahoo.co.jp/articles/b73e4cad9c444db3ce704196bc3bb610dc13f5ec,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250615-00000013-zdn_tt-000-1-view.jpg?exp=10800,2025-06-15T20:00:11+09:00,2025-06-15T20:00:11+09:00,TechTargetジャパン,zdn_tt,TechTargetジャパン,2016,"（写真：TechTargetジャパン）
組織は人工知能（AI）技術、特に画像やテキストを自動生成する「生成AI」の活用に向けた投資を活性化させている。コンサルティング会社Deloitte Touche Tohmatsuが2025年1月に公開した調査レポート「Now decides next: Generating a new future」では、調査対象になった組織の78％が「次の会計年度にAI関連の支出を増やす予定だ」と回答した。この調査は、2024年7月から9月にかけて、14カ国の経営幹部2773人を対象に実施したものだ。

　AI関連の投資が増えれば、生成AIが生み出すビジネス価値に対する期待も高まる。そもそも生成AIのROI（費用対効果）はどうすれば測定できるのか。
生成AIのビジネス価値はこうやって測定できる
科学技術雑誌「MIT Technology Review」が主催した2025年5月のAI関連イベント「EmTech AI」では、生成AIが組織にもたらす価値が強調された。投資を結果につなげるには、明確な目標を設定することはもちろん、それを達成するための方針を従業員に示すことも重要だ。

　従来のROIの測定方法は、投資に対し、売り上げや利益をどのくらい増やせたかに焦点を当てる。一方で生成AIの場合は「売り上げを増やす」よりも、業務効率化によって「支出を減らす」ことが主な成果になる。ビジネススクールMIT Sloan School of Managementの教授（金融工学分野）であるアンドリュー・ロー氏は、「組織は生成AIに対して生産性の向上を期待している」と述べる。

　金融業界では、さまざまな分析の業務に生成AIを取り入れる動きが広がっている。生成AIの中核となる大規模言語モデル（LLM）は、エンドユーザーによる自然言語での問い合わせや指示を可能にし、分析業務の効率化や自動化を支援する。「こうした進化によって、10～20社のクライアントしか分析できなかった金融アナリストが、100～200社を分析できるようになった」（ロー氏）

　AI技術を活用してタスクを自律的に実行するプログラムを「AIエージェント」と呼ぶ。MicrosoftのAIプラットフォーム部門バイスプレジデント、アシャ・シャルマ氏によると、最近は生産性向上を目指し、新規プロジェクトを立ち上げる際に、最初の段階からAIエージェントを“メンバー”として採用する「AIエージェントファースト」を方針に掲げている組織がある。
生成AIのROIを測定する方法
DeloitteのAI責任者ジム・ローワン氏は、生成AIのROIを測る方法について「ユースケースにおける価値創造に注目している」と語る。その価値はたいていの場合、即座のコスト削減ではなく、時間の節約や品質の向上といった形で現れると同氏は説明する。

　「製品の開発工程を加速させることは、単にコストの問題ではない」。そう話すのは、武田薬品工業の最高データ技術責任者を務めるガブリエレ・リッチ氏だ。同社は高品質の薬を開発するために生成AIを活用している。

　生成AIのROI測定を巡り、中長期的な視点が重要だとロー氏は指摘する。同氏は「短期的には、AI関連のインフラ構築や従業員向けトレーニングの費用が発生し、横ばいかマイナスのROIを経験する組織もある」とみる。しかし時間がたつにつれ、組織は生産性を向上させてAI関連投資の回収を図れるということだ。

　キーワードになるのが、改革の管理「チェンジマネジメント」だ。生成AIの活用によってさまざまな業務を自動化すれば、その分、従業員の時間が空く。しかし空いた時間を何に使うかを事前に決めておかなければ、生産性の低下につながる恐れがある。それを防ぐのが、チェンジマネジメントの役割だ。コンサルティング企業／国際会計事務所KPMGのAIトランスフォーメーション責任者を務めるケビン・ボーレン氏は、「組織は従業員に時間をどのように活用すべきかを明確に示す必要がある」と述べる。

　従業員のスキルアップに対する支援も大切だ。ロー氏は、「生成AIの導入によって仕事の内容が大きく変わる従業員に対し、組織はトレーニングを含む移行プロセスを手厚くサポートしなければならない」と説明する。その際には、生成AIのテスト的な導入が有効だ。テスト導入によって生成AIのメリットを従業員に体験してもらうことで、本格的な利用に当たってのモチベーション向上につなげられる。

本記事は米国Informa TechTargetの記事「How business leaders are measuring generative AI's ROI」を翻訳・編集したものです。一部、翻訳作業に生成AIを活用しています。
TechTargetジャパン",[],[]
AIを安心して使うには？　プライバシー侵害を防ぐ7つのベストプラクティス（TechTargetジャパン）,https://news.yahoo.co.jp/articles/1e4ca0b3b50d603e72361421ace79b4590321af3,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250615-00000012-zdn_tt-000-1-view.jpg?exp=10800,2025-06-15T08:00:11+09:00,2025-06-15T08:00:11+09:00,TechTargetジャパン,zdn_tt,TechTargetジャパン,2284,"（写真：TechTargetジャパン）
人工知能（AI）技術のビジネス活用が急速に進む一方、個人情報や企業秘密などの機密情報をAIモデルやAIベンダーがどう扱うのかに対するプライバシーへの懸念が浮上している。企業の社会的信頼にも関わるこうしたリスクに対処し、安全にAI技術を活用するための7つのベストプラクティスを解説する。
AIのプライバシー侵害を防ぐ7つのベストプラクティス
1．訓練のために収集するデータは最小限にとどめる

　AI技術を業務で使用する際は、その目的を達成するために必要なデータのみを収集するように徹底する。エンドユーザーの個人データやプロンプト（AIモデルへの指示）が、AIモデルの訓練にどのように使用されるのかについて、エンドユーザーが明確な説明を受け、納得した上で同意（インフォームドコンセント）していることを確認しなければならない。顧客応対にAIツールを導入する場合に、個人を特定できる情報や会話履歴を保存せず、問い合わせ対応に必要な情報のみを取り扱うようにするといった具合だ。

2．通信やデータを暗号化する

　エンドユーザーとAIツール間の全通信を暗号化し、第三者によるデータ盗難や傍受を防ぐ。AIモデル訓練用のデータ、システムのバックアップ、開発環境などに保存されているデータも暗号化し、不正アクセスを阻止する。暗号鍵を安全に管理する専用システムを導入することも有効だ。

3．機密データを匿名化する

　個人情報、健康情報、財務情報などの機密情報を削除またはマスキングして、第三者がエンドユーザーの個人行動を分析（ユーザープロファイリング）することを防ぐには、以下に挙げるプライバシー保護技術を活用できる。

・データマスキング
・・データの一部を本来の内容とは異なる値や記号などに置き換えたり非表示にしたりして、機密性を確保する技術

・トークン化
・・機密データを固有のトークンに置き換えて情報を管理する技術

・差分プライバシー
・・個人情報を含むデータに意図的なノイズデータを加えることで、データ全体の統計情報から特定の個人を識別できないようにする技術

　AIモデルの性能を維持しつつリスクを低減する上では、以下のプライバシー保護技術の採用も検討するとよい。

・フェデレーテッドラーニング（連合学習）
・・複数の場所にある訓練データを集約することなく、分散したまま訓練に活用する機械学習手法

・秘匿マルチパーティー計算
・・元データを明かすことなく、暗号化したまま計算処理をする技術

4．説明可能なAIモデルを導入する

　説明可能なAIモデルは、性能と信頼性を維持しながら、エンドユーザーには出力しか見せないというブラックボックス化のリスクを軽減する。そうしたAIモデルを実現する手法の一例である「LIME」（Local Interpretable Model-agnostic Explanations）は、AIモデルへの入力データを少しずつ変化させてその出力結果を分析することで、どの要素がAIモデルの意思決定に影響を与えているのかを可視化する手法だ。

5．コンプライアンス状況を継続的に確認する

　自社が利用しているAIツールが、EU（欧州連合）の「一般データ保護規則」（GDPR）や米カリフォルニア州の「カリフォルニア州消費者プライバシー法」（CCPA）といったプライバシー関連規制に準拠していることを確認する。定期的な監査、コンプライアンス（法令順守）関連文書を管理し、データ収集および利用に関するエンドユーザーへの説明が重要だ。これらの措置は、規制当局による調査の際に、企業がデューデリジェンス（適正な評価手続き）を果たしたことの証拠になり得る。

6．強固なアクセス制御を実装する

　AIツールと関連データのアクセス権限を、必要最低限の担当者のみに付与する。エンドユーザーの役割に基づいてアクセス権限を設定する「ロールベースアクセス制御」（RBAC）を導入し、誰がいつ機密データを参照したのかを追跡できるようログを取得、監視する。これによって社内データの不正利用リスクを低減し、問題発生時の責任の所在を明確にする企業の説明責任体制を確立できる。

7．AIガバナンス体制を整える

　企業がAI技術を導入、運用するための、各部門や担当者の役割、責任範囲、手順を定義するAIガバナンス体制を策定する。AIモデルのエラーやデータ侵害といった予期しない問題に備えて、問題発生時の報告ルートや対処手順を具体的に定めたインシデント対応計画も盛り込むべきだ。

　暗号化基準の徹底や、監査に備えたデータリネージ（データの出自や変更履歴）の維持など、データスチュワードシップ（データの適切な定義や利用を推進する取り組み）を実現するための手順を整備する。AIモデルの判断が倫理的な問題や不公平な結果を招かないよう、具体的な倫理基準を設定することも不可欠だ。問題を早期に発見するためには、AIモデルのバイアスを定期的にチェックしたり、AIモデルの弱点を検証する「敵対的テスト」といったリスク評価手法を取り入れたりすることが有効だ。

本記事は米国Informa TechTargetの記事「Address top AI privacy concerns with this 7-point checklist」を翻訳・編集したものです。一部、翻訳作業に生成AIを活用しています。
TechTargetジャパン",[],[]
