headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
「全く新しいプラットフォーム」　半導体設計IPベンダーがAI需要に応える（電波新聞デジタル）,https://news.yahoo.co.jp/articles/ed6918a1d65124cc30d7e4a1a59f54f7e35ddb10,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250910-00010002-dempad-000-1-view.jpg?exp=10800,2025-09-10T19:50:46+09:00,2025-09-10T19:50:46+09:00,電波新聞デジタル,dempad,電波新聞デジタル,722,"オンライン説明会に登壇した横山社長
英アームは10日、コンピューティングシステムの設計を支援する新CSS（コンピュート・サブ・システム）プラットフォーム「Lumex」の提供を始めたと発表した。新たなCPU（中央演算処理装置）「C1」とGPU（画像処理半導体）「Mali」を統合し、モバイル機器などオンデバイスでAI（人工知能）を活用するためのSoC（システム・オン・チップ）設計基盤を提供する。
【関連イラスト】Lumexの全体イメージ
同社はこれまでCPUコア「Cortex」を中心にモバイル向けの設計用IP（知的財産）を提供してきたが、AI搭載に向け、CSSを中心とするプラットフォームへの転換を図った。

AIに必要な計算を高速化する命令セットの拡張機能「SME2」との統合も含め、ハードウエアからソフトまでを全体として提供することで、AI搭載の需要に応える。IPベンダーとして知られる同社だが、「プラットフォーム・ファースト」への転換を表明しており、今回の発表はその一環と言える。

　オンライン説明会で同社日本法人の横山崇幸社長は、Lumexについて「全く新しいコンピュート・プラットフォ―ム」と強調する。

　新CPUのC1は、フラッグシップの「C1-Ultra」から「C1-Nano」まで全4種類をそろえ、ピーク時性能やチップ面積を考慮し自由に選択できる。GPUのMaliは飛躍的に進化し、「Mali G1-Ultra」が描画を行うレイトレーシング性能は前世代比で2倍に向上。AIの推論性能は、最大で20%高速化するなど性能が高まった。全体のAI性能はSME2へ対応することで、最大で5倍に高速化されたという。
電波新聞社報道本部",[],[]
生成AIのストレージを効率管理　HPC関連企業が日本投資倍増で意欲（電波新聞デジタル）,https://news.yahoo.co.jp/articles/d01569415d1272be71c317a262e0a70ca0891fee,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250910-00010001-dempad-000-1-view.jpg?exp=10800,2025-09-10T11:11:02+09:00,2025-09-10T11:11:02+09:00,電波新聞デジタル,dempad,電波新聞デジタル,891,"今回、日本展開強化のためラウンドテーブルを開いた。中央左がトリンドル社長
ストレージ製品を手がける米データダイレクト・ネットワークス（DDN）の日本法人が9日、AI（人工知能）の開発用データ基盤「Infinia」の国内販売を始めた。AIアプリケーション開発支援のプログラムも提供する。長年HPC（ハイ・パフォーマンス・コンピューティング）分野に携わってきた実績を土台に、よりエンドユーザーに近い領域の開拓も狙う。
【関連写真】「スケーラブルなアプリケーションをサポートできる」とInfiniaの強みを語るトリンドル社長
今回のInfiniaは、低遅延で高速という特徴を持つストレージプラットフォーム。LLM（大規模言語モデル）の推論では、各トークンを生成する際に過去の演算結果を再利用する「KVキャッシュ」が重要な役割を果たす。Infiniaは、KVキャッシュをどのメモリにどう配置し保持するかを最適化し、GPUの効率的な稼働を支える。さらに開発者向けには、SDK（ソフトウェア開発キット）も提供し、アプリから容易に利用できる環境を整える。

　同社は元々、スーパー・コンピューターなど、HPC分野のストレージに関するシステムを追求。効率的なデータ管理に関する技術や知見を積み重ねてきた。AIの用途が推論にも広がる中で、推論用途のAIアプリベンダー向けにも技術を提供しようと、Infiniaの開発に至った。

　日本法人のDDNジャパンで社長を務めるロベルト・トリンドル氏は都内で同日開いた発表会で、Infiniaについて「これまでのカテゴリーにない製品」と強調。その役割にも触れ、「HPC側では効率性を追求してきた。これにより、生成AIの分野でも成功する」と力説した。

　全世界の売上高のうち15～20％を占める日本は、同社にとって重要な市場だ。これまでNECやソフトバンクを顧客としてきた。Infiniaの投入により、AIアプリ側にも照準を向け、今後3年で日本への投資額を倍増させる計画だ。AIアプリ開発支援プログラムに対応する人員確保などに充てるという。
電波新聞社報道本部",[],[]
米エヌビディア、動画生成用GPU発表　7.5倍のAI性能、来年末提供（電波新聞デジタル）,https://news.yahoo.co.jp/articles/7e9c85d06bbfff3ce9939a123044be41b098b0e6,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250910-00010000-dempad-000-1-view.jpg?exp=10800,2025-09-10T00:00:24+09:00,2025-09-10T00:00:24+09:00,電波新聞デジタル,dempad,電波新聞デジタル,595,"米カリフォルニア州サンタクララで開催されたAIインフラサミット2025で発表
米エヌビディアは9日、大規模なコンテキスト（文脈）の処理を行う新GPU（画像処理半導体）「Rubin CPX」を発表した。すでに明らかになっていた同社の次世代GPUアーキテクチャー「Rubin」を採用し、100万トークン規模のコーディングや動画生成を高速で行う。2026年末の提供を予定。
【関連写真】Rubin CPX
新製品は、新たなプラットフォーム「Vera Rubin NVL144 CPX」上で稼働する。これは、同社の最新AI処理システム「GB300 NVL72」の7.5倍のAI性能を実現。メモリーも、100TB（テラバイト）の容量と1.7Pbps（ペタビット毎秒）の帯域幅を備える。

　動画データを変換するデコーダーとエンコーダー、文脈を踏まえた推論処理機能を単一チップに集積。同社によると、1億ドルの投資に対し50億ドルのトークン収益を生み出すという。

　同社は、GPU上でAI（人工知能）を開発するためのソフトウエア基盤「CUDA」を提供している。今回の製品では、こうした強みも生かし、ソフト面のサポートを行う。

　同社のジェンスン・フアンCEOは「新カテゴリーのプロセッサーを導入することで、AIコンピューティングの最前線に新たな飛躍をもたらす」とコメントしている。
電波新聞社報道本部",[],[]
