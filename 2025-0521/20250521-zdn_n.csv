headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
「圧倒的シェアの一因だった」――終了する“ドコモ絵文字”への思い、生みの親・ニコニコ栗田代表が明かす（ITmedia NEWS）,https://news.yahoo.co.jp/articles/7689cb775ce911f9da38815fc1ee11fb6c439a21,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250521-00000134-zdn_n-000-2-view.jpg?exp=10800,2025-05-21T19:33:30+09:00,2025-05-21T19:49:01+09:00,ITmedia NEWS,zdn_n,ITmedia NEWS,1276,"ドコモ絵文字（出典：ニュースリリース）
NTTドコモは5月21日、1999年から独自に提供してきた「ドコモ絵文字」の提供を、6月下旬以降の発売機種から順次終了すると発表した。開発者であるニコニコの栗田穣崇代表はこれを受けて同日、自身のXアカウント（@sigekun）で「提供終了記念」としてユーザーからの質問を募り、ドコモ絵文字への思いや開発時のエピソードを次々と明かした。
【画像】栗田代表が気に入っているという「ハート」「バー」の絵文字など（計3枚）
ドコモ絵文字の開発にかかった期間について、栗田代表は「構想は数カ月、開発は1カ月弱」だったと説明。最初に完成したのは「雨」の絵文字だったという。開発当初は、約200個近くを1カ月弱で作ったとのこと。

　「一番作るのが面倒だった絵文字」を問われると、「コンビニ」「ガソリンスタンド」を挙げた。「12×12ドットの制約内での表現が難しく、結局文字になった」という。

　各絵文字への配色については、「自分の一存で、その絵文字に合う色を6色の中から選んだ」と説明。「病院は最初赤にしたが、赤十字に怒られたため黒に変更した」とのエピソードも明かした。

　「お気に入りの絵文字は？」との問いには、「ハート」の絵文字を挙げた。その理由は「どんな誹ぼう中傷でも語尾にこれをつけると打ち消す力があるから」（栗田代表）。デザイン面では「カクテル」（“バー”の絵文字）の絵文字を気に入っているという。

　「絵文字はドコモの業績にどれほど貢献できたのか」との問いには、「2000年代前半のドコモの圧倒的なシェア率の要因の1つではあったと思う」と振り返った。

　一方で、「『ドコモ絵文字をやめてほしい』という意見が近年多く見られてきたが、どう感じていたか」と問われると、「全ての絵文字やダークモードに対応できなかったので、当然だと思います。自分ではどうしようもないですけど」と冷静な受け止めを見せた。なお、同氏が最後に使ったドコモ絵文字搭載端末は「Xperia SO-52Bが最後だったと思う」とのこと。

　99年に登場したドコモ絵文字は、同社の携帯電話向けネットサービス「iモード」の対応端末に搭載され、メールやWebなどモバイル通信の普及とともに広く使われた。2010年に世界共通の文字コード「Unicode」に収録され、国際的に広がった“Emoji”の発祥としても、高い評価を受けている。

　16年には、初期のドコモ絵文字176種類がニューヨーク近代美術館（MoMA）に「デジタルコミュケーションの新しいかたち」として収蔵された。栗田代表は同日の別のポストで「まさか1カ月弱で作ったものが26年残るとは思わなかった」との感慨も漏らした。

　栗田代表は95年にNTTドコモに入社し、iモードや絵文字の企画・開発などに携わった。09年に退社したのちは、ぴあやバンダイナムコエンターテインメントなどを経て15年にドワンゴへ入社。17年12月に、ニコニコの運営責任者に就任している。
ITmedia NEWS",[],[]
Google WorkspaceにもGemini　GmailのパーソナライズやMeetのリアルタイム通訳など（ITmedia NEWS）,https://news.yahoo.co.jp/articles/6d0e5b241c0e615ad7e7143354fd23e32696102a,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250521-00000127-zdn_n-000-1-view.jpg?exp=10800,2025-05-21T18:12:24+09:00,2025-05-21T18:12:24+09:00,ITmedia NEWS,zdn_n,ITmedia NEWS,1485,"通訳設定画面
米Googleは5月20日（現地時間）、開発者会議Google I/O 2025の基調講演で、「Google Workspace」の機能強化について、主にAIモデル「Gemini」の活用とパーソナライズに焦点を当てて説明した。
AIアバターを選ぶ
Workspaceでは現在、AIアシスタントが毎月20億回利用されているという。
Gmailの新機能
パーソナライズしたスマートリプライ

　Gmailには2015年からAIが返信内容を提案する「スマートリプライ」機能があるが、新機能では、ユーザーの過去のメールやGoogleドライブのファイルから関連情報を参照し、ユーザーがよく使う言い回しやトーン、スタイルに合わせて返信の候補を作成する。

受信トレイの整理機能

　Geminiに指示を出すだけで、不要なメールを削除したりアーカイブしたりできるようになる。例えば、「去年の毎朝新聞社からの未読メールをすべて削除して」といった指示が可能だ。この機能は7～9月期に提供開始の予定。
Google Meetのほぼリアルタイム音声通訳
発せられた言葉を、相手が理解できる言語に、ほぼリアルタイムで翻訳して音声で伝える「speech translation」機能が追加される。

　音訳時には、話者の声、トーン、表情も反映される。女性同士の会話のデモ動画では、英語の話者が話し始めて少しすると似た音声のスペイン語が被さり、スペイン語の話者でも同様になっている。

　まずは英語とスペイン語に対応し、数週間以内に他の言語も追加の予定だ。

　Workspaceのビジネス顧客むけに今年後半に早期テストが行われる見込み。
Google Vidsの新機能
昨年11月に発表された「Google Vids」は、テキスト入力でプレゼン動画などを作成できるGemini搭載アプリ。「Google AI Pro」と「Google AI Ultra」プランで提供している。

Googleスライドからプレゼン動画

　新たに、「Googleスライド」で作成した既存のプレゼン資料を動画に変換できる機能が追加される。Geminiは、スクリプト、ナレーション、アニメーションなどの生成をサポートする。この機能は7～9月期に提供開始の予定。

「ええと」や「あのぅ」を1クリックでカット

　また、録画した動画の文字起こしを生成し、「ええと」「あのぅ」といった無駄な言葉や不自然な無音部分を1クリックで特定し、削除できるようになる。この機能は7～9月期にLabsで利用可能になる予定。

音声バランス調整

　動画全体の音声レベルを1クリックで自動調整できるようになる。この機能は6月に提供開始の予定。

AIアバター

　スクリプトを入力するだけで、AIアバターがその内容を話す動画を作成できる。複数の男女のアバターが用意されている。
Googleドキュメントのライティング支援
Googleドライブ内の関連資料（プレゼン資料や報告書など）をGoogleドキュメントにリンクすると、Geminiがこれらの情報源だけを参照してライティング支援を行う。これにより、調査報告やビジネスプラン作成の際、必要な文脈を正確に把握して作業を進められる。この機能は7～9月期に提供の予定。
Workspace全体に「Imagen 4」
スライド、Vids、ドキュメントなどで画像を生成する際、最新画像AIモデル「Imagen 4」を利用できるようになる。同日より提供開始。
ITmedia NEWS",[],[]
トヨタ、新型「RAV4」公開　純ガソリンエンジンモデルなくなる　日本では2025年度発売（ITmedia NEWS）,https://news.yahoo.co.jp/articles/bf6c79761fe990a718521778540375c6646c2634,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250521-00000118-zdn_n-000-2-view.jpg?exp=10800,2025-05-21T16:31:28+09:00,2025-05-21T16:32:15+09:00,ITmedia NEWS,zdn_n,ITmedia NEWS,780,"（写真：ITmedia NEWS）
トヨタ自動車は5月21日、クロスオーバーSUVの新型「RAV4」を公開した。同社で初めて、自社グループのソフトウェア開発プラットフォーム「Arene」（アリーン）を採用。日本では2025年度内に発売予定。
【画像を見る】新型RAV4のプロトタイプ
PHEVとHEVをラインアップし、純ガソリンエンジンモデルがなくなる。PHEVには、同社による最新世代のハイブリッドカー向け機構を初めて搭載し、バッテリーを大容量化した他、モーター出力も向上した。電動モーターでの航続距離は従来の95kmから150kmに伸びたという。

　デザインはバンパーとグリルを一体化した「CORE」に加え、大型のグリルを備えた「ADVENTURE」、車体の剛性を高めたスポーツモデル「GR SPORTS」をそろえる。

　Areneは子会社のウーブン・バイ・トヨタが手掛ける。一部報道媒体ではOSとも表現されるが、同社広報によると正しくはソフトウェア開発プラットフォームという。

　RAV4では、マルチメディアシステムが搭載する音声認識機能を、AreneのSDK（ソフトウェア開発キット）を使って開発。応答速度・理解精度を向上させたとうたう。さらに、AIでドライバーの異常を検知し、運転の継続が困難な場合には、自動で車両を減速・停車させる機能も同様に改良。路肩に退避スペースが確認できた場合には、減速後、路肩へ寄せて停車できるよう改善した。さらに、これまでオプションとして提供していた急加速の抑制機能を標準搭載したという。

　トヨタはソフトウェア検証ツールや、データ収集基盤を備えるAreneを活用し、安全に関する技術の開発効率を高める方針。新型RAV4を皮切りに、同様にAreneを活用した車両の開発も本格化するという。
ITmedia NEWS",[],[]
メルカリ、トラブルの損害は“全額補償”へ　不正利用者の徹底排除も宣言（ITmedia NEWS）,https://news.yahoo.co.jp/articles/af5876f5904ab7a1428aae974d832969404e3ce9,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250521-00000116-zdn_n-000-1-view.jpg?exp=10800,2025-05-21T16:18:34+09:00,2025-05-21T16:18:34+09:00,ITmedia NEWS,zdn_n,ITmedia NEWS,798,"（出典：メルカリ）
メルカリは5月21日、不正利用者の排除と被害に遭った利用者の救済を掲げ、新たな3つの取り組みを公表した。AIによる不正監視の強化、「メルカリ鑑定センター」の設立、そして「全額補償サポートプログラム」の導入が柱となる。
【画像】メルカリは不正利用者の「徹底的な排除」と利用者の「徹底的な救済」をアピール
全額補償サポートプログラムは、トラブルが発生した際に、その購入代金や販売利益の全額を補償するというもの。7月に開始する予定で、併せて補償を受けるためのガイドラインを公開する。

　メルカリ鑑定センターは、偽ブランド品の撲滅を目指し、鑑定できる商品を広げる取り組み。センターは9月に稼働予定で、あわせて一部商品の鑑定義務化なども検討していく。

　AI不正監視の強化は、巧妙化する不正利用の手口に対応するため、AIに疑わしい行為を学習させて不正リスクをスコア化。不正利用者を特定し、アカウントの利用制限や、場合によっては損害賠償請求などを含め責任を追及していく。

　さらにメルカリは、これらの取り組みの効果を定量的に可視化する「透明性レポート」を定期的に開示する考え。初回は8月を予定しているという。
利用者のX投稿が契機に
メルカリを巡っては、2024年11月に返品された商品の中身が抜き取られる被害に遭った利用者が事務局に相談したところ、一方的な返事しかもらえなかったというX投稿が話題に。その後、メリカリはサポート体制や補償方針の見直しと不正利用者対策を強化する方針を示した。

　メルカリは今後、利用者間では解決が難しい問題にも関与を強め、不正利用者は徹底的に排除するとしている。「月間2300万人が利用するアプリの提供事業者として、これまで以上に社会的責任が問われている。安心して安全に利用できる環境を提供するため、一層対策を強化する」。
ITmedia NEWS",[],[]
「長い間お疲れさまでした」──ドコモ絵文字の終了に“生みの親”、ニコニコ栗田代表も労い（ITmedia NEWS）,https://news.yahoo.co.jp/articles/094f2980bedaf484663341ac9db6288c9c9b9c9c,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250521-00000106-zdn_n-000-1-view.jpg?exp=10800,2025-05-21T13:44:33+09:00,2025-05-21T13:44:33+09:00,ITmedia NEWS,zdn_n,ITmedia NEWS,567,"（出典：X）
NTTドコモは5月21日、独自の「ドコモ絵文字」を終了すると発表した。1999年の誕生から26年。当時、ドコモで絵文字を開発したニコニコの栗田穣崇代表も「長い間お疲れさまでした！」と労った。
【画像】ドコモ時代のことを話す栗田氏（18年のインタビュー記事より）
栗田代表は同日、自身のXアカウントでドコモのプレスリリースを引用しつつ「ドコモ絵文字を世の中に送り出してから26年。auとの絵文字統合でリファインしてからも13年…役目を十分に果たしたというか、むしろ遅すぎるくらい…長い間お疲れさまでした！」と投稿した。

　絵文字は、1999年に同社の携帯電話向けネットサービス「iモード」と共に登場し、手軽で分かりやすいコミュニケーション手段として発達した。2010年には世界共通の文字コード「Unicode」に多数の“Emoji”が取り入れられて世界に普及。16年には「Emoji」の発祥として初期のドコモ絵文字176種類がニューヨーク近代美術館（MoMA）に収蔵された。

　栗田代表は、1990年代にNTTドコモに所属し、iモードや絵文字の立ち上げに携わった。絵文字については、ほぼ一人で開発したという逸話も残る。その後、ぴあやバンダイナムコゲームスなどを経て15年にドワンゴへ入社した。
ITmedia NEWS",[],[]
ドコモ絵文字、25年の歴史に幕　6月下旬以降の発売機種から提供終了（ITmedia NEWS）,https://news.yahoo.co.jp/articles/1111ac7f64004a26b4491a0bda312574091f0643,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250521-00000092-zdn_n-000-1-view.jpg?exp=10800,2025-05-21T11:49:00+09:00,2025-05-21T11:49:00+09:00,ITmedia NEWS,zdn_n,ITmedia NEWS,587,"提供を終了する「ドコモ絵文字」（NTTドコモ公式Webサイトより引用）
NTTドコモは5月21日、独自に提供してきた「ドコモ絵文字」を、6月下旬以降の発売機種から順次終了すると発表した。「昨今の端末の絵文字の利用状況を鑑みて」の判断としている。
【画像】終了後に提供される絵文字は？　Google・サムスンとの比較はこちら（計1枚）
韓国Samsung Electronics（以下、サムスン）のGalaxyシリーズでは7月以降に発売する機種から、その他のAndroid端末およびドコモケータイでは、6月下旬以降に発売される機種。提供終了後は、Galaxy製品ではサムスンが提供する絵文字を、それ以外のAndroid製品やドコモケータイではGoogleの「Noto Color Emoji」を提供する形となる。

　Galaxy製品では、7月以前に発売した一部の製品でも、10月以降のソフトウェアアップデートにより、ドコモ絵文字が利用できなくなるという。対象機種や時期の詳細は、ドコモのWebサイト上で別途案内するとしている。

　ドコモ絵文字は、1999年に同社のフィーチャーフォン向けに登場したオリジナル絵文字。「Emoji」の発祥として海外でも高い評価を受けており、16年には初期の176種類がニューヨーク近代美術館（MoMA）に収蔵された。
ITmedia NEWS",[],[]
Apple、「WWDC25」の基調講演は「画期的なアップデートの初披露から」　日本時間6月10日午前2時開始（ITmedia NEWS）,https://news.yahoo.co.jp/articles/d4de3ec79bdfbd7d62c6a64c43ee6750290f4074,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250521-00000088-zdn_n-000-1-view.jpg?exp=10800,2025-05-21T11:22:27+09:00,2025-05-21T11:22:27+09:00,ITmedia NEWS,zdn_n,ITmedia NEWS,563,"（出典：Apple）
米Appleは5月20日、年次開発者会議「WWDC（Worldwide Developers Conference）25」の概要を発表した。iOS19などの登場が期待される基調講演は、現地時間の6月9日午前10時から。日本時間では6月10日午前2時からとなっている。
【画像】「WWDC25」の公式サイトでも基調講演は視聴できる
同社によると、基調講演は「Appleのプラットフォームに登場予定の画期的なアップデートの初披露から始まる」という。AppleのWebサイトやApple TVアプリ、YouTubeのApple公式チャンネルで配信する。

　基調講演に続く「Platforms State of the Union」では、iOS、iPadOS、macOS、tvOS、visionOS、watchOSについて掘り下げる。こちらはデベロッパー向けのアプリやWebサイトで配信する予定だ。

　また開幕日には、Apple Parkに1000人を超えるデベロッパーや学生を招待し、開催を祝うリアルイベントを開催。Appleの技術者との直接交流などを予定している。

　この他、100を超える技術セッションを予定しているWWDC25。開催期間は現地時間の6月9日から13日まで。
ITmedia NEWS",[],[]
「Google Glass」の再来？　グーグルが「Android XR」を搭載したメガネ型プロトタイプ機をデモ（ITmedia NEWS）,https://news.yahoo.co.jp/articles/01dac448515eff384d0a52dcbc56632ce512ff39,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250521-00000083-zdn_n-000-1-view.jpg?exp=10800,2025-05-21T11:01:59+09:00,2025-05-21T11:01:59+09:00,ITmedia NEWS,zdn_n,ITmedia NEWS,1107,"（写真：ITmedia NEWS）
米Googleは、5月20日（現地時間）に開催した「Google I/O 2025」の基調講演にて、スマートグラスとヘッドセット向けの新プラットフォーム「Android XR」と「Gemini」の連携機能を発表した。また、ヘッドセットやメガネ型デバイスに、生成AI「Gemini」を搭載するデモとして、メガネ型デバイスの試作機を披露した。
【画像を見る】グーグルが開発したARグラスでできること（全9枚）
Android XRは様々なXRデバイスをサポートするプラットフォームで、2024年12月にGoogleが発表したもの。Geminiと連携することでユーザーと同じ視点から状況を理解し、ハンズフリーでサポートする機能を提供する。Android XRはまず、ヘッドセットに搭載される見込みで、韓国Samsung製の「Project Moohan」というコードネームの最初のヘッドセットデバイスが2025年に発売予定だ。

　続けて、Android XR搭載スマートグラスにも言及。「10年以上にわたって開発を続けてきた」と、2012年にお披露目された「Google Glass」（2015年に販売中止）に触れつつ、Android XR Glassesでは、カメラ、マイク、スピーカーを内蔵し、スマートフォンと連携してユーザーが見ている状況を理解するという。また、オプションのレンズ内ディスプレイにより、必要な情報をユーザーのみに表示する機能を持つ。

　基調講演では「Android XR Glassesの早期デモを見たい人はいますか？」という問い掛けとともに、スマートグラスのプロトタイプを披露。メッセージ送信、予定管理、ナビゲーション、写真撮影などの機能をデモンストレーションした。無線通信を使う関係上、人の多いGoogle I/Oの会場でのデモは途中うまく動作しない場面もあったものの、リアルタイム翻訳機能も披露し、会話をスマートグラスのディスプレイ上に「現実世界の字幕」として表示する機能を紹介していた。

　同社では、スマートグラスを実用化するために、Gentle MonsterやWarby Parkerなどのアイウェアブランドと提携し、スタイリッシュなスマートグラスの開発を進めている。また、Samsungとのパートナーシップを強化し、ヘッドセットだけでなくAndroid XR搭載スマートグラスの共同開発も行っている。

　Googleは開発者向けに、25年後半からこのプラットフォームでの開発を開始できるよう準備を進めているという。
ITmedia NEWS",[],[]
スマホのGeminiに“目”がついた　AIアシスタントの未来へ一歩前進　無料で誰でも利用可能（ITmedia NEWS）,https://news.yahoo.co.jp/articles/791350ff7fc9f705960038036dbabf12d2341234,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250521-00000078-zdn_n-000-1-view.jpg?exp=10800,2025-05-21T08:48:28+09:00,2025-05-21T08:48:28+09:00,ITmedia NEWS,zdn_n,ITmedia NEWS,882,"「Geminiアプリ」がアップデート
米Googleは5月20日（現地時間）、AIアシスタント「Gemini」のスマートフォンアプリに対し、カメラに写るものについて音声で質問ができる「Gemini Live」の機能を、全ユーザーに無料で開放した。Geminiアプリのアップデートの一環で、ほかにも画像生成など複数の機能を強化したという。
【画像でチェック】新しく無料で使える機能【全7枚】
スマートフォンのカメラを通して見えるものについて、検索したり質問したりできる機能。例えば、室内にある椅子を映しながら「どうやって置くするのが最適か？」と聞くと、置き場所や組み合わせるべき家具などを教えてくれる。

　この機能は2024年、AIアシスタントの研究プロジェクト「Project Astra」の一環として発表。25年4月からは有料版の「Gemini Advanced」と、同社のスマートフォン「Pixel 9」シリーズ、韓国Samsungの「Galaxy S25」ユーザー向けに提供を始めていた。

　他にも、画像生成機能には、同日に発表した新たなAIモデル「Imagen 4」を搭載。動画生成機能にも、同日発表の「Veo 3」を搭載した。画像生成機能は全ユーザーが無料で使える一方、動画生成機能は有料プラン「Gemini Ultra」の米国ユーザーが対象。

　質問に応じて詳細な分析とレポートを作成する機能「Deep Research」では、ユーザーの独自データを情報源として追加できるようになった。近日中に、Google DriveとGmail内の情報も参照可能になる予定だ。

　AIが文章作成やコーディングをサポートする機能「Canvas」には、対話形式の音声による要約作成機能などが加わった。加えて、同日に正式にリリースしたAIモデル「Gemini 2.5 Pro」を活用することで、コーディング性能も大幅に向上。自然言語による指示で“直観的”にコーディングする「Vibe Coding」（バイブコーディング）にも役立つという。
ITmedia AI＋",[],[]
都電を懐かしい“山吹色”に　都交通局がクラファン実施（ITmedia NEWS）,https://news.yahoo.co.jp/articles/0e775628a72d7db83891e8deb71c9e9edf0169d2,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250521-00000057-zdn_n-000-1-view.jpg?exp=10800,2025-05-21T08:20:14+09:00,2025-05-21T08:20:14+09:00,ITmedia NEWS,zdn_n,ITmedia NEWS,498,"昔の都電を思わせる山吹色を採用したデザイン画（出典：交通局、以下同）
東京都交通局は5月20日、東京さくらトリム（都電荒川線）の車両1両をリニューアルするためにクラウドファンディングを実施すると発表した。「ななつ星 in 九州」などをデザインした水戸岡鋭治さんが協力。2026年春ごろの運行を予定している。
【画像】返礼品の「車両デザイングッズ詰め合わせコース」
運行開始から30年以上が経過した都電の車両「8500形」1両を改装。昔の都電を思わせる山吹色にするという。内装には木材をふんだんに使い、座席は多様なパターンにデザインするという。

　水戸岡さんは「私が15歳の時、初めて東京駅で見た山吹色のかっこいい路面電車が大変印象的でした」という。今回のプロジェクトで「懐かしくて新しい都電の姿をお見せしたい」としている。

　クラウドファンディングはCAMPFIREで実施。目標金額は1700万円で、支援プランは3000円から50万円まで用意する。返礼品は「車両デザイングッズ詰め合わせコース」「車内に名称記載権コース」「お披露目式ご招待＆一番列車乗車コース」など。
ITmedia NEWS",[],[]
聞こえない音で“時計”を操作する攻撃　血圧計やレジのRTCに干渉、不正に制御　海外チームが発表（ITmedia NEWS）,https://news.yahoo.co.jp/articles/98b59f02289d9cbc224de9d3ac671d122f2a3a89,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250521-00000043-zdn_n-000-1-view.jpg?exp=10800,2025-05-21T08:05:13+09:00,2025-05-21T08:05:13+09:00,ITmedia NEWS,zdn_n,ITmedia NEWS,1382,"（写真：ITmedia NEWS）
中国科学院と米バージニア工科大学に所属する研究者らが発表した論文「TimeTravel: Real-time Timing Drift Attack on System Time Using Acoustic Waves」は、音波を使ってスマート機器の内部時計を勝手に操作できる脆弱性を示した研究報告だ。
【画像を見る】実験のセットアップ【全3枚】
「TimeTravel」と名付けられたこの攻撃は、テーブルなどの固体表面に伝わる音波を利用して、機器内部の時計（リアルタイムクロック：RTC）の進み方を速くしたり遅くしたりすることができる。

　多くの電子機器は正確な時間を保つためにRTCを使用している。例えば、医療機器での健康測定値の記録、店舗レジでの取引時間の管理、交通信号機の制御など、日常生活で使われるさまざまな機器がRTCに依存している。

　攻撃者は、まず超音波トランスデューサー（直径: 3cm、厚さ: 2mm）をターゲットとなる機器が置かれているテーブルなどに設置する。そして32.768kHzという特定の周波数の音波を発生させると、この音波がテーブルを伝わってRTC内部の水晶振動子に到達する。水晶振動子は音波の影響で余分な電気信号を発生させ、その結果、機器の内部時計の進み方が変化する。

　研究チームは9種類のRTCモジュールと7種類の市販デバイスでこの攻撃を検証した。実験では、最大93％の精度で時間操作に成功している。障害物がある環境下でも、77％以上の攻撃成功率を維持できた。

　実際の血圧計での検証結果を見てみると、正常時に122/74mmHgだった測定値が、攻撃によって101/57mmHgまで下がった。逆に、攻撃パラメータを変えると、血圧の測定値を158/105mmHgまで上げることもできた。血圧計はカフ（腕に巻く部分）を膨らませた後、一定の速度で徐々に空気を抜いていくが、この減圧プロセスの時間を操作することで測定値を制御する。

　この攻撃が危険な理由は明らかだ。例えば、病院で血圧計の測定値が操作されれば、医師が誤った診断や治療を行う恐れがある。また、商業用のPOSマシン（レジ）では、時間を操作して割引時間帯に戻し、不正に安い価格で商品を購入することも可能になる。

　重要なのは、この攻撃がネットワークへの侵入やパスワードなど特別な権限を必要としない点。攻撃者は単に音波を発生させる装置を機器の近くに設置するだけでよい。しかも、使用される音波は人間の耳には聞こえないため、攻撃が行われていることに気付きにくい。

　Source and Image Credits: Liu, Jianshuo, et al. “TimeTravel: Real-time Timing Drift Attack on System Time Using Acoustic Waves.” 

　※Innovative Tech：このコーナーでは、2014年から先端テクノロジーの研究を論文単位で記事にしているWebメディア「Seamless」（シームレス）を主宰する山下裕毅氏が執筆。新規性の高い科学論文を山下氏がピックアップし、解説する。X： ＠shiropen2
ITmedia NEWS",[],[]
タマネギを泣かずに切るコツ、物理学者が発表　ポイントは“ナイフの切れ味”と“切る速度”（ITmedia NEWS）,https://news.yahoo.co.jp/articles/e7aea235dc3a190d6111b133b66e03d87506e4a2,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250521-00000042-zdn_n-000-1-view.jpg?exp=10800,2025-05-21T08:05:08+09:00,2025-05-21T08:05:08+09:00,ITmedia NEWS,zdn_n,ITmedia NEWS,1236,"タマネギを泣かずに切る秘訣、物理学者が発表（画像作成：編集部）
米コーネル大学などに所属する研究者らが発表した論文「Droplet Outbursts from Onion Cutting」は、「玉ねぎを切ると涙が出る」現象の科学的メカニズムを解明した研究報告だ。
【画像を見る】実験のセットアップ【全3枚】
タマネギを切ると、涙を誘発する液体成分が放出されるが、これら液滴生成の根本的なメカニズムは十分に解明されていない。

　研究チームは高速カメラ技術を駆使し、毎秒5000～2万コマという超高速で、玉ねぎを切る瞬間を撮影。さらに特殊な粒子追跡技術とゆがみ分析技術を組み合わせることで、肉眼では見えない微小な液滴の動きを詳細に分析することに成功した。

　この研究で明らかになったのは、玉ねぎから液滴が放出されるプロセスが2段階で起こるということだ。第1段階では、ナイフが玉ねぎを切り始めた瞬間に内部に蓄積された圧力によって高速（秒速1～40m）で液体を噴出。第2段階では、この噴出した液体の糸状の流れが空気中でさらに小さな液滴に分裂していく。

　注目すべき発見は、ナイフの切れ味と切る速度が液滴の放出パターンに大きく影響するという点だ。研究では、刃の鋭さが0.91μm（非常に鋭い）から13.3μm（比較的鈍い）まで、また切断速度が秒速0.44～2.03mまでの範囲で実験した。

　結果として、切れ味の悪いナイフを使うと、放出される液滴の数が最大で約40倍に増加することが判明。また切断速度が速いほど、液滴の数は約4倍増加した。

　この現象を詳しく理解するため、研究チームは玉ねぎの組織構造に着目。玉ねぎの各層には硬い表皮と柔らかい内部組織があり、この二層構造が液滴放出のメカニズムに重要な役割を果たしている。切れ味の悪いナイフを使うと、表皮が破れるまでに内部組織が大きく圧縮され、その結果、表皮が最終的に破れた瞬間にバネのように高圧で液体が噴出するのだ。

　さらに研究チームは、玉ねぎを切る方向や温度（冷蔵または室温）が液滴放出に与える影響も調査した。これらの条件による液滴の速度分布には統計的に有意な違いは見られなかったが、一方で冷やした玉ねぎからはより多くの量の液体が放出される傾向が観察できた。

　Source and Image Credits: Wu, Zixuan, et al. “Droplet Outbursts from Onion Cutting.” arXiv preprint arXiv:2505.06016（2025）.

　※Innovative Tech：このコーナーでは、2014年から先端テクノロジーの研究を論文単位で記事にしているWebメディア「Seamless」（シームレス）を主宰する山下裕毅氏が執筆。新規性の高い科学論文を山下氏がピックアップし、解説する。X： ＠shiropen2
ITmedia NEWS",[],[]
Google I/O基調講演まとめ　「Gemini」で体験をさらにパーソナライズ（ITmedia NEWS）,https://news.yahoo.co.jp/articles/6d9e1f4952507d0947b37f5328dc7d21fca5ea20,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250521-00000077-zdn_n-000-1-view.jpg?exp=10800,2025-05-21T07:53:22+09:00,2025-05-21T07:53:22+09:00,ITmedia NEWS,zdn_n,ITmedia NEWS,4231,"スンダー・ピチャイCEO
米Googleは5月20日（現地時間）、年次開発者会議「Google I/O」をハイブリッドで開催した。例年通りスンダー・ピチャイCEOの挨拶で始まった約2時間の基調講演は昨年同様ほぼAIモデル一色で、「Gemini」という単語は95回、「AI」は92回発せられた。
XREALのProject Aura
本稿ではこの基調講演で発表されたことを簡単にまとめる。なお、開発者向け基調講演は別途行われており、技術的な詳細はそちらで発表された。

　ピチャイ氏は、GoogleのAIへの取り組み、特にGeminiの進化について説明した。「Gemini 2.5 Pro」がコーディングベンチマークでトップになったことや、「TPU Ironwood」などのAI向けのGoogleのインフラの強みを強調した。また、同社のAI製品が広く普及していることにも言及し、同社の数十年間の研究の成果が世界中の人々にとって現実のものとなっている新しいフェーズにあると語った。
「Project Starline」は「Google Beam」に
2021年のGoogle I/Oで発表した3D動画でのビデオ会議システム「Project Starline」を進化させた新しいAIファーストのプラットフォーム「Google Beam」を発表した。

　6台のカメラアレイがユーザーを捉え、AIがこれらを統合してほぼリアルタイムに3Dにレンダリングすることで、立体的で目の前にいるような相手と会話できるという。

　米HPと協力して開発した製品を、年内に一部の顧客向けに投入する計画。詳細は数週間後にHPから発表がある。
「Project Astra」の進化とGeminiアプリへの統合
既にPixel端末で利用できている「Gemini Live」は、周囲の世界を理解するユニバーサルAIアシスタント「Project Astra」がGeminiアプリに統合された機能だ。

　このGemini LiveがAndroidとiOSのGeminiアプリで、誰でも無料で利用できるようになる。

　Project Astraのライブ機能はGoogleアプリにも統合され、「Search Live」として提供される。機能はGeminiアプリのGemini Liveとほぼ同じだが、Geminiアプリを起動せずに、Googleアプリで利用できるようになるということだ。
Google検索の進化と「AI Mode」
Google検索の「AI Overviews」（日本では「AIによる概要」）は既に15億人以上が利用しているという。「Google検索で過去10年間で最も成功したローンチの1つ」だとしている。

新タブ「AI Mode」

　「AI Mode」は、この機能に慣れたユーザーや、より高度な検索体験を求めるユーザー向け新機能。検索画面に新たなタブとして表示される。まずは米国で同日からロールアウトする。

　従来の検索の2～3倍の長さのクエリやフォローアップの質問に対応する。デモでは、リビング用のラグを探す際、ライトグレーのソファがあるから部屋を明るく見せたいということを自然言語で入力すると候補になる商品が画像付きで表示され、フォローアップの質問として、やんちゃな子どもが4人いるという条件を追加すると、耐久性のある素材で作られた選択可能なラグに絞り込まれた。

　AI Modeでは、パーソナライズされた提案が可能になる。ユーザーの許可の下、Google検索にGmailなど他のGoogleのアプリを接続することで、過去のショッピング履歴やニュースレター購読などの情報に基づいて、より関連性の高い結果を提供できるようになる。この「Personal Context」機能は、ユーザーがいつでも管理できる。

バーチャル試着から購入まで可能な「Try It On」

　AI Modeの機能の1つとして、検索結果に表示された衣服をバーチャルに試着できるショッピング機能「Try It On」も発表された。

　検索結果の衣服の画像に「Try it On」ボタンが表示され、それをクリックして自分の全身写真を1枚アップロードすると、AIがユーザーの写真に衣服をレンダリングして重ねて見せる。ファッションに特化してトレーニングしたカスタム画像生成モデルを使っており、生地の物理特性（ドレープ、折り目、伸縮など）を考慮して、その服がユーザーが着た場合にどう見えるかをリアルにレンダリングする。

　この機能は同日から米国のSearch Labsで提供開始する。

　デモでは、試着して気に入った衣服について「track price」（価格追跡）し、購入する方法も紹介された。希望するサイズや目標価格を設定しておくと、目的の服の価格が目標価格まで下がると通知が来る。

　通知の内容を確認して「buy for me」をタップすると、AIエージェントがショッピングサイトで商品をカートに追加し、Google Payで決済まで完了する。この機能は米国内で数カ月中に利用可能になる予定だ。

「Deep Search」（Deep Researchとは別）

　AI Modeには、「Deep Search」機能も追加される。これは、ユーザーがさらに徹底的な応答を必要とする質問に対し、深い調査をサポートするものと、Google DeepMindのデミス・ハサビスCEOは説明した。

　ユーザーの質問を分解し、何十、数百もの検索を代理で実行し、膨大な情報の中から推論したレポートを数分で作成する。

　この機能は数カ月中に米国のSearch Labsで利用可能になる見込み。スポーツや金融関連のクエリに対して、データソースを分析し、視覚化されたチャートをオンザフライで生成する機能

　AI Modeには「Deep Research」も導入される。
Google Labs、Imagen、Veo
Google LabsとGeminiの上級副社長、ジョシュ・ウッドワード氏は、GeminiアプリとGoogle Labsについて説明した。

　Deep ResearchとCanvasの強化や、新たなコーディング製品として、非同期コーディングエージェント「Jules」を発表した。Julesは、GitHubリポジトリに接続してバグ修正やテストを自動化できる。来週中にパブリックβとして公開の予定だ。

Imagen 4

　画像生成のImagenが4になり、画質が向上し、毛皮やシフォン、水滴などがよりリアルに表現できるようになる。

　テキストレンダリングとタイポグラフィの精度が向上し、文字入りのポスターなども生成できるようになる。

　Geminiアプリだけでなく、WorkspaceのSlides, Vids, Docsでも利用可能になった。

Veo 3

　動画生成モデルのVeoは3になり、ネイティブオーディオ生成に対応した。効果音、環境音、キャラクター間の会話を生成できる。

Gemini in Chrome

　デスクトップ版のChromeブラウザにAIアシスタント機能として「Gemini in Chrome」が導入される。Webページの内容を自動的に理解し、要約したり、複雑な情報を明確にしたり、レビューを比較したりする。

　将来的には、複数のタブを横断したり、Webサイトをナビゲートしたりできるようになる予定。

　今週中に米国で英語のChromeを使用しているWindowsおよびmacOSの「Google AI Pro」および「Google AI Ultra」（後述）加入者向けにデスクトップで展開が開始される。
月額3万6400円の新サブスクプラン「Google AI Ultra」
今回発表された新機能を含む最先端の機能やモデルにアクセスできるサブスクリプションプランとして、新たに「Google AI Ultra」が発表された。

　月額249.99ドル（日本での価格は3万6400円）で、AIの使用上限も高く、クラウドストレージ容量も30Tバイトと豊富だ。

　また、これまで「Google One AIプレミアム」プランとして提供してきたAIに特化したサブスクプランを「Google AI Pro」と改称し、価格は据え置いたまま利用可能な機能を追加した。
AI映画制作ツール「Flow」
「Flow」は、Veo、Imagen、Geminiモデルを活用し、シネマティックなクリップ、シーン、物語を作成できるよう設計された映画制作ツール。

　独自の画像をアップロードしたり、Imagenを使って画像を生成したり、プロンプトや正確なカメラ制御を使ってクリップを組み立てたり、キャラクターやシーンの一貫性を維持したり、クリップをトリミングしたり延長したりできる。

　音楽生成AI「Lyria 2」も同日から一部のYouTubeクリエイターなどに提供を開始した。
Android XRのグラスはXREALも開発中
今回のGoogle I/Oでは、事前に別立てで紹介していたこともあり、Androidについては短く紹介したのみで、主に「Android XR」の進捗に重点が置かれた。

　ヘッドセットとメガネをサポートするAndroid XRの最初の搭載製品は、韓国Samsungの「Project Moohan」が今年後半に発売されるという既知の情報が繰り返された。

　メガネ型については、Samsungもリファレンスハードウェアを構築すること、Google自身もメガネブランドのGentle MonsterとWarby Parkerと提携してスタイリッシュなメガネの開発に取り組んでいることなどが発表された。

　また開発者向け基調講演でXREALが、Android XRプラットフォーム上に構築する次世代XRデバイス「Project Aura」を発表した。

　Project AuraはAndroid XRの2番目の公式デバイスになる見込み。詳細は6月開催のAugmented World Expoで発表の予定だ。
ITmedia NEWS",[],[]
これがAIと人間が共存する未来？　実用的なAIアシスタントを目指す「Project Astra」　Googleが新たなデモ動画公開（ITmedia NEWS）,https://news.yahoo.co.jp/articles/c3322033ab6577e5dcb854a218093c1bf86f257a,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250521-00000076-zdn_n-000-1-view.jpg?exp=10800,2025-05-21T07:32:13+09:00,2025-05-21T07:32:13+09:00,ITmedia NEWS,zdn_n,ITmedia NEWS,1003,"（写真：ITmedia AI＋）
米Googleは5月20日（現地時間）、同社の年次カンファレンス「Google I/O 2025」にて、AIアシスタントの研究プロジェクト「Project Astra」の新たなイメージ動画を公開した。動画では、スマートフォンに内蔵したAIアシスタントと会話しながら自転車を修理していく様子を収録。AIアシスタントと共に問題を解決していく様子を描いている。
【画像を見る】AIアシスタントが説明書を読み上げ【全4枚】
動画では、青年が自転車を修理する傍らで、スマホのAIアシスタントが自転車メーカーのサイト内にある説明書にアクセスし、修理に関するページを読み上げたり、「YouTubeで該当の自転車を修理する動画を調べて」というオーダーに対し、YouTubeから最適なものを探して再生したり、ユーザーをサポートしている

　またスマホのカメラを通して、自転車ショップから送られたメールの情報をもとに、カメラに映っているどのパーツを使えばよいかを判断したり、必要なパーツが自転車ショップにあるかAIが代わりに電話で在庫確認したりする、といった場面も見られる。

　Project Astraは、2024年に開催した「Google I/O 2024」で発表したプロジェクトで、「日常生活で本当に役立つ未来のAIアシスタントの構築」を目指している。24年には、スマホで撮影した物体をAIがリアルタイムに説明するデモなどを披露していた。

　Googleはこの1年間の研究成果として、より自然な音声出力や記憶機能の強化、コンピュータの制御機能などを、Geminiの会話モード「Gemini Live」に統合してきたと説明。今後はGoogle検索での新しい体験や、開発者向けAPI、開発中のスマートグラスなどの新しい形状のデバイスへも導入を進めていくという。

　YouTubeに掲載したデモ動画のコメント欄には「これは本当にすごい」「こんなにテクノロジーに興奮したのは久しぶり」など、このプロジェクトに期待する声などが上がっている。

　Googleではこの他にも、AIエージェントが人間のマルチタスクをどのように支援するか検証するプロジェクト「Project Mariner」も進行中。さまざまなアプローチで実用的なAIアシスタントの開発に取り組んでいる。
ITmedia AI＋",[],[]
「ソフトウェア開発インフラが整ってない」――“赤裸々すぎ”と話題のホンダテックブログ、突然の記事削除　「逆に印象悪い」の声も（ITmedia NEWS）,https://news.yahoo.co.jp/articles/d6ae70dcc2822fcff6ad6bc5732d426ac951f283,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250521-00000064-zdn_n-000-2-view.jpg?exp=10800,2025-05-21T07:20:08+09:00,2025-05-21T12:01:25+09:00,ITmedia NEWS,zdn_n,ITmedia NEWS,1693,"削除されたホンダのテックブログ記事（出典：web.archive.org、以下同）
「ソフトウェア企業でふつうに存在したインフラが存在しない」――本田技研工業（ホンダ）が5月19日に同社のテックブログで公開した記事「ソフトウェアエンジニアがHondaに転職して感じたこと4選」が話題だ。IT業界から自動車業界に転職し、ホンダに務めて2年目という社員がつづる赤裸々な内容が「公式ブログらしからぬギリギリな内容だ」とXなどで注目を浴びたが、20日になって記事を削除。「逆に印象が悪い」などと波紋を呼んでいる。
【画像】自動車業界へ転職後の体験談をつづったブログ記事（現在は削除済）
記事中では、AWSを活用して車載システムやアプリ向けのWebサービス・サーバ開発に携わる同社のソフトウェアエンジニアが、自身の経験をもとに、転職して感じたことをつづっていた。書き手はセキュリティ対策ソフトのパッケージベンダーから、自動車業界に転職して8年目の社員で、ホンダでの勤務は2年になるという。

　“4選”のうち、最初に挙げられていたのは「（ソフトウェア企業と比べて）ソフトウェアの仕事の経験がある人が少ない」こと。「われわれは自動車会社なので当たり前のことではあるのですが……」と前置きしつつ、「ソフトウェアの仕事をするときには、非常に手間がかかる」と率直につづっていた。

　2点目は「ソフトウェア開発のインフラが整っていない」こと。かつて勤務していたベンダーでは、「最高レベルのデスクトップPCと豊富なコンピュータリソースを自由に使えた」が、自動車業界への転職後は「仕事で使うのはノートPCだけ」になったと述べていた。

　業界の実態を紹介するとして、ホンダではない前職の自動車会社で、Androidを用いたカーナビを内製開発した際の経験も紹介。「ノートPCでAndroidをビルドすることはかなりのストレス」「インフラ構築にお金を使うために、ソフトウェアに詳しくない他部署の説得が必要だった」と、非IT企業への転職で感じたリアルな課題を打ち明けていた。

　3点目では「能力が高い人が多い」と業界を評価。「日本における自動車会社は、新卒・中途採用のマーケットで、優秀な従業員を採用し続けているというのも事実でしょう」と述べた上で、説明を行うことで一気に仕事がスムーズに進み始めるといった場面もあり、「自動車会社の従業員の底力を感じた」としていた。

　4点目では「労働組合の正体が分かる」という感想がつづられていた。給与やボーナスの交渉を担ってくれることをメリットとして挙げつつ、「選挙の際には労働組合関連の市議、県議、国会議員の応援などを求められる」との言及もあった。末尾では、最近の自動車がさまざまなソフトウェアを活用していることに触れ、「自動車会社のソフトウェアエンジニアとして、少しずつソフトウェアのことが分かる人を増やしていこうとしています」との意気込みが語られていた。

　SNS上では、こうした内容がいわゆるJTCの働き方やカルチャーをエンジニア視点で捉えたものとして注目され、はてなブックマークでは500を超えるブックマークを集めていた。

　記事中で語られるソフトウェア開発環境については「これを見て入りたいと思うソフトウェアエンジニアはいるのか」「ホンダクラスの企業でこれはありえない」といった驚きや批判の声も寄せられていた。こうした反響を受け、企業イメージへの影響を懸念して削除に至ったとの推測もある。

　一方で、エンジニア目線での率直な内情を企業ブログで明かしたことについて「懐が広い」「嫌みではなく、赤裸々で良い記事だと思った」と削除を惜しむ声も。中には「削除する方が、かえって印象が悪い」といった、ホンダの対応を批判する意見もある。

　ホンダのテックブログは4月25日に開設。同社のデジタルサービス ソフトウェア内製化チームとデジタルプラットフォーム開発チームが、使用技術やチーム運営の知見、イベント情報などを発信していくとしている。
ITmedia NEWS",[],[]
Google DeepMindから“拡散言語モデル”「Gemini Diffusion」登場　文字通り爆速で文章・コード生成（ITmedia NEWS）,https://news.yahoo.co.jp/articles/9a179562b98888652823f945ba06ed248f2f4d86,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250521-00000075-zdn_n-000-1-view.jpg?exp=10800,2025-05-21T07:05:03+09:00,2025-05-21T07:05:03+09:00,ITmedia NEWS,zdn_n,ITmedia NEWS,730,"超高速に文章やコードを生成できるAIモデル「Gemini Diffusion」（出典：Google DeepMind、以下同様）
米Google DeepMindは5月20日（現地時間）、開発者向け年次イベント「Google I/O 2025」の中で、超高速に文章やコードを生成できるAIモデル「Gemini Diffusion」を発表した。ウェイティングリストへの登録フォームを公開している。
【画像】Gemini 2.0 Flash Liteとの各種ベンチマーク性能の比較
速度は、ユーザーの入力を受け付けてから生成を始めるまでが約0.84秒。文章の生成速度は1479トークン／秒。1トークンはおおよそ1単語なので、約1500単語（1500文字ではない）が毎秒生成されるイメージだ。Google I/Oの中でも「またたく間に生成が終わる」と表現されていた。

　これは、画像生成や動画生成に使われている「拡散モデル」という生成手法を文章生成に取り入れたもの。現在主流の大規模言語モデル（LLM）は1トークンずつ生成しては再入力し次のトークンを生成する……ということを繰り返すため、「時間がかかり、かつ出力の品質や一貫性にも制限される可能性がある」とDeepMindは説明している。

　拡散モデルはランダムなノイズを洗練させていくことで最終的な出力結果を得るモデル。トークンを1つずつ予想するわけではなく、かつ生成プロセス中にエラーの修正も可能という。「数学やコードを含む編集タスクで優れた能力を発揮する」（同社）としている。

　性能については、得意不得意はあるもののGemini 2.0 Flash Liteと概ね同等のようだ。
ITmedia AI＋",[],[]
ついに「音声付き動画」の生成が可能に　Google、動画生成AIの最新モデル「Veo 3」発表（ITmedia NEWS）,https://news.yahoo.co.jp/articles/a796e091f9d1a905524e5d1aa75550febea53f6a,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250521-00000074-zdn_n-000-1-view.jpg?exp=10800,2025-05-21T06:13:21+09:00,2025-05-21T06:13:21+09:00,ITmedia NEWS,zdn_n,ITmedia NEWS,850,"（写真：ITmedia AI＋）
米Googleは5月20日（現地時間）、同社の年次カンファレンス「Google I/O 2025」にて、動画生成AI「Veo 3」と画像生成AI「Imagen 4」を発表した。
【画像を見る】Imagen 4で作成した画像の例（1/2）【全3枚】
Veo 3では、新たに音声付き動画の生成が可能になった。街中の交通音や公園の鳥のさえずりなどの効果音の他、キャラクター同士の対話などを生成できる。また、前モデル「Veo 2」よりも動画の品質が向上し、現実世界の物理法則や正確なリップシンクなどをより優れた形で出力できるようになった。

　まずは、月額249.99ドルのサブスクリプションサービス「Google AI Ultra」の米国ユーザーと、 「Vertex AI」のエンタープライズ向けユーザーに提供する。

　またVeo 2にも、動画内のオブジェクトを追加／削除できる機能や、アウトペインティングによる画像拡張機能などを実装。映画生成AIツール「Flow」を通せば「参照画像による動画生成」「カメラコントロール」も利用できるようにする。これらの機能は、今後数週間宙に「Vertex AI API」で提供する予定だ。
Imagen 4は最大2K解像度の画像を生成可能に
Imagen 4は、画像生成のスピードと精度が向上。さまざまなアスペクト比で最大2K解像度の画像を生成できる。また、文字表現やタイポグラフィの生成能力も大幅に上がっており、グリーティングカードやポスター、漫画なども簡単作れるとしている。

　また近日中に、前モデル「Imagen 3」と比べて、最大10倍の処理速度を実現する「Imagen 4の高速版」も公開する予定。

　Imagen 4は、AIアプリ「Gemini」や画像生成AI「Whisk」、Vertex AIなどの他、WorkspaceのGoogleスライドやVids、ドキュメントなどで同日から利用可能だ。
ITmedia AI＋",[],[]
グーグル、AI映画製作ツール「Flow」発表　プロンプトと画像からシーン生成、カットの追加・拡張も自在に（ITmedia NEWS）,https://news.yahoo.co.jp/articles/c162fad5b4e6fd2bd194e26263f2e746e1e37efe,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250521-00000073-zdn_n-000-2-view.jpg?exp=10800,2025-05-21T06:06:10+09:00,2025-05-21T06:50:17+09:00,ITmedia NEWS,zdn_n,ITmedia NEWS,866,"（写真：ITmedia NEWS）
米Googleは5月20日（現地時間）、同社の年次カンファレンス「Google I/O」で、AI映画製作ツール「Flow」を発表した。3つの画像と映像のイメージをプロンプトで入力すると数秒のシーンを生成。これにプロンプトを加えてカットを追加していったり、生成したシーンの長さを拡張したりして、長編動画としてストーリーを表現することができるという。
【画像を見る】グーグルが作った「AI映画製作ツール」を見てみる
最初のシーン生成に使う画像は、手持ちのものだけでなく、その場で作成することが可能。Googleが同日発表した画像生成モデル「Imagen」で生成した画像をイメージとして登録できる。

　デモでは、3mを超える鶏が後部座席にいる車を老人が運転し、崖にダイブしたあと鶏が車ごと持ち上げて空を飛ぶというショート動画を作成。老人、車の写真を追加した後、Imagenでシフトレバーの飾り（鶏の頭をかたどったもの）を生成。この3点の画像から最初のシーンの動画を出力した。

　続きとして、砂漠で60年代のアメ車を運転する老人の後ろに巨大な鶏が座っているというプロンプトから次のカットを生成。しかし最初に出力されたものは崖から落ちてしまうシーンとなっていたため、後半部分を追加プロンプトで拡張し、鶏が車を持ち上げて空を飛ぶシーンに作り変えた。こうした次に来るカットを生成し続けることで、動画生成AIでのストーリーテリングが可能になるとしている。

　Flowは、新しくできた有料プラン「Google AI Ultra」（月額249.99ドル）と、「Google One AI Premium」から名称変更した「Google AI Pro」（29.99ドル）ユーザー向けに提供。Ultraは新しい動画生成AI「Veo 3」への早期アクセスも可能となっている。なお、同日より米国にて提供を開始。他国は「Coming Soon」となっており、現時点で日本からはアクセスできない。
ITmedia NEWS",[],[]
Googleからも非同期コーディングエージェント「Jules」　OpenAI「Codex」対抗か（ITmedia NEWS）,https://news.yahoo.co.jp/articles/b7fedb26e93b84de80f40019d51d169fcd66a814,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250521-00000072-zdn_n-000-1-view.jpg?exp=10800,2025-05-21T06:05:32+09:00,2025-05-21T06:05:32+09:00,ITmedia NEWS,zdn_n,ITmedia NEWS,601,"Googleの非同期コーディングエージェント「Jules」（出典：Google、以下同様）
米Googleは5月20日（現地時間）、非同期コーディングエージェント「Jules」の提供を始めた。ソースコード管理プラットフォーム「GitHub」と接続し、ユーザーの指示に従ってソースコードを編集する。
【画像拡大】コードキャスト機能。対象とするコードに関する最近のアクティビティを要約した音声を作成
クラウド上で仮想マシン環境を起動し、ユーザーの指示に応じてAIがコードを編集。米OpenAIの「Codex」と概ね同様のことが可能だが、Codexは安全面からAIによるネットへのアクセスを遮断しているのに対し、Julesはインターネットアクセスが可能。Googleは「これにより強力なテスト、ビルド、デバッグツールが提供されるが、ネットにアクセスするPCなどと同様のセキュリティ対策を講じて環境を扱うことが重要」と説明している。

　β版の位置付けで、β版の期間中は無料で利用できる。ただし、無制限で利用できるわけではなく、「3つの同時タスク」「1日当たり合計5つのタスク」「1日5回のコードキャスト」を超えてしまうと、リセットされるまで新しいタスクの作成ができなくなる。

　コードキャストは音声サマリ機能。対象とするコードに関する最近のアクティビティを要約した音声を作成できる。
ITmedia AI＋",[],[]
Googleが軽量AIモデル「Gemma 3n」を発表　スマホ上で高性能マルチモーダルAI　Claude 3.7 Sonnetに肉薄（ITmedia NEWS）,https://news.yahoo.co.jp/articles/6331c274bd24ac4edc62f5efed7d9e7576579c77,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250521-00000071-zdn_n-000-1-view.jpg?exp=10800,2025-05-21T05:40:19+09:00,2025-05-21T05:40:19+09:00,ITmedia NEWS,zdn_n,ITmedia NEWS,1011,"（写真：ITmedia AI＋）
米Googleは5月20日、モバイルデバイス向けの新しいAIモデル「Gemma 3n」を発表した。スマートフォンやタブレットなどのモバイルデバイス上で直接動作する高性能なマルチモーダルAIで、テキスト、画像、音声、動画を理解・処理できる能力を備える。
【画像】ベンチマーク結果。Claude 3.7 Sonnetに近いレーティングスコアを獲得
同社のオープンなAIモデル「Gemma 3」シリーズの中でも、モバイルデバイス上での効率的な実行に特化して設計されている。Google DeepMindが開発した「Per-Layer Embeddings」と呼ばれる技術により、実際のパラメータ数は5Bと8B（50億、80億パラメータ）でありながら、メモリ上への展開が必要なパラメータ数は2Bと4B（データサイズとしては2GBから3GB）と比較的小さなフットプリントで動作する。

　Gemma 3nはモバイルデバイス上で従来のGemma 3 4Bと比較して約1.5倍速く応答を開始し、品質も大幅に向上しているという。また、「mix'n'match」と呼ばれる機能により、4Bモデルから特定のユースケースに最適なサブモデルを動的に作成し、品質とレイテンシーのトレードオフを調整することも可能だ。4Bのモデルは米Anthropicの「Claude 3.7 Sonnet」に肉薄するベンチマークスコアを獲得し、「GPT-4.1-nano」「Llama-4-Maverick」「Phi 4」を上回ったという。

　特筆すべき点として、Gemma 3nはオーディオ処理能力を備えており、高品質な自動音声認識や翻訳が可能になっている。また、日本語を含む多言語対応も強化したとしている。

　Gemma 3nの開発は、米Qualcomm、台湾MediaTek、韓国Samsung System LSIなどのモバイルハードウェアリーダーと緊密に協力して行われた。同じアーキテクチャは今年後半に提供される次世代のGemini Nanoにも採用される予定という。

　開発者は本日から早期プレビューとしてGemma 3nを利用できる。ブラウザ上で直接試せる「Google AI Studio」と、ローカル環境での開発に対応した「Google AI Edge」の2つの方法が提供されている。
ITmedia AI＋",[],[]
「Gemini 2.5 Pro」のさらに高度な思考モード「Deep Think」　性能は「o3」「o4-mini」超え（ITmedia NEWS）,https://news.yahoo.co.jp/articles/89da6151c6d6ebd608dd8a78dec8784706f843ee,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250521-00000070-zdn_n-000-1-view.jpg?exp=10800,2025-05-21T05:19:07+09:00,2025-05-21T05:19:07+09:00,ITmedia NEWS,zdn_n,ITmedia NEWS,449,"（写真：ITmedia AI＋）
米Googleは5月20日（現地時間）、AIモデル「Gemini 2.5 Pro」向けの新機能「Deep Think」を発表した。Geminiの高度な思考モードで、非常に複雑な数学やコーディングに対応できるように設計したもの。その性能は、各ベンチマークで米OpenAIのAIモデル「o3」と「o4-mini」を上回っている。
【画像を見る】各ベンチマークでのDeep Thinkの性能評価【全1枚】
Deep Thinkでは、応答する前に複数の仮説を検討できるようになる。これにより数学やコーディング、マルチモーダルの3つの分野で、従来のGemini 2.5 Proを含むトップモデルを上回るベンチマークスコアを記録したとしている。

　このような最先端の技術であることから他の機能よりも時間をかけて安全性評価を実施しており、現在は専門家に意見を求めている段階という。今後は一般提供の前にGemini APIを通じてテスターに提供していく。
ITmedia AI＋",[],[]
Googleが“月額249.99ドル”の高額サブスク発表　「Gemini」「NotebookLM」など使い放題　まずは米国のみで（ITmedia NEWS）,https://news.yahoo.co.jp/articles/4bebbd23100e437387c82a24cdcdf437fc196e42,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250521-00000069-zdn_n-000-1-view.jpg?exp=10800,2025-05-21T05:08:32+09:00,2025-05-21T05:08:32+09:00,ITmedia NEWS,zdn_n,ITmedia NEWS,910,"Googleが“月額249.99ドル”の高額サブスク「Google AI Ultra」発表
米Googleは5月20日（現地時間）、AIツールのサブスクリプションサービス「Google AI Ultra」を発表した。チャットAI「Gemini」やAIメモツール「NotebookLM」、映画作成AIツール「Flow」などAIツールが使い放題になる月額プラン。まずは月額249.99ドルで米国から提供し、近日中に他の国でも利用可能にする予定だ。
【画像を見る】Google AI Ultraで利用できるサービス一覧【全1枚】
Google AI Ultraで利用できるサービスは以下の通り。

・Gemini（Deep Researchを最大制限まで利用可能、Veo 2による動画生成機能、次世代モデル「Veo 3」への早期アクセス権。数週間以内には、新たな推論機能「Deep Think 2.5 Pro」にもアクセス可能になる）
・Flow（直感的な操作で、映画のようなシーンを作成できるAIツール）
・Whisk（文章と画像を入力で使える画像生成AI）
・NotebookLM（2025年後半には最大制限まで使用できる権限と、強化したAIモデル機能にアクセス可能になる予定）
・Gmail、ドキュメント、VidsなどのGemini機能
・ChromeでのGemini機能（21日から早期アクセスが可能）
・Project Mariner（Chromeブラウザ向けのAIエージェント）
・YouTube Premium
・30TBのストレージ

　既存の有料プランは「Google One AI Premium」から「Google AI Pro」に名称を変更し、一部サービスを追加した。追加料金なしでFlow（Veo 2モデルを利用可能）が利用可能になる他、ChromeでGeminiへの早期アクセスもできる。こちらはまず、米国の加入者向けに提供した後、他の国でも利用可能になる。

　また学生向けのGoogle AI Proへの1年間無料アクセス権について、新たに日本の学生にも対象を拡大する。
ITmedia AI＋",[],[]
Google検索に「AIモード」　質問を解釈してAIが回答、高度なレポートも作成　「エージェント機能」でチケット予約も（ITmedia NEWS）,https://news.yahoo.co.jp/articles/f833aa69f7c56726bf5fb215f0c71210359b4a11,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250521-00000068-zdn_n-000-1-view.jpg?exp=10800,2025-05-21T04:43:47+09:00,2025-05-21T04:43:47+09:00,ITmedia NEWS,zdn_n,ITmedia NEWS,797,"Google検索に「AIモード」登場
米Googleは5月20日（現地時間）、Google検索に「AIモード」を追加すると発表した。同社のAIモデル「Gemini 2.5」を活用。AI機能とWeb検索を組み合わせ、ユーザーの質問に対し、より高度な回答ができる。同日から米国で一般ユーザーに展開。同社の新機能の先行体験ユーザー向けに、今後数週間から数カ月以内に提供予定。
【画像を見る】「Deep Search」のイメージ【全6枚】
AIモードでは、ユーザーの質問を複数の関連トピックに分解し、各トピックを並列で検索する仕組みを採用した。これにより、従来のGoogle検索に比べ、Web上の情報をより深く掘り下げ、ユーザーの質問に的確に回答できるという。

　より詳細な回答が必要な場合は「Deep Search」も使える。Deep Searchでは、数百件の検索を実行し、取得した情報を分析。「わずか数分で専門家レベルの引用文献付きレポートを作成できる」とアピールしている。

　質問だけでなく、「レッズ戦の手頃なチケットを探して」といったユーザーの要求に対応する「エージェント機能」も提供する。ユーザーが探したい情報を調べ、適切な条件の予約や購入へのリンクを提示する。イベントのチケットやレストランの予約などで使えるとしている。

　他にも、ユーザーに最適な商品を見つけるサポートをするショッピング機能や、検索したデータをグラフ形式でビジュアル化する機能などを提供する。

　Gmailをはじめとした他のGoogleアプリと連携し、よりパーソナライズした検索もできる。質問や要求に対し、ユーザーの過去の検索履歴や、他のGoogleアプリのテキスト情報なども加味して回答する。

　AIモードでこれらの個人情報を活用するか否かは、ユーザー側で確認・管理できるとしている。
ITmedia AI＋",[],[]
「NotebookLM」に動画生成機能　実装時期は「かなり近いうちに」　まずは英語のみ対応（ITmedia NEWS）,https://news.yahoo.co.jp/articles/9a569b3c1f5e4b6146b729bf4af4a714e1b1232d,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250521-00000067-zdn_n-000-1-view.jpg?exp=10800,2025-05-21T03:47:14+09:00,2025-05-21T03:47:14+09:00,ITmedia NEWS,zdn_n,ITmedia NEWS,217,"（写真：ITmedia AI＋）
米Googleは5月20日（現地時間）、AIメモツール「NotebookLM」に動画生成機能を実装すると発表した。初めは英語のみ対応、かつ文章からの動画生成に対応する。その後、PDFや写真などもソースに追加できるようにする。
【画像を見る】「NotebookLM」に動画生成機能実装へ【全1枚】
動画生成機能の具体的な実装時期は明かしておらず「VERY SOON」としている。
ITmedia AI＋",[],[]
