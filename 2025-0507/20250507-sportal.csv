headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
「柔軟な心を育てる教育」「考え続けること」の大切さ共有 ハラリ氏囲み東大で公開イベント（Science Portal）,https://news.yahoo.co.jp/articles/f1c24efddcc3372bd1ababbfad6c3cc2333dbfe7,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250507-00010000-sportal-000-1-view.jpg?exp=10800,2025-05-07T15:18:58+09:00,2025-05-07T15:18:58+09:00,Science Portal,sportal,Science Portal,4551,"「デジタル時代の教育と科学の役割」案内図の一部（東京大学国際高等研究所東京カレッジ提供）
世界各国で出版された「サピエンス全史」などの著者でイスラエルの歴史学者・哲学者、ユヴァル・ノア・ハラリ氏が来日した。その言動が注目されている同氏を囲んだ公開イベント「デジタル時代の教育と科学の役割」が3月17日に東京大学安田講堂（東京都文京区）で開かれた。 議論や意見交換を通じてハラリ氏は「加速化する時代の変化に対応できる『柔軟な心』を育てる教育の重要性」を強調した。

　ハラリ氏は斬新な視点で人類史を考察し、「世界経済フォーラム年次総会（ダボス会議）」などの国際会議や各国での講演の場を通じ、人工知能（AI）に代表される先端テクノロジーの進歩が人間社会に与える影響について積極的に発言している。この中で、過去の技術が人間の手にあった道具であったのに対し、AIは自ら決定する能力を持ち得るため、人間の対応力が問われるなどと問題提起してきた。
ユヴァル・ノア・ハラリ氏
東大安田講堂で行われた公開イベントは東京大学国際高等研究所東京カレッジ、ドイツ日本研究所、河出書房新社が共催した。科学と社会の関係に詳しい林香里・東京大学理事・副学長・教授と江間有沙・東京大学東京カレッジ准教授も参加。江間氏はどんなにAIが進歩しても「世界の問題を考え続けること」の大切さを指摘した。AIの進歩は予測不可能だが、利便性とリスクをしっかり認識しながら開発と規制のバランスを取ること、そして人間しか持たない感情や共感力、創造性の可能性に期待する視点が印象的だった。
約1時間半にわたる、ハラリ氏を中心とした貴重なやり取りの中からテーマに即したポイント部分をレポートする。
生成AIの能力を評価しつつリスクを警鐘
公開イベントのやり取りやハラリ氏の発言の真意を理解するために同氏のプロフィールを改めて紹介する。
ハラリ氏は1976年、イスラエル北部のキリヤトアタ生まれの49歳だ。同国のヘブライ大学、英国のオックスフォード大学で中世史、軍事史を学び、2002年に博士号取得。現在、ヘブライ大学教授、英ケンブリッジ大学特別研究員を務めている。

　「サピエンス全史」は世界60カ国以上で出版されたとされる。このほか「ホモ・デウス」などの著書の累計は全世界で4500万部を超え、邦訳も多い。近著に情報ネットワークの歴史と今直面する危機の関係に焦点を当てた「NEXUS 情報の人類史」（河出書房新社）がある。
2018年のダボス会議では基調講演を行い、AIやバイオテクノロジーの発展により人間の身体や心、社会構造にどのような影響を与えるかの課題をいち早く指摘。20年のダボス会議でも講演し、AIにより個人データが収集、解析される危険性を強調している。
ダボス会議での発言は出席した各国の指導者に大きなインパクトを与えた。報道内容や公開された講演内容から判断される2回の会議での共通した問題意識のポイントは、テクノロジーの進歩が人間の自由や社会構造に与える影響と、個人・プライバシー保護の重要性、さらに地球規模の課題に対処するための国際協力・連携の重要性だ。
ユヴァル・ノア・ハラリ氏
最近では、ここ数年世界的に普及している生成AIの利便性と課題についての言及も注目されている。AIの発展を否定せず、その潜在能力を評価しつつ無規制、無制限に使用するリスクへの警鐘だ。こうした危機感がこの日の公開イベントでの発言の背景にある。
AIアルゴリズムが人間に代わる時代に
「情報ネットワーク」の歴史と今直面する危機の関係に焦点を当てた「NEXUS 情報の人類史」（上・下）の表紙（河出書房新社提供）
公開イベント「デジタル時代の教育と科学の役割」はドイツ日本研究所所長のフランツ・ヴァルデンベルガー氏がモデレーターを務めた。近著「NEXUS 情報の人類史」を引き合いに「この本の中で情報は『ストーリー（物語）』を作るために使われていると書いているが」とその意味をハラリ氏にたずねた。

　ハラリ氏は「ストーリーを語れる人は力がある。今やそうした力を持てるのは人間だけでなく、AIも新しいストーリーを開発できる存在だ」と述べた。ストーリーを使って情報を伝えたり、印象付けたりする手法「ストーリーテリング」が注目されており、最近ビジネスやマーケティングなど広い分野で活用されているこの手法を念頭に置いた発言とみられる。
東京大学副学長を務めながら社会情報学担当の教授で、同大学Beyond AI研究推進機構「AIと社会」創設ディレクターも務める林氏は、メディアのデジタル化が進んで誰もが発信でき、ジャーナリストになれる現象を指摘した。そして「誰でも社会のどこにいても自分自身のストーリーを作り出している」とAI時代、SNS時代の新たなメディアやジャーナリズムをめぐる課題を指摘し、「事実確認（ファクトチェック）は今のジャーナリストの世界では難しいが、デジタル化が進んでいる時代ではしなければならない」と述べた。
「これまで人間が担ってきた編集の仕事を（AI）アルゴリズムが行うようになった。フェイスブックも旧ツイッター（X）もアルゴリズムが編集の仕事を人間から奪っている。AIが単に人間の書いた記事を編集するだけでなく自分でストーリーをつくる時代が来ている」。ハラリ氏はこう強調している。
求められる「AIガバナンス」
東京大学東京カレッジの江間氏は科学技術社会論が専門で、AIやロボットを含む情報技術と社会の関係について研究し、特にAIガバナンスの問題に詳しい。
江間氏は「AIアルゴリズムは我々の世界や認知的考え、ソーシャルメディアといったものに影響を及ぼしている。ただ、ファクトチェックとかAIガバナンスとか（人間による）メカニズムが良い方で機能するならば悲惨な、カオスのような状況にはならないのではないか」と述べ、AIによる製品やサービスに対して人間が責任を持つことの重要性を強調した。
ハラリ氏は「AIは行為主体として大きなパワーを持っていて、今や金融の世界でも軍事の世界でも行為の主体になっている」としながらも、「究極的な責任はやはり人間にある」と江間氏と認識を共有していた。そして、AIアルゴリズムのガバナンスはSNSを運営する事業者が担うことから「事業者の責任」を指摘。「AIが関係していることが開示されなければならない」と語り、必要に応じて法律による規制も必要との考え方を示している。
討論、議論はAIと教育の問題に移った。「社会のデジタルトランスフォーメーション（DX）化が進んで教育が果たすべき役割は何か」はこの日の公開イベントの重要テーマだ。
左からヴァルデンベルガー、ハラリ、林、江間の各氏
「世界は10年後どのようになるか分からない。このため我々教育者の責任はより大きくなっている」「人間は生きている間はずっと（時代、社会の）変化を学習し続ける。今、最も重要なのは教育が、加速化する（時代の）変化に若者が対応できる『柔軟な心』を育てることができるかどうかだ」。イスラエルのヘブライ大学の教壇にも立つハラリ氏のこの指摘は重い。
AIが進歩するだけに「批判的思考」が重要
そしてハラリ氏は、AIが持つことができない、人間特有のものが感情であり、意識だという。大学の教育でも「身体と感情を（上手に）つなげなくてはならない」と言う。「身体」が何を指すのか抽象的だが、DX化の中で生じるさまざまな感情を自分（身体）がうまくバランスを取る大切さを説いた発言とみられる。
江間有沙氏
今の時代の教育の役割について江間氏はこう述べている。「世界に対し、社会に対して好奇心を追求し、継続して考え続けることがよいことであると教えることが教育の役割だと思う。生成AIに質問すると良い答えもあるが間違った情報も含め何らかの答えが戻ってくる。このため自分で考えることをやめてしまうリスクがある。私たちは社会的、政治的、環境的な問題、世界に関する問題について考え続けなければならない。継続して考え続けることがクリティカルシンキング（批判的思考）につながるかもしれない」。
生成AIは教育の現場でも普及している。AIによる社会の利便性が注目されるだけに批判的思考がますます重要になってくるのだという。
林香里氏
東京大学の副学長でもある林氏はAI時代に対応するために学内で進めている学際的取り組みの具体例を紹介した。続いてモデレーターのヴァルデンベルガー氏が、「大学は（基本的に）マス教育、大衆教育だがAIを使うことによって教育をパーソナライズ（個別化）できるのではないか。そうすると危険もあるのではないか」と述べ、ハラリ氏に教育の個人化について考えをたずねた。
ハラリ氏は「教育の個別化はAIのポジティブな可能性の一つだ」としつつ、AIと「親密な関係」をつくってしまうと人間同士の双方向の親密性が阻害される恐れがあるとの見方を示した。
自分を見失わないように「情報ダイエット」が必要
公開イベントの終盤で議論のポイントは「AI規制に関して日本が果たせる役割」に移った。
進行役のヴァルデンベルガー氏（一番左）の問いかけを聞くハラリ、林、江間の各氏
江間氏は2023年5月に広島で開かれた先進7カ国首脳会議（G7広島サミット）で決まったAI規制の国際枠組み策定のための「広島AIプロセス」を紹介。「日本は米国のようなAI技術は持っていないが、開発競争が激化する中で米国、欧州、中国とも異なる日本は仲介者になれるのではないか」と述べた。また開発と規制は車の両輪で両者のバランスの重要性も指摘した。
ユヴァル・ノア・ハラリ氏
ハラリ氏は「AIが人間のコントロールを外れてしまわないように全ての国が協力すべきだ」と国際協調の重要性を訴えた。林氏は「日本社会はお互いの信頼があり、安心感がある、安定していると感じられる社会だ。相手を思いやる、共感するという視点から日本は（AIの開発と規制について）何か貢献できるのではないか」と語っていた。
公開イベント会場になった東京大学安田講堂
公開イベントの最後に会場からの質疑が行われた。「友人が陰謀論を信じ始めている。どうしたらいいか」との質問に対するハラリ氏の回答は「多くの人が陰謀論に陥るのは彼らが社会に対する信頼を失い、阻害されていると感じ孤独感を持っているからで、まずは彼らと事実に基づいて議論することで、鍵は互いに共感を持つことだ」。
また高校生の「SNSの投稿で『いいね』を期待するあまり自分の個性が失われつつあると感じる」との問いに対しては「ジャンクフードばかり食べていると健康を害するようにジャンク情報しか入らないと不健康な精神状態になる。（ネット上にあふれる）情報のダイエットをする必要がある」とアドバイスしていた。
ハラリ氏を中心とした4人の議論、討論は「AI技術の進歩に対して人間ができること、人間がすべきこと」を考える上で示唆に富んでいた。
内城喜貴／科学ジャーナリスト、共同通信客員論説委員",[],[]
