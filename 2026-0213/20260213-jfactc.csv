headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
高市首相を熱狂的に応援する高齢者、踊りだす中道... 急増したAIによる偽画像/動画【#衆院選ファクトチェック 解説】（日本ファクトチェックセンター）,https://news.yahoo.co.jp/articles/b6c388d103ca562e4015119a42932f99e200ef39,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20260213-00010000-jfactc-000-1-view.jpg?exp=10800,2026-02-13T11:57:03+09:00,2026-02-13T11:57:03+09:00,日本ファクトチェックセンター,jfactc,日本ファクトチェックセンター,4412,"高市首相を熱狂的に応援する高齢者、踊りだす中道... 急増したAIによる偽画像/動画
2026年の衆院選で、明らかに増えたものがあります。生成AIによる画像や動画の捏造や改変です。「ディープフェイク」と呼ばれる手法が、いよいよ日本でも普及してきました。実際にどのようなAI製フェイクが拡散していたのでしょうか。
衆院選ディープフェイク検証記事は16本で急増
日本ファクトチェックセンター（JFC）が収集した衆院選に関するファクトチェック記事96本中、ディープフェイクもしくはそう疑われる画像や動画に関する検証記事は16本ありました。1本の記事で複数のディープフェイクについて解説した記事もあります。

2025年参院選ではディープフェイクを検証する記事は、ほとんどありませんでした。FIJが収集した236件の記事の中で見出しにAIがあるのは1本だけです（FIJ”参院選2025ファクトチェック”）。

2025年参院選でのディープフェイク検証の例：
JFC”トランプ大統領が岸田文雄氏について「グローバリストの操り人形」と発言? 繰り返し拡散するAI動画”
https://www.factcheckcenter.jp/fact-check/politics/false-trump-globalist-puppet-kishida/
急増の背景に生成AIの進化
世界的に見ると大型選挙が集中した2024年がディープフェイク大拡散の年になると懸念されていました。

ところが、台湾総統選、インド総選挙、欧州議会選、アメリカ大統領選、そして、日本の衆院選を調べても、予想されたほどには生成AIによる偽・誤情報の拡散は見られませんでした。

コロンビア大Knight First Amendment Instituteは「We Looked at 78 Election Deepfakes. Political Misinformation Is Not an AI Problem.（78の選挙関連ディープフェイクを検証 政治的誤情報はAIの問題ではない）」というレポートで状況を端的に示しました。

欧州でも、選挙結果に大きく影響を与えるようなディープフェイクの拡散は見られませんでした(TASK FORCE ON THE 2024 EUROPEAN PARLIAMENT ELECTIONS. “FINAL REPORT Outputs and outcomes of a community-wide effort”)。

インドでは、ファクトチェック12団体の共同プロジェクト「Deepfakes Analysis Unit（DAU、ディープフェイク分析班）」が検証にあたりましたが、JFCの問い合わせに「全体としてはAIを使わない『チープフェイク』が多かった」と述べました。

生成AIは当時すでに普及していましたが、現在ほどの描画力はなく、投稿しても簡単に偽情報と見極められるものが多く、拡散力は大きくありませんでした。

状況が変化してきたのは2025年です。生成AIが進化し、人間の目では判別が難しいディープフェイクが増えてきました。
クマや地震のディープフェイクで一般化
クマに関するディープフェイク動画
日本でまずディープフェイクの拡散が始まったのは「クマ」に関するものでした。

2025年夏以降、クマに人が襲われるというニュースが盛んに報じられるとともに、TikTokなどで、クマに関するディープフェイク動画が拡散するようになりました。

JFC”TikTokで拡散するAI生成によるクマ被害の偽動画に注意”
https://www.factcheckcenter.jp/fact-check/environment/bear-attack-ai-generated-videos/

さらに12月には青森県八戸市で震度6強を観測した地震で、様々なディープフェイク動画が拡散しました。

注目を集めるニュースが発生するとディープフェイクが拡散する、という流れは、この段階で一般化していました。

JFC”地震発生後に大量の生成AI動画、「ディープフェイク」は一般化 透かしや細部の確認など見分け方のコツも解説”
https://www.factcheckcenter.jp/fact-check/ai/false-aomori-quake-deepfake-videos/
衆院選で拡散したディープフェイクは政党・候補者が標的
AIで改変された中道の鎌田さゆり氏の画像
衆院選で検証された16本のディープフェイクには共通する特徴があります。それは政党・候補者を話題にしているというところです。

政党・候補者を話題にしたディープフェイクの例：
JFC”中道改革連合のロゴが中国の中革連にそっくり? 新党発表後に作られた偽ロゴ”
https://www.factcheckcenter.jp/fact-check/politics/fc-logo-similar-to-a-chinese-organisation/
JFC”中道・鎌田さゆり氏が中指を立てる画像? AI生成による改変”
https://www.factcheckcenter.jp/fact-check/politics/sayuri-kamata-middle-finger-ai-fake/
読売新聞”衆議院選挙:政見放送をAIで改ざん、中道の野田・斉藤両共同代表が踊り出すニセ動画が拡散…専門家「選挙ゆがみかねない」”


生成AIの発達によって、画像や動画の一部だけを改変したり、顔を政治家にすげ替えたりすることが容易になったことで、ディープフェイクで政党や候補者を貶めるような行為が広がりました。
ディープフェイクが広がることによる「嘘つきの分け前」
ディープフェイクの普及による悪影響は、たんに偽・誤情報が広がるということだけにとどまりません。情報生態系全体の信頼性が落ちてしまうという、より大きな問題があります。

JFCなどが生成AIで作られた画像や動画の検証を進めるとともに「この画像もAIなのではないか」という疑心暗鬼が広がりました。JFCではそのような事例も検証しました。

JFC”中道改革連合の街頭演説会に集まった聴衆の動画はAI生成? Grokによる不確かな判定”
https://www.factcheckcenter.jp/fact-check/politics/centrist-reform-coalition-crowd-ai-claim/

中道改革連合が投稿した街頭演説会の動画が「映像が不自然でAIではないか」という投稿が拡散しました。しかし、JFCで検証したところ、同じ場面を別の角度から撮影した動画が複数見つかり、その比較などから動画は実際の映像でAI生成ではないと判定しました。

実際は本物の映像なのに「偽物ではないか」という指摘が広がる現象のことを「嘘つきの分け前（Liar’s dividend)」と言います。

大量の偽・誤情報が広がることで、本物の情報まで「間違っているのではないか」と人々が疑心暗鬼になる。そうすると、得をするのは偽・誤情報をばら撒いている嘘つきです。

嘘が真実の中に紛れ、人々は何を信用すれば良いかわからなくなり、ファクトチェッカーも検証の的を絞りづらくなるからです。
AIの間違いが偽・誤情報をさらに拡散させる
中道の街頭演説をAIが「AI生成動画のようです」と誤判定
中道の街頭演説が「AIではないか」という情報が広がったきっかけは、AIの誤判定でした。

画像の不自然さからAIではないかと疑ったXユーザーが、XのAI「Grok」に「これはAI生成動画ですか」と聞いたところ、「AI生成動画のようです」と回答しました。

生成AIは非常に便利なツールで、JFCでも検証作業に活用しています。下調べのリサーチの補助や、ディープフェイク判定の補助に使っています。

しかし、AIの判定をそのまま記事に活用することはありません。最終確認はすべて人間がしています。AIは間違えることがあるからです。
高市首相を称賛するディープフェイクも
AIで生成された高市首相支持を訴える女性の動画
ディープフェイクは政党や政治家を貶めるだけでなく、称賛する方向でも使えます。例えば、JFCが検証した動画の中には「高市首相を熱烈に応援する高齢者」というものがありました。


JFC”高市首相支持を訴える女性達の動画? AIで生成”
https://www.factcheckcenter.jp/fact-check/politics/ai-generated-videos-of-enthusiastic-takaichi-supporters/

この動画を作っていたのは、もともとYouTubeで生成AI動画を公開するチャンネルでした。ところが、拡散したのはYouTube動画ではなく、その動画をAI生成であると書かずにXに投稿したものでした。

生成AIで作ったという文脈を切り離して拡散された動画は、より本物と誤認されやすくなります。投票に影響を与える恐れも出てきます。
広がる生成AIに対する対策は
JFCではディープフェイクの拡散に対して、ファクトチェックをするだけでなく、誰でも実践可能な見分け方について解説をしています。

JFC”ファクトチェッカーが実践している生成AIによるディープフェイクの見分け方”
https://www.factcheckcenter.jp/explainer/others/howto-deepfake-verification/

AI技術は進歩していますが、それでも多くのディープフェイクはいくつかのポイントを押さえれば、簡単に見分けられるものがまだまだ多いです。

例えば、ロゴやラベルの存在、細部の描写の破綻などです。発信源や関連情報を調べることで、矛盾に気づけることもあります。ただ、さらに技術が進化し、量が増えてくれば、個人で対応することは不可能です。

選挙に関わるディープフェイクが急増した韓国では選挙日の90日前から投票日までのディープフェイクを使った選挙運動を禁じました(時事通信“韓国大統領選でディープフェイク激増　削除要請1万件弱、処罰に困難も”、TBS”総選挙前にディープフェイク対策進める韓国　改正公職選挙法で処罰対象に、警察は“ディープフェイク発見ソフト”開発も”)。

ディープフェイクを含む偽・誤情報の対策に関する議論は、世界で広がっています。
古田大輔(Daisuke Furuta)",[],[]
