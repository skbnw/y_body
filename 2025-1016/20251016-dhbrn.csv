headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
AIに相談すると人は楽観的になり、予測精度を下げる（DIAMOND ハーバード・ビジネス・レビュー）,https://news.yahoo.co.jp/articles/2072f159c0100b4c1ec6e400ce25fd5321d919c0,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20251016-00012401-dhbrn-000-1-view.jpg?exp=10800,2025-10-16T12:00:41+09:00,2025-10-16T12:00:41+09:00,DIAMOND ハーバード・ビジネス・レビュー,dhbrn,DIAMOND ハーバード・ビジネス・レビュー,6412,"Ryan McVay/Muhla1/Getty Images
■AIを意思決定の場面で活用できるか

　多くの組織が、職場へのAIツールの統合を優先課題としている。それにはもっともな理由がある。初期の研究により、AIツールが単純作業や反復作業における業務のパフォーマンスを高め、リーダーのコミュニケーション能力を向上させ、組織の顧客基盤の拡大を支援できることが示されているからである。

　では、意思決定という、より重大な場面のパートナーとして、AIはどのように機能するのだろうか。

　この点を検証するために、筆者らは簡単な実験を行った。まず、300人以上のマネジャーと経営幹部に対して、過去のトレンドを確認したうえで株価を予測するよう依頼した。次に、参加者の半数には同僚と意見交換をする機会を、残りの半数にはチャットGPTに相談する機会を与えた。相談後、参加者は当初の予測を修正できることとした。

　すると、驚くべき結果が出た。チャットGPTに相談した経営幹部は、予測において著しく楽観的になる傾向が見られた。一方で、同僚と議論した場合には、慎重な姿勢が促される傾向があった。さらに、実際の株価に基づいて見ると、チャットGPTを利用した経営幹部は、同ツールに相談する前よりも精度の低い予測をしていたことがわかった。

　本稿では、筆者らが行った実験の内容とそこでの発見、その理由、そして、意思決定プロセスにAIを導入したいすべてのリーダーにとって、この知見が重要な理由を説明する。

■実験の内容

　この研究は、2024年6月から2025年3月にかけて行われたAI関連のエグゼクティブ教育セッションの中で実施された。参加者はさまざまな企業のマネジャーと経営幹部で、クラス内での演習に参加した。

　筆者らはまず、AI技術を支える役割によって急速に業績を伸ばしている大手半導体メーカー、エヌビディア（NVDA）の最近の株価チャートを全員に提示した。同社の株価は顕著な上昇を続けており、予測能力を試す現実的なケーススタディとして適していた（また、経営幹部たちの関心も非常に高かった）。

　次に、参加者に対して、1カ月後のエヌビディアの株価を各自で予測するよう依頼し、その数値を非公開で提出してもらった。次に、参加者をランダムに以下の2つのグループに分け、短時間の相談セッションを設けた。

・同僚と議論するグループ（対照群）:このグループの参加者は、少人数のチームに分かれ、数分間、それぞれの予想について意見を交換した。AIツールは一切使用せず、人間同士の会話のみで、各自の考えや手持ちの情報を共有した。これは、同僚の意見を聞くという従来型の意思決定アプローチを模したものである。

・チャットGPTに相談するグループ（処置群）:このグループの参加者はエヌビディアの株価に関して、チャットGPTに何を依頼してもよいとされた（最近の傾向を分析させる、1カ月後の予測を尋ねるなど）。ただし、同僚と話すことは禁じられていた。これは、経営幹部が同僚の代わりにAIアドバイザーに相談するという、AI支援型の意思決定プロセスを模擬したものである。

　この相談セッションを経て、全員があらためて1カ月後のエヌビディアの株価を予測し、その回答を収集した。

■結果

■AIはより楽観的な予測をもたらした

　最初の予測では、両グループの間に統計的に有意な差はなかった。すなわち、同僚と議論する前、またはAIに相談する前の段階では、両グループの幹部によるエヌビディアの株価予測は統計的に区別できなかった。

　しかし、相談セッションの後、チャットGPTを利用したグループは予測がより楽観的になっており、1カ月後の株価予測を平均で約5.11ドル上方修正していた。

■同僚との議論は、予測をより慎重にさせた

　対照的に、同僚と議論したグループは、株価予測を平均で約2.20ドル下方修正していた。また、このグループは、チャットGPTのグループよりも当初の予測を維持する傾向が強かった。変更を加えた場合でも、初期予測を下方修正する傾向があった。

　極端すぎる予測（株価予測が高すぎる、または低すぎるもの）を制御した後でも、同じパターンが一貫してみられた。

■AIとの相談は予測の精度を低下させた

　実験の実施から1カ月後、筆者らは参加者の株価予測と、実際のエヌビディアの株価データを比較した。その結果、両グループとも平均的に楽観的すぎる予測をしていたことが明らかになった。

　しかし、チャットGPTを利用したグループは、相談後に予測の精度がさらに悪化していた。一方、同僚と議論したグループは、相談後の予測のほうが、相談前よりも有意に精度が高かった。

■AIは過信を引き起こした

　全参加者のうち、およそ3分の1は、初回の予測において「ピンポイント予測」を提示していた（つまり、小数点以下を含む、1桁以上の小数を伴う数値を提示していた）。先行研究によれば、これは過信の指標とされている。

　筆者らが驚いたのは、同僚またはチャットGPTと相談した後に、予測の精度に対する過信の度合いに体系的な変化が見られた点である。チャットGPTと対話した参加者は、相談後にピンポイント予測を提示する傾向が有意に高まった。一方、同僚と議論したグループでは、修正後の予測においてピンポイント予測を提示する割合が有意に減少した。つまり、過信の度合いが弱まったのである。

■なぜAIは過信と楽観を生んだのか

　このように大きく異なる結果が出たのは、なぜだろうか。なぜAIツールに相談すると過大な予測と過信につながり、同僚との議論では、より謙虚で保守的になるのか。筆者らは、その理由を5つに特定した。

■1. 外挿バイアスとトレンド追随

　チャットGPTは「外挿バイアス」を助長した可能性がある。AIの知識は過去のデータに基づいているため、エヌビディアの最近の上昇トレンドをそのまま将来に延長しただけだった可能性がある。

　実際、この実験を行う直前の数カ月間、エヌビディアの株価は急激に上昇していた。最新の状況や転換点が近づいているという判断材料を持たないため、チャットGPTの分析は、「これまで上昇してきたのだから、今後も上がり続けるだろう」と想定していた可能性が高い。過去のデータパターンのみに基づくという特性上、AIのアドバイスは初めから楽観的な方向に偏りやすかった。

■2. 権威バイアスと情報過多

　チャットGPTに相談した幹部の多くは、AIによる詳細な回答と自信に満ちた表現に感銘を受けたと報告している。実験後のディスカッションでは、チャットGPTが徹底的かつ説得力のある大量のデータと理論的根拠を示していたため、それに比べると自分の当初の予測が不十分に感じられたとの声が寄せられた。

　チャットGPTに相談した幹部の多くは、AIによる詳細な回答と自信に満ちた表現に感銘を受けたと報告している。実験後のディスカッションでは、チャットGPTが徹底的かつ説得力のある大量のデータと理論的根拠を示していたため、それに比べると自分の当初の予測が不十分に感じられたとの声が寄せられた。

　これはAIに対する「権威バイアス」の一例である。自信に満ちた分析的な語り口で話すAIに触れることで、ユーザーはその提案を重視し、自身の判断よりも高く評価しがちになる。つまり、高度なAIが専門家の報告書のように聞こえることによって、「媒体の権威性」が楽観的な予測の信頼度を高めてしまったのである。

■3. 感情（または感情の欠如）

　人間には感情や直感があり、それが極端な予測の歯止めとなる場合がある。華々しい株価チャートを見た経営幹部は、「いまが株価のピークだとしたら、この後、暴落するかもしれない」と考え、一抹の警戒心を抱くかもしれない。

　今回の実験では、同僚との議論において、そうした感情面の慎重さが発揮されたと推察される。「この株はバブルっぽいから、少し控えめに考えるほうがよさそうだ」といった疑問や不安を口にする場面があった可能性がある。

　これに対し、チャットGPTにはそのような感情や直感は存在しない。人間が株価チャートの急騰を見た時に感じる「高所恐怖」のような感覚を持ち合わせていないのである。

　AIは不安に影響されない分析を提供できるが、それは同時に、楽観的なトレンドを見ても疑問を持たないということでもある。AIの出力だけに依存してしまうと、慎重になるべきだという人間の直感的判断を活かすことができない。今回の実験では、AI側に「間違うことへの恐怖感」が存在しないことが、大胆な予測が抑制されずに出された一因となった可能性がある。

■4. 仲間との調整と社会的力学

　同僚との議論は、AIとは異なる種類のバイアスと行動傾向をもたらし、一般に慎重さと合意形成を促す方向に働いた。グループでの議論では多様な視点が共有されるため、他者の予測が自分と異なっていることに気づくことが多い。筆者らの実験では、このような力学により、極端な意見が和らげられ、落としどころが見出される傾向があった。

　また、職場環境では、誰もが馬鹿げたほど強気な予測をする人物とは見られたくないと考える。「騙されてたまるか」という心理が働くのだ。過度な楽観主義は世間知らずに見えるため、グループ内には懐疑的な空気が生まれやすくなる。その結果、各人が意識的か否かにかかわらず、楽観的すぎる印象を避けようとし、全体として控えめな予測に落ち着いたと筆者らは考えている。

　これは古典的な「集団思考」とは対照的な現象である。互いに盛り上げ合うのではなく、目立ちすぎることを避けるために互いにブレーキをかけ合った結果、より保守的な合意が形成されたのである。

■5. 知識の幻想

　先行研究によれば、人はインターネットなどの膨大な情報源やコンピュータのような情報処理ツールにアクセスできる状況下では、自分がすべてを理解しているかのような幻想に陥りやすい。今回の実験でも、膨大な情報資源にアクセス可能な高度テクノロジーであるチャットGPTを利用した際に、多くの参加者にこの「知識の幻想」の影響が見られた。

■経営判断におけるAIの賢い活用法

　今回の調査結果は、リーダーや組織がAIツールを意思決定に統合する際に役立つ、重要な教訓を含んでいる。

■1. AIがもたらすさまざまなバイアスと「知識の幻想」に留意する

　チャットGPT（や類似の生成AIモデル）に相談すると、自身の予測に微妙ながらも重大な偏りが生じ、過剰な自信を持ってしまうおそれがある。AIを使って予測や戦略的判断を行う際には、AIの詳細な分析が役立つ一方で、人間が自然に持ち合わせている警戒的な視点が欠けることを忘れてはならない。

　そのため、AIに予測を行わせる場合には、分析させたいデータを明確に指定し、統計的な信頼区間を提示させるべきである。そして何より重要なのは、その予測が「なぜ」「どのように」間違う可能性があるのかをAIに説明させることである。これは、AIが持つバイアスを補正するうえで不可欠である。

■2. 人間同士の議論をなくさず、うまく活用する

　2つのグループの対照的な結果は、AIの偏りを補う手段として、同僚との議論がいかに有効であるかを示している。AIは瞬時に分析と情報を提供できるが、人間の知見にも十分な価値がある。同僚は、新たなデータや文脈を提供するだけでなく、「都合がよすぎる話」や「正確すぎる予測」に対して現実的な視点を加えることができる。

　実務においては、AIからのインプットと人間の対話を組み合わせるのが最善のアプローチかもしれない。たとえば、まずチャットGPTで素早く情報を得てから、それを土台にチームで議論する方法が考えられる。筆者らの研究は、このような組み合わせによってAIの強みと人間の判断を補完し合い、いずれか一方に偏った場合に生じる盲点を回避できることを示唆している。

　リーダーは、新たなテクノロジーを健全な懐疑心と対話とともに活用する文化を育むことで、よりバランスのとれた意思決定を実現できるはずである。

■3. 相手がAIであれ人間であれ、批判的思考が不可欠

　アドバイスの出所がAIであれ同僚であれ、経営幹部はみずからの批判的思考を働かせる必要がある。予測の根拠について問いかけるべきである。たとえば、チャットGPTに対しては、「この予測はどのデータに基づいているのか」「抜け落ちている最近の要因はないか」と尋ねることができる。同僚に対しては、「不確実性のために、慎重すぎる予測に偏っていないか」と問うべきである。

　とりわけAIのように権威ある口調で話す存在については、その助言をそのまま受け入れないことが重要である。AIの回答は、最終的な答えではなく、探究の出発点ととらえるべきである。

　この姿勢は、まさに筆者ら自身の研究にも当てはまる。本研究は、制御されたエグゼクティブ教育の場で、限られた人数のマネジャーを対象に実施されたものであり、実際の取引環境における複雑さや感情的要因を完全に反映しているとは限らない。また、本研究では、エヌビディアという一銘柄の1カ月先の予測に焦点を当てており、他の証券や長期予測では異なる結果が得られる可能性がある。さらに、本研究で使用したチャットGPTモデルは、最新の市場データにアクセスできなかったため、他のAIツールやより新しいモデルを使用した場合には、異なる結果が得られる可能性がある。

　自身の研究とAI自体の双方について、その限界や交絡因子を理解することで、AIの回答に批判的な視点を持つ助けとなる。

■4. チーム内でのAI使用のガイドラインと研修を用意する

　組織としてAIによる助言やサポートを導入する際には、AIが過剰な自信を助長する可能性があることをあらかじめ周知すべきである。ギリシャ神話でユリシーズがセイレーンの誘惑に耐えるために蝋と縄を使ったように、組織にはAIを扱うためのガイドラインが必要である。

　たとえば、AIによる予測を得る前に、同僚との議論や最悪のシナリオの検討を必須とする仕組みを設けることが考えられる。AIと人間のインプットを組み合わせる仕組みを制度として組み込むことで、一方に偏った影響を回避することができる。

*　*　*

　AIの登場によって意思決定の方法は変わりつつあるが、人間の判断は依然として重要である。筆者らの実験は、こうした変化をデータに基づいて捉えようとする試みである。

　たとえ熟練した経営幹部であっても、説得力のあるAIの主張に影響を受けることがある。また、熱意に満ちたグループであっても、少し議論するだけで慎重な姿勢に変わることもある。AIと人間のどちらが常に優れているというわけではない。楽観が必要な場面もあれば、慎重さが求められる場面もある。

　リーダーにとって重要なのは、助言の出所を意識することである。AIからの助言であれば、人間の常識を加え、人間からの助言であれば、AIを使って見落としている外部視点がないかを確認することである。


""Research: Executives Who Used AI Made Worse Predictions,"" HBR.org, July 01, 2025.
ホセ・パラ＝モヤノ,パトリック・ラインメラー,カール・シュメダース",[],[]
