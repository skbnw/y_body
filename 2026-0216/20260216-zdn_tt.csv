headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
Copilotを使い続けた先に何が見えたか　信頼の揺らぎを示す調査結果を発表（TechTargetジャパン）,https://news.yahoo.co.jp/articles/c5ad330147b3e36963a332dbc2125b088eb97781,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20260216-00000029-zdn_tt-000-1-view.jpg?exp=10800,2026-02-16T20:05:09+09:00,2026-02-16T20:05:09+09:00,TechTargetジャパン,zdn_tt,TechTargetジャパン,1760,"（写真提供：iStock）
2025年11月3日（米国時間）、カリフォルニア大学サンディエゴ校（University California San Diego）のコンピュータサイエンス研究チームは「GitHub Copilot」や「ChatGPT」などの生成AI（人工知能）を用いたコーディング支援ツールに対する学部生の信頼度を追跡した研究結果を公表した。研究は、AIがコードを生成する環境で、学生がどの程度AIを信頼し、どのように使い方を調整していくのかを検証したものだ。
学生の信頼は「一時的に上昇、その後に沈静化」
同研究チームが本研究を実施した背景にはソフトウェアエンジニアリング業界における生成AIコーディング支援ツールの普及がある。コンピュータサイエンスを専攻する学生は、就職後に業務でこれらのコーディング支援ツールを使う可能性が極めて高い。そのため、研究チームは、AIリテラシーに加えて、コーディング支援ツールへの信頼をどのように調整するかを教育する必要があると考えている。

　こうした問題意識から、企業で広く使われているコーディング支援ツールとしてGitHub Copilotを取り上げ、学生がGitHub Copilotについて学び、使用する中で、信頼がどのように、なぜ変化するかを調査した。

　研究は、米国のコンピュータサイエンス専攻の3年生と4年生の合計71人を対象に実施された。対象学生の約半数はGitHub Copilotの利用経験がなかった。まず80分間の授業でCopilotの仕組みや使い方を解説し、その場でツールを用いてコーディングさせたところ、授業後には約50％の学生が「信頼が高まった」と回答し、約17％は「信頼が下がった」と答えたという。

　続いて、学生は10日間にわたり、大規模なオープンソースコードベースに対して小さな新機能を追加するプロジェクトに取り組んだ。この間、GitHub Copilotを継続的に利用させ、その後に信頼度の変化を再度尋ねたところ、約39％が「信頼が増加」、約37％が「信頼がやや低下」、約24％が「変化なし」と回答した。カリフォルニア大学の研究チームは「短期的には信頼が高まりやすいが、実践的な長期課題を通じて、AIの限界や誤りも体験し、評価が揺れ動く様子が見て取れる」と分析している。

　同大学コンピュータサイエンス工学科の准教授アダルベルト・ジェラルド・ソーサイラジ 氏は、「研究を通じて平均的には学生の信頼は高まったが、より複雑なプロジェクトを終えた後、GitHub Copilotを十分に使いこなすには一部のタスクを手作業でこなせる有能なプログラマーが必要だと学生が感じるようになった 」と述べている。
「AI任せ」にしないための4つの教育的ポイント
研究チームは、コンピュータサイエンス教育における具体的な推奨事項として、次の4点を示した。

・学生が生成AIへの信頼と期待を調整するのに役立つように、さまざまな難易度のタスク（大規模なコードベースのタスクを含む）でコーディング支援ツールを使用する機会を学生に提供する
・学生が生成AIの出力をどの程度信頼できるかを判断できるように、コーディング支援ツールなしでも大規模なコードベースのコードを理解、修正、デバッグ、テストできるように教える
・学生がコーディング支援ツールに期待される動作を理解できるように、生成AIが自然言語処理によってどのように出力を生成するのかを教える
・大規模コードベースを扱うのに役立つコーディング支援ツールの主要機能を明示的に紹介し、デモで示す
編集者の一言解説
企業の情報システム部門や開発部門でも、GitHub CopilotやChatGPTなどの生成AIを「開発支援ツール」として導入する動きが広がっている。今回の研究は大学生を対象としたものだが、開発者が「AIへの信頼度を一度高めてから、実務を通じて冷静に調整していく」というプロセスは、企業の現場でも起こり得る。企業は生成AIを使えるようにするだけでなく、どのタスクに使い、どの範囲は人がレビューするかといったことを教育し、運用ルールとして明示することが重要だろう。
TechTargetジャパン",[],[]
