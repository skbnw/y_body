headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
ここがAI進化の分水嶺　1970～2000年代を貫く技術革命の全貌（TechTargetジャパン）,https://news.yahoo.co.jp/articles/0c4a458595f535b0d3558b81cc47f625faba544a,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250717-00000031-zdn_tt-000-1-view.jpg?exp=10800,2025-07-17T20:00:12+09:00,2025-07-17T20:00:12+09:00,TechTargetジャパン,zdn_tt,TechTargetジャパン,3536,"（写真：TechTargetジャパン）
人工知能（AI）技術はどのような技術や理論に基づいて構築されたのか。4回にわたってその歴史を紹介する。本稿は、1978年に登場した“あのゲーム”から紹介する。
いにしえのあのゲームもAIの起源？
1978年（プロシージャルコンテンツ生成）

　カリフォルニア大学ロサンゼルス校（UCLA：University of California, Los Angeles）の職員だったドン・ワース氏が、ローグライクゲーム（アルゴリズムによってプレイごとにマップが自動で生成されるゲーム）の「Beneath Apple Manor」を開発した。限られた性能のハードウェアでゲームの世界を生成するため、アルゴリズムを使用してコンテンツを自動的に生成する「プロシージャルコンテンツ生成」（PCG：Procedural Content Generation）を活用した。

1980年（プロシージャルコンテンツ生成）

　マイケル・トイ氏とグレン・ウィッチマン氏が「UNIX」OSを基盤としたゲーム「Rogue」を開発した。RogueもPCGを使用しており、マップ、レベル、キャラクターといった要素を自動で生成できた。両氏はA.I. Designを共同設立してRogueをPCに移植し、PCG技術の普及によってゲーム業界に影響を与えた。

1985年（ベイジアンネットワーク）

　コンピュータ科学者で哲学者のジュディア・パール氏が、確率変数間の依存関係をグラフ構造で表現する「ベイジアンネットワーク」を確立した。不確実性下での意思決定支援システムの基盤技術として、後のAI発展に寄与した。

1986年（RNN）

　カリフォルニア大学バークレー校（University of California, Berkeley）の教授、マイケル・アーウィン・ジョーダン氏が論文「Serial order: a parallel distributed processing approach」にて、誤差を伝搬して重みを調整する学習メカニズムを発表した。これは後の深層学習モデル「回帰型ニューラルネットワーク」（RNN：Recurrent Neural Network）の発展に間接的に寄与した。

1988年（パラメトリックモデリング）

　ソフトウェアベンダーPTCが、3D（3次元）CAD（コンピュータ支援設計）ソフトウェア「Pro/ENGINEER」（Pro/E）を発表した。「パラメトリックモデリング」（寸法変更が全関連要素に自動反映する）を採用しており、従来と比べて設計効率が向上した。同製品はのちに名称を「Creo Parametric」と変更し、建設機械メーカーのCaterpillarや農業機械や建設機械のメーカー、Deere＆Company（John Deereの名称で事業展開）などの産業機器開発を支援している。

1989年（CNN、画像認識）

　ヤン・ルカン氏、ヨシュア・ベンジオ氏、パトリック・ハフナー氏が「畳み込みニューラルネットワーク」（CNN：Convolutional Neural Network）を画像認識に利用できることを実証した。CNNの一つ、「LeNet-5」は手書き数字を正確に識別する新技術として高い精度を達成した。その後登場した大規模画像データベース「ImageNet」（コンピュータ科学者、フェイ・フェイ・リー氏が開発）とCNNベースの深層学習モデル「AlexNet」（2012年に公開）によって、画像認識技術のさまざまな分野での応用が可能となった。

1990年（LSTM、LSA）

　セップ・ホッホライター氏とユルゲン・シュミットフーバー氏がRNNの一種「長・短期記憶」（LSTM：Long Short-Term Memory）を開発した。RNNが持つ課題（RNNの勾配消失問題）を克服するために開発され、長いシーケンスを保持したり分析したりすることが可能となった。

　1990年に、ベルコミュニケーションズリサーチ（Bell Communications Research）、シカゴ大学（University of Chicago）、ウェスタンオンタリオ大学（University of Western Ontario）の研究チームが論文「Indexing by Latent Semantic Analysis」を発表した。「潜在意味解析」（LSA：Latent Semantic Analysis）は、トレーニングテキストのサンプルにある単語間の意味的関係を特定する手法を提供し、単語間の意味関係を自動で識別する技術「word2vec」や大規模言語モデル（LLM）「BERT」（Bidirectional Encoder Representations from Transformers）開発への道を開いた。
1991年～2014年
1991年（ガウス分布を用いたスプラッティング）

　ノースカロライナ大学チャペルヒル校（University of North Carolina at Chapel Hill）のリー・アラン・ウェストオーバー氏が、3Dコンテンツ表現技術「ガウス分布を用いたスプラッティング」（Gaussian splatting）の基礎について博士論文で発表した。

2003年（FNN）

　モントリオール大学（Universite de Montreal）の研究者らが論文「A Neural Probabilistic Language Model」を発表した。「順波及型ニューラル」（FNN：Feed-forward Neural Network）を使用した言語モデリング手法を提案し、単語の意味とコンテキストを自動的にベクトル化する技術の研究を促進した。

2006年（視覚的物体認識、AIシステム）

　フェイ・フェイ・リー氏がImageNetを開発した。視覚的物体認識の基礎を築き、AlexNetによる物体認識と生成の進歩に貢献した。

　IBMの人工知能（AI）システム「IBM Watson」は、クイズ番組「Jeopardy!」で人間に勝つことを目標に開発された。その目標は、2011年に歴代チャンピオンのケン・ジェニングス氏を破る形で達成された。

2011年（音声アシスタント）

　Appleが音声駆動型アシスタント「Siri」をリリースした。音声リクエストに応じて応答を生成し、ユーザーの音声指示に応じてアクションを実行できる。

2012年（GPUを使用した深層学習アルゴリズムの並列処理）

　コンピュータ科学者アレックス・クリジェフスキー氏がAlexNet CNNアーキテクチャを設計した。GPU（グラフィックス処理装置）の進歩を活用してニューラルネットワークを自動的にトレーニングする方法を開拓した。同年に開催された画像認識の国際大会ImageNet Large Scale Visual Recognition Challengeでは、2位に10.8％以上の差をつけて優勝した。これが深層学習ブームの起爆剤となった。

2013年（word2vec）

　Googleの研究者トーマス・ミコロフ氏らがword2vecを開発した。この技術によって、未加工のテキストを深層学習アルゴリズムで処理可能なベクトル形式に変換することが容易になった。

2014年（GAN、VAE）

　コンピュータ科学者イアン・グッドフェロー氏らが画像生成技術である「敵対的生成ネットワーク」（GAN ：Generative Adversarial Network）の論文を発表した。2つのニューラルネットワークを対立させて、リアルな画像を生成できるようにするAI技術を確立した。

　科学者ディーデリク・キンフマ氏とコンピュータ科学者マックス・ウェリング氏は「変分オートエンコーダー」（VAE：Variational AutoEncoder）を提唱した。VAEは画像、動画、テキストの生成に用いられる。入力データをより効果的に表現し、それを元の形式や別の形式へ変換する新しい手法を確立した。

本記事は米国Informa TechTargetの記事「History of generative AI innovations spans 9 decades」を翻訳・編集したものです。一部、翻訳作業に生成AIを活用しています。
TechTargetジャパン",[],[]
