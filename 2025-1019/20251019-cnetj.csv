headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
「アップル製メガネ」の登場は近い？必要なピースは既にそろっている（CNET Japan）,https://news.yahoo.co.jp/articles/be68b75c568855075efaacf8e9e092475755330b,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20251019-35239327-cnetj-000-1-view.jpg?exp=10800,2025-10-19T07:30:00+09:00,2025-10-19T07:30:00+09:00,CNET Japan,cnetj,CNET Japan,3438,"「アップル製メガネ」の登場は近い？必要なピースは既にそろっているの画像
スマートグラスが注目を集めている。Metaの最新のRay-Banモデルは現在発売中で、最新のOakleyモデルも間もなく登場する。Googleとサムスンも、おそらく2026年には「Android XR」で競争に参入するだろう。このような勢いを見ていると、Appleが遅かれ早かれ独自のスマートグラスを投入するのは必然だと常に感じていたが、最近の兆候は「早い」方を示唆している。
【画像】すべて見る
報道によると、Appleは既存のVRヘッドセット「Vision Pro」の後継機で、より小型軽量になるとうわさされていた「Vision Air」の開発を中断し、スマートグラスを優先しているという。筆者にはこれが、MetaやサムスンからGoogle、Snap、Amazon、Xreal、Rokid、さらにはOpenAIに至るまで、各社が販売、開発、あるいは模索中とうわさされるAIメガネの波に対抗するための方向転換のように思える。

　この秋、筆者はさまざまなスマートグラスを試す中で、Appleにとってのピースがそろいつつあると感じている。同社は市場にインパクトを与えるための製品カタログとウェアラブル技術をすでに確立しており、われわれが思うよりはるかに先を進んでいる。ここでは、Appleの現在のヘッドホン、スマートウォッチ、スマートフォン、そしてソフトウェアが、同社初のスマートグラスをどのように形作る可能性があるかを見ていきたい。

AirPodsがもたらすオーディオ技術

　Appleは10年以上にわたって、われわれの顔に向けた技術に取り組んできた。2016年に筆者が初めて「AirPods」を装着したとき、その奇妙な見た目をからかわれたものだが、それはAppleがわれわれの顔に向けたデザインの可能性を試しているように感じられた。そして、その試みは成功した。今日では誰もがAirPodsなどのワイヤレスイヤホンを身に着けており、それをからかわれることもない。

　それ以来、Appleはスマートグラスにぴったりなコンピュテーショナルオーディオ機能を次々と発表している。最新のAirPodsファームウェアに搭載されたリアルタイム翻訳、うなずくジェスチャーでのクイック返信、心拍数追跡、周囲の騒音をフィルタリングして集中力を高めたり難聴を補ったりする機能、そして空間3Dオーディオなどだ。さらに、「AirPods 4」には新しいオープンイヤー型のノイズキャンセリング技術があり、米食品医薬品局（FDA）が認可した聴覚補助機能も搭載されている。後者は、Nuanceなどの企業が手がけるスマートグラスにすでに登場している機能だ。

　これらの技術はすべて、フレームに超小型のオープンイヤースピーカーを内蔵したスマートARグラスに応用できる可能性がある。AirPodsはほんの始まりにすぎないのかもしれない。

Apple Watchがもたらす操作技術

　Metaの最新のディスプレイ付きスマートグラスには「Neural Band」が付属している。これは電極で微細な筋肉の動きを読み取り、空中でのジェスチャーに変換してレンズ上のディスプレイを操作するものだ。Appleはすでに、手首をベースにした独自のジェスチャーコントロールでこの分野に足を踏み入れている。

　「Apple Watch」はすでに、メッセージへのクイック返信や電話の応答、タイマーの停止などができるダブルタップやシェイクで消去といったジェスチャーに対応している。筆者は、これほど早い段階でダブルタップがApple Watchに登場したことに感銘を受け、それがVRやARのヘッドセットとどれほど自然に連携できるだろうかとすぐに考えた。

　AppleのメガネはApple Watchと直接連携して画面上の表示に素早くアクセスすることも可能かもしれない。カメラ付きメガネのビューファインダーや、連携アプリを選択するためのウェアラブルタッチスクリーンとして考えてみてほしい。Metaはすでに、Neural Bandがウォッチにもなる柔軟性を持つ可能性を示唆しており、Googleにもウォッチとメガネを連携させる計画がある。

iPhone Air（とVision Pro）がもたらすカメラ技術

　Appleは高性能カメラを小さなスペースに収めることにかけてはベテランだ。この秋に発表された超薄型の「iPhone Air」は、これまでで最も見事な小型化を成し遂げたが、メガネにはさらに小さなカメラが求められる。

　Appleには、すでにヘッドセットにカメラやセンサーを搭載してきた経験がある。Vision Proに搭載されている多数のカメラは、Appleのメガネに搭載されるであろうどんなものよりもはるかに複雑だろう。

　そしてAppleは、既存の操作方法を流用することもできる。iPhoneの「カメラボタン」にはすでに静電容量式タッチセンサーが搭載されており、これはメガネのフレームのつる（アーム）を使ってどのように操作するかを示唆しているのかもしれない。

　もしかしたらAppleは、ステレオ3D録画機能を追加するかもしれない。そうなれば、メガネで空間ビデオを撮影し、後にVisionヘッドセットで追体験できるようになる。これは、Vision Proがヘッドセット内での録画機能で売り込もうとした、「思い出を記録する」というのと同じ理想だ。

Appleに求められる、ビジュアルAIの強化

　Appleのメガネには、iPhoneの「ビジュアルインテリジェンス」のような、カメラを認識するAIサービスが必要になるだろう。Googleの「Gemini」やMetaの「Meta AI」に追いつくには、まだやるべきことがたくさんある。しかし、メガネはその技術を導入するのに最適な場所となり、撮影したデータを使って長期的にAIモデルを訓練することさえ可能かもしれない。

　Metaがそうしているように、メガネでAIの課題を解決することは、将来的に自動車のような他のAppleのプロジェクトにおけるAIの向上につながる可能性がある。

Apple Storeはメガネのデモにうってつけ

　Metaは新しい「Display」グラスをデモするための店舗体験を構築しようとしているが、Appleにはすでに世界中に店舗網がある。Vision Proの発売時に複雑な技術デモを行ったのと同じ店舗だ。それらはメガネのフィッティングに最適だろう。処方箋は、Vision ProがレンズパートナーであるZeissとすでに行っているように、オンラインで対応できる。

スマートフォンとの密な連携はAppleの得意分野

　既存のスマートグラスはスマートフォンやアプリストアとの連携という点で不十分だが、Appleなら誰にも負けないほどうまくその問題を解決できる可能性がある。GoogleとAppleがスマートフォンのOSであるAndroidとiOSへのパイプラインを支配しているため、スマートグラスメーカーは、スマートフォンやスマートウォッチなどのデバイスをシームレスに連携させるための接続機能を構築する上で、両社に左右されることになる。

　Metaのメガネはスマートフォンアプリを介して動作させる必要があり、「Siri」やGeminiのサービスからは切り離されている。GoogleのAndroid XRはAndroidでのメガネとの連携を深めるのに役立つはずであり、AppleはiOSで同じことをする必要がある。Appleが自社でメガネを製造すれば、他社ブランドのサポートにつながったり、iOSアプリ開発者がメガネ全般に関心を持つきっかけになったりするかもしれない。

　Apple製メガネの登場について確かなことは、おそらく少なくとも2026年まで分からないだろう。そのため、今のところはすべてが憶測にすぎない。しかし、すべてのピースを組み合わせると、かなり特別なスペックが想像できる。あとは、Appleがそれを筆者の顔に着けてくれるのを待つだけだ。

この記事は海外Ziff Davis発の記事を朝日インタラクティブが日本向けに編集したものです。",[],[]
