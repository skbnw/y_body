headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
AI投資企業の95％が成果ゼロ　突破口となる時給14万円のエンジニアが挑む企業AI革命（AMP［アンプ］）,https://news.yahoo.co.jp/articles/be314cd573f76a39a3563ba61c89aa8aab395ef8,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20251126-00010000-ampreview-000-1-view.jpg?exp=10800,2025-11-26T12:05:21+09:00,2025-11-26T12:05:21+09:00,AMP［アンプ］,ampreview,AMP［アンプ］,3588,"AI投資企業の95％が成果ゼロ
マサチューセッツ工科大学（以下、MIT）が2025年7月に発表した調査結果が、多くの企業経営者に衝撃を与えた。米国企業が生成AIに投じた350〜400億ドルという巨額の投資に対し、95%のプロジェクトがビジネスインパクトや損益への成果を生み出していないことが分かったためだ。
企業AI投資の95%が無駄に
S&Pの調査でも、AIの導入を断念する企業の割合は前年の17%から42%へと急増、プロジェクトの平均46%が概念実証（以下、PoC）段階と本格導入の間で中止されていることが判明した。別の調査でも、企業のAI導入プロジェクトのうち80%が失敗に終わる可能性が指摘されている。

調査会社Gartnerは、2025年末までに少なくとも30%の生成AIプロジェクトがPoC後に放棄されると予測。その理由として、データ品質の悪さ、不十分なリスク管理、コスト増大、不明確なビジネス価値を挙げている。

もう一つの深刻な問題は、AIが自信たっぷりに誤った回答を返してしまうことだ。アジア太平洋地域を対象としたAvanadeの調査では、96%の組織がAIを意思決定の支援に活用している一方で、AI出力への信頼度は2023年の48%から2024年には26%へと半減した。Avanade APAC 社長のバヴィア・カプール氏は「モデルが適切に訓練されていない場合、AIは必ずしも正確ではない情報を生成する。そのリスクとガバナンスの問題が広く認識され始めている」と指摘する。

さらに、MITの調査は企業がAIを「静的な科学プロジェクト」として扱ってしまう構造的な問題を浮き彫りにした。ほとんどの生成AIシステムはフィードバックを保持せず、業務の文脈に適応できず、時間とともに改善されない状態になっているのだ。

60%の組織がエンタープライズグレードのAIツールを評価（検討・デモ利用）したものの、パイロット段階に進んだのは20%、プロダクション環境に到達したのはわずか5%に過ぎなかった。現場の業務理解が浅いまま技術先行でPoCを始めてしまい、実用化の壁にぶつかるケースが後を絶たない。
「分からない」を学習するAIの革新性
この課題に正面から挑むのが、米サンフランシスコのPromptQLだ。同社は企業価値10億ドルを超えるAIユニコーン企業で、ここ数カ月で世界最大級の企業と7桁ドル（1億5,000万円以上）規模の契約を複数締結した実績を持つ。

PromptQLの最大の特徴は、AIに「自信満々に間違える」ことをやめさせた点にある。同社の共同創業者兼CEO タンマイ・ゴパール氏は「最大の問題は正確に答えられないことではない。AIが不正確なときでも正確なふりをすることだ」と指摘。この「自信満々な誤答」は、ユーザーがすべてのAI回答を検証しなければならない「検証税」を生み、生産性向上効果を帳消しにしてしまう。

同社が開発したのは、AIに不確実性を示す能力と、フィードバックから学習する能力を持たせる仕組みだ。具体的には、いきなり答えを出すのではなく、まず「どう答えを導き出すか」という手順を企業ごとの業務用語で組み立てる。その手順は実行する際にルール違反がないかチェックされ、確実に実行できる作業へと変換される。

この設計により、システムは自身の確信度を較正し、不確実な場合は回答を控える「棄権」機能を実行できるようになった。確信度が低いとき、ユーザーは不足している文脈や方針選択を補うことができ、その修正は系譜情報とともに記録される。次回の更新時、AIは企業の定義、データの癖、プロセスを学習し、使用回数とともに精度が向上していくという流れだ。

ゴパール氏はこれを「精度のフライホイール」と呼ぶ。ネイティブな不確実性の提示→人間による誘導→モデル改善という循環が、単なる回答の蓄積ではなく計画空間とドメイン知識そのものを更新していく。従来の大規模言語モデルがハルシネーション（虚偽情報）を認識できないのに対し、PromptQLのシステムは「分からない」と明示できる点で根本的に異なる。
時給14万円でも引き合いが殺到する理由
PromptQLは時給900ドル（約14万円）という価格でAIエンジニアを派遣するコンサルティングサービスを開始したことでも注目を浴びる。既存コンサルティング企業への挑戦となるためだ。

時給14万円というのは、一見すると高額に映るが、既存大手コンサルティング企業の典型的なエンゲージメントコストと比べればかなり安い。同社がベータ版の製品で3～5カ月のうちに7桁ドル規模の契約を複数締結していることも、コストパフォーマンスの高さを物語る。

顧客企業には、年間売上500～600億ドル規模の世界最大のネットワーク企業、世界最大のファストフードチェーン、世界2大食品配達企業などが名を連ねる。取引量の多い企業では約1ペタバイトのデータを処理し、大規模な営業組織では複数の子会社や買収企業にまたがる2万5,000人のユーザーに展開されているという。

なぜこれほど同社のコンサルティングサービスに対する需要が高いのか。理由の1つは、AI人材の世界的な供給不足にある。

米国労働統計局によると、AIエンジニアの年収の中央値は14万5,080ドル。また、2025年の業界データを見ると、米国のAI特化型ソフトウェアエンジニアの平均年収は24万5,000ドルで、経験豊富なスタッフエンジニアレベルでは非AI技術者より18.7%高い報酬を得ていることが判明した。ソフトウェア企業Intuitでは、AIスタッフエンジニアが約91万7,000ドルを稼ぐ一方、非AI技術者は約51万5,000ドルと、40万ドル近い差が生まれている状況だ。

こうした人材市場の逼迫に加え、クライアントがPromptQLを評価するのは「正直なAI」がもたらす信頼性にある。早期顧客は、自信満々に誤答を返すAIシステムを信頼性の高い代替手段に置き換えることで「数百万ドルの節約」を実現したと報告する。

確実性を装って現場を混乱させるよりも、分からないことを明示するシステムの方が、実務では圧倒的に価値が高いという判断だ。
PoCで終わらせない。実装成功への具体的ステップ
では、日本企業はこの「9割失敗」の罠をどう避ければよいのか。まず重要なのは、AI導入前に明確な目的とKPIを設定することだ。多くの失敗したプロジェクトに共通するのは、適切な計画の欠如。解決すべきビジネス課題を明確にせず、「とりあえずAIを試す」という散発的なアプローチでは、PoCで終わる可能性が高い。

データ整備も見逃せない要素だ。冒頭でも触れたが、Gartnerは、2025年末までに少なくとも30%の生成AIプロジェクトが、データ品質の悪さを理由にPoC後に放棄されると予測している。不正確で出所不明、偏りがあり古いデータは、AIの出力にそのまま問題を再現してしまう。加えて、インフラ面の準備も欠かせない。計算能力、ネットワーク帯域幅、データストレージといった基盤がなければ、テストで95%の精度を達成しても、本番環境では60%が失敗する事態に陥る。

もう一つの鍵は、AIの結果を検証する人間の体制だ。MITの調査では、データサイエンス機能とビジネス部門の間のインターフェースで問題が発生することが明らかになった。技術を実装する専門家が日常業務に統合されず、部門間にサイロが生まれた結果だ。自社の業務担当者や専門家が、AIの出力を検証し修正する仕組みを構築することで、PromptQLのような「精度のフライホイール」を社内でも回していくことが可能になる。

日本特有の事情も考慮すべきだろう。2025年5月に可決された日本のAI活用推進法は、詳細な規定ではなく高レベルの原則を定める「基本法」として構造化されている。この法律は企業に直接的な義務を課さず、政府の施策への協力を「努力する」という非拘束的な性格を持つ。罰則は存在せず、重大な権利侵害の場合に企業名を公表する「ネーム・アンド・シェイム」方式を採用している点が特徴となる。

この柔軟なアプローチは、企業の自主的なガバナンス構築を前提としたものだ。また、2024年に公開されたAIビジネス事業者向けガイドラインは、経営層レベルでの責任と内部の説明責任体制の確立を求めており、拘束力はないものの裁判所の解釈や行政指導、ESG評価に影響を与える可能性があると見られている。海外の成功例に学びつつ、こうした日本の法的・文化的文脈に合わせた運用設計が、AI導入成功への近道となるはずだ。
文：細谷 元（Livit）",[],[]
