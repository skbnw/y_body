headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
ソフトバンクとAmpereが共同検証--CPUによるAI推論最適化（ZDNET Japan）,https://news.yahoo.co.jp/articles/413d910472c176ee9f1439aded24c722dd2f8975,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20260217-35243983-zdnet-000-1-view.jpg?exp=10800,2026-02-17T16:51:00+09:00,2026-02-17T16:51:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,918,"ソフトバンクとAmpereが共同検証--CPUによるAI推論最適化の画像
ソフトバンクとAmpereは2月17日、CPUを活用したAI推論の効率化に関する共同検証を開始したと発表した。AIエージェント時代を見据え、多数の小規模AIモデルをCPU上で分散運用し、計算資源の効率を高めることが狙いだ。

　AIの普及が進む中、大規模言語モデル（LLM）だけでなく、用途特化型でパラメーター数が比較的少なくても高い実用性を持つAIモデルの需要が増している。特にAIエージェント、業務自動化、ネットワーク制御の領域では、低遅延・常時稼働・高い電力効率を兼ね備えた推論処理が必須となる。しかし、GPU中心の構成ではコストや消費電力が課題となるケースがあり、CPUの活用が有力視されてきた。

　今回の共同検証では、分散環境を前提に小規模言語モデル（SLM）やMoE（Mixture of Experts）モデルをCPU上で実行し、その性能や運用性を評価。ソフトバンクが開発するAIモデル配分オーケストレーターを用いることで、CPUのみを搭載したノード、CPUとGPUを組み合わせたノードのいずれにおいても、負荷に応じた柔軟なモデル配置が可能であることを確認した。

　さらに、オープンソースのAI推論フレームワーク「llama.cpp」をベースに、Ampere製CPU向けに最適化した「Ampere optimized llama.cpp」を実装。これにより、一般的なGPUベースの構成と比較して消費電力を抑えつつ、同時実行可能数を増やせることが分かったほか、モデルの読み込み時間も大幅に短縮され、高速なモデル切り替えにも対応できることを確認したという。

　今後は、複数のAIモデルを動的に切り替えながら TPS（Tokens Per Second：1秒当たりのトークン生成数）を安定維持できるAI推論プラットフォームの実現に向け、取り組みを継続する。ソフトバンクはAmpereとの協業を通じ、次世代AIインフラを支える要素技術として低遅延かつ高効率なAI推論環境の確立を推進し、AIエージェントやSLMのさらなる活用拡大に貢献していく考えだ。",[],[]
行田市、請求業務のデジタル化でSaaSを活用--財務会計システムを2027年に更新（ZDNET Japan）,https://news.yahoo.co.jp/articles/19f25696a84eaa023b6008ee55d11bdbbe572cc8,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20260217-35243979-zdnet-000-1-view.jpg?exp=10800,2026-02-17T16:15:00+09:00,2026-02-17T16:15:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,714,"行田市、請求業務のデジタル化でSaaSを活用--財務会計システムを2027年に更新の画像
埼玉県行田市は、請求業務をデジタル化する「BtoBプラットフォーム 請求書」を導入、3月1日から運用を開始する。サービスを提供するインフォマートが2月17日に発表した。

　デジタル技術の活用で質の高い行政サービスの提供と行政事務の効率化を目指しているという行田市は、ペーパーレス化を進めているが、財務事務については紙の請求書を紙の帳票にのり付けして回議、押印する事務処理が基本となっており、思うように業務改善が進んでいない状態だったという。

　同市は2027年に財務会計システムの更新を控え、財務事務全般の完全デジタル化を目指している。まずは、請求書をデータでやり取りできる環境を整備するため、BtoBプラットフォーム 請求書の導入を決定。財務会計システム更新までの1年半で取引事業者に電子請求書を普及、定着させることで将来的に財務事務を完全デジタル化した際の効果が高まることを期待している。

　2月3日に取引事業者向けの説明会を開催。オフライン、オンラインをあわせて約350人が参加し、市と取引事業者、双方の業務効率化に向けた電子請求書発行への協力を呼び掛けた。

　BtoBプラットフォーム 請求書の導入で請求データの送付や受け取りがクラウドで完結できる。郵送や持参する手間を省くことで取引事業者と市の職員双方のペーパーレス化や業務効率化につながると説明している。財務会計システムの更新でBtoBプラットフォーム 請求書を連携させることで、債権者情報や金額の手入力が不要となり、正確かつ短時間で伝票を作成できる見込みとしている。",[],[]
住信SBIネット銀行、不正検知と顔認証を連動させた新たな不正対策（ZDNET Japan）,https://news.yahoo.co.jp/articles/458dfac49887b74a476a3c2ef0f33d1c38389927,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20260217-35243971-zdnet-000-1-view.jpg?exp=10800,2026-02-17T14:26:00+09:00,2026-02-17T14:26:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,764,"住信SBIネット銀行、不正検知と顔認証を連動させた新たな不正対策の画像
住信SBIネット銀行は2月17日、不正アクセスやなりすまし、不正口座利用の防止に向け、不正検知と顔認証を連動させた新たな不正対策を導入した。DTSのマネーロンダリング対策パッケージソリューション「AMLion（アムリオン）」とLiquidが提供する認証サービス「LIQUID Auth（リキッドオース）」を組み合わせて採用する。3月より順次導入される予定だ。

　特殊詐欺や不正口座売買、フィッシング経由の認証情報盗難などの増加により、不正アクセスリスクは高まっている。対応するには取引時の不正検知と本人利用確認の両輪での対策が必要となっていた。

　LIQUID Authは、ネットバンキングやECなどで利用者本人を確認するデジタル本人認証基盤。「electronic Know Your Customer（eKYC）」と連携した身元確認済みの顔データを活用した高精度顔認証が特徴で、「Fast IDentity Online（FIDO）」認証、端末認証など複数方式を組み合わせて利用可能だ。

　一方、金融活動作業部会（FATF）や金融庁ガイドラインに準拠したAML/CFTソリューションであるAMLionは、顧客管理や疑わしい取引の検知などの機能を1つのプラットフォームとして提供。詐欺や金融犯罪に対応する。

　今回の導入は、すでに住信SBIネット銀行が導入しているデジタル本人認証基盤のLIQUID Authと、新たに導入したAML/CFTソリューションを組み合わせることで、口座開設から初回利用、日々の取引まで、正当な利用であることを一貫して確認できる体制を構築するもの。これにより、不正利用を未然に防止し、利便性と安全性の両立を追求していく。",[],[]
OpenAI、リアルタイムコーディング向けの「GPT-5.3-Codex-Spark」を公開（ZDNET Japan）,https://news.yahoo.co.jp/articles/669142783ad2958f9eadad684daf1387b1fe0b9a,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20260217-35243959-zdnet-000-1-view.jpg?exp=10800,2026-02-17T10:47:00+09:00,2026-02-17T10:47:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,1633,"OpenAI、リアルタイムコーディング向けの「GPT-5.3-Codex-Spark」を公開の画像
OpenAIは米国時間2月12日、「GPT-5.3-Codex」の小型版で、コーディングエージェント「Codex」でのリアルタイムコーディング向けに設計された「GPT-5.3-Codex-Spark」の研究プレビュー版を公開した。OpenAIの報告によると、GPT-5.3-Codex-Sparkはこれまでの15倍のコード生成速度を実現しながら、「実運用のコーディングタスクに対応できる高い性能を維持」しているという。ただし、注意すべき点もあるため、後ほど説明する。

　GPT-5.3-Codex-Sparkは、まず月額200ドル（日本では3万円）の「Pro」プランのユーザーのみに提供され、プレビュー期間中は別途レート制限が適用される。CodexにおけるOpenAIの通常のリリース戦略に従うとすれば、次は「Plus」ユーザーが対象となり、他のプランのユーザーへの提供も比較的早く開始されるだろう。

　OpenAIによれば、GPT-5.3-Codex-Sparkは「Codexとリアルタイムに連携するために特化して設計された当社初のモデル」で、「的確な編集やロジックの再構成、インターフェースの改善を行い、その結果を即座に確認」できるという。

　また、リクエストからレスポンスまでのパイプライン全体でレイテンシーの削減（応答時間の高速化）を実現したとしている。クライアントとサーバー間の往復ごとのオーバーヘッドは80％、トークンごとのオーバーヘッドは30％削減されたという。最初のトークンが表示されるまでの時間も、セッション初期化の見直しとストリーミング処理の最適化によって50％短縮されている。

　GPT-5.3-Codex-Sparkは、1月に発表されたOpenAIとCerebrasの提携における最初のマイルストーンであり、Cerebrasの「Wafer Scale Engine 3」（WSE-3）上で動作する。WSE-3は高性能な人工知能（AI）チップアーキテクチャーで、パンケーキほどの大きさのウエハスケールプロセッサー1枚にすべての計算リソースを配置することによって高速化を実現している。

　さらに、GPT-5.3-Codex-Sparkは「エージェント型ソフトウェアエンジニアリング能力を評価するベンチマークである『SWE-Bench Pro』および『Terminal-Bench 2.0』」において、「GPT-5.3-Codexと比べて、短時間でタスクを完了しながらも高い性能」を示したと、OpenAIは述べている。

　ただし、ここで注意点がある。OpenAIはGPT-5.3-Codexを2月5日に発表した際、同社が公開している「Preparedness Framework」に基づき、GPT-5.3-Codexをサイバーセキュリティにおいて「High capability（高能力）」に分類された初のモデルだと説明していた。だが、GPT-5.3-Codex-Sparkに関しては、「サイバーセキュリティにおける高い能力について、当社のPreparedness Frameworkが定めるしきい値に達する可能性はない」と認めている。

　それでも、OpenAIが構想するワークフローモデルは興味深いものだ。同社は最終的に、Codexが「インタラクティブな作業サイクルを維持しつつ、長時間にわたる処理をバックグラウンドのサブエージェントに委任」したり、「網羅性や処理速度が求められる場合には、複数のモデルへ並列にタスクを分散」したりできるようにすることを目指している。そうすれば、「あらかじめ単一のモードを選択する必要」がなくなると同社は説明している。

この記事は海外Ziff Davis発の記事を4Xが日本向けに編集したものです。",[],[]
ソフトバンク、AIアプリに応じてGPUを分割し、最適に割り当てる機能を開発--AMDと共同検証（ZDNET Japan）,https://news.yahoo.co.jp/articles/0626a355b90f3f17b98d541c1362a9dc312d223e,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20260217-35243949-zdnet-000-1-view.jpg?exp=10800,2026-02-17T09:00:00+09:00,2026-02-17T09:00:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,1948,"ソフトバンク、AIアプリに応じてGPUを分割し、最適に割り当てる機能を開発--AMDと共同検証の画像
ソフトバンクは、米Advanced Micro Devices（AMD）と連携して同社のGPU（画像処理半導体）「AMD Instinct GPU」を次世代のAI（人工知能）インフラの計算資源として活用するための共同検証を開始した。2月16日に発表した。

　大規模言語モデル（LLM）などのAIモデルを利用するアプリケーション需要は拡大を続けている。ソフトバンクの先端技術研究所は、AIアプリケーションのモデル規模や実行要件に応じて計算資源を柔軟に制御できる次世代のAIインフラの実現を目指し、計算資源を管理したりAIアプリケーションを最適に配分したりする「オーケストレーター」の開発を進めてきている。

　推論サービスはLLMの規模、同時に実行するモデル数といった用途やアクセス数で必要となるGPUのリソース量が常に変動する。GPUは高価な計算資源であり、サービス提供者は限られたGPUを複数の用途、複数のモデルに割り当てながら運用する必要がある。

　このとき、需要の変動に対して割り当ての粒度を細かく調整できないと、小さいモデルに対して必要以上に大きなGPUを割り当ててしまうなど、リソースのミスマッチが起こりやすくなる。結果として、GPUの一部が使われない状態（余剰）が生じ、必要なタイミングで大きなモデル、あるいは複数の小さなモデルに対して容量を確保できず、処理待ちや起動遅延の発生につながる。このように、余剰は無駄になるだけでなく、需要の増減に応じた柔軟なサービス提供を難しくする要因にもなるという。

　こうした背景から、サービス提供者にとっては、AIアプリケーションのモデル規模や同時実行要件などに応じてGPUリソースを「必要な分だけ」割り当てることが重要になる。需要の変動にあわせて割り当てを最適に調整できれば、余剰を抑えながらひっ迫も避けやすくなり、稼働率や提供効率、サービス品質の向上につながる。

　余剰を抑え、設備稼働率と提供効率を高めるためのアプローチの一つが、GPUを用途に応じて分割して利用するという考え方だ。

　Instinct GPUは、DRAMチップを垂直に積み重ねて、GPUの近くに配置する高速大容量メモリー技術である「High Bandwidth Memory（HBM）」を採用しており、GPUリソースを分割して扱える仕組みである「GPUパーティショニング」を搭載しており、必要に応じて1台のGPUを複数の区画（論理デバイス）として利用できる。

　推論サービスごとに「必要な分だけ」のGPUリソースを割り当て、1台のGPU上で複数の推論サービスを並行して展開することで、余剰リソースの発生を抑えられるという。限られたGPUをより細かな単位で利用できるようになり、需要変動の大きい環境でも運用の選択肢が広がるとしている。

　Instinct GPUは、計算処理を担う「演算リソース」と「メモリ構成」という2つの観点で論理的な構成が定義されている。具体的には、GPUの演算リソースを構成するXCD（Accelerator Complex Die）を分割単位とする「コンピュートパーティショニング」と、GPUインスタンスから見えるメモリ構成を制御するNPS（NUMA Per Socket）を分割単位とする「メモリーパーティショニング」が用意されている。

　コンピュートパーティショニングの分割モードは、SPX、DPX、QPX、CPXが存在し、1枚のInstinct GPUをそれぞれ1、2、4、8個のGPUインスタンスとして切り出すことができる。

　メモリーパーティショニング（NPS）は、HBMのメモリー領域を変更し、GPUインスタンスがアクセスするメモリーを制御する機能。NPS1、NPS2、NPS4、NPS8が定義されており、各GPUインスタンスが使うメモリー領域を最適に配置し、メモリーアクセスは高速になる。

　2種類のパーティショニングは「メモリー側の分割数はコンピュート側の分割数を超えない」という制約のもとで、あらかじめ定義された互換性に基づいて設定される。

　先端技術研究所が開発中のオーケストレーターは、AIアプリケーションのデプロイ要求を受け取り、推論サービスの起動まで自動化する役割を担っている。このオーケストレーターにInstinct GPUが備えるGPUパーティショニング機能を組み合わせることで、ノード内のGPUリソースをAIモデルの要件に応じて動的に分割、割り当てて、推論サービスを起動できる仕組みを実装した。",[],[]
“通いたくなる”教育メタバースとは？--富士ソフトの「FAMcampus」が支える教育現場（ZDNET Japan）,https://news.yahoo.co.jp/articles/e03e096b1dc496832d196bd5f33cf22f0513deb8,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20260217-35243632-zdnet-000-1-view.jpg?exp=10800,2026-02-17T07:00:00+09:00,2026-02-17T07:00:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,2203,"富士ソフト プロダクト事業本部 みらい教育事業部 戦略企画グループ 課長の中村隼人氏
富士ソフトは、2022年から教育メタバース「FAMcampus（ファムキャンパス）」を提供しており、既に40の教育機関、26の自治体で活用が進んでいる。「みんなを感じられるバーチャル教育空間」をコンセプトに、オンライン授業の場としてだけでなく、授業前後のコミュニケーションを補完する“学校に近い体験”を実現している。

　FAMcampusがどのように不登校支援や新たな学びの形を支えているのかについて、プロダクト事業本部 みらい教育事業部 戦略企画グループ 課長の中村隼人氏に聞いた。

　文部科学省「令和6年度児童生徒の問題行動・不登校等生徒指導上の諸課題に関する調査」によると、小・中学校における不登校児童生徒数は過去最多の35万3970人（2023年度は34万6482人）となり、12年連続で増加している。

　自治体は教育支援センターの運営強化を進めているものの、外出すること自体が負担となり、対面施設を利用できず、適切な支援や学習を受けられないケースが少なくない。

　そこで同社は、メタバースを用いたオンライン支援の仕組みを提供することで、児童生徒が社会との接点を持ち続けられる居場所を創出し、引きこもりから「外に出たい」という意欲が戻るまでのプロセスを後押ししている。

　FAMcampusは、2020年のコロナ禍を機に開発され、当初は学習塾を対象に提供が開始された。当時オンライン授業はウェブ会議ツールの活用が中心で、授業が終了した瞬間にコミュニケーションが断絶してしまうという課題があった。FAMcampusは、この授業前後のコミュニケーションを補完する目的があったという。

　同サービスは、教育専用に設計された仮想空間が特徴で、GIGA端末でも円滑に動作し、1フロア150人まで接続ができる。2Dメタバースを採用することで、操作性を高めるとともに、教員は児童生徒の様子を俯瞰（ふかん）しやすく、生徒同士も「誰が空間にいるのか」を一目で把握できるため、モチベーションの向上につながる。

　加えて、教育現場の声を反映した独自の機能が搭載されている。ログイン時にその時の気分を入力する「いまの気持ち機能」では、支援員が児童の状態を可視化し、適切な声がけを行うための判断材料となっている。

　また、チャット機能とは異なる「つぶやき機能」は、独り言からゆるいつながりを生みだし、教員や仲間との間接的なコミュニケーションを促進している。ほかにも、顔・声出しが苦手な児童生徒に向けた「ビデオマスク／ボイスチェンジ機能」など、多くの実用的な機能が展開されている。

　フロアには、教室のほか休憩スペースや自習室、会議室、職員室などが用意されている。そのため、「授業前にログインして雑談や自習をし、時間になったら教室へ移動する」といった学校に近い体験が可能だ。

　FAMcampusがほかのメタバースサービスと一線を画すのは、単なる空間の提供にとどまらない「通い続けたくなる要素」があることだという。中村氏は、メタバース空間の提供だけでは「空間の過疎化」が課題となると指摘する。

　単に空間を用意するだけでは利用の定着が進まず、誰もいない状態になり、児童生徒が使わなくなるという悪循環が発生してしまう。そこで同サービスでは、授業を行うためのカリキュラムや講師、イベントの開催、悩み相談に応じる支援専門員を含めたパッケージも提供している。

　提供するカリキュラムは、児童生徒のレベルに応じて幾つかの支援メニューを提供しており、主要5科目を中心とした講義形式のメニューや、学校の教材などを活用した個別学習、また「脳トレ」など児童生徒の関心を高めるような実用的な授業も用意している。

　その成果は着実に現れており、教育支援センターを利用していない児童生徒への支援を実現したほか、保護者からは「生活習慣が改善された」「明るくなり、いろいろな話ができるようになった」といった声が寄せられている。中には、メタバース内での交流を通じて友人に会いに行ったり、学校へ復帰したりする事例も出ているという。

　同社は2022年から文科省の実証事業に参画し、不登校支援におけるメタバース空間の有効性を検証してきた。2025年には、「令和7年度　次世代の学校・教育現場を見据えた先端技術・教育データの利活用推進（最先端技術及び教育データ利活用に関する実証事業）」に採択され、FAMcampusと教育データを活用し、包括的な不登校支援を実施するとともに、非言語コミュニケーションによる心理状態改善の検証を行っている。

　今後は、バーチャルとリアルを連動させ、メタバースでの児童生徒の活動データを教員と共有することで、個々の特性に合わせたシームレスな学習支援の実現を目指すとしている。また、不登校支援だけでなく、離島や遠隔地の教育格差を是正するためのプラットフォームとしての活用も検討している。実際に鹿児島県では、離島間をつなぎ、別々の教室でも同様の授業を受けられるような支援も行われているという。

　富士ソフトは、学びの多様性が広がる中で、児童生徒の“学ぶ場所”と“安心していられる場所”の創出に、引き続き注力する構えだ。",[],[]
AIで変わったテクノロジー投資の現在地--Andreessen Horowitzのパートナーに聞く（ZDNET Japan）,https://news.yahoo.co.jp/articles/b66269d1c359861804bc80b4d492863b8d5b849f,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20260217-35243826-zdnet-000-1-view.jpg?exp=10800,2026-02-17T06:30:00+09:00,2026-02-17T06:30:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,3140,"AIで変わったテクノロジー投資の現在地--Andreessen Horowitzのパートナーに聞くの画像
加熱する一方の現在のAI市場を投資家はどう見ているのか。米ベンチャーキャピタル大手のAndreessen Horowitz（a16z）でインフラ領域のゼネラルパートナーを務めるMartin Casado氏は、「私が注目しているのは、人々の課題を解決する可能性を持ったツールだ」と話す。同氏にAI分野への投資や日本に対する見解などを聞いた。

　Casado氏は、2016年にa16zへ参画し、a16zが出資するAIスタートアップなど20社近くの取締役を務める。a16z以前は、VMwareでネットワークおよびセキュリティの上級副社長 兼 ゼネラルマネージャーを務めるなど、ITインフラ分野のビジネスと技術で豊富な知見や経験を有している。

　2022年にOpenAIが「ChatGPT」を一般公開してから続く現在のAIブームは、勢いを増すばかり。OpenAIやAnthropicなど現在のAI市場をリードする新興企業の急成長ぶりには目を見張るものがある。AI企業への出資と、資金を得たAI企業の研究開発やインフラなどへの投資の規模はあまり巨大だ。それ故に、「AIバブルはいつ弾けるのか」と懸念する声も根強くある。

　Casado氏は、「まだ誰もAIが持つ真の能力を把握できないでいるため、AI（のブーム）に後ろ向きになり始めたというよりは、混乱しているというのが実情ではないか」と述べる。

　現在のAIブームの以前は、特にソフトウェア企業への投資が活況を見せた。ソフトウェア企業が開発するSaaSなどが企業や組織の生産性を大きく引き上げ、その対価として得る収益がソフトウェア企業の成長をけん引した。しかし、生成AIが情報の検索や要約、コンテンツの創造を担い始めたことで、従来のソフトウェア企業の存在意義が問われるようになり、成長性に対する不安が一瞬でも高まるだけで、時価総額が著しく低下する事態も起きている。

　「確かに、資金が伝統的なソフトウェアの市場から流出し始めていると感じるが、実際にAIの活用によって（ユーザーの企業や組織の）生産性が高まるという新たな価値が生まれている」

　「利益を生み出し、早期に黒字を達成しているAI企業は確かに存在する。歴史的に見ると、これまでAI企業が株式公開で市場からこんなにも高い評価を得ることはまれだった。だが、現在の状況は昔とは異なる。上場を目指すAI企業は非常に多く、どの程度が実際にそこに至ることができるかは未知数でもある」

　投資市場には、いまだAIを“万能な魔法の杖”とみなし、“究極のAI”と称される汎用型AI（AGI）の実現が近づいているとの声すら聞かれる。2025年には「AIエージェント元年」とのマーケティングメッセージが飛び交い、2026年は、ビジネスパーソンなどの生産性を向上する生成AIから、人に代わり業務を自律的にこなすAIエージェントに主役が変わるとの主張は多い。

　だが、Casado氏は「AIはツールだ」と言い切る。

　「正直に言えば、私はいまだAIエージェントという言葉の定義を完全には理解していない。AIによりソフトウェア開発やカスタマーサービスなど多くの分野に生産性向上の価値をもたらしているのは確かだが、現在の用途はあくまで人間を助けるツールであり、プロセスの中に人間が介在する『Human-in-the-Loop』の形になっている」

　「現在のAIは、むしろ『インテリジェントRPA（Robotic Process Automation）』と捉えるべきだろう。成功している多くの企業は、依然としてテキストベースの処理や言語による人間の支援に特化している」

　「ましてや、AIがいわゆるAGIになるのかどうかも分からない。AGIはよく企業経営のビジョンとして語られるが、実際にモデルを使っていれば、それが“生きている”わけではないと痛感するはずだ。われわれは、定義すら曖昧なAGIの実現を前提に投資することはない。AIとは、コーディングや言語、推論などによって人々が抱えている課題や問題を解決するためツールだ。そして、それはコンピューティングパワーの延長線上にあるのだ」
またCasado氏は、AI投資が従来のソフトウェア投資とは本質的に異なると指摘する。ソフトウェア投資では、仮に10人の組織に10億ドルを投じてもビジネスがAIほどにはスケールしなかったが、AI投資では10億ドルのうち8億ドルをGPUや学習データの購入に当てることで巨大な価値を創出するという。

　「AIのイノベーションとは、テクノロジーであり、同時に資本の投じ方のイノベーションでもある。米国には、このような投資を意思決定できるエコシステムが存在する。しかし、米国以外ではまだ乏しいだろう」

　日本では、2024～2025年に米国のテクノロジー大手各社がデータセンターを中心に日本でAIインフラに巨額の投資を行う計画を相次いで発表した。これで日本も“AI大国”への道筋が開いたかのようにも映ったが、あくまで主導権は米国のテクノロジー大手の側にある。

　Casado氏は、今から最先端のAIモデルを構築しようとすれば10億ドル規模の資金が必要だとし、最近の経済安全保障の観点から注目される「ソブリン（主権）AI」に対しては、「米国や中国のオープンソースモデルを使って特定領域でポストトレーニングをすればある程度可能だろうが、ゼロから作るのは極めて高コストだ」と話す。ただ、同氏は日本企業が伝統的にITシステムの構築に非常に強い印象を持っているとも述べ、「日本で（AIシステムの構築に）取り組む企業が非常に少ないのは驚きだ」と語っている。

　むしろ日本に期待されるのは、AIのインフラシステムよりも基盤モデルの分野だとCasado氏。

　「基盤モデルは資本要件が極めて高く、現状では米国と中国が主導権を握っているが、多くの日本企業が独自の基盤モデルを持つことが重要だ。日本には優れた知的財産（IP）があり、コンテンツとAIの相性は抜群に良い。日本は規制にも適切に対応し、ロボティクス分野でも強みを持っている。日本は米国へのサプライチェーンにおいて重要な地位を占めている。基盤モデルはソフトウェアというよりシステムやチップに近い複雑なプロジェクトであり、日本にとって大きなチャンスであるはずだ。私たちは、日本の起業家や先進的な企業とのパートナーシップを求めている」

　a16zは2月10日、動画生成「Shizuku AI」などを手掛けるしずくAiへの出資を発表した。a16zが日本企業を対象とするのは初になるという。

　AI企業への投資は、ある種の賭け事のようでもある。Casado氏は、「リスクは極めて高いが、AI投資での最大の失敗は『真の勝者』に投資できないこと。ベンチャーキャピタルの利益はポートフォリオにあるわずか数社によって生み出される。AI業界の変化は激しく、数カ月、時には数日で勢力図が塗り替わる」と述べる。

　「われわれの手法はとてもシンプルだ。50の有望な市場があったとして、その市場の将来性を予測するのではなく、それぞれの市場で最高のチームを見つけ出す。その市場にチームを率いる優れたリーダーが3人いると確信した瞬間に投資を決断するのだ。なぜなら、たとえその市場が未成熟でも、優れたリーダーは家族も巻き込み、自分の人生や時間を賭けている。だからこそ、チームが極めて重要だ」",[],[]
AIにおける4種類の深刻な脆弱性--既知の解決策は存在せず（ZDNET Japan）,https://news.yahoo.co.jp/articles/79760a5d2e2f92dbd7555d0c59dcd8ff77048fce,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20260217-35243835-zdnet-000-1-view.jpg?exp=10800,2026-02-17T06:00:00+09:00,2026-02-17T06:00:00+09:00,ZDNET Japan,zdnet,ZDNET Japan,3933,"AIにおける4種類の深刻な脆弱性--既知の解決策は存在せずの画像
AIシステムは現在、多方面から同時に攻撃を受けており、セキュリティ研究者によれば、その脆弱（ぜいじゃく）性の多くには既知の解決策が存在しないという。脅威アクターは自律型AIエージェントを乗っ取ってサイバー攻撃を仕掛け、わずか60ドルの費用と250件のドキュメントで学習データを汚染している。また、プロンプトインジェクション攻撃は大規模言語モデル（LLM）の56％に対して成功し、モデルのリポジトリーには数十万もの悪意あるファイルが潜んでいる。ディープフェイクを用いたビデオ会議による詐欺被害も、数千万ドル規模に達している。

　AIを利便性の高いものにする機能そのものが、皮肉にも悪用の隙を与えている。システムの進化速度が上がるにつれ、この現実の深刻さを増している。企業のセキュリティチームは現在、AIの導入を避けて競合に後れを取るか、攻撃者に悪用されている根本的な欠陥を抱えたままシステムを導入するかという、正解のない選択を迫られている。

　これまでの経緯と今後の展望を深く理解するため、主要な4つのAI脆弱性と、それらを標的とした攻撃手法、および専門家による評価を整理した。

自律型システムによる自律型攻撃の脅威

　2025年9月、Anthropicは中国の国家支援を受けるハッカー集団が同社のツール「Claude Code」を武器化したと発表した。これは、実質的な人間の介入なしに実行された初の大規模なサイバー攻撃事例として記録された。攻撃者は、悪意あるタスクを無害に見える複数のリクエストに断片化することで、防御的なセキュリティテストを実行しているとAIを欺き、ジェイルブレイク（脱獄）に成功した。Anthropicの技術報告書によれば、システムは自律的に偵察を行い、エクスプロイトコードを作成して、約30の標的からデータを抽出したという。

　ハーバード・ケネディ・スクールのBruce Schneier氏は、2025年8月のブログ投稿で、これらの攻撃に対して安全な自律型AIエージェントは存在しないと警告している。この事件は、AIエージェントの自律性が利便性と同時に危険性をもたらすという研究者の懸念を裏付ける形となった。それにもかかわらず、AIエージェントの導入は拡大の一途をたどっている。

　Deloitteの最新レポートによると、現在AIエージェントをある程度活用している企業は23％だが、2028年までにその割合は74％に達すると予測されている。また、現在は利用していないと回答した25％の企業も、将来的には5％まで減少する見通しだ。

　しかし、AIエージェントの導入はすでに企業のリスクとなっている。McKinseyの調査では、80％の組織が不適切なデータ露出や不正アクセスなどのトラブルを経験している。

　2024年には、Zenity Labsの研究者が「Microsoft Copilot」や「Google Gemini」「Salesforce Einstein」に影響を与えるゼロクリック攻撃の脆弱性を特定した。Absolute Securityの最高情報セキュリティ責任者（CISO）であるMatti Pearce氏は、AI活用のスピードがセキュリティ対策を上回っており、AIがAIを攻撃する「完璧な脅威の嵐」が企業ユーザーを襲うだろうと指摘している。

　こうしたリスクに対する規制やガイドラインの整備は遅れている。欧州連合（EU）の「EU AI Act」（EU AI法）は、高リスクのAIシステムに人間の監視を求めているが、自律型エージェントは想定外だ。米国では連邦レベルの規制は不透明で、州レベルの法律が先行しているものの、それらは事前の保護よりも事故後の対応に重点を置いている。米国国立標準技術研究所（NIST）は、2023年に発表した「AIリスクマネジメントフレームワーク」（AI RMF）に続き、現在はエージェント特化型のセキュリティフレームワーク構築に向けてフィードバックを募っている段階にある。
未解決の難題、プロンプトインジェクション

　プロンプトインジェクションが重大な脆弱性と認識されてから3年が経過したが、根本的な解決には至っていない。36種類のLLMを対象とした調査では、144パターンの攻撃のうち56％が成功しており、モデルの規模や性能が向上しても防御力は高まっていないことが示された。

　この脆弱性は、LLMがテキストを処理する仕組みに起因している。2022年にこの用語を提唱したセキュリティ研究者のSimon Willison氏は、AIには特定の単語を他より重要と判断するメカニズムがなく、単なるトークンの列として処理されるという構造的欠陥を指摘している。開発者がクエリーのパラメーター化によって解決したSQLインジェクションとは異なり、プロンプトインジェクションには同等の修正策が存在しない。AIアシスタントが隠された指示を含む文書を読み込むと、それを正当なユーザーコマンドと区別なく実行してしまう。

　OpenAIやAnthropic、Google DeepMindによる共同研究では、適応型攻撃によって公開されている防御策の90％以上が突破され、人間によるレッドチーミングでは全ての保護策が無効化された。セキュリティ研究者のJohann Rehberger氏は、信頼できないデータがクエリーに含まれる設計である限り、この問題は修正不可能であると断じている。Open Web Application Security Project（OWASP）も、LLMアプリケーションの脆弱性ランキングでプロンプトインジェクションを首位に挙げ、万全な防止策はないと警告している。

　2025年3月にGoogle DeepMindが発表したフレームワーク「CaMeL」は、特定の攻撃クラスに対する有効な緩和策として期待されているが、根本的な解決策ではない。

　Willison氏は、既存の「ガードレール」製品をうたうベンダーの解決策に対して、現時点では極めて懐疑的な見方を示している。

データポイズニング

　Google DeepMindの研究によれば、わずか60ドルの費用で主要なAI学習データを汚染することが可能であり、データポイズニングは最も安価で効果的な攻撃手法の一つとなっている。2025年10月のAnthropicと英国AI安全研究所による調査では、250件の汚染ドキュメントを混入させるだけで、パラメーター数にかかわらずLLMにバックドアを仕掛けられることが判明した。これは学習用トークンのわずか0.00016％にすぎない。

　実社会でも、2024年2月にJFrog Security Researchが「Hugging Face」上で約100個の悪意あるモデルを発見している。その中には、韓国のインフラに接続するリバースシェルを含むものも存在した。Berryville Institute of Machine Learningの共同創設者、Gary McGraw氏は、LLMは学習データそのものであり、データが汚染されていればモデルも汚染されると指摘する。

　データポイズニングが厄介なのは、推論時ではなくモデルそのものを腐敗させる点にある。脆弱性は稼働中のシステムに潜伏し、特定のトリガーを待つ。Anthropicの論文「Sleeper Agents」によれば、バックドアによる動作は教師あり微調整や強化学習を経ても持続し、大規模なモデルほど悪意ある動作を巧妙に隠蔽（いんぺい）することが分かっている。Microsoftがポイズニングの兆候を検知する手法を研究しているものの、完全な検出は依然として困難な状況にある。
人間を標的にするディープフェイク

　英エンジニアリング大手Arupの財務担当者は、最高財務責任者（CFO）や同僚が出席するビデオ会議に参加した後、合計2560万ドルを15回にわたって送金した。しかし、会議の出席者は全員AIが生成した偽物だった。攻撃者は、会議や企業資料から公開されている経営陣の動画を利用して、ディープフェイクモデルを学習させていた。

　経営幹部の露出の多さは、構造的な脆弱性となっている。講演やインタビューは声や映像を複製するための格好の学習素材となり、経営陣の権限を悪用すれば多額の送金承認も容易になる。Gartnerは、2028年までにソーシャルエンジニアリング攻撃の40％が、ディープフェイクを活用して経営幹部を標的にすると予測している。

　ディープフェイク作成の技術的障壁はすでに崩壊している。McAfee Labsによれば、わずか3秒の音声があれば85％の精度で複製が可能だ。また、「RTX 2070」程度のGPUがあれば、リアルタイムに顔を入れ替えるツールも利用できる。ダークウェブでは、動画なら50ドル、音声なら30ドルからディープフェイク作成サービスが提供されており、高精度なパッケージでも1分当たり2万ドル程度で取引されている。

　技術的な検知が追いつかない中、組織にはプロセスによる対抗策が求められている。事前に決めた合言葉の使用、登録済み番号への折り返し確認、多額の送金に対する複数人による承認権限の導入などが、現時点での有効な防御手段となっている。

この記事は海外Ziff Davis発の記事を4Xが日本向けに編集したものです。",[],[]
