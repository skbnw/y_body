headline,mainEntityOfPage,image,datePublished,dateModified,author,media_en,media_jp,str_count,body,images,external_links
加速するコーディングAIの小型化、140億パラメータでOpenAIに迫るDeepCoder（AMP［アンプ］）,https://news.yahoo.co.jp/articles/c2fc6e9df1b0dea3ca6b581529f0f7e3d8b9949a,https://newsatcl-pctr.c.yimg.jp/t/amd-img/20250601-00010000-ampreview-000-1-view.jpg?exp=10800,2025-06-01T06:00:10+09:00,2025-06-01T06:00:10+09:00,AMP［アンプ］,ampreview,AMP［アンプ］,3210,"Anthropicの牙城に挑むOpenAI、AIコーディングツール市場で攻防激化
加速するコーディングAIの小型化
生成AIのユースケースとして最も注目されている分野の1つがコーディングだ。

多くの企業では、Github CopilotやCursorなどのAIコーディングツールが導入され、開発プロジェクトで実際に活用されるシーンが増えている。

こうした中で、存在感を高めているのがOpenAIの最大のライバルとされるAnthropicだ。Claude 3.7 Sonnetを筆頭に、高いコーディング能力を持つモデルの開発に成功、テック企業や開発者から多くの支持を集めている。

たとえば、Claude 3.7 Sonnetは、ソフトウェアエンジニアリング能力を測るテストSWE-benchで70.3%という高スコアを記録し、OpenAIのo3-mini（49.3%）などの競合モデルを大きく引き離す。またコード生成だけでなく、実際のソフトウェア開発における問題解決能力の高さも評価されている。HTMLランディングページの生成では30秒以内に実用的なコードを生成することが可能とされ、さらにプロジェクト全体のコードベース理解やコード品質、エラーメッセージ分析などでも高い精度を維持できるとの評価を受けている。

こうした状況に危機感を抱いたOpenAIは、AIコーディングツール「Windsurf」の買収に向けた交渉を開始。買収額は30億ドル規模とされる。Windsurfの年間経常収益は1億ドルで、2025年2月時点の4,000万ドルから急成長を遂げている。

OpenAIは当初、もう1つの有力ツール「Cursor」の買収を検討していた。しかし、Cursorを展開するAnysphereは年間経常収益が3億ドルに達し、その成長性から独立路線を選択した。これを受けOpenAIは、代わりにWindsurfへと買収の矛先を向けた格好となる。

この攻防の背景には、AIと開発者の新たな協業モデル「Vibe Coding」の台頭があることにも触れるべきだろう。これは開発者が自然言語でAIに指示を出し、コードの生成を任せつつ、そのコードに調整や修正を加えるアプローチだ。セールスフォースでは、この手法により月間3万時間の開発時間削減を実現。新規開発の大半で「第一稿」と呼ばれる初期コードの作成をAIが担うようになっているという。

市場では、こうした開発手法の変化やモデル精度の改善を反映し、AIコーディングアシスタントの導入が加速している。スタックオーバーフローの調査では、開発者の76%がAIコーディングアシスタントを利用中か、利用を計画していることが判明。特に学術研究者（87%）、AIデベロッパー（76%）、フロントエンド開発者（75%）といった層での普及が進んでいる。
DeepCoder-14B、小型モデルで実現したOpenAIレベルの性能
もう1つ、AIコーディング分野で注目されているのが、小型コーディングモデルの開発動向だ。

多くの開発現場では、AnthropicのClaudeを利用するケースが多いが、簡単なタスクでは、低コストのモデルを利用したいというニーズも存在する。これに対応するのが、小型コーディングモデルとなる。

Together AIとAgenticaが共同で開発したオープンソースモデル「DeepCoder-14B」はその1つ。わずか140億のパラメータでOpenAIのo3-miniに匹敵する性能を実現したとして、開発者コミュニティで関心を集めている。たとえば、LiveCodeBench（LCB）では60.6%のPass@1精度を達成、o3-mini（60.9%）とほぼ同等の性能を実現した。また、Codeforcesでは1936の評価を獲得し、上位5%に入る成績を収めている。

開発チームは、強化学習（RL）によるトレーニングの課題に独自のアプローチで対応。特に、データセット品質に重点を置いたことが、モデル精度の大幅改善に寄与したという。

従来、コーディング分野は数学分野に比べ、信頼性の高い検証可能なデータが不足していた。これに対し、開発チームは計2万4,000件以上の高品質な問題を厳選。TACOから7,500件、PrimeIntellectのSYNTHETIC-1から1万6,000件、LiveCodeBenchから600件を選出した。さらに、データの品質を担保するため、厳格なフィルタリングの仕組みを実装。各問題で複数のユニットテストを設定するなど、慎重な検証プロセスを採用した。

32基のH100 GPUを使用し、わずか2週間半で学習を完了させた点も注目に値する。従来、長いコンテキストを必要とする強化学習は、時間のかかるプロセスだったが、開発チームは独自の最適化手法を導入。これにより、ベースラインと比較して最大2倍の高速化を実現した。

興味深いのは、コーディングタスクで訓練したにもかかわらず、数学的推論の能力も向上している点だ。米国で数学オリンピック予選を兼ねて開催されるAIME（2024年版）の問題を使ったベンチマークテストでは73.8%のスコアを達成し、ベースモデルから4.1%の改善を見せた。コーディングを通じて獲得した推論能力が、他の領域にも波及する可能性を示唆する結果となった。
オープンソース化の波、DeepCoderが切り開く新たな可能性
DeepCoder-14Bがオープンソースで公開されたことにより、小型コーディングモデルの開発がさらに加速する公算が高まる。

前述したように、コーディングAIの開発では、2つの大きな課題が存在した。1つは、AIの学習に必要な高品質なデータの不足だ。数学の問題と異なり、コーディングの問題は、その解答が正しいかどうかを確実に判定することが難しい。もう1つは、AIの学習に膨大な時間がかかる点だ。特に、長いプログラムを扱う場合、トレーニングに数週間から数カ月を要することもあった。

DeepCoderの開発チームは、これらの課題に独自の手法で対応。まず、データの品質管理では、3段階の厳格な基準を設定。1つ目は、すべてのプログラムを外部の公式ソリューションで自動的に検証すること。2つ目は、各問題に最低5つのテストケースを設定すること。3つ目は、データセット間で重複する問題を排除することだ。この手法により、2万4,000件の信頼性の高いデータセットを構築することに成功した。

学習時間の短縮では「One-Off Pipelining」という革新的な手法を導入した。従来のAI学習では、コードの生成（サンプリング）と学習（トレーニング）を順番に行っていたため、GPUの待機時間が発生していた。新手法では、これらの処理を並行して実行することが可能となった。さらに、コードのテスト実行も同時に行うことで、学習効率を最大2.5倍に高めることに成功している。

こうした技術革新の意義は大きい。従来、高性能なAIモデルの開発は、豊富な計算資源を持つ大手テック企業しか行えなかった。しかし、DeepCoderの手法を用いれば、小規模な組織でも高性能なAIモデルを開発することができる。実際、DeepCoderは32基のGPUを使用してわずか2週間半で学習を完了。140億というコンパクトなパラメータ数でありながら、OpenAIのo3-miniに匹敵する性能を実現したという事実は無視できない。

最新のMac MiniやMac Studioなどハードウェア側のAI処理能力の高まりも相まって、小型コーディングモデルの需要、そして開発速度はさらに高まっていくことになるだろう。
文：細谷元（Livit）",[],[]
